reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800720062-172.17.0.6-1597162954615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38863,DS-0bf0ec9d-2312-4ec4-a2de-475747efc3db,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-875f0231-3ab2-4d32-b45d-8d1328cf7268,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-2073345e-684f-4ff1-bc5c-862ba9f2743f,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-76bf148b-4dd2-4131-9142-c4c94af1945d,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-0206173e-9bf7-4727-9525-ff62c92594d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-20669816-5005-4714-b697-ab038e3d8aae,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-6775a5cb-77ca-4664-9c86-dcf8452e4494,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-0aab488d-d4eb-4b9d-a0e0-3479ac26a1fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800720062-172.17.0.6-1597162954615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38863,DS-0bf0ec9d-2312-4ec4-a2de-475747efc3db,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-875f0231-3ab2-4d32-b45d-8d1328cf7268,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-2073345e-684f-4ff1-bc5c-862ba9f2743f,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-76bf148b-4dd2-4131-9142-c4c94af1945d,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-0206173e-9bf7-4727-9525-ff62c92594d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-20669816-5005-4714-b697-ab038e3d8aae,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-6775a5cb-77ca-4664-9c86-dcf8452e4494,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-0aab488d-d4eb-4b9d-a0e0-3479ac26a1fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693702671-172.17.0.6-1597163132556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46294,DS-39e1c2d5-3a76-40d5-a8ae-78c4ed990cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-0c199604-5c8f-4f45-9621-293b8205fe93,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-1858debe-2eb2-4a33-b221-43f9912a1680,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-40979a4b-e9e9-4dd8-8144-9090b76bfedd,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-7e56ce0d-6fce-42fc-bb90-fe1d9e3d479f,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-f57b12ab-66cb-458c-98dc-25fcf6a72224,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-8cc6d33b-8b10-4acf-bfa0-efd7a756d04f,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-1407449c-fbcf-42c6-b459-59d3a4f15de5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693702671-172.17.0.6-1597163132556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46294,DS-39e1c2d5-3a76-40d5-a8ae-78c4ed990cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-0c199604-5c8f-4f45-9621-293b8205fe93,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-1858debe-2eb2-4a33-b221-43f9912a1680,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-40979a4b-e9e9-4dd8-8144-9090b76bfedd,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-7e56ce0d-6fce-42fc-bb90-fe1d9e3d479f,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-f57b12ab-66cb-458c-98dc-25fcf6a72224,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-8cc6d33b-8b10-4acf-bfa0-efd7a756d04f,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-1407449c-fbcf-42c6-b459-59d3a4f15de5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863874391-172.17.0.6-1597163205044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39374,DS-cc726e9c-1b36-4f98-bfc4-e96cc160c916,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-55d2ffdb-2edf-45b3-99e7-a3955e802ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-12fe204b-32de-4f27-ac6d-f17b9c881dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-dff0b76a-cc62-4d6c-beb0-6fc3fa0df958,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-f46c107f-1335-451d-b42e-f821718da9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-1ccee835-ddb5-4265-afb2-dbb22d1d0563,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-e4f5cc79-b6a8-4a91-8c23-ac6a64d82d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-713eb8c0-f33d-4a26-8b0d-9b5829a835c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863874391-172.17.0.6-1597163205044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39374,DS-cc726e9c-1b36-4f98-bfc4-e96cc160c916,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-55d2ffdb-2edf-45b3-99e7-a3955e802ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-12fe204b-32de-4f27-ac6d-f17b9c881dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-dff0b76a-cc62-4d6c-beb0-6fc3fa0df958,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-f46c107f-1335-451d-b42e-f821718da9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-1ccee835-ddb5-4265-afb2-dbb22d1d0563,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-e4f5cc79-b6a8-4a91-8c23-ac6a64d82d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-713eb8c0-f33d-4a26-8b0d-9b5829a835c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814390385-172.17.0.6-1597163312522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46348,DS-674026c9-6e52-4759-9aec-e5229063fcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-80ba51e9-5649-4953-b6bb-665b963410fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-b59325ca-565d-4392-a403-44139e123dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-121ec8c1-7e05-4710-9960-1eea592d1f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-0a4105da-0f2d-4b62-8213-c0d7b8e6a362,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-eb2cdd71-9757-4496-95b2-f72e8fc7ca3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-9714bbb1-6390-42f1-8271-50ec1e494440,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-2256f427-f587-4566-9aa8-22de12d7c7ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814390385-172.17.0.6-1597163312522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46348,DS-674026c9-6e52-4759-9aec-e5229063fcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-80ba51e9-5649-4953-b6bb-665b963410fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-b59325ca-565d-4392-a403-44139e123dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-121ec8c1-7e05-4710-9960-1eea592d1f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-0a4105da-0f2d-4b62-8213-c0d7b8e6a362,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-eb2cdd71-9757-4496-95b2-f72e8fc7ca3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-9714bbb1-6390-42f1-8271-50ec1e494440,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-2256f427-f587-4566-9aa8-22de12d7c7ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991397480-172.17.0.6-1597163949357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37970,DS-dc57de57-c081-471b-805e-bb5fdf217a63,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-c0dabf03-d31c-4e36-a1ba-12cc5afb32fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-2112cfc1-843e-44f0-8a98-6b612927853f,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-42541c41-95df-43e3-a256-24aa17b3f1de,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-41dd440d-ed7a-4be6-b66c-05ebfb87718e,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-83be1694-1675-4fc5-9913-685730c9120e,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-d838c4c9-c695-4191-a7a5-1ec660566971,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-22a8fcd9-b7b7-4ed0-9ef2-3e73f2162320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991397480-172.17.0.6-1597163949357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37970,DS-dc57de57-c081-471b-805e-bb5fdf217a63,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-c0dabf03-d31c-4e36-a1ba-12cc5afb32fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-2112cfc1-843e-44f0-8a98-6b612927853f,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-42541c41-95df-43e3-a256-24aa17b3f1de,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-41dd440d-ed7a-4be6-b66c-05ebfb87718e,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-83be1694-1675-4fc5-9913-685730c9120e,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-d838c4c9-c695-4191-a7a5-1ec660566971,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-22a8fcd9-b7b7-4ed0-9ef2-3e73f2162320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115379478-172.17.0.6-1597164136285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37991,DS-3699fdc9-1542-4626-8127-77f5936d9253,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-c23161a9-3ad1-4c53-8e98-6648e9be3bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-50ce6bb8-0d6a-4fac-9d9f-86af5bfb62ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-1fe4ac49-a658-4447-8082-ef4aff94e1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-ccde5865-447e-438e-8a36-48a636866dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-420d9ed6-1b1b-4e00-8544-c6a46465fb29,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-05041590-c7a4-4c67-afdc-5b938d8230f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-79baf4db-38ff-4675-ad84-6783fde051e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115379478-172.17.0.6-1597164136285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37991,DS-3699fdc9-1542-4626-8127-77f5936d9253,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-c23161a9-3ad1-4c53-8e98-6648e9be3bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-50ce6bb8-0d6a-4fac-9d9f-86af5bfb62ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-1fe4ac49-a658-4447-8082-ef4aff94e1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-ccde5865-447e-438e-8a36-48a636866dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-420d9ed6-1b1b-4e00-8544-c6a46465fb29,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-05041590-c7a4-4c67-afdc-5b938d8230f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-79baf4db-38ff-4675-ad84-6783fde051e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813061075-172.17.0.6-1597164171879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44114,DS-0c5ba5e8-273d-4ae4-a077-7543447d8585,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-8015c0e9-6dce-4371-b5e9-0724d9bd888d,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-f710f40f-1676-49af-b5e7-e6d15a112353,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-f3261bb7-3b48-4680-a5ba-00354c4c9701,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-2b26c744-071c-47b9-9bbd-3dac18230e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-9fd46d6d-27e5-42c2-baed-144f3bfbc6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-799b022a-fd23-46a1-b534-049a3807c248,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-ab532112-18cf-4816-88b4-df14969a2cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813061075-172.17.0.6-1597164171879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44114,DS-0c5ba5e8-273d-4ae4-a077-7543447d8585,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-8015c0e9-6dce-4371-b5e9-0724d9bd888d,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-f710f40f-1676-49af-b5e7-e6d15a112353,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-f3261bb7-3b48-4680-a5ba-00354c4c9701,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-2b26c744-071c-47b9-9bbd-3dac18230e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-9fd46d6d-27e5-42c2-baed-144f3bfbc6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-799b022a-fd23-46a1-b534-049a3807c248,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-ab532112-18cf-4816-88b4-df14969a2cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957805187-172.17.0.6-1597164794858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-5a894777-dbee-4e6c-a36d-0f651e35ed10,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-0b86caef-4d8e-4efe-bfa4-8c63f84302dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-001939fe-3a8f-4ae6-868d-336cfbcf6eac,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-e5466da8-91e9-4cae-a8b4-06ee411b5c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-3f343a63-9059-45c9-9e57-ffb79a8dba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-9fcd88b1-0676-4e75-8154-e15307322e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-c4fe746a-573c-49f1-841a-133bcf512cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-0031eaba-8b93-4be7-9b52-61a45eab1dd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957805187-172.17.0.6-1597164794858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-5a894777-dbee-4e6c-a36d-0f651e35ed10,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-0b86caef-4d8e-4efe-bfa4-8c63f84302dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-001939fe-3a8f-4ae6-868d-336cfbcf6eac,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-e5466da8-91e9-4cae-a8b4-06ee411b5c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-3f343a63-9059-45c9-9e57-ffb79a8dba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-9fcd88b1-0676-4e75-8154-e15307322e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-c4fe746a-573c-49f1-841a-133bcf512cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-0031eaba-8b93-4be7-9b52-61a45eab1dd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534308257-172.17.0.6-1597165112154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44430,DS-4cc1abc2-c3c1-4b4c-87b0-b1b8efb51468,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-d7f15b62-6571-49f6-9ec2-c1210a5c55aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-a55c9448-d083-4deb-a4ef-0cf17aaeb19e,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-f09a124d-4f1e-4167-8512-c4fe8efaeefb,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-cca941fe-0c3f-47e3-b940-ef25dcfbeb21,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-9f5d9ffe-52e6-4a03-b727-0bd9d0d455ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-714b8281-c617-4be5-8c44-cd778a05f6da,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-3d267b0f-c6b0-4341-a237-b422051d2ea9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534308257-172.17.0.6-1597165112154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44430,DS-4cc1abc2-c3c1-4b4c-87b0-b1b8efb51468,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-d7f15b62-6571-49f6-9ec2-c1210a5c55aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-a55c9448-d083-4deb-a4ef-0cf17aaeb19e,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-f09a124d-4f1e-4167-8512-c4fe8efaeefb,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-cca941fe-0c3f-47e3-b940-ef25dcfbeb21,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-9f5d9ffe-52e6-4a03-b727-0bd9d0d455ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-714b8281-c617-4be5-8c44-cd778a05f6da,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-3d267b0f-c6b0-4341-a237-b422051d2ea9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643995899-172.17.0.6-1597165147540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40914,DS-a42fdda7-421e-4f4f-b920-110288aa3e36,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-133b0da4-757d-4a0a-a494-31e2f08dc9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-6e7eae18-b819-47ad-898f-49a5c03c70c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-a4b856bb-0462-4909-ae4e-047014ea3be3,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-4e6c5ebb-a710-424a-9b70-0cbfb4f68c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-e74a355c-a0e9-4f9b-9d39-b8c1b18f4934,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-a03e0f82-0bb4-487f-8db3-61c2de4b3c19,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-3f66eff9-d5e0-4ba7-931d-acf4aeb7043b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643995899-172.17.0.6-1597165147540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40914,DS-a42fdda7-421e-4f4f-b920-110288aa3e36,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-133b0da4-757d-4a0a-a494-31e2f08dc9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-6e7eae18-b819-47ad-898f-49a5c03c70c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-a4b856bb-0462-4909-ae4e-047014ea3be3,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-4e6c5ebb-a710-424a-9b70-0cbfb4f68c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-e74a355c-a0e9-4f9b-9d39-b8c1b18f4934,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-a03e0f82-0bb4-487f-8db3-61c2de4b3c19,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-3f66eff9-d5e0-4ba7-931d-acf4aeb7043b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629289010-172.17.0.6-1597165248304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44700,DS-cf1e4e00-27ad-4d20-842a-437c517a2da6,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-c9094030-925e-44b7-bf1f-fd22bfef3602,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-667aeb5b-2bff-413e-ad70-eac3c0328477,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-d46b5e43-f446-40de-a9ea-44043f866102,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-599bcd75-71c3-4987-912d-c944ec28f05e,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-804710e8-ed4d-41d8-8103-4cf1f0494603,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-220be724-b01e-4583-8877-0dbf2af7db82,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-28c598f2-89ca-4c9e-bfe2-c461708b5e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629289010-172.17.0.6-1597165248304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44700,DS-cf1e4e00-27ad-4d20-842a-437c517a2da6,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-c9094030-925e-44b7-bf1f-fd22bfef3602,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-667aeb5b-2bff-413e-ad70-eac3c0328477,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-d46b5e43-f446-40de-a9ea-44043f866102,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-599bcd75-71c3-4987-912d-c944ec28f05e,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-804710e8-ed4d-41d8-8103-4cf1f0494603,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-220be724-b01e-4583-8877-0dbf2af7db82,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-28c598f2-89ca-4c9e-bfe2-c461708b5e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906380127-172.17.0.6-1597165321706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44246,DS-d8e06627-1c97-4e18-839a-847b91e2b011,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-2f4127e9-0400-4c0e-94e7-9252e1c866ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-4b7e9e5c-175e-4758-87a0-69cd344ab9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-e1b8f048-a0a4-4bc5-ae5f-7bf1c1f5c9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-bf973f8b-f99b-4128-90a5-4e1da2180b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-3b8fe7ce-4f9a-4c07-92b4-52bf0868f397,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-26c8be99-ed0b-4b07-88a9-b695d8a41980,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-b7faef62-7a39-490d-a8ec-e3eb35536f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906380127-172.17.0.6-1597165321706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44246,DS-d8e06627-1c97-4e18-839a-847b91e2b011,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-2f4127e9-0400-4c0e-94e7-9252e1c866ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-4b7e9e5c-175e-4758-87a0-69cd344ab9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-e1b8f048-a0a4-4bc5-ae5f-7bf1c1f5c9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-bf973f8b-f99b-4128-90a5-4e1da2180b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-3b8fe7ce-4f9a-4c07-92b4-52bf0868f397,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-26c8be99-ed0b-4b07-88a9-b695d8a41980,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-b7faef62-7a39-490d-a8ec-e3eb35536f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849775762-172.17.0.6-1597165389928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40336,DS-088e9977-ee46-4f46-a825-e9cd8329fdea,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-7c276654-48de-4b6e-a26f-23147dd2f8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-b98b3e70-6a98-4c16-b726-30351bf766eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-330335aa-1467-42e2-8595-19cb8223853d,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-f2cbbcb8-40a8-4274-b257-033a89fa129c,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-d2d86f8e-87e9-4f68-9a6a-82c8247c4058,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-2ca064f4-ed97-4bd0-959b-3a8a35181b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-a5edc05e-f330-465b-aa50-fbc2f81c8b48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849775762-172.17.0.6-1597165389928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40336,DS-088e9977-ee46-4f46-a825-e9cd8329fdea,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-7c276654-48de-4b6e-a26f-23147dd2f8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-b98b3e70-6a98-4c16-b726-30351bf766eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-330335aa-1467-42e2-8595-19cb8223853d,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-f2cbbcb8-40a8-4274-b257-033a89fa129c,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-d2d86f8e-87e9-4f68-9a6a-82c8247c4058,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-2ca064f4-ed97-4bd0-959b-3a8a35181b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-a5edc05e-f330-465b-aa50-fbc2f81c8b48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705032311-172.17.0.6-1597165771646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41404,DS-86d10b49-ad34-44bc-82da-5ab480cec996,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-fff9332b-4b85-4901-8ea8-e817cf883ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-a3b07580-fedd-456c-9dbc-f9eaf19b21f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-db193162-1a3b-4678-ac23-52b73c7cde4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-7daf50e3-7cd2-48c8-8da4-d652212849d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-7085e279-56db-4d61-b6e9-870fd1c30fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-46f6fce7-c1e1-4511-999d-93cf27b3ee05,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-45c03859-b8ac-4a20-81d1-7ccff374dd95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705032311-172.17.0.6-1597165771646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41404,DS-86d10b49-ad34-44bc-82da-5ab480cec996,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-fff9332b-4b85-4901-8ea8-e817cf883ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-a3b07580-fedd-456c-9dbc-f9eaf19b21f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-db193162-1a3b-4678-ac23-52b73c7cde4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-7daf50e3-7cd2-48c8-8da4-d652212849d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-7085e279-56db-4d61-b6e9-870fd1c30fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-46f6fce7-c1e1-4511-999d-93cf27b3ee05,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-45c03859-b8ac-4a20-81d1-7ccff374dd95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940201639-172.17.0.6-1597166197670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38076,DS-b1143a2e-5115-44d4-9459-b17017b128ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-b4223806-1ea1-41a8-ba25-1ba1cddf2562,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-adb1284c-45dd-4869-b975-20bf7c657bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-e4dc00e9-15e3-422f-8c90-e42bc9bfbba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-f68d144e-1534-4063-ba24-a90457396266,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-7e9d0125-dfd9-45e6-80f2-4756678401b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-329ed65e-1ea1-4f84-90a4-97d005b30b50,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-3d208888-fd36-4eaa-9455-ff4707e7e17a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940201639-172.17.0.6-1597166197670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38076,DS-b1143a2e-5115-44d4-9459-b17017b128ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-b4223806-1ea1-41a8-ba25-1ba1cddf2562,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-adb1284c-45dd-4869-b975-20bf7c657bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-e4dc00e9-15e3-422f-8c90-e42bc9bfbba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-f68d144e-1534-4063-ba24-a90457396266,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-7e9d0125-dfd9-45e6-80f2-4756678401b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-329ed65e-1ea1-4f84-90a4-97d005b30b50,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-3d208888-fd36-4eaa-9455-ff4707e7e17a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658833058-172.17.0.6-1597167513460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42568,DS-6d32b575-2930-45e1-8c82-0a12cd945652,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-eaa54b45-092e-4ddf-9c09-a4e3a351dbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-0eba2e15-7603-418c-9d29-2e97742acfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-12a80755-07d0-48e2-992d-66c69122ac05,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-24ea64d4-073b-445b-a366-0f32b4b3f3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-cf0ee30e-0ccb-434a-9a68-c4aa12b9c731,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-66852b93-cf6f-4e09-a13d-ba98dbf8ba62,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-f76c5307-c181-4624-90ab-4bb270a68583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658833058-172.17.0.6-1597167513460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42568,DS-6d32b575-2930-45e1-8c82-0a12cd945652,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-eaa54b45-092e-4ddf-9c09-a4e3a351dbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-0eba2e15-7603-418c-9d29-2e97742acfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-12a80755-07d0-48e2-992d-66c69122ac05,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-24ea64d4-073b-445b-a366-0f32b4b3f3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-cf0ee30e-0ccb-434a-9a68-c4aa12b9c731,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-66852b93-cf6f-4e09-a13d-ba98dbf8ba62,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-f76c5307-c181-4624-90ab-4bb270a68583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502124669-172.17.0.6-1597168033037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42676,DS-8e12edb2-48ff-471a-925b-c043886bf04d,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-2f1b41ea-17e9-4ea1-8bd6-731635a60130,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-580ae7c8-ec17-4b96-9c16-523ebf90b442,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-598c0b51-7523-4a3c-8413-265b40922c82,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-2bfc3518-785b-44b8-95c4-0101772ea3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-70c992e3-455c-4c0f-98d4-73b54a82bdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-d04210fc-0023-41a4-99dd-f5f2c281080d,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-614f51f8-c180-4940-ada3-9555c5e56d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502124669-172.17.0.6-1597168033037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42676,DS-8e12edb2-48ff-471a-925b-c043886bf04d,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-2f1b41ea-17e9-4ea1-8bd6-731635a60130,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-580ae7c8-ec17-4b96-9c16-523ebf90b442,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-598c0b51-7523-4a3c-8413-265b40922c82,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-2bfc3518-785b-44b8-95c4-0101772ea3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-70c992e3-455c-4c0f-98d4-73b54a82bdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-d04210fc-0023-41a4-99dd-f5f2c281080d,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-614f51f8-c180-4940-ada3-9555c5e56d2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5220
