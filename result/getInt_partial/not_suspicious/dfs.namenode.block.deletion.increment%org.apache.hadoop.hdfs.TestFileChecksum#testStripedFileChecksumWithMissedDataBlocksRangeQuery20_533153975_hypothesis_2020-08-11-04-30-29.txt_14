reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-522248823-172.17.0.15-1597120707380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42527,DS-83bcf7e0-1b08-4bb9-a14a-29414094a931,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-af7740cc-03b5-4e45-b47b-12fce6ac8230,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-7fd8978d-4e7f-402d-9431-2d84ed3aa4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-380c97c5-eecf-4b22-a9a8-5664c4e2cace,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-cea27bd4-d1d4-4d90-ad9c-7e8ce7c25a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-f68881bd-28af-4630-b9f7-48a3350f38b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-5f8633df-2083-46e7-a8ff-7a97837bcf51,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-abac7504-d23f-43ef-b58f-af290c9fb5e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-522248823-172.17.0.15-1597120707380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42527,DS-83bcf7e0-1b08-4bb9-a14a-29414094a931,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-af7740cc-03b5-4e45-b47b-12fce6ac8230,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-7fd8978d-4e7f-402d-9431-2d84ed3aa4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-380c97c5-eecf-4b22-a9a8-5664c4e2cace,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-cea27bd4-d1d4-4d90-ad9c-7e8ce7c25a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-f68881bd-28af-4630-b9f7-48a3350f38b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-5f8633df-2083-46e7-a8ff-7a97837bcf51,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-abac7504-d23f-43ef-b58f-af290c9fb5e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-283750231-172.17.0.15-1597120932049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39366,DS-a2850dd8-fcf8-42a4-aa5f-57a97abbf6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-d85cf7e1-7aa9-4f4b-ae4b-531bd0660c05,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-51f42147-11dc-4660-b49e-4441e11cd726,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-0b258166-d9aa-4730-a314-89e26e4bf1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-0ef740a9-e9a2-47cf-b275-95d4cfd4fe66,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-f7af0ed8-de96-4f33-acef-e270ebe463a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-304d182c-92c9-4b09-b876-520b1abec530,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-b2e981ef-43f6-4ced-8d55-69543a6f35fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-283750231-172.17.0.15-1597120932049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39366,DS-a2850dd8-fcf8-42a4-aa5f-57a97abbf6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-d85cf7e1-7aa9-4f4b-ae4b-531bd0660c05,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-51f42147-11dc-4660-b49e-4441e11cd726,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-0b258166-d9aa-4730-a314-89e26e4bf1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-0ef740a9-e9a2-47cf-b275-95d4cfd4fe66,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-f7af0ed8-de96-4f33-acef-e270ebe463a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-304d182c-92c9-4b09-b876-520b1abec530,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-b2e981ef-43f6-4ced-8d55-69543a6f35fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118451522-172.17.0.15-1597121171413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44999,DS-aa7d430f-214b-427f-9bb5-47856cb6fcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-58feceae-e819-4248-ae14-4c152b58c389,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-6b199cfb-8d20-46af-ad57-d815894b561e,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-0d64cd79-94d9-44d8-98a3-bf2980e24c75,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-db3cc09a-b788-4f74-993b-b9d14d5bde8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-93e0cbe4-cd76-4ec2-8011-f0be47125817,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-f1e3234d-7e8f-4500-b8b9-ec3ed54bbf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-f2cca654-e173-476b-b3bd-ad385f274c9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118451522-172.17.0.15-1597121171413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44999,DS-aa7d430f-214b-427f-9bb5-47856cb6fcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-58feceae-e819-4248-ae14-4c152b58c389,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-6b199cfb-8d20-46af-ad57-d815894b561e,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-0d64cd79-94d9-44d8-98a3-bf2980e24c75,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-db3cc09a-b788-4f74-993b-b9d14d5bde8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-93e0cbe4-cd76-4ec2-8011-f0be47125817,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-f1e3234d-7e8f-4500-b8b9-ec3ed54bbf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-f2cca654-e173-476b-b3bd-ad385f274c9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1245582753-172.17.0.15-1597121300769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39140,DS-b2fdad56-fcfb-4aee-a577-e6a1c4cdfe66,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-6ab7fee6-f497-42c3-b281-79ca21948149,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-d7c50ccb-bf14-4b0c-82ff-d8fb3beae02d,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-f68e6beb-aaa0-4fa6-87f7-6f3d7d3c648d,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-c764fbd4-f474-47b5-b267-fefc4f973ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-0493aaa7-1c43-4acd-9bef-3b429ead649d,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-d5117b69-8ffe-44a9-a47a-8c1969ab19fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-26ea1832-0ce5-4351-b6d5-bdf9f8046a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1245582753-172.17.0.15-1597121300769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39140,DS-b2fdad56-fcfb-4aee-a577-e6a1c4cdfe66,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-6ab7fee6-f497-42c3-b281-79ca21948149,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-d7c50ccb-bf14-4b0c-82ff-d8fb3beae02d,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-f68e6beb-aaa0-4fa6-87f7-6f3d7d3c648d,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-c764fbd4-f474-47b5-b267-fefc4f973ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-0493aaa7-1c43-4acd-9bef-3b429ead649d,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-d5117b69-8ffe-44a9-a47a-8c1969ab19fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-26ea1832-0ce5-4351-b6d5-bdf9f8046a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057736955-172.17.0.15-1597121714766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44274,DS-551108ab-d084-4072-9806-685632e84ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-600ac681-0bc6-4344-9d47-b91601a77bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-288ed881-6653-4d7d-8ee3-d07a9b83e1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-e18ed027-aa6b-4d2c-bf2c-35ad53363665,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-a83ca79d-6ad2-4862-ac70-5e454efa3d79,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-98d162d6-a800-4e27-adb6-a9579509ebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-bbf00193-927d-4168-a58f-02f9842f4cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-c25e30fe-66c3-44df-9597-2370d42fed5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057736955-172.17.0.15-1597121714766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44274,DS-551108ab-d084-4072-9806-685632e84ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-600ac681-0bc6-4344-9d47-b91601a77bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-288ed881-6653-4d7d-8ee3-d07a9b83e1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-e18ed027-aa6b-4d2c-bf2c-35ad53363665,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-a83ca79d-6ad2-4862-ac70-5e454efa3d79,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-98d162d6-a800-4e27-adb6-a9579509ebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-bbf00193-927d-4168-a58f-02f9842f4cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-c25e30fe-66c3-44df-9597-2370d42fed5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110957076-172.17.0.15-1597121994103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36593,DS-9ea37c2d-ccf5-455e-9101-e5d979054ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-e5ada523-8c44-439b-ba12-d98725b8cc38,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-371cd05f-0d1c-42ad-9a00-3481b71e7b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-ce9c3cf5-e2c4-4a84-ad2e-c1378125b305,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-e2a8ec1b-a3c2-4be9-a075-791e1acf2e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-0a6cee2a-fc6e-49f2-a522-24606622ae02,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-3e3eb8c2-d97e-4705-b860-57c26a20feb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-3701136d-9287-43b3-9166-8a9643f3311b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110957076-172.17.0.15-1597121994103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36593,DS-9ea37c2d-ccf5-455e-9101-e5d979054ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-e5ada523-8c44-439b-ba12-d98725b8cc38,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-371cd05f-0d1c-42ad-9a00-3481b71e7b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-ce9c3cf5-e2c4-4a84-ad2e-c1378125b305,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-e2a8ec1b-a3c2-4be9-a075-791e1acf2e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-0a6cee2a-fc6e-49f2-a522-24606622ae02,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-3e3eb8c2-d97e-4705-b860-57c26a20feb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-3701136d-9287-43b3-9166-8a9643f3311b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-297792152-172.17.0.15-1597122028901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41263,DS-a86ab2c8-b0aa-47fe-8ab4-52d70001e5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-8341b48f-0859-418e-b5a5-9fde5c2909e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-5272a6d4-f993-4867-8dfb-0cc42d394950,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-a55e5e07-91e0-4e84-8c5d-921f0a7aefc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-0d91eb4e-9e77-45a7-8c20-27849845bd93,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-258b6ece-b120-4451-8169-e6eee8c1d7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-77c87b96-7890-41f0-a43a-82fbd4780c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-7f3cb2be-0f51-4d1e-84b3-2d80722518ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-297792152-172.17.0.15-1597122028901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41263,DS-a86ab2c8-b0aa-47fe-8ab4-52d70001e5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-8341b48f-0859-418e-b5a5-9fde5c2909e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-5272a6d4-f993-4867-8dfb-0cc42d394950,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-a55e5e07-91e0-4e84-8c5d-921f0a7aefc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-0d91eb4e-9e77-45a7-8c20-27849845bd93,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-258b6ece-b120-4451-8169-e6eee8c1d7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-77c87b96-7890-41f0-a43a-82fbd4780c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-7f3cb2be-0f51-4d1e-84b3-2d80722518ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441761873-172.17.0.15-1597122471384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43290,DS-382c4c5a-a747-4559-b97c-201c2ae70515,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-c76ce806-83fe-49c1-8392-b4d9c53dd6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-307623d0-2e17-480d-9a61-1279a8a97eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-32b94f66-7017-487d-b2c4-3a1b052b9e72,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-bbd34da2-a801-4975-a31b-8449ce889667,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-967860e2-4bd7-4aea-9c06-535425ce4aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-f4a25790-b00b-4bfa-9fde-abf2e42fa140,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-db26b898-8148-407f-8b67-51a82e531042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441761873-172.17.0.15-1597122471384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43290,DS-382c4c5a-a747-4559-b97c-201c2ae70515,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-c76ce806-83fe-49c1-8392-b4d9c53dd6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-307623d0-2e17-480d-9a61-1279a8a97eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-32b94f66-7017-487d-b2c4-3a1b052b9e72,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-bbd34da2-a801-4975-a31b-8449ce889667,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-967860e2-4bd7-4aea-9c06-535425ce4aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-f4a25790-b00b-4bfa-9fde-abf2e42fa140,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-db26b898-8148-407f-8b67-51a82e531042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1714851252-172.17.0.15-1597122918275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37355,DS-36dbb334-daa8-45e3-97b7-a1061ba5b38c,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-0af15d26-ed4e-4dd7-9b31-13f4a6d95127,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-4fb5065b-229a-47f5-954d-23cd89881696,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-5b553a4c-de33-4fbf-acd9-4ef20d775905,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-4b4ede0f-fac8-4330-98bf-8dea4743da71,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-19027c9b-4b79-4ffe-9069-0ccf5a7d72c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-5e55aa2a-103d-4c50-be62-0ee03c8c8ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-f1bed62d-bc87-488d-a076-28b252f15a4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1714851252-172.17.0.15-1597122918275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37355,DS-36dbb334-daa8-45e3-97b7-a1061ba5b38c,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-0af15d26-ed4e-4dd7-9b31-13f4a6d95127,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-4fb5065b-229a-47f5-954d-23cd89881696,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-5b553a4c-de33-4fbf-acd9-4ef20d775905,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-4b4ede0f-fac8-4330-98bf-8dea4743da71,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-19027c9b-4b79-4ffe-9069-0ccf5a7d72c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-5e55aa2a-103d-4c50-be62-0ee03c8c8ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-f1bed62d-bc87-488d-a076-28b252f15a4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303877063-172.17.0.15-1597122961746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43751,DS-51fb8721-16b9-42d5-8084-eee89dbb31e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-4f4bdf51-b6ee-4a7f-a0be-bebf7910840b,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-89e566db-b3d8-4418-942d-efca81fa0634,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-68375ec9-0885-4359-8623-aa4c23d8fa71,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-914759a6-99c3-4b89-b2d2-f81ec42f14fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-b4f455a8-29a3-4bba-9111-d6f19a862b01,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-9b0d902b-c81f-48dc-8b4c-dee899301550,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-2117a8f7-0e03-491c-a091-6a6bb3d0d8de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303877063-172.17.0.15-1597122961746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43751,DS-51fb8721-16b9-42d5-8084-eee89dbb31e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-4f4bdf51-b6ee-4a7f-a0be-bebf7910840b,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-89e566db-b3d8-4418-942d-efca81fa0634,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-68375ec9-0885-4359-8623-aa4c23d8fa71,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-914759a6-99c3-4b89-b2d2-f81ec42f14fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-b4f455a8-29a3-4bba-9111-d6f19a862b01,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-9b0d902b-c81f-48dc-8b4c-dee899301550,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-2117a8f7-0e03-491c-a091-6a6bb3d0d8de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123604856-172.17.0.15-1597123076003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38893,DS-96166a92-e172-44c8-85ca-d1bb8614dad1,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-47b372ca-92c2-4e1e-96d8-b51092040dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-74ac343f-1b0b-4c2b-8090-e0b26e3b1f83,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-6685c0bc-4144-4262-aca8-4a115cb960e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-97175830-2f63-435b-8d39-7cc48622e4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-967c92c5-1392-4623-a36f-564c01e1487a,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-1d058129-56d9-41e4-b2f6-47cbb320bce9,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-14c22067-e0ae-4dc3-adb9-1a68e358f2e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123604856-172.17.0.15-1597123076003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38893,DS-96166a92-e172-44c8-85ca-d1bb8614dad1,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-47b372ca-92c2-4e1e-96d8-b51092040dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-74ac343f-1b0b-4c2b-8090-e0b26e3b1f83,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-6685c0bc-4144-4262-aca8-4a115cb960e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-97175830-2f63-435b-8d39-7cc48622e4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-967c92c5-1392-4623-a36f-564c01e1487a,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-1d058129-56d9-41e4-b2f6-47cbb320bce9,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-14c22067-e0ae-4dc3-adb9-1a68e358f2e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970328842-172.17.0.15-1597123170885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37416,DS-ac3f2cf9-c738-4b3b-80e7-19eb6fbed420,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-6bc1e258-c2a0-4042-b327-9b8838d0ec59,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-556b4472-cc33-4a03-abdb-265678ae30f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-5fd3c154-d508-4bcc-b531-9091557db719,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-008f6674-5f24-4321-afad-194f5122c8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-ee81274f-bea1-43f8-bb4b-df6430d1c867,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-07e7c5c4-9b8c-4f29-a94a-ecf8b881603c,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-1260d674-8d08-4ba8-899e-273752a7368b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970328842-172.17.0.15-1597123170885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37416,DS-ac3f2cf9-c738-4b3b-80e7-19eb6fbed420,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-6bc1e258-c2a0-4042-b327-9b8838d0ec59,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-556b4472-cc33-4a03-abdb-265678ae30f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-5fd3c154-d508-4bcc-b531-9091557db719,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-008f6674-5f24-4321-afad-194f5122c8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-ee81274f-bea1-43f8-bb4b-df6430d1c867,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-07e7c5c4-9b8c-4f29-a94a-ecf8b881603c,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-1260d674-8d08-4ba8-899e-273752a7368b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628095237-172.17.0.15-1597124327722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43921,DS-670901ba-a63d-4c73-b7a5-c6138a25b9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-f9253186-f347-4af0-b949-5288bf22c4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-8ebed0de-6ebb-403e-a9c2-6be930e58f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-5b41589a-3350-4458-b21a-7bf9b25a85a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-5e37ba4c-3793-45db-bfd2-eb8332215cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-b1e6c491-0f5b-47ae-8765-357d433fbd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-db4c6f70-0950-470b-ace0-ff9ead83fa34,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-9bd1bff1-906e-4fc5-acf8-9b1ad26d2099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628095237-172.17.0.15-1597124327722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43921,DS-670901ba-a63d-4c73-b7a5-c6138a25b9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-f9253186-f347-4af0-b949-5288bf22c4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-8ebed0de-6ebb-403e-a9c2-6be930e58f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-5b41589a-3350-4458-b21a-7bf9b25a85a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-5e37ba4c-3793-45db-bfd2-eb8332215cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-b1e6c491-0f5b-47ae-8765-357d433fbd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-db4c6f70-0950-470b-ace0-ff9ead83fa34,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-9bd1bff1-906e-4fc5-acf8-9b1ad26d2099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275742821-172.17.0.15-1597124397368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42289,DS-59a6dfde-7edb-45a0-8449-cae0d344940e,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-b1ecf175-3639-47c8-9458-c0c7e2757cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-576571e6-2261-4aba-be5d-7697260e494a,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-53df0445-b07b-4a89-b1b5-252b78821c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-0fd6a7be-15d3-473a-8f73-975f7fb3d49c,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-848a5841-67f2-4e05-a6d0-871004f9a84d,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-7eb31483-38da-4734-9f55-61287022c012,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-ec73da8f-2942-4a94-9d9e-19bacb447193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275742821-172.17.0.15-1597124397368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42289,DS-59a6dfde-7edb-45a0-8449-cae0d344940e,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-b1ecf175-3639-47c8-9458-c0c7e2757cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-576571e6-2261-4aba-be5d-7697260e494a,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-53df0445-b07b-4a89-b1b5-252b78821c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-0fd6a7be-15d3-473a-8f73-975f7fb3d49c,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-848a5841-67f2-4e05-a6d0-871004f9a84d,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-7eb31483-38da-4734-9f55-61287022c012,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-ec73da8f-2942-4a94-9d9e-19bacb447193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block.deletion.increment
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1075391878-172.17.0.15-1597125178914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41119,DS-b52a7e51-a5ae-468b-a986-867472984fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-ad3a16b5-c86f-4f73-a139-edaa6fe90e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-d9711583-d333-4d3c-8e4d-a876ddab03a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-4be8f08d-c768-4903-8811-1ba20ea7741a,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-32b6a296-e1ea-4512-896a-70f742a940d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-47f1f36c-5e66-42ca-8254-14e977daf0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-ae46dcea-6704-4fa1-8e50-8474f0bfbc78,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-2dc41be5-56f6-4396-96a9-65dbebdb6044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1075391878-172.17.0.15-1597125178914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41119,DS-b52a7e51-a5ae-468b-a986-867472984fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-ad3a16b5-c86f-4f73-a139-edaa6fe90e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-d9711583-d333-4d3c-8e4d-a876ddab03a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-4be8f08d-c768-4903-8811-1ba20ea7741a,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-32b6a296-e1ea-4512-896a-70f742a940d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-47f1f36c-5e66-42ca-8254-14e977daf0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-ae46dcea-6704-4fa1-8e50-8474f0bfbc78,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-2dc41be5-56f6-4396-96a9-65dbebdb6044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5129
