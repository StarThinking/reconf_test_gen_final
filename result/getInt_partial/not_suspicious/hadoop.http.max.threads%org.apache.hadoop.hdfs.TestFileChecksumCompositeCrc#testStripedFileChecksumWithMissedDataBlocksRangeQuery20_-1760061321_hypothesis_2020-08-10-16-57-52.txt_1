reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1888225665-172.17.0.6-1597079005187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37193,DS-8eaa14f1-2edb-4317-9ad3-290dab9816e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-a9e32c48-5617-4d5b-96ae-8639124e80e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-4011d661-487f-4e1e-9829-6e94753005c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-23ad370d-3aca-46f9-ad8a-a1d47d1a8766,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-2fa31e67-3597-4ed6-9d11-2282f84e53d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-dff8e226-aa69-4dca-a4ab-a0c7f5da639e,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-7d57189f-87ef-4bda-b95b-34012d9e694a,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-6b63485c-b594-46d2-a367-10555289b174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1888225665-172.17.0.6-1597079005187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37193,DS-8eaa14f1-2edb-4317-9ad3-290dab9816e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-a9e32c48-5617-4d5b-96ae-8639124e80e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-4011d661-487f-4e1e-9829-6e94753005c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-23ad370d-3aca-46f9-ad8a-a1d47d1a8766,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-2fa31e67-3597-4ed6-9d11-2282f84e53d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-dff8e226-aa69-4dca-a4ab-a0c7f5da639e,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-7d57189f-87ef-4bda-b95b-34012d9e694a,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-6b63485c-b594-46d2-a367-10555289b174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1210747487-172.17.0.6-1597079140733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42126,DS-e1b64fb9-c74e-4ac2-878f-ccc40162ed90,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-988908df-4c09-4757-befa-b5fed6ee0170,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-95e6a448-1927-42ff-adef-cac9d896c5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-32762ac5-db6a-447b-8619-ae98c65baea2,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-a48cecd8-0b52-465c-ab9c-df6427178be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-30cce225-3f61-4a5f-bef9-e4aa89169a13,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-ae5fbd92-b93e-4c7d-9f94-8e85b0179371,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-21a73601-e16b-403d-be03-cbf7a1e8d4a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1210747487-172.17.0.6-1597079140733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42126,DS-e1b64fb9-c74e-4ac2-878f-ccc40162ed90,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-988908df-4c09-4757-befa-b5fed6ee0170,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-95e6a448-1927-42ff-adef-cac9d896c5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-32762ac5-db6a-447b-8619-ae98c65baea2,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-a48cecd8-0b52-465c-ab9c-df6427178be0,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-30cce225-3f61-4a5f-bef9-e4aa89169a13,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-ae5fbd92-b93e-4c7d-9f94-8e85b0179371,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-21a73601-e16b-403d-be03-cbf7a1e8d4a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-210233832-172.17.0.6-1597079451590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39967,DS-f1712724-0072-4176-b427-6885efe827e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-7ee442fd-4c6c-4291-907f-69d90a605a54,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-9316549a-50c5-459b-a35d-8724b523e338,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-5b52e180-e46a-4505-9ab0-805b372b1ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-ce526fa1-6be9-4768-bb4b-dcab4344db10,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-05675ba2-16ad-403c-8a9d-9f47a6cab082,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-77086414-6da9-4952-952c-f1a50242b9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-c50a35ea-2ed4-4fcc-be65-e9c0b8181c83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-210233832-172.17.0.6-1597079451590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39967,DS-f1712724-0072-4176-b427-6885efe827e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-7ee442fd-4c6c-4291-907f-69d90a605a54,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-9316549a-50c5-459b-a35d-8724b523e338,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-5b52e180-e46a-4505-9ab0-805b372b1ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-ce526fa1-6be9-4768-bb4b-dcab4344db10,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-05675ba2-16ad-403c-8a9d-9f47a6cab082,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-77086414-6da9-4952-952c-f1a50242b9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-c50a35ea-2ed4-4fcc-be65-e9c0b8181c83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735437448-172.17.0.6-1597079955925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36637,DS-61246a74-552d-4f03-9bf7-22160470d3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-92b326e9-fb76-41db-82c1-bcad05f5d587,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-247f4648-3856-42bd-b612-1a6c7d849c85,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-bdab847d-73b4-434d-a7a3-b0963131dee8,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-ff83e360-caac-4967-a5db-3494194898a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-4ac14d03-8791-443e-9f7b-3d1074582a26,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-c5dd0b9c-ae56-4b3e-b041-bdca1d5dfcee,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-a4c0c16a-11d3-4f96-b78b-67c4405003c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735437448-172.17.0.6-1597079955925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36637,DS-61246a74-552d-4f03-9bf7-22160470d3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-92b326e9-fb76-41db-82c1-bcad05f5d587,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-247f4648-3856-42bd-b612-1a6c7d849c85,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-bdab847d-73b4-434d-a7a3-b0963131dee8,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-ff83e360-caac-4967-a5db-3494194898a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-4ac14d03-8791-443e-9f7b-3d1074582a26,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-c5dd0b9c-ae56-4b3e-b041-bdca1d5dfcee,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-a4c0c16a-11d3-4f96-b78b-67c4405003c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2108325098-172.17.0.6-1597080133597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43864,DS-25ca339f-54c5-4b39-a727-d2e1573b1db0,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-66ed104a-2a9e-4b4b-9efe-147c1cdde53a,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-dda418bd-807f-49ab-ae56-31a5c6d5cb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-868189ed-048a-47dd-960e-8db63c6e8cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-a508c72a-1192-49b4-a9f7-e93fbad7d8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-30f21feb-792c-4e12-8c5d-a8cfd3afcb89,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-e555a9a6-788b-4805-905c-6b2be94afa19,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-69e5c18b-5b4c-4cf6-80fb-89c94e90e84b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2108325098-172.17.0.6-1597080133597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43864,DS-25ca339f-54c5-4b39-a727-d2e1573b1db0,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-66ed104a-2a9e-4b4b-9efe-147c1cdde53a,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-dda418bd-807f-49ab-ae56-31a5c6d5cb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-868189ed-048a-47dd-960e-8db63c6e8cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-a508c72a-1192-49b4-a9f7-e93fbad7d8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-30f21feb-792c-4e12-8c5d-a8cfd3afcb89,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-e555a9a6-788b-4805-905c-6b2be94afa19,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-69e5c18b-5b4c-4cf6-80fb-89c94e90e84b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854074248-172.17.0.6-1597080236996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36442,DS-14c6061c-575a-49fb-a13d-95257552b7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-413c09f9-53cd-4e44-9eec-93664853d141,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-3236aa82-b7e1-422f-b227-3ff15b0c0b25,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-aa0334d7-a882-41d6-9183-868a4b89dd63,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-b3b7a729-1bdc-475b-9b77-da49059b5e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-6d1b71d6-5220-446d-a2a3-f186fcd8c4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-21f553e1-c626-4973-92c9-73e50dc9fb73,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-2ac37438-72ec-480e-beef-d3332005ffe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854074248-172.17.0.6-1597080236996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36442,DS-14c6061c-575a-49fb-a13d-95257552b7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-413c09f9-53cd-4e44-9eec-93664853d141,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-3236aa82-b7e1-422f-b227-3ff15b0c0b25,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-aa0334d7-a882-41d6-9183-868a4b89dd63,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-b3b7a729-1bdc-475b-9b77-da49059b5e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-6d1b71d6-5220-446d-a2a3-f186fcd8c4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-21f553e1-c626-4973-92c9-73e50dc9fb73,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-2ac37438-72ec-480e-beef-d3332005ffe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-791872599-172.17.0.6-1597080680388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40953,DS-67c56b34-5858-46fc-8d88-88f1b087df37,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-840f009d-6257-4e15-bd99-9506e22edbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-8137d900-5faf-4177-96e2-ce9239e4c9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-7c590051-eb24-4ead-8eff-584326edcd19,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-741d6706-b0e7-4a41-b792-4e3a49bf203c,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-e1f263a9-88da-4abb-95f2-2cc325d49b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-c84a3366-823f-4226-b217-d5127e92d5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-f586ede8-45dc-48a7-831c-d0bf03528b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-791872599-172.17.0.6-1597080680388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40953,DS-67c56b34-5858-46fc-8d88-88f1b087df37,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-840f009d-6257-4e15-bd99-9506e22edbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-8137d900-5faf-4177-96e2-ce9239e4c9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-7c590051-eb24-4ead-8eff-584326edcd19,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-741d6706-b0e7-4a41-b792-4e3a49bf203c,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-e1f263a9-88da-4abb-95f2-2cc325d49b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-c84a3366-823f-4226-b217-d5127e92d5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-f586ede8-45dc-48a7-831c-d0bf03528b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440722830-172.17.0.6-1597080719652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43264,DS-a37e5d2e-aec2-4709-aa09-c16528e0a526,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-9bfb90d4-0ed1-4de0-aa9d-6d568af5f5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-11f2e703-6d96-4868-8a7b-c379f86b2064,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-45e9d30d-3b57-4383-bd8b-2d4463d98750,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-d554b4cc-709d-41de-8170-d008ee955f13,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-f29246e8-9ccc-41fc-9c06-691861d5115a,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-325cce8d-57a8-4829-9640-7a6921fb6d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-81e7b195-c2d6-4fae-aae4-427319e705d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440722830-172.17.0.6-1597080719652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43264,DS-a37e5d2e-aec2-4709-aa09-c16528e0a526,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-9bfb90d4-0ed1-4de0-aa9d-6d568af5f5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-11f2e703-6d96-4868-8a7b-c379f86b2064,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-45e9d30d-3b57-4383-bd8b-2d4463d98750,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-d554b4cc-709d-41de-8170-d008ee955f13,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-f29246e8-9ccc-41fc-9c06-691861d5115a,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-325cce8d-57a8-4829-9640-7a6921fb6d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-81e7b195-c2d6-4fae-aae4-427319e705d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194096769-172.17.0.6-1597080829922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33226,DS-7b25ce02-bc52-4be0-8d8f-59876469514c,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-695bf31e-7f03-4a2c-944f-ddc1aa27eaea,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-68d1ab3b-740e-4a87-81fc-fa074968293c,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-049d3614-81c6-498c-ae81-1c7e2f07bca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-6224e3cf-7f67-4128-84ce-1b01642c3115,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-fdd783bf-f65d-47fb-9144-ac746ce91722,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-a894030c-25c2-4a25-afaa-f1794b438214,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-00c4c09e-5ba9-466b-9422-c26c32773fe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194096769-172.17.0.6-1597080829922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33226,DS-7b25ce02-bc52-4be0-8d8f-59876469514c,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-695bf31e-7f03-4a2c-944f-ddc1aa27eaea,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-68d1ab3b-740e-4a87-81fc-fa074968293c,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-049d3614-81c6-498c-ae81-1c7e2f07bca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-6224e3cf-7f67-4128-84ce-1b01642c3115,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-fdd783bf-f65d-47fb-9144-ac746ce91722,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-a894030c-25c2-4a25-afaa-f1794b438214,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-00c4c09e-5ba9-466b-9422-c26c32773fe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-419863007-172.17.0.6-1597081772785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36428,DS-87119503-f2f0-4212-abd8-4c56dfb74f80,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-654d1255-54af-4fed-8c21-ea177e12b9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-9d0b8345-4423-4b29-ab40-0d8909b28fac,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-c18ad1f8-41a0-4dc2-9927-1c9981aaac4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-473f271f-bea0-4d65-b13b-9c1de876c4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-ca0eb452-1db6-41d0-91b4-ddb15ebeae13,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-08e492e1-e862-49f5-9de7-15e402bd8303,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-69a2239c-fca5-4437-8024-58350e30567f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-419863007-172.17.0.6-1597081772785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36428,DS-87119503-f2f0-4212-abd8-4c56dfb74f80,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-654d1255-54af-4fed-8c21-ea177e12b9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-9d0b8345-4423-4b29-ab40-0d8909b28fac,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-c18ad1f8-41a0-4dc2-9927-1c9981aaac4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-473f271f-bea0-4d65-b13b-9c1de876c4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-ca0eb452-1db6-41d0-91b4-ddb15ebeae13,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-08e492e1-e862-49f5-9de7-15e402bd8303,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-69a2239c-fca5-4437-8024-58350e30567f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-482095217-172.17.0.6-1597081966699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37394,DS-7ca36dd8-211f-415a-8780-3d12ab5cc3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-337b6a4d-d9b0-4d55-a8f0-fa7ceba41a48,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-3279cd63-1265-4399-b2aa-f7f48401f84e,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-b36a389a-6aaf-473f-a902-61983ff0b360,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-e3072a5c-9f49-46b7-a9c0-774faea16283,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-ef6005df-87d6-4dda-a5dc-d7cf1f7abb41,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-4914b2ea-81a7-4dcc-ad68-043d15199cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-00e9643b-532e-45e4-84e3-fcdf87b4dd7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-482095217-172.17.0.6-1597081966699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37394,DS-7ca36dd8-211f-415a-8780-3d12ab5cc3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-337b6a4d-d9b0-4d55-a8f0-fa7ceba41a48,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-3279cd63-1265-4399-b2aa-f7f48401f84e,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-b36a389a-6aaf-473f-a902-61983ff0b360,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-e3072a5c-9f49-46b7-a9c0-774faea16283,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-ef6005df-87d6-4dda-a5dc-d7cf1f7abb41,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-4914b2ea-81a7-4dcc-ad68-043d15199cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-00e9643b-532e-45e4-84e3-fcdf87b4dd7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785701315-172.17.0.6-1597082176146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41678,DS-2c98437d-4e51-417d-b37b-8cd191e46572,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-ade38bde-9db8-4378-ad43-3f02c94cc642,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-129bc3f9-fe6c-4170-97ee-da8a5a0ec844,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-7bf018f2-291e-4aa1-9cce-e208a1f439d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-4b9493b1-ebbb-49e5-83f1-1808a9888a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-fe246531-7cfe-482a-a4d9-c70786c889e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-b16c0171-2a41-4b47-ab6a-614d170c483d,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-fa42d5b6-9b18-4703-bc9c-3f6b6cd30820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785701315-172.17.0.6-1597082176146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41678,DS-2c98437d-4e51-417d-b37b-8cd191e46572,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-ade38bde-9db8-4378-ad43-3f02c94cc642,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-129bc3f9-fe6c-4170-97ee-da8a5a0ec844,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-7bf018f2-291e-4aa1-9cce-e208a1f439d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-4b9493b1-ebbb-49e5-83f1-1808a9888a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-fe246531-7cfe-482a-a4d9-c70786c889e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-b16c0171-2a41-4b47-ab6a-614d170c483d,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-fa42d5b6-9b18-4703-bc9c-3f6b6cd30820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505219790-172.17.0.6-1597082285243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-7d3dce71-e70d-4137-8607-bd8ec3226b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-304d5f82-3d1a-4c1e-978c-e67af19b94f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-462510bc-f5f1-45b7-b1f3-7fb9ba4fbd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-7e878c0b-aa7e-4c11-9456-89e5f0eb796d,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-41840a50-e749-49da-bb35-e08c1ad897ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-61e5df56-409e-4aa0-b6c2-3eebcf387120,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-ffd1c90e-330a-4e17-b583-058411d5b745,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-80001bb0-8a6d-444c-90f7-aab327e5297d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505219790-172.17.0.6-1597082285243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-7d3dce71-e70d-4137-8607-bd8ec3226b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-304d5f82-3d1a-4c1e-978c-e67af19b94f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-462510bc-f5f1-45b7-b1f3-7fb9ba4fbd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-7e878c0b-aa7e-4c11-9456-89e5f0eb796d,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-41840a50-e749-49da-bb35-e08c1ad897ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-61e5df56-409e-4aa0-b6c2-3eebcf387120,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-ffd1c90e-330a-4e17-b583-058411d5b745,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-80001bb0-8a6d-444c-90f7-aab327e5297d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815758120-172.17.0.6-1597082317437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34948,DS-40974a2b-8962-450a-b04e-267fd0945abc,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-6d7edcbe-2117-4a25-a026-0fac2e0ce1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-2145b93d-ecdb-4673-973f-ce4a8589fffb,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-28112230-98ff-4d79-b0b6-a8ae5198b721,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-361b59a6-a160-4f51-96df-4f4c98cb17db,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-a242d8de-6be9-4765-9953-d0a9c21b2f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-48a51c28-79c7-4118-88d7-5b923c61fffe,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-639a406a-b62a-4e07-b445-0ffe76fc53fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815758120-172.17.0.6-1597082317437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34948,DS-40974a2b-8962-450a-b04e-267fd0945abc,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-6d7edcbe-2117-4a25-a026-0fac2e0ce1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-2145b93d-ecdb-4673-973f-ce4a8589fffb,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-28112230-98ff-4d79-b0b6-a8ae5198b721,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-361b59a6-a160-4f51-96df-4f4c98cb17db,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-a242d8de-6be9-4765-9953-d0a9c21b2f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-48a51c28-79c7-4118-88d7-5b923c61fffe,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-639a406a-b62a-4e07-b445-0ffe76fc53fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830115277-172.17.0.6-1597082467918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44037,DS-3fc2d7bb-1ae8-48ec-ae8f-29878b9cb7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-aece7ee3-9e31-4e13-80c4-d398a03af9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-fe3becfc-f271-4d35-880a-0ee6bf2fb4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-8e9cab57-4845-40ca-96ae-7995838a557e,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-d4c28523-7a6a-4790-b412-85be36a34b49,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-a5c12df0-79fc-483d-a107-270e300cde04,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-5c2106fd-6694-4663-a166-1286043c623d,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-bbd6f9d6-8c12-4a1e-b6a6-548416872e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830115277-172.17.0.6-1597082467918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44037,DS-3fc2d7bb-1ae8-48ec-ae8f-29878b9cb7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-aece7ee3-9e31-4e13-80c4-d398a03af9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-fe3becfc-f271-4d35-880a-0ee6bf2fb4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-8e9cab57-4845-40ca-96ae-7995838a557e,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-d4c28523-7a6a-4790-b412-85be36a34b49,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-a5c12df0-79fc-483d-a107-270e300cde04,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-5c2106fd-6694-4663-a166-1286043c623d,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-bbd6f9d6-8c12-4a1e-b6a6-548416872e25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413654827-172.17.0.6-1597082784532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34750,DS-ca88a700-3fd9-4280-88fd-9e643443a979,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-f8faa4b7-0eb3-4ec2-aa5c-4e8e6b7038ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-bc63db24-4b3c-4fd4-b420-dab6e485d9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-47c88061-1721-410e-845f-5aec9e563eca,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-c923cfb5-60a8-46bb-9e31-8d4de30bdcff,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-98a13f8d-0274-49b2-9ba3-f57e0d6cd722,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-e3e52272-bfd0-4035-9db8-9e6d7ab49e45,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-437a5602-952c-4ac5-b5e7-0018d56300f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413654827-172.17.0.6-1597082784532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34750,DS-ca88a700-3fd9-4280-88fd-9e643443a979,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-f8faa4b7-0eb3-4ec2-aa5c-4e8e6b7038ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-bc63db24-4b3c-4fd4-b420-dab6e485d9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-47c88061-1721-410e-845f-5aec9e563eca,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-c923cfb5-60a8-46bb-9e31-8d4de30bdcff,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-98a13f8d-0274-49b2-9ba3-f57e0d6cd722,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-e3e52272-bfd0-4035-9db8-9e6d7ab49e45,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-437a5602-952c-4ac5-b5e7-0018d56300f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-493618263-172.17.0.6-1597082899489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33710,DS-ebb94192-aaae-478b-a767-87958c0e872e,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-58e1079b-709e-40cb-81cc-f27da613daa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-b2f61b45-2a50-4b3e-9b3b-f4dbbbf79081,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-cd648d7d-549a-467e-886c-e2c76e5566c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-981cabef-c23f-4e21-bd77-d46fb42807dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-97e3251a-0312-4c99-9b52-d408aa22dec5,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-7666e767-5db5-487f-88dd-c1ebbfc0be82,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-b2261af0-1d12-49b7-bfdf-5c8d4c0eb8bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-493618263-172.17.0.6-1597082899489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33710,DS-ebb94192-aaae-478b-a767-87958c0e872e,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-58e1079b-709e-40cb-81cc-f27da613daa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-b2f61b45-2a50-4b3e-9b3b-f4dbbbf79081,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-cd648d7d-549a-467e-886c-e2c76e5566c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-981cabef-c23f-4e21-bd77-d46fb42807dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-97e3251a-0312-4c99-9b52-d408aa22dec5,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-7666e767-5db5-487f-88dd-c1ebbfc0be82,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-b2261af0-1d12-49b7-bfdf-5c8d4c0eb8bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835418442-172.17.0.6-1597084106274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38844,DS-f1f5b1e6-a3d7-4c86-9e46-61a4fb2ea6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-5c46a5d5-b92b-44c4-a9a2-acef13c1ec3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-66fab11c-84ec-4dc9-89d0-909300697a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-daa13e9d-bee9-487e-abf9-ee44b9d1d74a,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-504b7209-53a7-4a75-9211-17171381a767,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-836aab8d-4326-419f-bcba-c5b73b4c03fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-17730897-f081-4cb7-afb8-98571a71c083,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-b4004ecd-a834-430e-9232-9637015c7bb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835418442-172.17.0.6-1597084106274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38844,DS-f1f5b1e6-a3d7-4c86-9e46-61a4fb2ea6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-5c46a5d5-b92b-44c4-a9a2-acef13c1ec3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-66fab11c-84ec-4dc9-89d0-909300697a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-daa13e9d-bee9-487e-abf9-ee44b9d1d74a,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-504b7209-53a7-4a75-9211-17171381a767,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-836aab8d-4326-419f-bcba-c5b73b4c03fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-17730897-f081-4cb7-afb8-98571a71c083,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-b4004ecd-a834-430e-9232-9637015c7bb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5460
