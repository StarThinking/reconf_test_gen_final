reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371623596-172.17.0.12-1597142720017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43932,DS-8fb6a6d5-3362-4947-8e8b-e95ba0dbb583,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-b12ae9c2-35ac-43a9-9eca-e1c36f35df9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-6c5e0fab-0d31-4096-8e87-43a191a22c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-da838522-0d96-4d38-83eb-8f4dfe45b2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-ffe0c1ad-6fcb-4333-b980-aa4b3ace2f06,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-435bc2b5-4b2f-48cd-b72c-d31a161a5a21,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-7dfd16d2-0963-406b-b3b2-6a51245a5842,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-35163529-eaa5-4fa6-912f-4b341ccefd5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371623596-172.17.0.12-1597142720017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43932,DS-8fb6a6d5-3362-4947-8e8b-e95ba0dbb583,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-b12ae9c2-35ac-43a9-9eca-e1c36f35df9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-6c5e0fab-0d31-4096-8e87-43a191a22c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-da838522-0d96-4d38-83eb-8f4dfe45b2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-ffe0c1ad-6fcb-4333-b980-aa4b3ace2f06,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-435bc2b5-4b2f-48cd-b72c-d31a161a5a21,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-7dfd16d2-0963-406b-b3b2-6a51245a5842,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-35163529-eaa5-4fa6-912f-4b341ccefd5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879155143-172.17.0.12-1597142756838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35295,DS-f3137f16-e827-40af-90ce-8cf30d3428df,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-895cbed3-a84d-4dcc-a532-ad2dc4e4547b,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-afe9fcf0-d52f-4a3d-a5ac-a0b622b499ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-c2ec9d54-7449-4bc6-bc8c-023854624f37,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-0a6d87ca-96db-4cd0-a6a5-b0995272f325,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-8664f45f-e2ba-4b7d-a971-ecc26fd7c600,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-f80fe1f5-cd33-4aa4-bfd6-e6896c7a6f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-4a8d8196-d8f3-4759-961f-410f90d5ef3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879155143-172.17.0.12-1597142756838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35295,DS-f3137f16-e827-40af-90ce-8cf30d3428df,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-895cbed3-a84d-4dcc-a532-ad2dc4e4547b,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-afe9fcf0-d52f-4a3d-a5ac-a0b622b499ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-c2ec9d54-7449-4bc6-bc8c-023854624f37,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-0a6d87ca-96db-4cd0-a6a5-b0995272f325,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-8664f45f-e2ba-4b7d-a971-ecc26fd7c600,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-f80fe1f5-cd33-4aa4-bfd6-e6896c7a6f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-4a8d8196-d8f3-4759-961f-410f90d5ef3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232415796-172.17.0.12-1597142862271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39806,DS-dc4b92ab-98a2-4537-bf20-c492e8b2ffbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-01183ad5-2b0d-427c-9439-7588cfd4d3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-185474ad-a0b6-4ddb-ad86-ea40dd0269dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-24a62276-9a2d-4d46-9370-19c6353b9174,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-860c73de-3394-4bda-94de-7962c6dafd74,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-fa183980-0fb4-45b9-8095-fbeb0982dc91,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-ebcb4517-54ff-472a-b7bc-012eac1eb2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-60a7c6ad-99e2-4995-9b62-850d6ff827c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232415796-172.17.0.12-1597142862271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39806,DS-dc4b92ab-98a2-4537-bf20-c492e8b2ffbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-01183ad5-2b0d-427c-9439-7588cfd4d3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-185474ad-a0b6-4ddb-ad86-ea40dd0269dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-24a62276-9a2d-4d46-9370-19c6353b9174,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-860c73de-3394-4bda-94de-7962c6dafd74,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-fa183980-0fb4-45b9-8095-fbeb0982dc91,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-ebcb4517-54ff-472a-b7bc-012eac1eb2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-60a7c6ad-99e2-4995-9b62-850d6ff827c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81296778-172.17.0.12-1597142935919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40909,DS-9557447a-090f-4a62-be67-6fe07e311a67,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-39a6bf72-a76d-40a5-ad3d-99b38c58e98a,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-32dd2d06-07e3-4001-a603-0e85b57ec005,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-5eec21c9-bc60-4dbb-b5da-0b049c1a4054,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-3c464d19-e8fc-4ea9-9323-e9832a51fcb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-dccc5465-4bda-4695-94e8-571dbbf8e0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-1f7dd560-7f28-4d47-8c46-51c0479a2800,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-62f30af6-c250-424e-9271-9a3dc1988f98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81296778-172.17.0.12-1597142935919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40909,DS-9557447a-090f-4a62-be67-6fe07e311a67,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-39a6bf72-a76d-40a5-ad3d-99b38c58e98a,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-32dd2d06-07e3-4001-a603-0e85b57ec005,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-5eec21c9-bc60-4dbb-b5da-0b049c1a4054,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-3c464d19-e8fc-4ea9-9323-e9832a51fcb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-dccc5465-4bda-4695-94e8-571dbbf8e0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-1f7dd560-7f28-4d47-8c46-51c0479a2800,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-62f30af6-c250-424e-9271-9a3dc1988f98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054165695-172.17.0.12-1597143049080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36092,DS-2b2b0785-9532-48c3-bd71-11d337010b08,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-e56c6a3a-0d61-4175-a4f5-ddf110d3a8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-2f5fb181-70fe-4395-8139-11f28d767470,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-7f65d10a-fa20-44d5-b7e9-139939023e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-e3e43465-3c00-47cf-a1af-b5354ed174b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-c853ae01-e40f-4f1a-a52c-6b55df424345,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-d38a0c9b-d873-48f2-87fb-0024b32c2b83,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-f21ad20a-56fd-4991-b550-974ec2bc13d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054165695-172.17.0.12-1597143049080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36092,DS-2b2b0785-9532-48c3-bd71-11d337010b08,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-e56c6a3a-0d61-4175-a4f5-ddf110d3a8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-2f5fb181-70fe-4395-8139-11f28d767470,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-7f65d10a-fa20-44d5-b7e9-139939023e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-e3e43465-3c00-47cf-a1af-b5354ed174b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-c853ae01-e40f-4f1a-a52c-6b55df424345,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-d38a0c9b-d873-48f2-87fb-0024b32c2b83,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-f21ad20a-56fd-4991-b550-974ec2bc13d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638979421-172.17.0.12-1597143199392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41083,DS-2fe18a6f-bb64-410d-ac98-3aac77138500,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-934964fa-f9d7-4112-bc2c-61df08daa422,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-060f34d1-f9e6-40e7-8fd2-7ca355071353,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-addb5f32-2b0c-41c6-984a-bf8af567fb22,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-4e8c31c1-e2e7-408f-9bfe-c1b2d6994a58,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-aeb6cd5e-6c24-4c84-8e61-05b1ad47ea80,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-780c2767-4e4a-461e-9bf7-3b213b0a44ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-f85e6aae-a9ad-48a9-b3f1-c1576c357825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638979421-172.17.0.12-1597143199392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41083,DS-2fe18a6f-bb64-410d-ac98-3aac77138500,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-934964fa-f9d7-4112-bc2c-61df08daa422,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-060f34d1-f9e6-40e7-8fd2-7ca355071353,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-addb5f32-2b0c-41c6-984a-bf8af567fb22,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-4e8c31c1-e2e7-408f-9bfe-c1b2d6994a58,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-aeb6cd5e-6c24-4c84-8e61-05b1ad47ea80,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-780c2767-4e4a-461e-9bf7-3b213b0a44ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-f85e6aae-a9ad-48a9-b3f1-c1576c357825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280649487-172.17.0.12-1597144514806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40222,DS-43ad53aa-bc3e-4422-88a3-badf857326a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-31535c9b-5441-4007-9faa-eb3f77e09aec,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-23374384-ca0b-4cea-9d48-b76bb99a5512,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-6bc64144-4f84-4afc-9f72-1209bfbefe9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-8b9eab27-ea2f-4182-b5c5-ce11ea5eefe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-58f71902-080a-475a-8b60-0fc507c3bcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-6becae68-ca30-41a7-9bac-d77fd36917cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-690ea38a-3fd0-4914-8bbf-8557649b4b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280649487-172.17.0.12-1597144514806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40222,DS-43ad53aa-bc3e-4422-88a3-badf857326a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-31535c9b-5441-4007-9faa-eb3f77e09aec,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-23374384-ca0b-4cea-9d48-b76bb99a5512,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-6bc64144-4f84-4afc-9f72-1209bfbefe9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-8b9eab27-ea2f-4182-b5c5-ce11ea5eefe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-58f71902-080a-475a-8b60-0fc507c3bcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-6becae68-ca30-41a7-9bac-d77fd36917cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-690ea38a-3fd0-4914-8bbf-8557649b4b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285613386-172.17.0.12-1597144842359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42460,DS-5030ad81-7c3d-46ad-a341-62fe1ab9c956,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-c4e86dbd-e7a2-42db-a9ba-240a6b3e0401,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-09f1055c-0f5b-4771-be11-929cc54ec3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-97f4dc62-12f7-4761-ac8a-15ea45f5f04a,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-902e4c1a-8e47-4e2a-a9b0-0dc2503aeb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-8135171d-1882-4518-b572-9b29b36680e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-ebcd6381-8238-4b84-aeae-0e7e21fad98b,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-34d029df-33ff-4227-8641-384610d17297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285613386-172.17.0.12-1597144842359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42460,DS-5030ad81-7c3d-46ad-a341-62fe1ab9c956,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-c4e86dbd-e7a2-42db-a9ba-240a6b3e0401,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-09f1055c-0f5b-4771-be11-929cc54ec3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-97f4dc62-12f7-4761-ac8a-15ea45f5f04a,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-902e4c1a-8e47-4e2a-a9b0-0dc2503aeb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-8135171d-1882-4518-b572-9b29b36680e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-ebcd6381-8238-4b84-aeae-0e7e21fad98b,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-34d029df-33ff-4227-8641-384610d17297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590912451-172.17.0.12-1597144879645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36836,DS-42093f2c-f735-4299-be45-788ed03e729f,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-7c509d3e-b2ca-4edd-a6cc-d5e7194ac0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-5790de46-30f4-4a6e-9576-3dcd0e14943d,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-372a87e8-246b-4368-a1eb-ebae4dd8b954,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-273508ef-6688-48f3-8f88-b1154326a351,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-1043133e-3027-47c4-86c1-df64f86d459e,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-9af36292-8d62-47c0-a12f-b35509240959,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-e7669b3a-8a41-4287-b3da-6759762d0918,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590912451-172.17.0.12-1597144879645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36836,DS-42093f2c-f735-4299-be45-788ed03e729f,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-7c509d3e-b2ca-4edd-a6cc-d5e7194ac0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-5790de46-30f4-4a6e-9576-3dcd0e14943d,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-372a87e8-246b-4368-a1eb-ebae4dd8b954,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-273508ef-6688-48f3-8f88-b1154326a351,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-1043133e-3027-47c4-86c1-df64f86d459e,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-9af36292-8d62-47c0-a12f-b35509240959,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-e7669b3a-8a41-4287-b3da-6759762d0918,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860174187-172.17.0.12-1597145111173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46877,DS-3c349f0b-43a6-41af-8534-e3abdff709cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-ea7541b2-5ef5-457b-90c6-3e1dccb0566a,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-7e24653d-610f-4628-97a3-036b202f0eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-283fd722-92a5-470f-889e-f5e6d707b5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-a118ecf8-e51d-4526-8be8-788c69550c97,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-5c1132ed-1ef2-4e0c-a32b-195d9ff3a3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-bc196c06-6392-40ce-99db-ffcb24193393,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-03280056-28a5-4fbc-af72-1bbb46aa1342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860174187-172.17.0.12-1597145111173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46877,DS-3c349f0b-43a6-41af-8534-e3abdff709cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-ea7541b2-5ef5-457b-90c6-3e1dccb0566a,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-7e24653d-610f-4628-97a3-036b202f0eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-283fd722-92a5-470f-889e-f5e6d707b5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-a118ecf8-e51d-4526-8be8-788c69550c97,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-5c1132ed-1ef2-4e0c-a32b-195d9ff3a3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-bc196c06-6392-40ce-99db-ffcb24193393,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-03280056-28a5-4fbc-af72-1bbb46aa1342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395218742-172.17.0.12-1597145946188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37000,DS-14bdf982-df1e-4d8a-947c-b851b1730dac,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-42508e45-6a0c-49e2-8cec-6abfbaba9a59,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-d95d371f-e640-45ba-9093-091a36878250,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-5daab16e-5fb0-47bd-9bc2-17beb2727f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-9373a607-23cf-4170-8e53-d106bab6b062,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-84be2b57-54fc-470a-8db6-0c7ba2cc19c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-a7a78bb6-c8b2-4cd7-97c4-fd57b7f2edec,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-004744c9-0c0c-47a7-b147-df1d756902e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395218742-172.17.0.12-1597145946188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37000,DS-14bdf982-df1e-4d8a-947c-b851b1730dac,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-42508e45-6a0c-49e2-8cec-6abfbaba9a59,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-d95d371f-e640-45ba-9093-091a36878250,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-5daab16e-5fb0-47bd-9bc2-17beb2727f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-9373a607-23cf-4170-8e53-d106bab6b062,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-84be2b57-54fc-470a-8db6-0c7ba2cc19c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-a7a78bb6-c8b2-4cd7-97c4-fd57b7f2edec,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-004744c9-0c0c-47a7-b147-df1d756902e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506576667-172.17.0.12-1597146047670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37372,DS-739febbe-e2d7-47f6-b9f8-8ad12543a979,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-2193bcd1-ab9e-4c5c-87af-0add71570602,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-1b047146-0573-4290-994d-244ed2bc9863,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-eb677574-d6ee-47c5-ad41-be2344a18bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-f11519ed-c22a-47af-b4c7-696183f86d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-60dccb5b-536e-48ba-b8e1-98a3dc3ebdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-00dd1f8d-8821-4be0-b639-b1cfbcce698a,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-54305308-4415-4842-a6c1-3bb8229ec4ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506576667-172.17.0.12-1597146047670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37372,DS-739febbe-e2d7-47f6-b9f8-8ad12543a979,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-2193bcd1-ab9e-4c5c-87af-0add71570602,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-1b047146-0573-4290-994d-244ed2bc9863,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-eb677574-d6ee-47c5-ad41-be2344a18bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-f11519ed-c22a-47af-b4c7-696183f86d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-60dccb5b-536e-48ba-b8e1-98a3dc3ebdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-00dd1f8d-8821-4be0-b639-b1cfbcce698a,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-54305308-4415-4842-a6c1-3bb8229ec4ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754094609-172.17.0.12-1597146256196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34456,DS-a6615fd6-0172-4f25-8526-8f0de9244616,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-f3360ee5-afd2-4553-9159-09e2e426fad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-230d74ef-d81c-40c9-b676-71c05fe40663,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-9ec7a339-9737-48fa-a4e1-93cab8c28473,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-75a099a9-d697-4706-b91e-6c92d49f4dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-73fe4091-46b5-4c45-a53e-e472cecafb53,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-3b3ba7b9-040f-49f0-91f2-687057c37060,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-b2750c1b-19d8-4268-9f8f-e9494ccd01f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754094609-172.17.0.12-1597146256196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34456,DS-a6615fd6-0172-4f25-8526-8f0de9244616,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-f3360ee5-afd2-4553-9159-09e2e426fad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-230d74ef-d81c-40c9-b676-71c05fe40663,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-9ec7a339-9737-48fa-a4e1-93cab8c28473,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-75a099a9-d697-4706-b91e-6c92d49f4dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-73fe4091-46b5-4c45-a53e-e472cecafb53,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-3b3ba7b9-040f-49f0-91f2-687057c37060,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-b2750c1b-19d8-4268-9f8f-e9494ccd01f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608140256-172.17.0.12-1597146298177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40310,DS-5fe11737-7007-471a-8b8c-b20f18426c79,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-18deafd1-bf1f-455d-a1b4-cc115e346093,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-8138d805-6fe6-4b4d-b0e7-043f0643c058,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-0b32149a-b791-4783-a1ae-5330f54e7844,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-8cf599fb-9200-4843-99cd-bf6d1f831ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-84db635d-9cec-4e9a-b7d1-9c210cca4d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-608985d8-244b-48c0-8d3d-2a7a3206b819,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-b7380a80-8125-4353-bd0c-1786fda6c1d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608140256-172.17.0.12-1597146298177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40310,DS-5fe11737-7007-471a-8b8c-b20f18426c79,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-18deafd1-bf1f-455d-a1b4-cc115e346093,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-8138d805-6fe6-4b4d-b0e7-043f0643c058,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-0b32149a-b791-4783-a1ae-5330f54e7844,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-8cf599fb-9200-4843-99cd-bf6d1f831ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-84db635d-9cec-4e9a-b7d1-9c210cca4d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-608985d8-244b-48c0-8d3d-2a7a3206b819,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-b7380a80-8125-4353-bd0c-1786fda6c1d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100638773-172.17.0.12-1597146575368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43766,DS-48d769c6-fc14-45ff-9d77-db464ec9fe32,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-4450b5d9-21c9-4c40-8c7e-fe23d83dd5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-cc59a673-29ae-4f25-9686-20ad8765b6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-3ce4e35c-f8cb-4923-aad0-dc54b8aaf368,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-3a081fdf-7bac-444e-84f2-4913879e0b14,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-5dfdef24-350a-47d7-9add-bd74091ea2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-03d4d57c-e81c-44c7-9abd-750bcea677da,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-7fa573dd-2f69-4b2a-b57c-c9ce360c1a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100638773-172.17.0.12-1597146575368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43766,DS-48d769c6-fc14-45ff-9d77-db464ec9fe32,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-4450b5d9-21c9-4c40-8c7e-fe23d83dd5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-cc59a673-29ae-4f25-9686-20ad8765b6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-3ce4e35c-f8cb-4923-aad0-dc54b8aaf368,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-3a081fdf-7bac-444e-84f2-4913879e0b14,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-5dfdef24-350a-47d7-9add-bd74091ea2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-03d4d57c-e81c-44c7-9abd-750bcea677da,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-7fa573dd-2f69-4b2a-b57c-c9ce360c1a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387155782-172.17.0.12-1597146837038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39756,DS-6ec08295-3e14-41aa-bcc1-ba30dc01fb59,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-eb7f2472-f746-43b2-a30e-d819c6fbd9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-1ee37ec9-4263-46d6-ad8d-75ce85825cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-703a9776-de72-4fb0-9ee7-f018f63dfca5,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-245142d6-6963-4e8d-a674-fdae9ccc15bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-bcac662e-58b4-4633-8885-3796231216ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-4c6c3d41-cbdd-48cd-b1c1-f945325719df,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-33644e49-3780-449b-a71d-078b599645aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387155782-172.17.0.12-1597146837038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39756,DS-6ec08295-3e14-41aa-bcc1-ba30dc01fb59,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-eb7f2472-f746-43b2-a30e-d819c6fbd9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-1ee37ec9-4263-46d6-ad8d-75ce85825cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-703a9776-de72-4fb0-9ee7-f018f63dfca5,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-245142d6-6963-4e8d-a674-fdae9ccc15bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-bcac662e-58b4-4633-8885-3796231216ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-4c6c3d41-cbdd-48cd-b1c1-f945325719df,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-33644e49-3780-449b-a71d-078b599645aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588593029-172.17.0.12-1597147399147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46853,DS-dd8e10c8-e865-4f28-8a74-3e930cf49d13,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-19153d1f-e3b2-4276-b81f-4955a4d59904,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-ea53af35-5504-440b-a7aa-9077d852808a,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-e9ffdd7d-6f90-4916-ab76-830e22b8f989,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-57cc24a1-5604-4b09-964c-cd50fe0743cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-2774dd0b-e1ee-48c4-8520-442b563f7615,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-5f47e7a5-f9c1-496e-9f8f-f5fb6d60221b,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-15668c69-0bfe-4c3b-b52f-27d456d04bf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588593029-172.17.0.12-1597147399147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46853,DS-dd8e10c8-e865-4f28-8a74-3e930cf49d13,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-19153d1f-e3b2-4276-b81f-4955a4d59904,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-ea53af35-5504-440b-a7aa-9077d852808a,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-e9ffdd7d-6f90-4916-ab76-830e22b8f989,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-57cc24a1-5604-4b09-964c-cd50fe0743cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-2774dd0b-e1ee-48c4-8520-442b563f7615,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-5f47e7a5-f9c1-496e-9f8f-f5fb6d60221b,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-15668c69-0bfe-4c3b-b52f-27d456d04bf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802781257-172.17.0.12-1597147507345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37068,DS-2978ce12-c584-4843-a939-96d3181fc989,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-4a119114-8c27-4c96-b9f0-d8d070415a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-ea92cc1b-7a93-4215-8b79-7dd8c810d1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-84c2171e-dfea-4d70-97b9-ae8a30c4caf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-696f9c64-6cd9-4226-b03f-998481a27cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-02c6181b-4708-48a0-8140-40d0eafe7d20,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-1eeebc1f-50b6-495d-a801-f8b63975e34e,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-295a9aa6-f9b8-4e24-b251-8de786a0220b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802781257-172.17.0.12-1597147507345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37068,DS-2978ce12-c584-4843-a939-96d3181fc989,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-4a119114-8c27-4c96-b9f0-d8d070415a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-ea92cc1b-7a93-4215-8b79-7dd8c810d1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-84c2171e-dfea-4d70-97b9-ae8a30c4caf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-696f9c64-6cd9-4226-b03f-998481a27cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-02c6181b-4708-48a0-8140-40d0eafe7d20,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-1eeebc1f-50b6-495d-a801-f8b63975e34e,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-295a9aa6-f9b8-4e24-b251-8de786a0220b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237867787-172.17.0.12-1597147576129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44164,DS-aba4aec6-8dbb-4f8a-99eb-a030e33c75e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-24d3a32c-da61-4323-a818-d726df56dfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-953827ed-7b72-4b25-8acd-65e2a608dc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-0fb453b4-841a-4a2e-b379-4d63a5d85332,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-9300b433-91c3-400d-b91d-234dec8d807c,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-240246bc-5c04-48e4-a21d-6d1a9964ef42,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-37b41c48-7d5d-41a4-86d7-3d3b731b5758,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-1509950b-8acb-416b-aa28-9effb7b8f5d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237867787-172.17.0.12-1597147576129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44164,DS-aba4aec6-8dbb-4f8a-99eb-a030e33c75e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-24d3a32c-da61-4323-a818-d726df56dfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-953827ed-7b72-4b25-8acd-65e2a608dc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-0fb453b4-841a-4a2e-b379-4d63a5d85332,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-9300b433-91c3-400d-b91d-234dec8d807c,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-240246bc-5c04-48e4-a21d-6d1a9964ef42,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-37b41c48-7d5d-41a4-86d7-3d3b731b5758,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-1509950b-8acb-416b-aa28-9effb7b8f5d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686174478-172.17.0.12-1597147729317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34442,DS-e56fa024-15b4-4ec6-82cf-e77f55f9da20,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-7438750f-98c1-4c1e-b94b-c52651636d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-3420f644-9987-44ac-9885-d332ea38073f,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-2f303f8e-4fa5-4562-b54d-e4d754d3d08a,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-77c97982-b832-4026-b64c-f8c030e75866,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-e5b6b0ad-4585-4038-a839-6b171739103d,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-ec1c7c94-0b7f-4b93-9439-3f0387abb4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-2e786d1a-419a-4fba-8565-c8a5683bf54e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686174478-172.17.0.12-1597147729317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34442,DS-e56fa024-15b4-4ec6-82cf-e77f55f9da20,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-7438750f-98c1-4c1e-b94b-c52651636d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-3420f644-9987-44ac-9885-d332ea38073f,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-2f303f8e-4fa5-4562-b54d-e4d754d3d08a,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-77c97982-b832-4026-b64c-f8c030e75866,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-e5b6b0ad-4585-4038-a839-6b171739103d,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-ec1c7c94-0b7f-4b93-9439-3f0387abb4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-2e786d1a-419a-4fba-8565-c8a5683bf54e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ls.limit
component: hdfs:NameNode
v1: 1000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450746886-172.17.0.12-1597148018428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46466,DS-2432e364-d8b2-4c5e-b96c-fbd20d4bd801,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-32c8133d-63ce-4102-afb5-72688b07b70a,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-df5ddc71-5e96-4cab-8bf6-7f2e1dd4e3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-a8914c6d-facf-4f9b-9589-d34a03694437,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-d841b1d3-3e43-4f76-a013-92886c5d4b19,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-e8b49ad2-38eb-45ef-ac8c-eb2d51f82349,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-85852616-8f9b-4d85-9873-606268544db6,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-e52231b9-c7ac-4420-8f87-dcc3306c127b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450746886-172.17.0.12-1597148018428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46466,DS-2432e364-d8b2-4c5e-b96c-fbd20d4bd801,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-32c8133d-63ce-4102-afb5-72688b07b70a,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-df5ddc71-5e96-4cab-8bf6-7f2e1dd4e3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-a8914c6d-facf-4f9b-9589-d34a03694437,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-d841b1d3-3e43-4f76-a013-92886c5d4b19,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-e8b49ad2-38eb-45ef-ac8c-eb2d51f82349,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-85852616-8f9b-4d85-9873-606268544db6,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-e52231b9-c7ac-4420-8f87-dcc3306c127b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5398
