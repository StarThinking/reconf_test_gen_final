reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123473-172.17.0.19-1597092721777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33215,DS-358c0dfd-b0fd-4077-bd4d-7f326ba6d420,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-d90da80b-c751-4bf6-af65-007179d6f385,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-3089eb13-9e75-4662-a574-c1ed92ab27b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-d32e69af-b50c-4707-9136-acb349c07985,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-0c076e17-d2af-4bc3-afe3-4fcf413ed167,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-880f6078-28c7-4b7b-97bb-d843f3e80da0,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-cd7f3e77-066a-474b-bc26-8245542de360,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-fffcb70b-4ad8-4f6a-a8fe-23a064f4599d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123473-172.17.0.19-1597092721777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33215,DS-358c0dfd-b0fd-4077-bd4d-7f326ba6d420,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-d90da80b-c751-4bf6-af65-007179d6f385,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-3089eb13-9e75-4662-a574-c1ed92ab27b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-d32e69af-b50c-4707-9136-acb349c07985,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-0c076e17-d2af-4bc3-afe3-4fcf413ed167,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-880f6078-28c7-4b7b-97bb-d843f3e80da0,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-cd7f3e77-066a-474b-bc26-8245542de360,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-fffcb70b-4ad8-4f6a-a8fe-23a064f4599d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992096439-172.17.0.19-1597092833803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42238,DS-28bfbace-fdbc-4482-a8f5-7a6865ba64e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-ac4fce86-4161-4ee5-bef3-9a08e9e7e4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-27500d9c-6798-441f-acc1-357e6fe6c56c,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-5f794a60-d6e3-47ab-b9d9-74e0fbc1b894,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-a3574394-b295-43f8-bd6c-d2d56657328c,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-5c1f439e-410d-435f-b966-1f347ff5f59a,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-1436b980-6cb1-4015-846a-42dab4346c92,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-5c2843ec-7c21-4290-a307-e74eb0d552ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992096439-172.17.0.19-1597092833803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42238,DS-28bfbace-fdbc-4482-a8f5-7a6865ba64e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-ac4fce86-4161-4ee5-bef3-9a08e9e7e4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-27500d9c-6798-441f-acc1-357e6fe6c56c,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-5f794a60-d6e3-47ab-b9d9-74e0fbc1b894,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-a3574394-b295-43f8-bd6c-d2d56657328c,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-5c1f439e-410d-435f-b966-1f347ff5f59a,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-1436b980-6cb1-4015-846a-42dab4346c92,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-5c2843ec-7c21-4290-a307-e74eb0d552ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336223095-172.17.0.19-1597094079185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37588,DS-7e7d6a54-81cb-43e4-a3b7-c7409ae43562,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-ee6efc19-0c57-4281-8ec5-6e3c8ad7d659,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-47c32b50-e9f4-49a8-beb3-f95e1b205cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-1bef2be0-7683-4559-8864-8184253fca5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-e4258430-ba24-4eeb-8db2-a06ef1bf8eea,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-7e46df28-452b-4972-9d98-313cd2127a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-20376dc5-e83d-483d-8168-e3be34201a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-e9de40f1-c88f-4f21-acd2-2ed8c652f491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336223095-172.17.0.19-1597094079185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37588,DS-7e7d6a54-81cb-43e4-a3b7-c7409ae43562,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-ee6efc19-0c57-4281-8ec5-6e3c8ad7d659,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-47c32b50-e9f4-49a8-beb3-f95e1b205cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-1bef2be0-7683-4559-8864-8184253fca5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-e4258430-ba24-4eeb-8db2-a06ef1bf8eea,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-7e46df28-452b-4972-9d98-313cd2127a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-20376dc5-e83d-483d-8168-e3be34201a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-e9de40f1-c88f-4f21-acd2-2ed8c652f491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691034301-172.17.0.19-1597094295405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42415,DS-7a18e17d-8636-49fb-92b1-c36e10099479,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-60889110-2302-4465-a5f0-1e8fda373adf,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-cabec5c5-2e96-4ed5-acd0-16be3fdf1f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-5cd7cb9b-dc06-4097-8816-d56bb865637e,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-ef6bf033-7397-4464-a67c-e989b2023a43,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-857de570-6108-4ef9-98db-579282901cda,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-a85d435b-1a00-4062-b0fc-0df43b217777,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-9d8d2860-4804-47d4-9289-544298d8ce57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691034301-172.17.0.19-1597094295405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42415,DS-7a18e17d-8636-49fb-92b1-c36e10099479,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-60889110-2302-4465-a5f0-1e8fda373adf,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-cabec5c5-2e96-4ed5-acd0-16be3fdf1f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-5cd7cb9b-dc06-4097-8816-d56bb865637e,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-ef6bf033-7397-4464-a67c-e989b2023a43,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-857de570-6108-4ef9-98db-579282901cda,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-a85d435b-1a00-4062-b0fc-0df43b217777,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-9d8d2860-4804-47d4-9289-544298d8ce57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40167016-172.17.0.19-1597094406033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41522,DS-a36f0267-9784-4efb-a2f0-96dbf1788c21,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-b5068525-dddd-4919-aed7-ce2611aa5935,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-d4fc37c5-9769-4c45-97f9-e37c3883ffbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-379cb0e5-543c-4405-8e24-10f2b360fa83,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-3829c669-ea1a-4ef6-8ecf-2f716d2d4346,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-8e8592b2-25c4-45c5-a8ec-87a79d046cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-fdbad533-f168-47e8-bc18-550424619475,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-76a13458-32c8-4a96-99b6-3f3ee1d8b89a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40167016-172.17.0.19-1597094406033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41522,DS-a36f0267-9784-4efb-a2f0-96dbf1788c21,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-b5068525-dddd-4919-aed7-ce2611aa5935,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-d4fc37c5-9769-4c45-97f9-e37c3883ffbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-379cb0e5-543c-4405-8e24-10f2b360fa83,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-3829c669-ea1a-4ef6-8ecf-2f716d2d4346,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-8e8592b2-25c4-45c5-a8ec-87a79d046cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-fdbad533-f168-47e8-bc18-550424619475,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-76a13458-32c8-4a96-99b6-3f3ee1d8b89a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174610498-172.17.0.19-1597094730592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36376,DS-09712b3f-2d01-44fc-b896-9c1e94587a65,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-50b6aa3a-9eac-40a2-9920-aae108a54077,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-cc287ff7-b1a7-4734-a611-60dd06dd9794,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-6de4e60c-90c5-4b58-bec3-15b84ea9b3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-c7066173-8722-4440-892a-355fc5833e05,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-03d77227-1be4-432f-91a7-e02f9efc2d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-fb217366-63ee-4f13-89ad-eb4793b61bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-2e3a6b15-b4d7-4594-9cfa-81a2d513ca94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174610498-172.17.0.19-1597094730592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36376,DS-09712b3f-2d01-44fc-b896-9c1e94587a65,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-50b6aa3a-9eac-40a2-9920-aae108a54077,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-cc287ff7-b1a7-4734-a611-60dd06dd9794,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-6de4e60c-90c5-4b58-bec3-15b84ea9b3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-c7066173-8722-4440-892a-355fc5833e05,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-03d77227-1be4-432f-91a7-e02f9efc2d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-fb217366-63ee-4f13-89ad-eb4793b61bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-2e3a6b15-b4d7-4594-9cfa-81a2d513ca94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954732014-172.17.0.19-1597095679327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35144,DS-3b3fd97c-b1a0-4a79-9d24-b19d16bd7739,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-6796bf10-bb1f-4963-b67c-4c25d6b99c91,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-1c34a018-5e91-47a4-9aec-5b4102192e60,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-5b6c19d1-46a7-4cb3-ba16-4781c5edae49,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-a5357430-7d5b-461c-9a5b-1314ce44856d,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-18b34d37-ed93-4d97-95c7-6f32f0bceaef,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-3bc5cdbb-403e-4c2e-b738-d95c0385f3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-e5984381-b762-4747-85ad-45a124b9fd90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954732014-172.17.0.19-1597095679327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35144,DS-3b3fd97c-b1a0-4a79-9d24-b19d16bd7739,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-6796bf10-bb1f-4963-b67c-4c25d6b99c91,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-1c34a018-5e91-47a4-9aec-5b4102192e60,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-5b6c19d1-46a7-4cb3-ba16-4781c5edae49,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-a5357430-7d5b-461c-9a5b-1314ce44856d,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-18b34d37-ed93-4d97-95c7-6f32f0bceaef,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-3bc5cdbb-403e-4c2e-b738-d95c0385f3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-e5984381-b762-4747-85ad-45a124b9fd90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503018993-172.17.0.19-1597095868794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33648,DS-d6ed37b5-3104-4312-b08e-976ce9244c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-08b97b90-905b-432c-b5a1-b953a278fc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-d0cadaa2-b505-4b60-9e92-cad8e437ff73,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-35e72132-fe2c-4837-b217-f9736a903ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-123c16e5-64d1-4d70-9de4-981f8a7b246a,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-ac11cfb2-365b-4721-a969-4a7c4ef2f1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-ea4a6f05-accb-4408-820f-445af5dfb94d,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-cdc234fe-a398-46e5-8da6-cbf3d70232bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503018993-172.17.0.19-1597095868794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33648,DS-d6ed37b5-3104-4312-b08e-976ce9244c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-08b97b90-905b-432c-b5a1-b953a278fc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-d0cadaa2-b505-4b60-9e92-cad8e437ff73,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-35e72132-fe2c-4837-b217-f9736a903ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-123c16e5-64d1-4d70-9de4-981f8a7b246a,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-ac11cfb2-365b-4721-a969-4a7c4ef2f1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-ea4a6f05-accb-4408-820f-445af5dfb94d,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-cdc234fe-a398-46e5-8da6-cbf3d70232bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035206674-172.17.0.19-1597096099385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39138,DS-42e1691c-e030-40c4-9ce4-655a7fa34f29,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-46296a52-176c-42db-b59d-9a47a5dc65df,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-5ed40737-8190-4b31-88c3-25c300460f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-0ce473e0-cb93-4a86-8fcf-944ca4734aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-c40d1983-64e0-4192-a0c0-12fe8c3d383e,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-af9232b0-8e20-406d-bff7-caa6cf48aed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-f4d49d08-8595-4ad0-82af-507c82af1be8,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-714e6aa4-0000-476c-b560-326895d0a5c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035206674-172.17.0.19-1597096099385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39138,DS-42e1691c-e030-40c4-9ce4-655a7fa34f29,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-46296a52-176c-42db-b59d-9a47a5dc65df,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-5ed40737-8190-4b31-88c3-25c300460f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-0ce473e0-cb93-4a86-8fcf-944ca4734aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-c40d1983-64e0-4192-a0c0-12fe8c3d383e,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-af9232b0-8e20-406d-bff7-caa6cf48aed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-f4d49d08-8595-4ad0-82af-507c82af1be8,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-714e6aa4-0000-476c-b560-326895d0a5c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389821977-172.17.0.19-1597096246066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33650,DS-2e793210-6e18-4ac2-bff0-78643b72eb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-a771f643-ee58-4dd1-8a3d-51c6dc97a55c,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-071075f3-c213-4584-9053-9d3db33818be,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-56aa4bf3-1782-49f1-ad9f-97acb6eb9b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-6412e565-169c-43b0-ae02-67e0fad1d64f,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-b6b915b8-d1f4-4a8b-8003-a5823742abda,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-37074b10-2215-44b8-8307-e5a3d694e2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-bab0cb59-d517-467f-a713-51ad1e6ef484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389821977-172.17.0.19-1597096246066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33650,DS-2e793210-6e18-4ac2-bff0-78643b72eb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-a771f643-ee58-4dd1-8a3d-51c6dc97a55c,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-071075f3-c213-4584-9053-9d3db33818be,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-56aa4bf3-1782-49f1-ad9f-97acb6eb9b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-6412e565-169c-43b0-ae02-67e0fad1d64f,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-b6b915b8-d1f4-4a8b-8003-a5823742abda,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-37074b10-2215-44b8-8307-e5a3d694e2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-bab0cb59-d517-467f-a713-51ad1e6ef484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467373112-172.17.0.19-1597096464553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40421,DS-95519c9c-cd40-48c6-906d-e2d1d1fe58b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-631e11e3-4d3e-4eeb-b17c-11b07cea1596,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-5cbddd17-c2cc-4eac-9a93-69f31c4f8af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-92a0aaa6-6245-4725-82dd-0b2c44ff4e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-7ddf4f1d-1426-4ecb-8916-09680146e479,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-67c00edf-90b4-44bd-8366-3a024788a888,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-3d011d4d-7071-44d2-b2c6-41690678e544,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-67ae4dc6-f8cc-4f58-930e-a5f3de73331b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467373112-172.17.0.19-1597096464553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40421,DS-95519c9c-cd40-48c6-906d-e2d1d1fe58b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-631e11e3-4d3e-4eeb-b17c-11b07cea1596,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-5cbddd17-c2cc-4eac-9a93-69f31c4f8af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-92a0aaa6-6245-4725-82dd-0b2c44ff4e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-7ddf4f1d-1426-4ecb-8916-09680146e479,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-67c00edf-90b4-44bd-8366-3a024788a888,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-3d011d4d-7071-44d2-b2c6-41690678e544,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-67ae4dc6-f8cc-4f58-930e-a5f3de73331b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326101088-172.17.0.19-1597097428410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38440,DS-b9dc9f98-dd3e-4e47-a75a-265b9d2e7f11,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-93979d02-9617-4110-9068-eaea80e96524,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-c65e1084-549e-4a73-91b9-00363b58e7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-031a1559-fe11-4f01-92bc-3b875cdcedb3,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-ef7e0c1f-db37-4533-b8e7-e75515141a65,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-9557a87d-a4cb-4c28-9d64-89f3d82bfd53,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-10387f9e-0a27-4ae3-b349-e2eae5422b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-82d9b17e-9cff-4b39-8d37-0343e1fcfa1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326101088-172.17.0.19-1597097428410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38440,DS-b9dc9f98-dd3e-4e47-a75a-265b9d2e7f11,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-93979d02-9617-4110-9068-eaea80e96524,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-c65e1084-549e-4a73-91b9-00363b58e7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-031a1559-fe11-4f01-92bc-3b875cdcedb3,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-ef7e0c1f-db37-4533-b8e7-e75515141a65,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-9557a87d-a4cb-4c28-9d64-89f3d82bfd53,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-10387f9e-0a27-4ae3-b349-e2eae5422b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-82d9b17e-9cff-4b39-8d37-0343e1fcfa1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397773913-172.17.0.19-1597097468084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34619,DS-999377c1-b589-4350-8ceb-afcd82afa896,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-31df2208-0ea6-4f3e-978b-8440664db086,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-7734587e-9ab0-46e3-802e-199f10a073cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-1be2dc2f-a309-4b93-bb30-7dc48e2aedca,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-ec778f6b-6c62-4419-8c73-9fb611049b84,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-d8dd0da2-5d01-4731-8dd5-b372cfc349d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-7d0e0ac7-aae2-4726-b7f7-baeb5610d492,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-8aac61c7-81ef-4f16-aca4-46842eda110d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397773913-172.17.0.19-1597097468084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34619,DS-999377c1-b589-4350-8ceb-afcd82afa896,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-31df2208-0ea6-4f3e-978b-8440664db086,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-7734587e-9ab0-46e3-802e-199f10a073cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-1be2dc2f-a309-4b93-bb30-7dc48e2aedca,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-ec778f6b-6c62-4419-8c73-9fb611049b84,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-d8dd0da2-5d01-4731-8dd5-b372cfc349d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-7d0e0ac7-aae2-4726-b7f7-baeb5610d492,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-8aac61c7-81ef-4f16-aca4-46842eda110d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777909160-172.17.0.19-1597097945944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34762,DS-a34228ea-e78e-492b-a6e7-87c35db017c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-20a917e6-d524-48da-a451-6678b7c2cff3,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-2aac63e6-3e09-442e-9827-114387630cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-7dd9ca25-4afd-40dd-9588-3853e6005fed,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-efceca47-930a-4038-bff9-75d1ebbf691f,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-23e6d992-7efa-4720-92e6-547df1c6577a,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-8792b1bc-2000-45fa-b5dc-c2907be2f2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-0e57ef54-d24f-4a33-b9ff-f1b8b2c60906,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777909160-172.17.0.19-1597097945944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34762,DS-a34228ea-e78e-492b-a6e7-87c35db017c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-20a917e6-d524-48da-a451-6678b7c2cff3,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-2aac63e6-3e09-442e-9827-114387630cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-7dd9ca25-4afd-40dd-9588-3853e6005fed,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-efceca47-930a-4038-bff9-75d1ebbf691f,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-23e6d992-7efa-4720-92e6-547df1c6577a,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-8792b1bc-2000-45fa-b5dc-c2907be2f2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-0e57ef54-d24f-4a33-b9ff-f1b8b2c60906,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253987288-172.17.0.19-1597098315838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39602,DS-73e1e367-3f42-47f7-8adb-60507bd373a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-f8aa1bd0-dba7-4d0b-9b1a-8eab84ee3436,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-e581ee73-fd76-4ae4-8899-a9f1e7fd8e20,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-2a752edb-9555-4187-90eb-c8b0b50b989f,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-a4334441-cf85-44db-9e20-f3ccc587ff96,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-ba5294ab-d2b9-49b1-858d-76c6e6adee6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-ef4fad5b-c174-4b40-8a06-b1c21f9477d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-44a8e0f1-b7c5-4781-be1d-8707f70f2a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253987288-172.17.0.19-1597098315838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39602,DS-73e1e367-3f42-47f7-8adb-60507bd373a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-f8aa1bd0-dba7-4d0b-9b1a-8eab84ee3436,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-e581ee73-fd76-4ae4-8899-a9f1e7fd8e20,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-2a752edb-9555-4187-90eb-c8b0b50b989f,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-a4334441-cf85-44db-9e20-f3ccc587ff96,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-ba5294ab-d2b9-49b1-858d-76c6e6adee6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-ef4fad5b-c174-4b40-8a06-b1c21f9477d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-44a8e0f1-b7c5-4781-be1d-8707f70f2a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5667
