reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1542785629-172.17.0.13-1597103464741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44012,DS-e34744af-d3f1-4a14-99fc-e54d185e03fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-541f216a-49ba-4b94-8a16-886265728fda,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-60705168-4228-425a-97bd-3da160de90b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-c544280c-3f5b-40d9-ac02-afbb8b856471,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-be680982-bcf1-4016-afbb-2f33526e5ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-2f8026c1-6b02-46c9-8ca8-6b84af23a29a,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-e2e5b17e-8aa9-44f6-91ef-068159dea85e,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-1be56cf1-1acc-449d-8183-19f554b23045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1542785629-172.17.0.13-1597103464741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44012,DS-e34744af-d3f1-4a14-99fc-e54d185e03fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-541f216a-49ba-4b94-8a16-886265728fda,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-60705168-4228-425a-97bd-3da160de90b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-c544280c-3f5b-40d9-ac02-afbb8b856471,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-be680982-bcf1-4016-afbb-2f33526e5ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-2f8026c1-6b02-46c9-8ca8-6b84af23a29a,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-e2e5b17e-8aa9-44f6-91ef-068159dea85e,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-1be56cf1-1acc-449d-8183-19f554b23045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327339747-172.17.0.13-1597103637181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39939,DS-58e40511-31c4-4f4a-8206-954c05ecbecd,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-e2ffe0d9-9920-480e-966f-74a970594465,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-84e8580c-9991-45bb-9c86-3adbbbe0b791,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-aa015771-9cbf-4a11-8dd2-2ed136b38f81,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-3c57a0cb-de71-4229-ba46-48426654a5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-5d1a37d4-5976-4885-88e8-ef630edb65f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-166c58da-625a-4b9f-bacd-237a8d5c5127,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-3ebad070-f70f-4340-b09d-ce8bd22b1d9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327339747-172.17.0.13-1597103637181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39939,DS-58e40511-31c4-4f4a-8206-954c05ecbecd,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-e2ffe0d9-9920-480e-966f-74a970594465,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-84e8580c-9991-45bb-9c86-3adbbbe0b791,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-aa015771-9cbf-4a11-8dd2-2ed136b38f81,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-3c57a0cb-de71-4229-ba46-48426654a5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-5d1a37d4-5976-4885-88e8-ef630edb65f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-166c58da-625a-4b9f-bacd-237a8d5c5127,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-3ebad070-f70f-4340-b09d-ce8bd22b1d9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615618475-172.17.0.13-1597104047421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34388,DS-f923f669-1d34-4f36-ba0e-69cb627ee8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-3224df75-8dda-4c91-892f-9d53f8ac9545,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-899eb3ec-dcfa-47eb-9496-38e04bfacfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-6a3573d1-0e87-4bec-b31a-3c27dc7f94f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-927133db-1052-437b-8a08-41676e5214e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-26d585ee-d168-4776-ba21-fd9a59e44d52,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-a52c518f-8ec4-404a-94cd-400e25d64930,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-8cb48777-bc16-4e9f-a775-0d9ca438e8bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615618475-172.17.0.13-1597104047421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34388,DS-f923f669-1d34-4f36-ba0e-69cb627ee8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-3224df75-8dda-4c91-892f-9d53f8ac9545,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-899eb3ec-dcfa-47eb-9496-38e04bfacfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-6a3573d1-0e87-4bec-b31a-3c27dc7f94f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-927133db-1052-437b-8a08-41676e5214e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-26d585ee-d168-4776-ba21-fd9a59e44d52,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-a52c518f-8ec4-404a-94cd-400e25d64930,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-8cb48777-bc16-4e9f-a775-0d9ca438e8bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174892083-172.17.0.13-1597104310046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38003,DS-1a2ed7a6-da2f-415b-986e-96d124d007e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-1e671c59-1782-47d6-aa3e-6f0232e544b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-6ed0c3d1-8c4b-4f3f-a25c-6f5cdb22e0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-af9126bf-189d-438b-88e9-2e635195c201,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-1aefed89-0350-468b-9d11-5e2e61dc3f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-b79f900d-7ceb-4b5e-95b5-bf22289c3520,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-e5486108-38bb-4e2e-bb26-f3d2e917102e,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-a565f4d8-bc1c-4418-b8c1-71d3917e9259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174892083-172.17.0.13-1597104310046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38003,DS-1a2ed7a6-da2f-415b-986e-96d124d007e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-1e671c59-1782-47d6-aa3e-6f0232e544b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-6ed0c3d1-8c4b-4f3f-a25c-6f5cdb22e0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-af9126bf-189d-438b-88e9-2e635195c201,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-1aefed89-0350-468b-9d11-5e2e61dc3f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-b79f900d-7ceb-4b5e-95b5-bf22289c3520,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-e5486108-38bb-4e2e-bb26-f3d2e917102e,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-a565f4d8-bc1c-4418-b8c1-71d3917e9259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129899055-172.17.0.13-1597105150976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-e1eddba3-2fbe-4823-82c4-1c93d3c13bba,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-aab240c8-7f99-49f5-8f3a-470f2051ff8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-da9ce359-1aef-46ed-90f4-4c4c77d7c8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-b049640f-f33b-422a-b461-a360d8114780,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-254d7766-ca9e-45db-8a85-da05f7edd220,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-6e5413cc-4a99-4224-97b7-fca411395de1,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-ac2b6981-07e6-468e-ac63-16493ab21e80,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-15f96cf9-d6a8-40fb-9cc8-8c2a9b997c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129899055-172.17.0.13-1597105150976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-e1eddba3-2fbe-4823-82c4-1c93d3c13bba,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-aab240c8-7f99-49f5-8f3a-470f2051ff8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-da9ce359-1aef-46ed-90f4-4c4c77d7c8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-b049640f-f33b-422a-b461-a360d8114780,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-254d7766-ca9e-45db-8a85-da05f7edd220,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-6e5413cc-4a99-4224-97b7-fca411395de1,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-ac2b6981-07e6-468e-ac63-16493ab21e80,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-15f96cf9-d6a8-40fb-9cc8-8c2a9b997c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129938597-172.17.0.13-1597106021306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41927,DS-7dd82464-eb13-4885-aa8e-55e27a519104,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-3a52c8a1-447c-4f3d-8a91-d6150e2e2953,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-50665aef-7ef0-4d61-a219-34b55af633d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-317f5293-9369-4e31-8e07-7ff912a54950,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-59432590-715a-484e-bd33-b586db5c869f,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-4ae5cb2c-902c-41ed-a107-3e7ac0e66bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-db303ca6-edf7-461c-abff-6f7b91f152aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-e6beff32-7bca-416a-b3ac-a45fe46523e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129938597-172.17.0.13-1597106021306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41927,DS-7dd82464-eb13-4885-aa8e-55e27a519104,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-3a52c8a1-447c-4f3d-8a91-d6150e2e2953,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-50665aef-7ef0-4d61-a219-34b55af633d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-317f5293-9369-4e31-8e07-7ff912a54950,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-59432590-715a-484e-bd33-b586db5c869f,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-4ae5cb2c-902c-41ed-a107-3e7ac0e66bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-db303ca6-edf7-461c-abff-6f7b91f152aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-e6beff32-7bca-416a-b3ac-a45fe46523e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574743998-172.17.0.13-1597106475832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35452,DS-dbe35386-f4dc-4056-8f8c-4701a5fc8761,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-a2e104ce-afc9-48a8-9d22-fe06d515c194,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-60d292cd-9f83-43fa-9abe-31ca9392decf,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-1c5c5554-a74e-45ed-8b8e-94c42998b12f,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-a91ff6cb-4715-405e-8477-499589852bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-31ca6580-3933-4cf2-a627-73ecf5feb99a,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-ac65b31e-724a-4fac-9909-9d9a21c7680a,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-ba700062-8056-4d8f-a7bd-b3b1aa85c271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574743998-172.17.0.13-1597106475832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35452,DS-dbe35386-f4dc-4056-8f8c-4701a5fc8761,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-a2e104ce-afc9-48a8-9d22-fe06d515c194,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-60d292cd-9f83-43fa-9abe-31ca9392decf,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-1c5c5554-a74e-45ed-8b8e-94c42998b12f,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-a91ff6cb-4715-405e-8477-499589852bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-31ca6580-3933-4cf2-a627-73ecf5feb99a,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-ac65b31e-724a-4fac-9909-9d9a21c7680a,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-ba700062-8056-4d8f-a7bd-b3b1aa85c271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1315544850-172.17.0.13-1597106831035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36061,DS-c8ccaab3-816f-4898-b68f-adc30e32decb,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-fd7dc416-d6e5-4436-8584-96c31bb388b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-e222a83d-0fed-4841-8cd4-26a3c6f6aaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-4cad28a0-d6a6-47af-a257-31c30d235beb,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-aa4969ae-36f2-4531-a2d1-2f2414d44aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-0f0975fa-6568-4555-838f-4d941fd487c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-6ed8d1d9-0f47-4be3-8049-5a18d3c68e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-177398f4-f35d-4056-9aab-0e9c54a22c23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1315544850-172.17.0.13-1597106831035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36061,DS-c8ccaab3-816f-4898-b68f-adc30e32decb,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-fd7dc416-d6e5-4436-8584-96c31bb388b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-e222a83d-0fed-4841-8cd4-26a3c6f6aaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-4cad28a0-d6a6-47af-a257-31c30d235beb,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-aa4969ae-36f2-4531-a2d1-2f2414d44aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-0f0975fa-6568-4555-838f-4d941fd487c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-6ed8d1d9-0f47-4be3-8049-5a18d3c68e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-177398f4-f35d-4056-9aab-0e9c54a22c23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817319832-172.17.0.13-1597106975512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43302,DS-2ab1ad6c-8efc-4f33-9174-fc426db40445,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-ef83e323-1f23-4544-9acd-ec4dabd9e5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-21b50f4e-d09a-4546-88e3-24f04b1bbd34,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-050ff7d2-7b04-4397-a90e-ee601cadec1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-9c185f03-22e0-4ff5-a75a-d5cadaa6928a,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-7de93070-c250-4610-be1f-b12e805ceede,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-a85f9915-1a42-439f-81ec-1d14a903e304,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-51b22e56-740a-4525-8ec8-5b35c4c5b6d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817319832-172.17.0.13-1597106975512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43302,DS-2ab1ad6c-8efc-4f33-9174-fc426db40445,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-ef83e323-1f23-4544-9acd-ec4dabd9e5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-21b50f4e-d09a-4546-88e3-24f04b1bbd34,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-050ff7d2-7b04-4397-a90e-ee601cadec1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-9c185f03-22e0-4ff5-a75a-d5cadaa6928a,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-7de93070-c250-4610-be1f-b12e805ceede,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-a85f9915-1a42-439f-81ec-1d14a903e304,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-51b22e56-740a-4525-8ec8-5b35c4c5b6d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1962735742-172.17.0.13-1597107152577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45482,DS-bcb167de-d90f-4922-84ea-11bd4e52593b,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-6028dde0-84a8-4c20-b22a-47e17c2afe45,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-4d3a6cde-f39c-49de-a2f1-bd04f1408903,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-9c2b066c-a900-4b54-a6a9-5c53f7fae262,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-a5daf6b6-27ee-4c5d-9508-72f4369c40e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-cd5170ca-c825-4272-bc3d-1a149a3b6c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-d922ebd6-61ef-4250-92e8-2e94e81cafbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-c9661670-a33f-4779-b0a5-8f39beb12235,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1962735742-172.17.0.13-1597107152577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45482,DS-bcb167de-d90f-4922-84ea-11bd4e52593b,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-6028dde0-84a8-4c20-b22a-47e17c2afe45,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-4d3a6cde-f39c-49de-a2f1-bd04f1408903,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-9c2b066c-a900-4b54-a6a9-5c53f7fae262,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-a5daf6b6-27ee-4c5d-9508-72f4369c40e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-cd5170ca-c825-4272-bc3d-1a149a3b6c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-d922ebd6-61ef-4250-92e8-2e94e81cafbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-c9661670-a33f-4779-b0a5-8f39beb12235,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587216053-172.17.0.13-1597107239257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35034,DS-15043d89-21ab-4281-9dfe-dd5615c6ab6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-66aa4004-1151-4ab7-a4e3-36bd38931b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-279265f5-1549-4498-971d-b7752dde33a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-608c98b6-70c2-4b36-a6b1-634f590f4324,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-3edc6c01-9708-42eb-a8b7-08d51caf637d,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-09d99e25-6a27-4198-ad81-03a536271d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-3250fdc1-49e9-455d-909c-447ae9957867,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-58ca824b-f942-4a8d-9223-2de2df0cccb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587216053-172.17.0.13-1597107239257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35034,DS-15043d89-21ab-4281-9dfe-dd5615c6ab6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-66aa4004-1151-4ab7-a4e3-36bd38931b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-279265f5-1549-4498-971d-b7752dde33a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-608c98b6-70c2-4b36-a6b1-634f590f4324,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-3edc6c01-9708-42eb-a8b7-08d51caf637d,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-09d99e25-6a27-4198-ad81-03a536271d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-3250fdc1-49e9-455d-909c-447ae9957867,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-58ca824b-f942-4a8d-9223-2de2df0cccb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292563832-172.17.0.13-1597107330909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42290,DS-a2e2d382-1321-4903-a133-3d346117b05c,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-486634a9-d252-4e2a-9068-86c6bb3bf74e,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-94e23f6d-ffc0-4f00-962e-4cdb62ff6c35,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-a4f2ec9c-d927-40dd-9a76-85c9ad6d8a12,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-b4c6f3a5-edd9-464f-b66e-da3676a97366,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-5d2db518-7d64-455c-882f-b94dbb907fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-efd95349-3264-4c57-b0ec-4ef1d9d093ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-289aea61-9e51-47fc-9dad-ea044d7fd663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292563832-172.17.0.13-1597107330909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42290,DS-a2e2d382-1321-4903-a133-3d346117b05c,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-486634a9-d252-4e2a-9068-86c6bb3bf74e,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-94e23f6d-ffc0-4f00-962e-4cdb62ff6c35,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-a4f2ec9c-d927-40dd-9a76-85c9ad6d8a12,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-b4c6f3a5-edd9-464f-b66e-da3676a97366,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-5d2db518-7d64-455c-882f-b94dbb907fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-efd95349-3264-4c57-b0ec-4ef1d9d093ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-289aea61-9e51-47fc-9dad-ea044d7fd663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306058565-172.17.0.13-1597107381050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37039,DS-4ab8e63f-86ce-45a0-b380-d9ea16bc3d09,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-2cf7ebce-175d-4c5c-9f3d-80c440f563b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-f1641cd8-9e9a-45b4-86d6-b74a19127de9,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-7848a7f3-cb6c-48c3-9654-fc139fb3aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-70ec3ab8-b67e-472f-958b-9f5dd1aa19cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-d060547a-18e3-44f5-8904-30da84a10098,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-84827f10-e1c7-466f-adff-7cfadc275aae,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-920e9641-c0dd-4577-a885-079ee2df980f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306058565-172.17.0.13-1597107381050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37039,DS-4ab8e63f-86ce-45a0-b380-d9ea16bc3d09,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-2cf7ebce-175d-4c5c-9f3d-80c440f563b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-f1641cd8-9e9a-45b4-86d6-b74a19127de9,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-7848a7f3-cb6c-48c3-9654-fc139fb3aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-70ec3ab8-b67e-472f-958b-9f5dd1aa19cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-d060547a-18e3-44f5-8904-30da84a10098,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-84827f10-e1c7-466f-adff-7cfadc275aae,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-920e9641-c0dd-4577-a885-079ee2df980f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903605075-172.17.0.13-1597107504501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41391,DS-88c56ccd-136e-4e1a-b087-6e386aadc33c,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-d03c859e-b4e2-4c0a-b13a-1184b347d13a,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-e5700fcc-8f20-4262-ae02-cb584cb367ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-e4be3dd5-3bb7-4a91-9da3-dcbdffc4256b,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-5e5365dd-cd8d-40f0-bcf2-295d6272d89e,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-803cc911-901f-451a-ab08-4f85c6791883,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-c5e02ec7-bc22-48fa-b6c6-1ef2f1f04f08,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-b4cf055b-ed2b-472d-bbba-fc1b4f40eb38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903605075-172.17.0.13-1597107504501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41391,DS-88c56ccd-136e-4e1a-b087-6e386aadc33c,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-d03c859e-b4e2-4c0a-b13a-1184b347d13a,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-e5700fcc-8f20-4262-ae02-cb584cb367ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-e4be3dd5-3bb7-4a91-9da3-dcbdffc4256b,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-5e5365dd-cd8d-40f0-bcf2-295d6272d89e,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-803cc911-901f-451a-ab08-4f85c6791883,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-c5e02ec7-bc22-48fa-b6c6-1ef2f1f04f08,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-b4cf055b-ed2b-472d-bbba-fc1b4f40eb38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519159902-172.17.0.13-1597107778658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46821,DS-575bf5d1-528b-474b-a7e9-d0a933efe65f,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-9e989518-d833-448b-8748-3c25fd914b60,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-482ca72f-5325-4d25-942b-1027a8b83f93,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-531a63a7-a75e-4402-85d3-2f00e7d857de,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-30cd57a2-78f8-4a55-9c86-c44fcebaa553,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-a09a7212-a12b-478e-96f7-a73cee666f40,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-e3030345-9950-4a3a-9506-8b0aec7f62ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-5a6f552a-f031-4e6e-a02d-99beee290de9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519159902-172.17.0.13-1597107778658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46821,DS-575bf5d1-528b-474b-a7e9-d0a933efe65f,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-9e989518-d833-448b-8748-3c25fd914b60,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-482ca72f-5325-4d25-942b-1027a8b83f93,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-531a63a7-a75e-4402-85d3-2f00e7d857de,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-30cd57a2-78f8-4a55-9c86-c44fcebaa553,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-a09a7212-a12b-478e-96f7-a73cee666f40,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-e3030345-9950-4a3a-9506-8b0aec7f62ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-5a6f552a-f031-4e6e-a02d-99beee290de9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129257607-172.17.0.13-1597108395516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46626,DS-8a8ff225-abeb-403b-ad69-73ed365cf98e,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-5178062e-9d17-45f9-9c62-3385f0db3f83,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-7a5955d8-7e74-41aa-ad2d-b132c689fe1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-12a5de52-7a35-4064-8c24-40908a832ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-62697098-6eb0-4e94-915e-eca4deec0763,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-44d1df55-7004-4b3e-8e5f-8773055f1091,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-bd75a896-63ee-4d06-9d59-5f177db5ed40,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-c5fbefa0-d2fc-4b3f-9ed6-a62b5b5982a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2129257607-172.17.0.13-1597108395516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46626,DS-8a8ff225-abeb-403b-ad69-73ed365cf98e,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-5178062e-9d17-45f9-9c62-3385f0db3f83,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-7a5955d8-7e74-41aa-ad2d-b132c689fe1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-12a5de52-7a35-4064-8c24-40908a832ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-62697098-6eb0-4e94-915e-eca4deec0763,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-44d1df55-7004-4b3e-8e5f-8773055f1091,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-bd75a896-63ee-4d06-9d59-5f177db5ed40,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-c5fbefa0-d2fc-4b3f-9ed6-a62b5b5982a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826521035-172.17.0.13-1597108760764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38530,DS-c00af4bc-d36b-48d6-996d-de0b4741be43,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-395b0940-2fc7-416d-873d-3c277d5a2d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-664ddb77-64ec-45eb-b5f1-ab1b761508b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-22aede0d-8d29-43dd-815a-d1e06d6659af,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-a1bc10a1-7b8b-4595-b704-816539185b89,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-b7838aee-9473-47c3-8654-f92383531a08,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-f2e8d6d2-bb12-454f-b227-2ea97a21a88c,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-748b6992-c926-47b2-896a-e081dc33dd7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826521035-172.17.0.13-1597108760764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38530,DS-c00af4bc-d36b-48d6-996d-de0b4741be43,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-395b0940-2fc7-416d-873d-3c277d5a2d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-664ddb77-64ec-45eb-b5f1-ab1b761508b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-22aede0d-8d29-43dd-815a-d1e06d6659af,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-a1bc10a1-7b8b-4595-b704-816539185b89,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-b7838aee-9473-47c3-8654-f92383531a08,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-f2e8d6d2-bb12-454f-b227-2ea97a21a88c,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-748b6992-c926-47b2-896a-e081dc33dd7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67737061-172.17.0.13-1597108847871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33417,DS-85c68711-51de-4cde-96f5-416b6659c3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-1d7167d4-9505-48cf-a1e9-326b392137ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-1aa446eb-e4d0-4404-a834-da9dffd85cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-29f35f6a-6e61-40db-a5d3-2e0f406f2895,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-d95440e1-742d-4509-b706-549c601b1a33,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-0e85cfe9-a0ae-488e-af44-15aa4acd055c,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-14d4d54e-4084-4fcd-a53d-37e6cce5caa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-bac25fdc-65f6-4075-847e-143ba313bac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67737061-172.17.0.13-1597108847871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33417,DS-85c68711-51de-4cde-96f5-416b6659c3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-1d7167d4-9505-48cf-a1e9-326b392137ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-1aa446eb-e4d0-4404-a834-da9dffd85cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-29f35f6a-6e61-40db-a5d3-2e0f406f2895,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-d95440e1-742d-4509-b706-549c601b1a33,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-0e85cfe9-a0ae-488e-af44-15aa4acd055c,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-14d4d54e-4084-4fcd-a53d-37e6cce5caa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-bac25fdc-65f6-4075-847e-143ba313bac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-195261915-172.17.0.13-1597108901202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42183,DS-c8a4d460-c69a-4847-952e-45fb2c534a64,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-5f5212b7-0cdb-4833-ba6e-823b75613914,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-2b818b9f-1c8e-4da6-8923-55d9ec61bd46,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-d39e8549-99b2-4fd8-b3c8-ef7b3c69c43f,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-cb89c291-f236-4223-a0d4-a0a137ce51f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-3ac842fb-4d3f-455b-b8fe-ada741dccc88,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-824f4694-878d-4009-9755-1cd84d62c760,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-8a5bad5f-bc78-4ae1-9dfa-8ded65a5504d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-195261915-172.17.0.13-1597108901202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42183,DS-c8a4d460-c69a-4847-952e-45fb2c534a64,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-5f5212b7-0cdb-4833-ba6e-823b75613914,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-2b818b9f-1c8e-4da6-8923-55d9ec61bd46,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-d39e8549-99b2-4fd8-b3c8-ef7b3c69c43f,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-cb89c291-f236-4223-a0d4-a0a137ce51f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-3ac842fb-4d3f-455b-b8fe-ada741dccc88,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-824f4694-878d-4009-9755-1cd84d62c760,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-8a5bad5f-bc78-4ae1-9dfa-8ded65a5504d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1636652437-172.17.0.13-1597108984194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42890,DS-693de80c-bebf-4c62-a589-87f9d2ee0fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-40346891-b889-4643-90cc-6ca00d41282e,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-be9db5ae-d1ce-43ab-a177-a7d6342c8b18,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-5aa67dfb-0e2f-4b3a-81b1-d53be370cd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-244eb5cd-804e-4651-9c58-d538851ed85d,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-52a693ad-7643-47bc-b42e-8e771c0c0fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-2fbeeeec-bc32-4c80-aea0-27cd7ba5b942,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-9b0ec339-9da9-4833-9150-aee3ac8dd790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1636652437-172.17.0.13-1597108984194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42890,DS-693de80c-bebf-4c62-a589-87f9d2ee0fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-40346891-b889-4643-90cc-6ca00d41282e,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-be9db5ae-d1ce-43ab-a177-a7d6342c8b18,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-5aa67dfb-0e2f-4b3a-81b1-d53be370cd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-244eb5cd-804e-4651-9c58-d538851ed85d,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-52a693ad-7643-47bc-b42e-8e771c0c0fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-2fbeeeec-bc32-4c80-aea0-27cd7ba5b942,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-9b0ec339-9da9-4833-9150-aee3ac8dd790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-41570499-172.17.0.13-1597109153697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43728,DS-0b8b313f-93c1-4385-9e48-35d60a4f58d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-dee6bd8c-81b6-4b84-9d3e-739c655eb096,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-de75034f-037d-4817-a308-76a491a936d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-c8e8d5d3-a723-4535-9740-8859ff6458db,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-30209b60-9b5a-4738-afbd-0849a0e1d77c,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-cda4a086-f1aa-4de1-9112-ea712c088752,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-a16da669-b24f-473a-9e39-dde1031fcecd,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-d78dc6d8-d4c5-4263-ab32-c665f64576cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-41570499-172.17.0.13-1597109153697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43728,DS-0b8b313f-93c1-4385-9e48-35d60a4f58d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-dee6bd8c-81b6-4b84-9d3e-739c655eb096,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-de75034f-037d-4817-a308-76a491a936d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-c8e8d5d3-a723-4535-9740-8859ff6458db,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-30209b60-9b5a-4738-afbd-0849a0e1d77c,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-cda4a086-f1aa-4de1-9112-ea712c088752,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-a16da669-b24f-473a-9e39-dde1031fcecd,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-d78dc6d8-d4c5-4263-ab32-c665f64576cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6650
