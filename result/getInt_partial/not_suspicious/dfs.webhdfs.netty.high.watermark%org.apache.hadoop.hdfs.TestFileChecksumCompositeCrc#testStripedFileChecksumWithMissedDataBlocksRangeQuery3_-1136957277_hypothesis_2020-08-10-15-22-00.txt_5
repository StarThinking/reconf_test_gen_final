reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1411411135-172.17.0.16-1597073230552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37682,DS-a25cc058-dcc2-4a62-93a4-9eb796b0064a,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-c91894f1-6470-4991-a930-92eef4439bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-c493880e-ffa1-4b51-b7f2-4555aedd8de7,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-6eb141a4-bab5-4248-8438-ffdd296305d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-d353d1eb-0bd2-4be9-a119-64c85da8137b,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-cc4ae6f1-6038-4bce-9309-20987faef3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-3f5091f1-12e9-4542-a813-baa4bd1c8479,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-23acba8f-a65d-4b92-ac5a-b02d1cb324a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1411411135-172.17.0.16-1597073230552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37682,DS-a25cc058-dcc2-4a62-93a4-9eb796b0064a,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-c91894f1-6470-4991-a930-92eef4439bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-c493880e-ffa1-4b51-b7f2-4555aedd8de7,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-6eb141a4-bab5-4248-8438-ffdd296305d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-d353d1eb-0bd2-4be9-a119-64c85da8137b,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-cc4ae6f1-6038-4bce-9309-20987faef3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-3f5091f1-12e9-4542-a813-baa4bd1c8479,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-23acba8f-a65d-4b92-ac5a-b02d1cb324a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399829616-172.17.0.16-1597073718618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44743,DS-262f5f58-ab16-464f-a8bc-e9afb78813c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-fe5e6b88-0770-4ea5-ab56-ab55924334ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-7218b429-ee2f-4c20-bfff-23ba6815733d,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-a0610c86-fbc9-4c7d-8fd1-38697d195481,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-5a56b0d3-de6b-4119-af06-22bdfe3ae063,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-b1c1303b-32eb-4bfc-b934-7382b51fa108,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-e8d91f96-f3f4-4761-a403-cb8697ecd2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-0c9ec01d-4a50-4558-a045-72fccbfdc06e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399829616-172.17.0.16-1597073718618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44743,DS-262f5f58-ab16-464f-a8bc-e9afb78813c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-fe5e6b88-0770-4ea5-ab56-ab55924334ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-7218b429-ee2f-4c20-bfff-23ba6815733d,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-a0610c86-fbc9-4c7d-8fd1-38697d195481,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-5a56b0d3-de6b-4119-af06-22bdfe3ae063,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-b1c1303b-32eb-4bfc-b934-7382b51fa108,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-e8d91f96-f3f4-4761-a403-cb8697ecd2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-0c9ec01d-4a50-4558-a045-72fccbfdc06e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032902140-172.17.0.16-1597075191192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44562,DS-925b2dab-aff7-4e28-ba5d-15340c66fc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-2adc4e34-dd7f-4090-b087-29e53345c4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-5ef5ee43-8a9b-4f01-8ba7-1853dc458a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-1e52faba-6d4b-4a09-ab73-0f105ad41771,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-4536f2df-ba04-489e-8a57-adf1dbb6923d,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-7cd87404-d10d-42a9-b59e-4084cbdae3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-111cfca4-4ef8-4cc2-a688-ac86fe640a99,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-e0e2cbc2-2858-46da-8b09-7b5cb01d8a13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032902140-172.17.0.16-1597075191192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44562,DS-925b2dab-aff7-4e28-ba5d-15340c66fc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-2adc4e34-dd7f-4090-b087-29e53345c4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-5ef5ee43-8a9b-4f01-8ba7-1853dc458a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-1e52faba-6d4b-4a09-ab73-0f105ad41771,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-4536f2df-ba04-489e-8a57-adf1dbb6923d,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-7cd87404-d10d-42a9-b59e-4084cbdae3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-111cfca4-4ef8-4cc2-a688-ac86fe640a99,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-e0e2cbc2-2858-46da-8b09-7b5cb01d8a13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695319674-172.17.0.16-1597075339308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46101,DS-0bdf0e21-0577-4d60-a3f3-d732c097a5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-b5f1542a-c412-43e4-bb86-0f133e2bdab4,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-ace76369-d2a4-49c8-8a42-513c2ec5597c,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-3262d46d-4695-4f02-bddf-b5dfb1ed474f,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-aa20c79c-1ef4-4d70-8f7d-727c73f406a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-8e99f0e7-dc68-463a-aa42-d8ce65545268,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-f4964ac3-8842-4ee0-aa41-f4f744c2b412,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-13b34ded-03e7-4bef-9037-c92c1f599ea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695319674-172.17.0.16-1597075339308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46101,DS-0bdf0e21-0577-4d60-a3f3-d732c097a5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-b5f1542a-c412-43e4-bb86-0f133e2bdab4,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-ace76369-d2a4-49c8-8a42-513c2ec5597c,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-3262d46d-4695-4f02-bddf-b5dfb1ed474f,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-aa20c79c-1ef4-4d70-8f7d-727c73f406a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-8e99f0e7-dc68-463a-aa42-d8ce65545268,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-f4964ac3-8842-4ee0-aa41-f4f744c2b412,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-13b34ded-03e7-4bef-9037-c92c1f599ea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499706681-172.17.0.16-1597075434149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37257,DS-cf88a2d0-4d27-482c-8274-45bd281ac722,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-89f92092-ad07-4830-88d9-833fa17912c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-0d427673-840b-4006-b896-7e579c0ad14e,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-03803339-e78a-4905-a186-4890e048420e,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-15321977-a05a-4d35-bf30-fc2067b1048c,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-9ffb6e54-269e-4633-a525-4c39b17e163e,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-3f8525de-4153-46a6-992b-0fe9bd5d10c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-c3257e2a-80a2-4afa-b14f-56ad969eb762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499706681-172.17.0.16-1597075434149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37257,DS-cf88a2d0-4d27-482c-8274-45bd281ac722,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-89f92092-ad07-4830-88d9-833fa17912c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-0d427673-840b-4006-b896-7e579c0ad14e,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-03803339-e78a-4905-a186-4890e048420e,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-15321977-a05a-4d35-bf30-fc2067b1048c,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-9ffb6e54-269e-4633-a525-4c39b17e163e,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-3f8525de-4153-46a6-992b-0fe9bd5d10c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-c3257e2a-80a2-4afa-b14f-56ad969eb762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665423786-172.17.0.16-1597075851193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33761,DS-9f729e64-ae43-4572-8e22-cd09a50b59a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-4c9d2a78-1ddb-48f0-a830-3db75fed7d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-7ac273e5-d166-4f23-a79b-323945d3540e,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-6beb752f-4d62-4c10-b816-0de1dfe60892,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-55758b7c-ca13-41ee-9244-72c406c3784b,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-bc10dbf7-29e9-45d1-8695-07d8f0444d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-0e0f2a01-d9c8-4d39-b4cd-724a3ec77bea,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-bf6cb2a7-9242-4d44-b9bb-77743178520e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665423786-172.17.0.16-1597075851193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33761,DS-9f729e64-ae43-4572-8e22-cd09a50b59a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-4c9d2a78-1ddb-48f0-a830-3db75fed7d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-7ac273e5-d166-4f23-a79b-323945d3540e,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-6beb752f-4d62-4c10-b816-0de1dfe60892,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-55758b7c-ca13-41ee-9244-72c406c3784b,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-bc10dbf7-29e9-45d1-8695-07d8f0444d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-0e0f2a01-d9c8-4d39-b4cd-724a3ec77bea,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-bf6cb2a7-9242-4d44-b9bb-77743178520e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059039650-172.17.0.16-1597076358591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40364,DS-8a222a45-536e-4df2-a4f9-ab96f77b305c,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-7b31b117-bd19-4c90-96aa-8d60e294de91,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-fe06d652-95a4-4e99-9aa7-d8c1e3de8139,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-fe487465-74b7-4c7b-bb11-188139e22841,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-134234b1-830a-4bf0-b878-39f7d7aebd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-557a1d3c-8114-4e4e-93b8-412fe0bee3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-6a2366cb-385a-417f-8256-60066dc14699,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-4f2adb27-265f-4516-91e1-365a8d7c9274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059039650-172.17.0.16-1597076358591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40364,DS-8a222a45-536e-4df2-a4f9-ab96f77b305c,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-7b31b117-bd19-4c90-96aa-8d60e294de91,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-fe06d652-95a4-4e99-9aa7-d8c1e3de8139,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-fe487465-74b7-4c7b-bb11-188139e22841,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-134234b1-830a-4bf0-b878-39f7d7aebd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-557a1d3c-8114-4e4e-93b8-412fe0bee3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-6a2366cb-385a-417f-8256-60066dc14699,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-4f2adb27-265f-4516-91e1-365a8d7c9274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962962123-172.17.0.16-1597076411575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34241,DS-3434c52e-82df-4c21-8240-cf3973c998dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-119bbd7f-297a-4e85-a931-b0add84017b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-cdc0d338-44e0-4263-8762-1001d0ee845f,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-0f094a2e-50f6-40de-abcf-a023930f4e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-eb0b317e-ee62-4a6b-afb7-06baeeaf8bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-33494e40-2943-4b2a-b1b2-74c8dcf9c10f,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-3d2f533b-4c7a-4654-9fd4-8376e43b3e40,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-14b8c57d-540b-4671-8bef-f3d435932941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962962123-172.17.0.16-1597076411575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34241,DS-3434c52e-82df-4c21-8240-cf3973c998dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-119bbd7f-297a-4e85-a931-b0add84017b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-cdc0d338-44e0-4263-8762-1001d0ee845f,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-0f094a2e-50f6-40de-abcf-a023930f4e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-eb0b317e-ee62-4a6b-afb7-06baeeaf8bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-33494e40-2943-4b2a-b1b2-74c8dcf9c10f,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-3d2f533b-4c7a-4654-9fd4-8376e43b3e40,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-14b8c57d-540b-4671-8bef-f3d435932941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502340244-172.17.0.16-1597076463561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33041,DS-0c336de5-05b3-4c54-874b-929466576e42,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-8896dbf3-23f0-47c9-81ca-99364080bf91,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-8f885eaf-57e0-4556-9e12-027d62a3f73e,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-9b67d33e-8b26-4970-8283-910c92d9c4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-039609cd-ea80-41d8-b879-008af8eb561d,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-ea6f936a-b6e9-4933-bbbe-66d204452ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-72942bf5-6265-48b0-b19c-4596da9a4f80,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-46456287-bfbe-44fd-b029-d972c6e7d393,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502340244-172.17.0.16-1597076463561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33041,DS-0c336de5-05b3-4c54-874b-929466576e42,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-8896dbf3-23f0-47c9-81ca-99364080bf91,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-8f885eaf-57e0-4556-9e12-027d62a3f73e,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-9b67d33e-8b26-4970-8283-910c92d9c4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-039609cd-ea80-41d8-b879-008af8eb561d,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-ea6f936a-b6e9-4933-bbbe-66d204452ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-72942bf5-6265-48b0-b19c-4596da9a4f80,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-46456287-bfbe-44fd-b029-d972c6e7d393,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2070213232-172.17.0.16-1597077210905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46006,DS-0ad9c77b-fc7b-4c02-8d03-580c1df32329,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-ec9629b0-1a24-4a19-bbbf-93e7b73d781d,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-2cf1c0f8-d741-419b-840e-238964abe918,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-ec96bc9b-e966-4777-aaba-a524b3959720,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-033a9669-a050-4919-8027-12e3a5753504,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-3087ef5a-839a-4cc9-8958-d86907f341ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-db697f8f-41bc-49ca-aa93-84343e9c6226,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-dcecd7c0-500a-4cda-a541-46ac9b8c3042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2070213232-172.17.0.16-1597077210905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46006,DS-0ad9c77b-fc7b-4c02-8d03-580c1df32329,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-ec9629b0-1a24-4a19-bbbf-93e7b73d781d,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-2cf1c0f8-d741-419b-840e-238964abe918,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-ec96bc9b-e966-4777-aaba-a524b3959720,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-033a9669-a050-4919-8027-12e3a5753504,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-3087ef5a-839a-4cc9-8958-d86907f341ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-db697f8f-41bc-49ca-aa93-84343e9c6226,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-dcecd7c0-500a-4cda-a541-46ac9b8c3042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551072727-172.17.0.16-1597077808693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33757,DS-16e666ad-bfe2-4a8a-9504-44ac0afab276,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-a745014e-68e8-44ba-aabf-22b1f5277b64,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-4389ef36-c626-425d-9855-ab6b72730d97,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-1e404992-ea89-4753-8e1a-0ad71ea8aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-bae88436-cc75-4c81-8fba-aa5d0d7ac241,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-65dfd6be-3a6f-4c46-9bbe-3c7b835aec57,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-d99a86a8-6456-40a8-9fec-ae1ee4b08411,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-6fd64813-1a71-4e3d-97b9-7a12cc8a0174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551072727-172.17.0.16-1597077808693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33757,DS-16e666ad-bfe2-4a8a-9504-44ac0afab276,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-a745014e-68e8-44ba-aabf-22b1f5277b64,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-4389ef36-c626-425d-9855-ab6b72730d97,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-1e404992-ea89-4753-8e1a-0ad71ea8aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-bae88436-cc75-4c81-8fba-aa5d0d7ac241,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-65dfd6be-3a6f-4c46-9bbe-3c7b835aec57,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-d99a86a8-6456-40a8-9fec-ae1ee4b08411,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-6fd64813-1a71-4e3d-97b9-7a12cc8a0174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672805491-172.17.0.16-1597078054751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34644,DS-d8695c55-905e-47eb-a45d-c78d04c52d16,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-3714ccf4-76e1-488c-a1b6-600f6f64dc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-3dc3b357-4e8f-4f1a-932e-91631e314485,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-60e5578f-827f-40d4-8688-660d618deba5,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-c66ffddb-18fd-4d13-adae-0a32dadad88d,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-9239c4d9-9da9-4878-83ea-34df86fb9c35,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-58e665d9-5dde-41d1-b4aa-2bc6063b17d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-1d744a45-3f0e-48da-aec0-2d76ef8e5c9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672805491-172.17.0.16-1597078054751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34644,DS-d8695c55-905e-47eb-a45d-c78d04c52d16,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-3714ccf4-76e1-488c-a1b6-600f6f64dc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-3dc3b357-4e8f-4f1a-932e-91631e314485,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-60e5578f-827f-40d4-8688-660d618deba5,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-c66ffddb-18fd-4d13-adae-0a32dadad88d,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-9239c4d9-9da9-4878-83ea-34df86fb9c35,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-58e665d9-5dde-41d1-b4aa-2bc6063b17d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-1d744a45-3f0e-48da-aec0-2d76ef8e5c9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625500105-172.17.0.16-1597078148666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40119,DS-3d705a16-3953-4188-9ae8-a6110fc580db,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-2a8bd8ec-7671-4fbd-960a-59912d214779,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-47ba49b0-cd3b-4784-a65e-c86b399242fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-84ea88f5-d65b-4da9-8fbc-a01be2424f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-31d32b0b-190e-4747-8b78-89f99ac24c99,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-60dffda5-9ba8-48d3-8b47-ce4f9de5a0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-118662f8-55ff-42b2-97d8-0ac7bf0d6bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-a57b0f6e-074f-45fb-8334-73024fe34ccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625500105-172.17.0.16-1597078148666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40119,DS-3d705a16-3953-4188-9ae8-a6110fc580db,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-2a8bd8ec-7671-4fbd-960a-59912d214779,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-47ba49b0-cd3b-4784-a65e-c86b399242fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-84ea88f5-d65b-4da9-8fbc-a01be2424f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-31d32b0b-190e-4747-8b78-89f99ac24c99,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-60dffda5-9ba8-48d3-8b47-ce4f9de5a0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-118662f8-55ff-42b2-97d8-0ac7bf0d6bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-a57b0f6e-074f-45fb-8334-73024fe34ccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713271204-172.17.0.16-1597078552917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-31899131-d996-4f0c-9a9a-f5ca18eea468,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-84e2e350-23aa-4f4f-9df3-bc613cd8d818,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-64ed648f-af29-4cd9-ada1-1d050b6f2faa,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-1b467ee3-a504-4f12-856d-1676768c7f62,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-237c0b48-5184-4840-a4c8-96605ca63e40,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-cdcdaf7f-ba86-435e-9558-6762606317cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-718b6f7c-2354-4b0d-9d72-2cdc7014ab02,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-a0d372c7-fedb-4e94-8370-bc26f107e9c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713271204-172.17.0.16-1597078552917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-31899131-d996-4f0c-9a9a-f5ca18eea468,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-84e2e350-23aa-4f4f-9df3-bc613cd8d818,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-64ed648f-af29-4cd9-ada1-1d050b6f2faa,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-1b467ee3-a504-4f12-856d-1676768c7f62,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-237c0b48-5184-4840-a4c8-96605ca63e40,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-cdcdaf7f-ba86-435e-9558-6762606317cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-718b6f7c-2354-4b0d-9d72-2cdc7014ab02,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-a0d372c7-fedb-4e94-8370-bc26f107e9c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 256
v2: 65535
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577907816-172.17.0.16-1597079537022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36534,DS-2fb1ba4f-a223-49ff-b726-2744d4218850,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-4e2e86dd-4648-4cfe-964f-9ba5a3fa8f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-d2c90100-660b-42cb-a057-cdd0982a6589,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-cabfd986-1d30-4a83-96cf-5c175a5722a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-05169d3f-cdcd-4aa2-b5f0-0c647232d18a,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-aceec3ea-fc71-40c3-9ace-a3c1f7f28b55,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-92957655-6479-4188-b48d-8b5e882f07aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-e473b4ca-ecbf-4b80-ae33-5fbe1cc22d96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577907816-172.17.0.16-1597079537022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36534,DS-2fb1ba4f-a223-49ff-b726-2744d4218850,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-4e2e86dd-4648-4cfe-964f-9ba5a3fa8f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-d2c90100-660b-42cb-a057-cdd0982a6589,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-cabfd986-1d30-4a83-96cf-5c175a5722a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-05169d3f-cdcd-4aa2-b5f0-0c647232d18a,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-aceec3ea-fc71-40c3-9ace-a3c1f7f28b55,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-92957655-6479-4188-b48d-8b5e882f07aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-e473b4ca-ecbf-4b80-ae33-5fbe1cc22d96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 7039
