reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344721655-172.17.0.19-1597197922645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46103,DS-2d35b95b-835a-4360-90ba-51b546711697,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-7b10b1e7-2c8f-4737-b820-2a35a0bd5cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-952c5dde-8156-48c2-97fd-6e67cd32a620,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-a3120799-f3b2-4580-9181-263d6383b0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-72d442ec-629d-40d9-a8f6-b13ea030854d,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-c3a73781-afd5-48d5-9a42-f25c4e28e197,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-c4021e35-3a93-4cac-bc32-cb03c611a7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-3b0b0ca6-f769-41cb-881a-6e640df75370,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344721655-172.17.0.19-1597197922645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46103,DS-2d35b95b-835a-4360-90ba-51b546711697,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-7b10b1e7-2c8f-4737-b820-2a35a0bd5cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-952c5dde-8156-48c2-97fd-6e67cd32a620,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-a3120799-f3b2-4580-9181-263d6383b0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-72d442ec-629d-40d9-a8f6-b13ea030854d,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-c3a73781-afd5-48d5-9a42-f25c4e28e197,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-c4021e35-3a93-4cac-bc32-cb03c611a7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-3b0b0ca6-f769-41cb-881a-6e640df75370,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1694574643-172.17.0.19-1597198397003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45062,DS-975319c5-658d-498e-8238-6c1e4a6d14ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-af8287b9-f4a5-4752-a5c9-60d1af9aeacf,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-f3bc4a5f-ff92-4209-b6da-67bd02892d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-7b4ce6c0-4ab6-4904-86da-14a1dcf90100,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-1476b030-7ea3-428c-b3e7-782e3a61be6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-1a22f884-628e-48c8-a88b-f9ae9278cd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-496ae8d5-5f40-4f4f-b3a0-b23390e12bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-52dcefe9-3480-48f5-adf7-5430ecffe5d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1694574643-172.17.0.19-1597198397003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45062,DS-975319c5-658d-498e-8238-6c1e4a6d14ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-af8287b9-f4a5-4752-a5c9-60d1af9aeacf,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-f3bc4a5f-ff92-4209-b6da-67bd02892d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-7b4ce6c0-4ab6-4904-86da-14a1dcf90100,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-1476b030-7ea3-428c-b3e7-782e3a61be6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-1a22f884-628e-48c8-a88b-f9ae9278cd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-496ae8d5-5f40-4f4f-b3a0-b23390e12bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-52dcefe9-3480-48f5-adf7-5430ecffe5d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121320252-172.17.0.19-1597198573074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-f27fbcf8-ccc0-4c2e-b807-2db9b324959a,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-230d8d15-1796-42f3-9314-ae39caccd2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-16b6b9f2-4c9e-47f2-87f8-d67da2be8c65,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-aa145d3b-d6df-42e5-b7d0-9b1c9bdbab9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-4a6b2305-fdba-4dd9-b7bb-72d1a298310d,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-c2333c8e-f179-44a4-9ee4-00d2793ced9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-463b1a57-939b-4619-9d5e-1559fc32c4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-b4568568-511c-4984-8e1e-6ab35a0daf9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121320252-172.17.0.19-1597198573074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-f27fbcf8-ccc0-4c2e-b807-2db9b324959a,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-230d8d15-1796-42f3-9314-ae39caccd2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-16b6b9f2-4c9e-47f2-87f8-d67da2be8c65,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-aa145d3b-d6df-42e5-b7d0-9b1c9bdbab9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-4a6b2305-fdba-4dd9-b7bb-72d1a298310d,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-c2333c8e-f179-44a4-9ee4-00d2793ced9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-463b1a57-939b-4619-9d5e-1559fc32c4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-b4568568-511c-4984-8e1e-6ab35a0daf9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552225308-172.17.0.19-1597198766949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40828,DS-e5ce3f6d-bff3-41c8-bbe6-4892d725177c,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-1fa52cbd-1186-4489-844e-b91d75519b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-e3b06955-82b6-490e-b284-d8962edf20ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-37ef3f0a-620a-4307-b2fb-7e99939d6f06,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-1f31ca04-f41d-4651-bdfd-efa14d5ee918,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-e9afe925-39a3-4ac3-8636-20326b1880fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-22a7d603-5cf2-4b46-99da-e3a31d249986,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-f5a4f841-3d07-4c02-b7b9-b8ab650fba7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552225308-172.17.0.19-1597198766949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40828,DS-e5ce3f6d-bff3-41c8-bbe6-4892d725177c,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-1fa52cbd-1186-4489-844e-b91d75519b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-e3b06955-82b6-490e-b284-d8962edf20ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-37ef3f0a-620a-4307-b2fb-7e99939d6f06,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-1f31ca04-f41d-4651-bdfd-efa14d5ee918,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-e9afe925-39a3-4ac3-8636-20326b1880fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-22a7d603-5cf2-4b46-99da-e3a31d249986,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-f5a4f841-3d07-4c02-b7b9-b8ab650fba7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050600807-172.17.0.19-1597198989580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37511,DS-b7d4dc21-9a5d-46f5-8b43-9742b6b55a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-b5e386ec-bef7-4447-a21a-a0b3509d053a,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-2eeb88fb-d443-44e3-a9c7-37d518fc78e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-ff95a58c-815a-4997-bf51-245bbe5d2358,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-d3eb6bc2-4e96-4a0d-980e-510b7fd50d31,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-68d77612-a759-4d73-adf5-7b4a662f0a15,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-78c94fd1-8d51-4af7-885e-70adf4b2cf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-eddb84e8-3ad1-4ff4-9aa9-7ad62be0e76e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050600807-172.17.0.19-1597198989580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37511,DS-b7d4dc21-9a5d-46f5-8b43-9742b6b55a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-b5e386ec-bef7-4447-a21a-a0b3509d053a,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-2eeb88fb-d443-44e3-a9c7-37d518fc78e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-ff95a58c-815a-4997-bf51-245bbe5d2358,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-d3eb6bc2-4e96-4a0d-980e-510b7fd50d31,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-68d77612-a759-4d73-adf5-7b4a662f0a15,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-78c94fd1-8d51-4af7-885e-70adf4b2cf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-eddb84e8-3ad1-4ff4-9aa9-7ad62be0e76e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342872388-172.17.0.19-1597199378408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40129,DS-4e9b4695-95ed-49eb-885a-088b91a75362,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-10409fe6-52ed-4ee7-b4cd-de4dd9ea90a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-670612c4-fe80-4043-b435-7f259d3043c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-59051b01-a4e7-4ab3-8778-707143c8d76d,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-429f40a3-639c-488e-8380-4045a3a994c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-cd0cc756-abf0-486d-9d53-52d69232edfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-db82e331-f5f1-437c-833f-79fa6509bc20,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-bcd26d07-ed56-48cc-8504-02a1acfc286d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342872388-172.17.0.19-1597199378408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40129,DS-4e9b4695-95ed-49eb-885a-088b91a75362,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-10409fe6-52ed-4ee7-b4cd-de4dd9ea90a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-670612c4-fe80-4043-b435-7f259d3043c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-59051b01-a4e7-4ab3-8778-707143c8d76d,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-429f40a3-639c-488e-8380-4045a3a994c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-cd0cc756-abf0-486d-9d53-52d69232edfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-db82e331-f5f1-437c-833f-79fa6509bc20,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-bcd26d07-ed56-48cc-8504-02a1acfc286d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716556383-172.17.0.19-1597200481464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35448,DS-5d05be87-e2c9-480c-8bec-11733b2f416f,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-b501af54-a393-4983-a133-5d76c5b58041,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-05db379b-8189-40c6-ba9d-287c5b3c8fda,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-35bce4b1-f3fc-4663-bd52-f9581700a494,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-8192d819-3772-4bd0-9743-a449f01e77cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-7da79c5b-869a-47b6-88e1-85cff2ab30b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-b67e36ea-0f49-4136-a5fa-32aba0f20789,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-94e60909-08d7-4cef-9d8a-48354f6f554c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716556383-172.17.0.19-1597200481464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35448,DS-5d05be87-e2c9-480c-8bec-11733b2f416f,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-b501af54-a393-4983-a133-5d76c5b58041,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-05db379b-8189-40c6-ba9d-287c5b3c8fda,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-35bce4b1-f3fc-4663-bd52-f9581700a494,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-8192d819-3772-4bd0-9743-a449f01e77cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-7da79c5b-869a-47b6-88e1-85cff2ab30b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-b67e36ea-0f49-4136-a5fa-32aba0f20789,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-94e60909-08d7-4cef-9d8a-48354f6f554c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71553773-172.17.0.19-1597200751215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38742,DS-b18a2cbb-82f7-4d89-b75b-935d2a480de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-4a903021-1e8f-4915-968c-9d5b94736048,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-60049439-91de-4d5b-9f5f-5ca4749f58fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-dd9269f0-d39f-4738-960b-af79da33ecf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-b19ddeaf-ae25-4e36-8593-d76cb782c0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-5a07c5c5-674d-4b4d-a955-52075d04822a,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-db8c8d5c-32a0-45e2-8ce0-aa8ce1742022,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-507fbf26-3d69-4755-949a-fe19471cf659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71553773-172.17.0.19-1597200751215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38742,DS-b18a2cbb-82f7-4d89-b75b-935d2a480de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-4a903021-1e8f-4915-968c-9d5b94736048,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-60049439-91de-4d5b-9f5f-5ca4749f58fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-dd9269f0-d39f-4738-960b-af79da33ecf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-b19ddeaf-ae25-4e36-8593-d76cb782c0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-5a07c5c5-674d-4b4d-a955-52075d04822a,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-db8c8d5c-32a0-45e2-8ce0-aa8ce1742022,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-507fbf26-3d69-4755-949a-fe19471cf659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63110609-172.17.0.19-1597200829345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37387,DS-fc426dec-6712-4acd-807d-1d982268b9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-9e65936f-c45d-44ec-b1ae-0a14cfb328b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-225f7c5c-93ea-408d-a140-53b689ef0e02,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-ccff8b55-dc9a-4a4f-a645-a8c1fa571884,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-6167ec47-9910-417b-b76d-6de5f75228af,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-7143ac98-427f-4dad-9647-c4f4da750795,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-dc285a68-4132-4c94-81cc-1118e929b6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-cbe32da2-053e-4761-bb65-86c6d576e7da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63110609-172.17.0.19-1597200829345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37387,DS-fc426dec-6712-4acd-807d-1d982268b9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-9e65936f-c45d-44ec-b1ae-0a14cfb328b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-225f7c5c-93ea-408d-a140-53b689ef0e02,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-ccff8b55-dc9a-4a4f-a645-a8c1fa571884,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-6167ec47-9910-417b-b76d-6de5f75228af,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-7143ac98-427f-4dad-9647-c4f4da750795,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-dc285a68-4132-4c94-81cc-1118e929b6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-cbe32da2-053e-4761-bb65-86c6d576e7da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010783564-172.17.0.19-1597201414460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41599,DS-f2d300c3-e54b-4a31-b04b-411a60441527,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-7bb6824f-87a8-4ebf-aee0-0bcc472e9165,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-bfe528a5-0fd1-497d-971f-8abb2ff71ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-85669c32-d0c4-4a11-a508-b498a1160308,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-c99be0fc-c84a-40b5-beba-178fa4b7be3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-8f90a76c-bad9-4543-ba85-3a602713b236,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-d86516d0-0676-446a-99fc-8b3a0fefef99,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-67c55f1e-9a8a-4d25-8b08-6fb611165b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010783564-172.17.0.19-1597201414460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41599,DS-f2d300c3-e54b-4a31-b04b-411a60441527,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-7bb6824f-87a8-4ebf-aee0-0bcc472e9165,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-bfe528a5-0fd1-497d-971f-8abb2ff71ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-85669c32-d0c4-4a11-a508-b498a1160308,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-c99be0fc-c84a-40b5-beba-178fa4b7be3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-8f90a76c-bad9-4543-ba85-3a602713b236,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-d86516d0-0676-446a-99fc-8b3a0fefef99,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-67c55f1e-9a8a-4d25-8b08-6fb611165b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930590107-172.17.0.19-1597201487558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38304,DS-82b049fd-f6be-43e8-80f5-b875269af46b,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-e454044e-5867-4399-857f-a4e168f8dc21,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-2a7d255b-f776-44a0-b98b-1138465dca23,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-3b849615-5634-4cab-bf18-30329f2597d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-280d9b79-e859-492e-9d3f-65d925ce5f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-0dba3b99-029c-466c-b539-17726dcf2cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-754165da-9240-4890-9a28-f6493d2d62c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-4af25966-f63d-41e6-8403-1cd28108cf58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930590107-172.17.0.19-1597201487558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38304,DS-82b049fd-f6be-43e8-80f5-b875269af46b,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-e454044e-5867-4399-857f-a4e168f8dc21,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-2a7d255b-f776-44a0-b98b-1138465dca23,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-3b849615-5634-4cab-bf18-30329f2597d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-280d9b79-e859-492e-9d3f-65d925ce5f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-0dba3b99-029c-466c-b539-17726dcf2cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-754165da-9240-4890-9a28-f6493d2d62c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-4af25966-f63d-41e6-8403-1cd28108cf58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291215867-172.17.0.19-1597201812966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43292,DS-7dfc3a4f-db4b-4ae2-97a5-9fb812a56407,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-5d663ea8-4ede-4fb3-b51f-372d8e425d35,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-098e7513-2c5a-4336-8958-0e73d7a36c55,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-2f67b228-4d29-4ca9-8c3e-4c7e1a7049cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-1c5d4cf2-900c-4c8c-8168-55dde5d3283f,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-7445de55-1302-46f2-952c-d258889a1f81,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-9ec85a02-443a-4ee7-9362-093b43a70945,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-7b66a6a6-24b0-46fd-aa21-5ded42ff1f5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291215867-172.17.0.19-1597201812966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43292,DS-7dfc3a4f-db4b-4ae2-97a5-9fb812a56407,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-5d663ea8-4ede-4fb3-b51f-372d8e425d35,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-098e7513-2c5a-4336-8958-0e73d7a36c55,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-2f67b228-4d29-4ca9-8c3e-4c7e1a7049cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-1c5d4cf2-900c-4c8c-8168-55dde5d3283f,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-7445de55-1302-46f2-952c-d258889a1f81,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-9ec85a02-443a-4ee7-9362-093b43a70945,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-7b66a6a6-24b0-46fd-aa21-5ded42ff1f5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225385828-172.17.0.19-1597202886763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36709,DS-baa767ca-c88f-4e80-9fa6-4b7547c0c055,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-6f2e936d-a752-4268-81f2-82d4493d7c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-221311a4-062c-46ae-9088-cb98ed4a33e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-11cc9d3a-2ae3-4932-b0d6-41505b8a7220,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-8bc98831-b850-4b83-b226-9cd6a9270ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-f5de4fb4-62a6-4169-bd15-4a58bcf32300,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-8a0ea5b9-de28-44e2-ab9a-26ba99ed1925,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-61559c63-b122-4be1-af6e-6d77b04e9c28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225385828-172.17.0.19-1597202886763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36709,DS-baa767ca-c88f-4e80-9fa6-4b7547c0c055,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-6f2e936d-a752-4268-81f2-82d4493d7c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-221311a4-062c-46ae-9088-cb98ed4a33e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-11cc9d3a-2ae3-4932-b0d6-41505b8a7220,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-8bc98831-b850-4b83-b226-9cd6a9270ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-f5de4fb4-62a6-4169-bd15-4a58bcf32300,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-8a0ea5b9-de28-44e2-ab9a-26ba99ed1925,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-61559c63-b122-4be1-af6e-6d77b04e9c28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 21600s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794065751-172.17.0.19-1597203336210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32844,DS-bc314f74-f930-4ace-8991-a8b9c38dd9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-eb1533c7-936a-41b7-b314-2b27cf0af12f,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-3726637a-de62-45cb-9fc1-e430cc0cd749,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-e6955afb-20c4-470e-948e-44c0fcbea324,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-53a03a0b-2a68-44ed-8359-927659d0a378,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-47844c47-548d-4230-a0b9-9efc49fdb632,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-43f4ca69-8399-4427-a7c8-7ca48fd0c641,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-04e434d9-d4b1-4786-a842-cb7ee114c53b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794065751-172.17.0.19-1597203336210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32844,DS-bc314f74-f930-4ace-8991-a8b9c38dd9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-eb1533c7-936a-41b7-b314-2b27cf0af12f,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-3726637a-de62-45cb-9fc1-e430cc0cd749,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-e6955afb-20c4-470e-948e-44c0fcbea324,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-53a03a0b-2a68-44ed-8359-927659d0a378,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-47844c47-548d-4230-a0b9-9efc49fdb632,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-43f4ca69-8399-4427-a7c8-7ca48fd0c641,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-04e434d9-d4b1-4786-a842-cb7ee114c53b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5695
