reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966521454-172.17.0.18-1597043010756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38520,DS-42c36b8d-77a5-4e4a-90b7-d661eddcf302,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-ac9dbe7c-2c10-4df0-90b0-d8534ae428e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-e7c3aa3a-8704-4636-9280-ba5267d5d781,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-b7dee121-51bc-46bb-adaf-bbd28d8dfdad,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-91ff2e33-76b9-4513-ad4f-72d557ed369e,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-2afe7c44-d861-4b41-ba8b-6fd0b33b9dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-eb2bd3e1-8bf7-4e49-bc20-d9e23ac799e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-4916f7a1-afd6-45ad-b7d7-003998234720,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966521454-172.17.0.18-1597043010756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38520,DS-42c36b8d-77a5-4e4a-90b7-d661eddcf302,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-ac9dbe7c-2c10-4df0-90b0-d8534ae428e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-e7c3aa3a-8704-4636-9280-ba5267d5d781,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-b7dee121-51bc-46bb-adaf-bbd28d8dfdad,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-91ff2e33-76b9-4513-ad4f-72d557ed369e,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-2afe7c44-d861-4b41-ba8b-6fd0b33b9dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-eb2bd3e1-8bf7-4e49-bc20-d9e23ac799e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-4916f7a1-afd6-45ad-b7d7-003998234720,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204049966-172.17.0.18-1597043235268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34238,DS-02186095-dc30-4dc7-a58a-dd91cfb7241c,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-9ffccfa6-a038-45a8-a412-5f4c4195aaac,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-0c0a068f-1d85-4625-97e6-0d0334e6fab4,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-457938f7-3265-4a67-80e5-31e9449a3f74,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-db690c3c-2545-4e9c-993a-80be68b4da15,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-adaca227-d260-4c61-9519-2834e14920b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-1f4d6c2d-e143-4ef6-b5a4-a6e898d90662,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-25a97176-328c-49b9-843d-ba84c7515832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204049966-172.17.0.18-1597043235268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34238,DS-02186095-dc30-4dc7-a58a-dd91cfb7241c,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-9ffccfa6-a038-45a8-a412-5f4c4195aaac,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-0c0a068f-1d85-4625-97e6-0d0334e6fab4,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-457938f7-3265-4a67-80e5-31e9449a3f74,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-db690c3c-2545-4e9c-993a-80be68b4da15,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-adaca227-d260-4c61-9519-2834e14920b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-1f4d6c2d-e143-4ef6-b5a4-a6e898d90662,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-25a97176-328c-49b9-843d-ba84c7515832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1753094744-172.17.0.18-1597043348368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36113,DS-b1a7f5d4-d214-4a73-bc39-199ff761af39,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-51b3ae57-40e1-4e38-81ae-534fb74ae857,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-4a82a9de-c1e1-4370-9be3-0356c8643a37,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-2863965d-7ca2-47b9-a24f-a4b8eda80c34,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-c44823e6-2859-43d9-ba5e-ed42c261bc49,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-1c81689c-8a24-49d1-bf0d-1147eb558b51,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-f713b604-3cfe-4ffe-8c74-3c7143bddba5,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-3c55cdc0-461a-4719-b4d2-629d03d14a87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1753094744-172.17.0.18-1597043348368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36113,DS-b1a7f5d4-d214-4a73-bc39-199ff761af39,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-51b3ae57-40e1-4e38-81ae-534fb74ae857,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-4a82a9de-c1e1-4370-9be3-0356c8643a37,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-2863965d-7ca2-47b9-a24f-a4b8eda80c34,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-c44823e6-2859-43d9-ba5e-ed42c261bc49,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-1c81689c-8a24-49d1-bf0d-1147eb558b51,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-f713b604-3cfe-4ffe-8c74-3c7143bddba5,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-3c55cdc0-461a-4719-b4d2-629d03d14a87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740280740-172.17.0.18-1597043849234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43387,DS-629823ed-f09e-4dc7-a329-c93bbe4f6cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-02907a38-bbdf-44da-9918-9c50f7ecb7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-f8db4152-db06-4e7a-ae30-92e1777d8f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-8311da07-2e9b-4e8b-97cb-97de751fd3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-83dd6c1c-dcd3-46dc-8471-e99465d6718d,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-d45079be-c2e5-4424-ad2c-892d3185c423,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-d6bd21f5-9d19-4263-af4d-3a15496db574,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-c7087952-0c33-4234-99ee-137ba878d275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740280740-172.17.0.18-1597043849234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43387,DS-629823ed-f09e-4dc7-a329-c93bbe4f6cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-02907a38-bbdf-44da-9918-9c50f7ecb7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-f8db4152-db06-4e7a-ae30-92e1777d8f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-8311da07-2e9b-4e8b-97cb-97de751fd3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-83dd6c1c-dcd3-46dc-8471-e99465d6718d,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-d45079be-c2e5-4424-ad2c-892d3185c423,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-d6bd21f5-9d19-4263-af4d-3a15496db574,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-c7087952-0c33-4234-99ee-137ba878d275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523294954-172.17.0.18-1597043974967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-a4965298-c4ae-409e-a9de-cfebfaf8a22a,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-d8ab8ad4-666c-4450-89b3-547eaf41e13b,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-439b31e7-323c-4362-b83b-3b40faeadd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-30215ef6-a543-45ac-ba23-957c591dc7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-05596a9c-d95a-424a-8cb4-bef0faafc0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-a2013ba0-6dbe-4043-b5bb-c7f38fe6efec,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-eb1a9ff6-b8e2-430f-b6cc-33dbc0ba30bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-017df9f6-35bd-4095-9234-3d2bfff7bb23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523294954-172.17.0.18-1597043974967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-a4965298-c4ae-409e-a9de-cfebfaf8a22a,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-d8ab8ad4-666c-4450-89b3-547eaf41e13b,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-439b31e7-323c-4362-b83b-3b40faeadd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-30215ef6-a543-45ac-ba23-957c591dc7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-05596a9c-d95a-424a-8cb4-bef0faafc0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-a2013ba0-6dbe-4043-b5bb-c7f38fe6efec,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-eb1a9ff6-b8e2-430f-b6cc-33dbc0ba30bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-017df9f6-35bd-4095-9234-3d2bfff7bb23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-273637241-172.17.0.18-1597044031257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38099,DS-a591f72f-51cb-4ff6-82cb-cce09078b65a,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-359f75f2-5318-4ea4-a6ed-a1ff64a568d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-1f875d6e-f4b4-45f7-894c-b46f6d6e5127,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-5e55801e-a380-4236-895e-1de303634877,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-f85c92b4-c359-4189-8f65-d3590774c1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-bfbb725c-7f6e-4624-bde4-7b611870334f,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-a7d64997-0bca-440b-ae82-800a190c9f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-2808aba1-70f9-4d22-ba74-061271d99a57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-273637241-172.17.0.18-1597044031257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38099,DS-a591f72f-51cb-4ff6-82cb-cce09078b65a,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-359f75f2-5318-4ea4-a6ed-a1ff64a568d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-1f875d6e-f4b4-45f7-894c-b46f6d6e5127,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-5e55801e-a380-4236-895e-1de303634877,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-f85c92b4-c359-4189-8f65-d3590774c1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-bfbb725c-7f6e-4624-bde4-7b611870334f,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-a7d64997-0bca-440b-ae82-800a190c9f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-2808aba1-70f9-4d22-ba74-061271d99a57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1207564464-172.17.0.18-1597044430886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41371,DS-6f65c5ed-da01-4522-9bdf-824df202553a,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-5977d1b5-4c1d-46da-9eb0-b2c6afd1cde5,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-4057e12c-0de3-4a54-baa3-26452097451d,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-1598ef60-e413-4695-b780-9cd463b4c3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-86da4094-f4c1-41c8-9702-8af1de8fc974,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-dd25efdb-0b82-4913-b3bd-503712d36f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-f92ee514-7365-4008-850e-7365967935be,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-a572d1c8-e5e8-4504-bbbe-73e95659d93f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1207564464-172.17.0.18-1597044430886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41371,DS-6f65c5ed-da01-4522-9bdf-824df202553a,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-5977d1b5-4c1d-46da-9eb0-b2c6afd1cde5,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-4057e12c-0de3-4a54-baa3-26452097451d,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-1598ef60-e413-4695-b780-9cd463b4c3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-86da4094-f4c1-41c8-9702-8af1de8fc974,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-dd25efdb-0b82-4913-b3bd-503712d36f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-f92ee514-7365-4008-850e-7365967935be,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-a572d1c8-e5e8-4504-bbbe-73e95659d93f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1344131156-172.17.0.18-1597045437252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38859,DS-77eec908-7932-49ed-bd77-7bd930e153e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-d54b4f2c-950a-4bb1-9414-0d58a02425e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-fc6ddb97-de1f-40d0-adcd-70446aaaacca,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-98324769-3de7-46ae-a86d-20698b480afe,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-28d6ba38-f174-4628-b874-ded2be225440,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-5114c5b8-a34b-4bd4-b8ff-febf2ac5d315,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-c5727cac-505c-4746-bfa2-f1726f78a297,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-f6acf4f9-549b-40ed-872d-708a36c3a365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1344131156-172.17.0.18-1597045437252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38859,DS-77eec908-7932-49ed-bd77-7bd930e153e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-d54b4f2c-950a-4bb1-9414-0d58a02425e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-fc6ddb97-de1f-40d0-adcd-70446aaaacca,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-98324769-3de7-46ae-a86d-20698b480afe,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-28d6ba38-f174-4628-b874-ded2be225440,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-5114c5b8-a34b-4bd4-b8ff-febf2ac5d315,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-c5727cac-505c-4746-bfa2-f1726f78a297,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-f6acf4f9-549b-40ed-872d-708a36c3a365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054989831-172.17.0.18-1597045583164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46422,DS-2cce0a6f-6724-4e14-b8c7-172381f50a66,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-bfd4a75f-74b7-49b5-8883-6fff05a1d026,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-16b7abeb-9a39-4fde-83b3-f9d621abce1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-9cd69e87-2a9f-403b-9b6a-01d46d41feaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-ca218317-7739-4efd-934c-6202b60cd45b,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-513fcd55-d10d-4746-b622-0d2a10dd1da3,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-d4294c72-8587-4c23-affd-bfa6705f9e01,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-f5df4856-db92-4121-928b-eec7886e694d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054989831-172.17.0.18-1597045583164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46422,DS-2cce0a6f-6724-4e14-b8c7-172381f50a66,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-bfd4a75f-74b7-49b5-8883-6fff05a1d026,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-16b7abeb-9a39-4fde-83b3-f9d621abce1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-9cd69e87-2a9f-403b-9b6a-01d46d41feaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-ca218317-7739-4efd-934c-6202b60cd45b,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-513fcd55-d10d-4746-b622-0d2a10dd1da3,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-d4294c72-8587-4c23-affd-bfa6705f9e01,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-f5df4856-db92-4121-928b-eec7886e694d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283371609-172.17.0.18-1597045869063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37612,DS-f2fe120e-3b28-4bfd-aa3b-41bf77bc7d86,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-5d8f14ab-e041-4db0-a5c5-21a835ec54ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-b4a472c6-e773-437b-8fc4-817193db8175,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-72e4a320-24a9-4dc2-a088-fa29f1d39eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-bbed510f-2199-4a9c-b131-854d374b6923,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-a36c3887-7cca-4d53-a7d3-ca57f3da723b,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-a018b033-33a6-4050-9031-1a60147d4192,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-970fcd7b-a62d-40b9-bc19-6a040c4ed6ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283371609-172.17.0.18-1597045869063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37612,DS-f2fe120e-3b28-4bfd-aa3b-41bf77bc7d86,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-5d8f14ab-e041-4db0-a5c5-21a835ec54ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-b4a472c6-e773-437b-8fc4-817193db8175,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-72e4a320-24a9-4dc2-a088-fa29f1d39eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-bbed510f-2199-4a9c-b131-854d374b6923,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-a36c3887-7cca-4d53-a7d3-ca57f3da723b,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-a018b033-33a6-4050-9031-1a60147d4192,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-970fcd7b-a62d-40b9-bc19-6a040c4ed6ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1984502143-172.17.0.18-1597046522634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45108,DS-2742dd8e-3d1d-4103-b493-e49f18798634,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-4a2c994e-eef5-4ae6-a97a-e1a9c5ddcc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-3ec06e53-adb4-42eb-8c90-bad4b5eeaa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-7db51d96-cacc-4fca-97c3-fd4370cc482e,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-3fdde9f4-bb1f-44b2-83c9-3cc56788f3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-2f8f639a-a56a-413f-8c6c-9941cfeb55fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-de6d1948-bc24-44d2-b4db-a612beda49e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-741d0cac-29a0-4d85-b8c1-33da2dd225e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1984502143-172.17.0.18-1597046522634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45108,DS-2742dd8e-3d1d-4103-b493-e49f18798634,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-4a2c994e-eef5-4ae6-a97a-e1a9c5ddcc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-3ec06e53-adb4-42eb-8c90-bad4b5eeaa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-7db51d96-cacc-4fca-97c3-fd4370cc482e,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-3fdde9f4-bb1f-44b2-83c9-3cc56788f3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-2f8f639a-a56a-413f-8c6c-9941cfeb55fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-de6d1948-bc24-44d2-b4db-a612beda49e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-741d0cac-29a0-4d85-b8c1-33da2dd225e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487976168-172.17.0.18-1597046700301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38753,DS-c3a38ca4-694b-4659-8fbe-c44c3e3fa16c,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-6aad04aa-7385-40c0-88c1-d4eceba41be6,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-1b32b77f-3106-4441-81b7-f294e2301411,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-17a600fa-261e-485e-be5c-77945aa7fab1,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-36e62792-4fc8-4aa7-a4f0-e24188cb572d,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-c7f49bee-3a74-4c3b-a7ca-bbfb486c052b,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-a58cc96e-e3a2-45b4-ae05-68c0a8bb3453,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-f9b29835-1eea-40bd-bf7a-95f9e3b155a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487976168-172.17.0.18-1597046700301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38753,DS-c3a38ca4-694b-4659-8fbe-c44c3e3fa16c,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-6aad04aa-7385-40c0-88c1-d4eceba41be6,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-1b32b77f-3106-4441-81b7-f294e2301411,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-17a600fa-261e-485e-be5c-77945aa7fab1,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-36e62792-4fc8-4aa7-a4f0-e24188cb572d,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-c7f49bee-3a74-4c3b-a7ca-bbfb486c052b,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-a58cc96e-e3a2-45b4-ae05-68c0a8bb3453,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-f9b29835-1eea-40bd-bf7a-95f9e3b155a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1032616037-172.17.0.18-1597046773539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42118,DS-685bf2e9-d748-4cb5-b50a-c7eab7706ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-08e787d1-c825-4d5e-aba8-30f0055a2f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-2095ebad-74ae-4e58-b10b-7572cf4abe1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-2687e071-1396-4b97-99b9-9d70a11e9258,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-a431a98a-03d2-4811-82a0-2e6aa6076098,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-d807fe93-aaa5-449b-8911-dd36ba3787bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-d88f34f7-4e27-41ee-85b8-9e1a05eabfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-4e12baa4-8f1e-4c63-a994-15ac83a3dbdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1032616037-172.17.0.18-1597046773539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42118,DS-685bf2e9-d748-4cb5-b50a-c7eab7706ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-08e787d1-c825-4d5e-aba8-30f0055a2f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-2095ebad-74ae-4e58-b10b-7572cf4abe1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-2687e071-1396-4b97-99b9-9d70a11e9258,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-a431a98a-03d2-4811-82a0-2e6aa6076098,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-d807fe93-aaa5-449b-8911-dd36ba3787bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-d88f34f7-4e27-41ee-85b8-9e1a05eabfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-4e12baa4-8f1e-4c63-a994-15ac83a3dbdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745313627-172.17.0.18-1597046837253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46678,DS-ad4bc8f8-65ab-4715-b669-4d91f5bb5bef,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-929d5921-37d4-4d46-a619-a57c63bb53c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-b6921321-d320-4fff-83b3-d3022305d422,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-43844060-334f-4bb4-92c3-897130f6533a,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-2b1262cf-6c03-450a-96ea-0bc5a1fca476,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-5a66b089-f413-44e6-affb-d3d1058dc457,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-0be4b622-d063-4be9-acde-b735d416c7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-fc2697a7-47fa-471c-b67c-3b31757a5577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745313627-172.17.0.18-1597046837253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46678,DS-ad4bc8f8-65ab-4715-b669-4d91f5bb5bef,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-929d5921-37d4-4d46-a619-a57c63bb53c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-b6921321-d320-4fff-83b3-d3022305d422,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-43844060-334f-4bb4-92c3-897130f6533a,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-2b1262cf-6c03-450a-96ea-0bc5a1fca476,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-5a66b089-f413-44e6-affb-d3d1058dc457,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-0be4b622-d063-4be9-acde-b735d416c7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-fc2697a7-47fa-471c-b67c-3b31757a5577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754156164-172.17.0.18-1597046871147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39076,DS-c25d9d16-e53f-42b6-97da-17f2b3641bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-5441e6c3-603f-480d-add5-2afa43da1c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-846f30f3-779e-4b3d-9273-7da9f39a33bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-0af5b1d1-6e93-4358-a096-79f4690af910,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-cff8d5f9-39de-4a95-8fa7-15e911e1cedb,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-584c77e5-2fc4-40db-8320-5a6ef747db30,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-f6951dc5-5375-4dc7-ae2c-099b29ed659b,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-40903685-eb00-4304-9f3d-f5f090f2fe6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754156164-172.17.0.18-1597046871147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39076,DS-c25d9d16-e53f-42b6-97da-17f2b3641bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-5441e6c3-603f-480d-add5-2afa43da1c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-846f30f3-779e-4b3d-9273-7da9f39a33bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-0af5b1d1-6e93-4358-a096-79f4690af910,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-cff8d5f9-39de-4a95-8fa7-15e911e1cedb,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-584c77e5-2fc4-40db-8320-5a6ef747db30,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-f6951dc5-5375-4dc7-ae2c-099b29ed659b,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-40903685-eb00-4304-9f3d-f5f090f2fe6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801420131-172.17.0.18-1597047540736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37198,DS-3d7d5826-2d38-46e7-bb94-2bb719acc056,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-b67c6a5a-460c-4d5b-974a-5e88b60ec580,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-05908295-f2db-4e4c-9e01-d27c3230a3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-a455e416-4542-4c4e-8a41-81e29ee24169,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-68134121-5ae7-4206-ad41-c40043de257a,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-2c426fd6-9cb3-49d4-a3a7-9b29618c3690,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-c198fe83-a467-4f00-b807-f7611cfc3538,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-cde9d5ec-10be-43ae-a6b5-f18f063881c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801420131-172.17.0.18-1597047540736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37198,DS-3d7d5826-2d38-46e7-bb94-2bb719acc056,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-b67c6a5a-460c-4d5b-974a-5e88b60ec580,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-05908295-f2db-4e4c-9e01-d27c3230a3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-a455e416-4542-4c4e-8a41-81e29ee24169,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-68134121-5ae7-4206-ad41-c40043de257a,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-2c426fd6-9cb3-49d4-a3a7-9b29618c3690,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-c198fe83-a467-4f00-b807-f7611cfc3538,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-cde9d5ec-10be-43ae-a6b5-f18f063881c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 16
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639153682-172.17.0.18-1597047612090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33474,DS-6c0bf8b5-0977-4290-8d90-218f049420e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-104dfa57-7160-436e-9b4e-f9e84bddd5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-3294e991-c09e-4a25-8688-4cb058c86538,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-df6a99ef-97dc-434f-a5f8-9b7a104e9261,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-009cd184-38e5-43ad-b834-07c24700c08a,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-76cf2ea5-718e-4987-9db8-6b96b05b4227,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-be47bc18-91fa-4b18-8d2d-0e9710610500,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-cc6b23ae-5c30-4724-9a5d-e84dd3127ac4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639153682-172.17.0.18-1597047612090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33474,DS-6c0bf8b5-0977-4290-8d90-218f049420e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-104dfa57-7160-436e-9b4e-f9e84bddd5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-3294e991-c09e-4a25-8688-4cb058c86538,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-df6a99ef-97dc-434f-a5f8-9b7a104e9261,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-009cd184-38e5-43ad-b834-07c24700c08a,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-76cf2ea5-718e-4987-9db8-6b96b05b4227,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-be47bc18-91fa-4b18-8d2d-0e9710610500,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-cc6b23ae-5c30-4724-9a5d-e84dd3127ac4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5215
