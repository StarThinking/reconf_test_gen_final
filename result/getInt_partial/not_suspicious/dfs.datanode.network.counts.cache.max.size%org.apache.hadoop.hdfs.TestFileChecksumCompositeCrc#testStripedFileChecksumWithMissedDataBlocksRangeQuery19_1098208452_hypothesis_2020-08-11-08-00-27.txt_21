reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818552751-172.17.0.12-1597133050058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35444,DS-0085e45b-2f2e-4c2f-9160-c496c31be28e,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-d4cbb42a-8c91-4dcf-8df7-1e0a1706f8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-5eb2e3d9-bdee-4f6d-8c05-71c95f199310,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-fe873399-338b-4431-be0b-cbaa48e35445,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-5cf33c1e-f759-433b-82b2-b61c0b6c19c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-de3054ed-157b-4d61-a82b-9b1118c074f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-087a81fe-cbfb-4dfe-a676-e75436124198,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-25202b9d-5e43-40eb-90ea-564f87121403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818552751-172.17.0.12-1597133050058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35444,DS-0085e45b-2f2e-4c2f-9160-c496c31be28e,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-d4cbb42a-8c91-4dcf-8df7-1e0a1706f8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-5eb2e3d9-bdee-4f6d-8c05-71c95f199310,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-fe873399-338b-4431-be0b-cbaa48e35445,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-5cf33c1e-f759-433b-82b2-b61c0b6c19c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-de3054ed-157b-4d61-a82b-9b1118c074f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-087a81fe-cbfb-4dfe-a676-e75436124198,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-25202b9d-5e43-40eb-90ea-564f87121403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043333231-172.17.0.12-1597133093043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35526,DS-7180807b-681e-407f-9689-679ef403462b,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-f5344f84-e3b7-4187-9b0e-80da17b0438a,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-a03d429c-a738-4e0d-b85b-46a1a6260ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-28e1ec93-570b-4c44-bacc-27ca2eb15b28,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-c88587ee-19cb-4955-b746-819888e3d662,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-03bdfc36-345e-4fc8-ade8-72f23af93850,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-db7e2108-a277-47c9-adbf-6bde2feae51c,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-95fd0ae3-ac61-4463-bd11-1a8dbcce9e44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043333231-172.17.0.12-1597133093043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35526,DS-7180807b-681e-407f-9689-679ef403462b,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-f5344f84-e3b7-4187-9b0e-80da17b0438a,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-a03d429c-a738-4e0d-b85b-46a1a6260ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-28e1ec93-570b-4c44-bacc-27ca2eb15b28,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-c88587ee-19cb-4955-b746-819888e3d662,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-03bdfc36-345e-4fc8-ade8-72f23af93850,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-db7e2108-a277-47c9-adbf-6bde2feae51c,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-95fd0ae3-ac61-4463-bd11-1a8dbcce9e44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2115533270-172.17.0.12-1597133190529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45449,DS-14d77a9b-0ec4-4458-bab6-871a44b211f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-174341d3-ca34-45e1-845a-ddaf849a38d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-b16f175a-2ae5-4908-b3d3-0a8abd3d7aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-103bb7c1-1bdd-4401-bf29-06c7def4bf41,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-40e632fb-d3c6-4da9-a36f-0f629d502c59,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-53178ce7-15aa-40f1-8041-3eed82f1d61a,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-97acbc54-bf63-4194-9d56-5ce69cf4c067,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-75622867-dd79-49fd-b21c-20474e42e417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2115533270-172.17.0.12-1597133190529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45449,DS-14d77a9b-0ec4-4458-bab6-871a44b211f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-174341d3-ca34-45e1-845a-ddaf849a38d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-b16f175a-2ae5-4908-b3d3-0a8abd3d7aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-103bb7c1-1bdd-4401-bf29-06c7def4bf41,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-40e632fb-d3c6-4da9-a36f-0f629d502c59,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-53178ce7-15aa-40f1-8041-3eed82f1d61a,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-97acbc54-bf63-4194-9d56-5ce69cf4c067,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-75622867-dd79-49fd-b21c-20474e42e417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1468373548-172.17.0.12-1597133248998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-630b07d5-e09e-4dc7-a216-7899cb1ff312,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-ca2cd313-01ee-43ca-8a5d-f68642ca7a53,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-f5bb13d1-bee6-4efa-b35d-7288ce66ce6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-c5e39b67-8b4a-4543-944d-58bad1ac80f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-c08a4d73-4576-40f0-bce8-e2d9cfe7da0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-3e9c455d-df68-4939-b849-04068e168ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-53d5088e-d171-4c26-a99c-0182ffb170e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-0f8c63a3-b73a-4059-9498-fe2207e3f19d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1468373548-172.17.0.12-1597133248998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-630b07d5-e09e-4dc7-a216-7899cb1ff312,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-ca2cd313-01ee-43ca-8a5d-f68642ca7a53,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-f5bb13d1-bee6-4efa-b35d-7288ce66ce6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-c5e39b67-8b4a-4543-944d-58bad1ac80f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-c08a4d73-4576-40f0-bce8-e2d9cfe7da0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-3e9c455d-df68-4939-b849-04068e168ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-53d5088e-d171-4c26-a99c-0182ffb170e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-0f8c63a3-b73a-4059-9498-fe2207e3f19d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717171428-172.17.0.12-1597134480061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37071,DS-433ae78c-6d7f-459d-a170-80ab963fa005,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-bec2f9b8-635d-4117-91f9-8ba84cb7ef4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-b2dc28a0-dc5f-4a9c-afc1-a9593cdbd130,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-59010768-0ca6-415a-9eba-bb0c9a2358cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-e7967b62-17b7-4ae5-a031-1aba1a3c6c09,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-2b2f8e83-3ddb-4ff4-b486-8928c6ffe13f,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-69d90c95-993a-42a1-9b2e-c1aae4753296,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-9b32b2b4-4185-4c20-b0a1-c72930e42f70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717171428-172.17.0.12-1597134480061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37071,DS-433ae78c-6d7f-459d-a170-80ab963fa005,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-bec2f9b8-635d-4117-91f9-8ba84cb7ef4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-b2dc28a0-dc5f-4a9c-afc1-a9593cdbd130,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-59010768-0ca6-415a-9eba-bb0c9a2358cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-e7967b62-17b7-4ae5-a031-1aba1a3c6c09,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-2b2f8e83-3ddb-4ff4-b486-8928c6ffe13f,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-69d90c95-993a-42a1-9b2e-c1aae4753296,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-9b32b2b4-4185-4c20-b0a1-c72930e42f70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1221059333-172.17.0.12-1597135815839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45911,DS-a627cb62-917a-4cb1-89c4-d3110e27f429,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-bcae5425-752a-4dbc-8823-d46c62de8882,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-3f9999b4-7eb2-4516-94ad-e0c2faa850f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-59b5e805-db5a-44fc-a619-dbec2f63b0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-58b21fc0-81ca-4719-91ee-e1ffa88087ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-ba6a840a-5be8-4140-a46b-8441df045e71,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-21e48ef8-9222-4be3-a453-0da89596993f,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-90867097-235c-4f59-afde-1da60af3cf35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1221059333-172.17.0.12-1597135815839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45911,DS-a627cb62-917a-4cb1-89c4-d3110e27f429,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-bcae5425-752a-4dbc-8823-d46c62de8882,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-3f9999b4-7eb2-4516-94ad-e0c2faa850f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-59b5e805-db5a-44fc-a619-dbec2f63b0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-58b21fc0-81ca-4719-91ee-e1ffa88087ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-ba6a840a-5be8-4140-a46b-8441df045e71,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-21e48ef8-9222-4be3-a453-0da89596993f,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-90867097-235c-4f59-afde-1da60af3cf35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272911729-172.17.0.12-1597136129754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43202,DS-5e5f958b-aa9d-4292-916b-862ff408df73,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-622760fb-791a-4a0a-aba2-d9ec2e7bcbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-5808a19a-2e74-4434-bf58-bfa38f2fe0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-04837e5f-ea34-43eb-b078-dcab01944f02,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-1c774083-e50f-4027-b3ca-c550202a1797,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-8e10c106-b639-4648-97c0-66b5d3898ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-92c7aca8-cf56-4444-9ef5-6920259be5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-e449cca3-4649-4297-848d-375cb06eaa79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272911729-172.17.0.12-1597136129754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43202,DS-5e5f958b-aa9d-4292-916b-862ff408df73,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-622760fb-791a-4a0a-aba2-d9ec2e7bcbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-5808a19a-2e74-4434-bf58-bfa38f2fe0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-04837e5f-ea34-43eb-b078-dcab01944f02,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-1c774083-e50f-4027-b3ca-c550202a1797,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-8e10c106-b639-4648-97c0-66b5d3898ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-92c7aca8-cf56-4444-9ef5-6920259be5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-e449cca3-4649-4297-848d-375cb06eaa79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644379271-172.17.0.12-1597136238085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34947,DS-5d466b58-fb18-49f7-b003-eedb8bad8b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-3c7c189e-647e-4b7b-ba1a-2b60dd408c75,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-167a69ef-4320-4535-a28f-3e74ea839d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-4927439d-86d9-47be-be31-f519b9c6c85f,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-ef269f49-d458-4c3d-b622-f4c00cb6f414,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-dfcc181e-8dfb-4f18-afad-43268c9550a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-7c6b594d-1784-4a54-888b-5c817dbad514,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-7e7b3355-d54d-4f30-b639-718d15041cd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644379271-172.17.0.12-1597136238085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34947,DS-5d466b58-fb18-49f7-b003-eedb8bad8b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-3c7c189e-647e-4b7b-ba1a-2b60dd408c75,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-167a69ef-4320-4535-a28f-3e74ea839d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-4927439d-86d9-47be-be31-f519b9c6c85f,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-ef269f49-d458-4c3d-b622-f4c00cb6f414,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-dfcc181e-8dfb-4f18-afad-43268c9550a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-7c6b594d-1784-4a54-888b-5c817dbad514,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-7e7b3355-d54d-4f30-b639-718d15041cd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873559679-172.17.0.12-1597136444349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33026,DS-906f5800-263b-45e4-aec2-1e5cd12799d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-2be5ceaa-5d7e-4262-98d2-889a75df2d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-31dce876-b9cf-4e27-ba34-48ba965debba,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-fd2210db-e822-4b63-afb7-5d7164608d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-d55776d1-72aa-4bcf-b3b5-88b5768a831a,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-1d31549c-e259-4062-969a-7d4726f86962,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-e51cbbc5-1c3b-4282-bd7c-b004c2710da4,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-9744be23-f5fc-4b11-9200-e9c7865d1007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873559679-172.17.0.12-1597136444349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33026,DS-906f5800-263b-45e4-aec2-1e5cd12799d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-2be5ceaa-5d7e-4262-98d2-889a75df2d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-31dce876-b9cf-4e27-ba34-48ba965debba,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-fd2210db-e822-4b63-afb7-5d7164608d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-d55776d1-72aa-4bcf-b3b5-88b5768a831a,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-1d31549c-e259-4062-969a-7d4726f86962,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-e51cbbc5-1c3b-4282-bd7c-b004c2710da4,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-9744be23-f5fc-4b11-9200-e9c7865d1007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696922819-172.17.0.12-1597137576014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43583,DS-7f2458b3-092b-4503-bca4-8a345557c42f,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-d52b3d59-3833-4764-bb33-dc1bb2ecc1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-bb9b74bc-ae5f-41e4-8d41-3a132dc2d384,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-e7ecf528-d89f-4171-9610-61f8c0008dda,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-f3f6a0b4-8ec7-4352-a12c-1c001e5d73d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-fc72208a-f266-4b79-b03c-d47abf79ddff,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-4532b5ee-d6c0-4562-87ee-943f8b953590,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-24249f06-027e-4b54-8aec-193e761fcecf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696922819-172.17.0.12-1597137576014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43583,DS-7f2458b3-092b-4503-bca4-8a345557c42f,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-d52b3d59-3833-4764-bb33-dc1bb2ecc1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-bb9b74bc-ae5f-41e4-8d41-3a132dc2d384,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-e7ecf528-d89f-4171-9610-61f8c0008dda,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-f3f6a0b4-8ec7-4352-a12c-1c001e5d73d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-fc72208a-f266-4b79-b03c-d47abf79ddff,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-4532b5ee-d6c0-4562-87ee-943f8b953590,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-24249f06-027e-4b54-8aec-193e761fcecf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419541789-172.17.0.12-1597137720059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44454,DS-607fd4da-3f39-4af8-bb19-fd0c15953bae,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-bc75145b-90ff-41dd-9760-579a7cbdcb27,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-9c69b4fb-80d1-477f-842f-b4895b0c1abd,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-9a1a17b3-5184-4a5a-8f5e-47847db1b83c,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-3f4b0969-88da-4cdf-ac57-e4a69bfabfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-3211cba4-3607-4e7c-b490-0e3ed733d891,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-6fd2e234-2fdc-4a31-8730-33505aaab9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-5a3dbc8a-156e-4192-b22a-e3655d60343d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419541789-172.17.0.12-1597137720059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44454,DS-607fd4da-3f39-4af8-bb19-fd0c15953bae,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-bc75145b-90ff-41dd-9760-579a7cbdcb27,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-9c69b4fb-80d1-477f-842f-b4895b0c1abd,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-9a1a17b3-5184-4a5a-8f5e-47847db1b83c,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-3f4b0969-88da-4cdf-ac57-e4a69bfabfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-3211cba4-3607-4e7c-b490-0e3ed733d891,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-6fd2e234-2fdc-4a31-8730-33505aaab9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-5a3dbc8a-156e-4192-b22a-e3655d60343d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70076295-172.17.0.12-1597137892962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36481,DS-1397f22c-e291-41f8-95b6-cc2ef0336c22,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-089081db-34d0-4439-ab48-e7f34c8a7994,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-49657ff6-d384-48f8-a569-2a5bd9f2c055,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-7d5d7285-d442-411f-a5d6-85b260777857,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-e5959825-195a-438f-bbd3-3eeb51892a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-55b850d8-680f-42ce-a64d-ce7df51c6085,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-f27c68b1-9ad0-4255-a456-56751a157db1,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-53a00ac4-5c79-4e08-887d-a4f8dd1bae23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70076295-172.17.0.12-1597137892962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36481,DS-1397f22c-e291-41f8-95b6-cc2ef0336c22,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-089081db-34d0-4439-ab48-e7f34c8a7994,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-49657ff6-d384-48f8-a569-2a5bd9f2c055,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-7d5d7285-d442-411f-a5d6-85b260777857,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-e5959825-195a-438f-bbd3-3eeb51892a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-55b850d8-680f-42ce-a64d-ce7df51c6085,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-f27c68b1-9ad0-4255-a456-56751a157db1,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-53a00ac4-5c79-4e08-887d-a4f8dd1bae23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287482683-172.17.0.12-1597138043865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37976,DS-c3a0c136-8ff3-447b-926b-1f08ccaea12e,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-afb67ae0-43ba-4402-b22c-74216e10fa70,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-9e2c70ed-3a2c-49b6-bd6d-afc500d5ca09,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-e1566720-6036-4280-88dc-d9792179aa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-fc360a04-f52a-49fd-bdb3-4327f1f89bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-ed0ba540-5a4a-4b07-8364-c1e41bd64bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-7c40275e-3ea6-4173-ab57-6ab0b1a55373,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-49717dad-44f9-4662-88ec-d31901420c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287482683-172.17.0.12-1597138043865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37976,DS-c3a0c136-8ff3-447b-926b-1f08ccaea12e,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-afb67ae0-43ba-4402-b22c-74216e10fa70,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-9e2c70ed-3a2c-49b6-bd6d-afc500d5ca09,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-e1566720-6036-4280-88dc-d9792179aa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-fc360a04-f52a-49fd-bdb3-4327f1f89bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-ed0ba540-5a4a-4b07-8364-c1e41bd64bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-7c40275e-3ea6-4173-ab57-6ab0b1a55373,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-49717dad-44f9-4662-88ec-d31901420c41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548569464-172.17.0.12-1597138489890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33484,DS-b87688de-0868-4b71-ad90-5ee954415d39,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-e48db8d7-af02-4ab1-8465-66b05a1681ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-537d5e0d-36a6-411b-a8b2-f51d7aa8f763,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-ac1d880d-6835-4917-a9e4-9f503d02a6df,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-cde0510d-c326-4e77-992e-19a0f3bf334e,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-ddec2344-b0bc-42cb-a6d5-43863af9410d,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-9d7cc627-264c-49e3-9b35-f333dfb8b6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-75fa59ce-ebca-4f2f-bd8c-cdc4a04fb4bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548569464-172.17.0.12-1597138489890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33484,DS-b87688de-0868-4b71-ad90-5ee954415d39,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-e48db8d7-af02-4ab1-8465-66b05a1681ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-537d5e0d-36a6-411b-a8b2-f51d7aa8f763,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-ac1d880d-6835-4917-a9e4-9f503d02a6df,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-cde0510d-c326-4e77-992e-19a0f3bf334e,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-ddec2344-b0bc-42cb-a6d5-43863af9410d,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-9d7cc627-264c-49e3-9b35-f333dfb8b6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-75fa59ce-ebca-4f2f-bd8c-cdc4a04fb4bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-175123672-172.17.0.12-1597139115777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44745,DS-3fba1ea0-40fe-4cf9-abb0-4bb745ea0af5,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-c8cae621-5f51-4f22-890b-7dc420e90f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-16d4324f-8811-40dc-bbbb-43bce8b2d422,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-08348c6d-3297-446d-865b-12724e9592be,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-793555e7-e34a-4ce4-a552-5b284d510fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-a7d2a566-876a-45f8-99ab-740ed7f0f4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-04da1471-da64-4301-9515-2bd3ea141d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-a4510a47-676f-4fb1-8b0d-dec85204b1ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-175123672-172.17.0.12-1597139115777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44745,DS-3fba1ea0-40fe-4cf9-abb0-4bb745ea0af5,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-c8cae621-5f51-4f22-890b-7dc420e90f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-16d4324f-8811-40dc-bbbb-43bce8b2d422,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-08348c6d-3297-446d-865b-12724e9592be,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-793555e7-e34a-4ce4-a552-5b284d510fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-a7d2a566-876a-45f8-99ab-740ed7f0f4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-04da1471-da64-4301-9515-2bd3ea141d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-a4510a47-676f-4fb1-8b0d-dec85204b1ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008511472-172.17.0.12-1597139304957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41189,DS-96d9fc2c-4a4f-4770-862e-abd858ca9acc,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-0199765b-a3a8-4887-b423-5082525250a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-0780caed-97a1-4b94-a218-eecb53afc44c,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-e41c888c-b9b2-4f72-ba64-b61cf3b03021,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-46ea3996-443a-4c06-9962-75e62934fcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-c0e9d71b-6230-469d-9661-85d6125ff313,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-3cbc3e47-22f7-40ae-9480-95287e39383a,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-ce9506a9-2cf7-4ddb-ba4e-c75efc4e041e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008511472-172.17.0.12-1597139304957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41189,DS-96d9fc2c-4a4f-4770-862e-abd858ca9acc,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-0199765b-a3a8-4887-b423-5082525250a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-0780caed-97a1-4b94-a218-eecb53afc44c,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-e41c888c-b9b2-4f72-ba64-b61cf3b03021,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-46ea3996-443a-4c06-9962-75e62934fcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-c0e9d71b-6230-469d-9661-85d6125ff313,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-3cbc3e47-22f7-40ae-9480-95287e39383a,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-ce9506a9-2cf7-4ddb-ba4e-c75efc4e041e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 2047
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277882133-172.17.0.12-1597139774410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38976,DS-9c18d40d-5b1a-4264-9e11-dd7ed5d3e87f,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-98b5b015-010d-45d1-94c5-76fcfb1a13fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-188ac1bc-4382-4457-bb79-1a517e19a9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-7a4f1d50-9101-42dd-9964-49d7637c4c56,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-6f0f04e3-ea09-4081-9ff2-fd77e4c7a84b,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-7a40a7f8-d10d-4d4c-8ab3-6a29b208ca29,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-2bd31a48-58dd-413f-b32b-196d61790339,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-495b94ed-aea0-471d-b952-410325c94203,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277882133-172.17.0.12-1597139774410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38976,DS-9c18d40d-5b1a-4264-9e11-dd7ed5d3e87f,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-98b5b015-010d-45d1-94c5-76fcfb1a13fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-188ac1bc-4382-4457-bb79-1a517e19a9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-7a4f1d50-9101-42dd-9964-49d7637c4c56,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-6f0f04e3-ea09-4081-9ff2-fd77e4c7a84b,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-7a40a7f8-d10d-4d4c-8ab3-6a29b208ca29,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-2bd31a48-58dd-413f-b32b-196d61790339,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-495b94ed-aea0-471d-b952-410325c94203,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6993
