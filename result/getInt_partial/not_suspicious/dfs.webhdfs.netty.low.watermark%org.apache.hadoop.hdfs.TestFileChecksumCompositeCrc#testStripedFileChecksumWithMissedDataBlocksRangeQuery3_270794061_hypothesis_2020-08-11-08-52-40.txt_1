reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127236609-172.17.0.12-1597136046868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46572,DS-60b98d38-9ad6-4407-bd2e-8a41233e2b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-c5351ca0-998e-421a-8718-45b11250e175,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-3285d635-3949-459b-b40a-773ca7065341,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-e743fdd7-5ba3-4eb6-990c-5dbefb6ea954,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-21e879ab-349b-4e1d-b1c3-ad0cbee28182,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-b713942d-b9d7-47e4-92c5-8a865086494e,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-c063463c-0468-4a06-b738-954d3327cc73,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-c8bfee76-74a2-4d91-8a57-d5fd687de4a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127236609-172.17.0.12-1597136046868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46572,DS-60b98d38-9ad6-4407-bd2e-8a41233e2b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-c5351ca0-998e-421a-8718-45b11250e175,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-3285d635-3949-459b-b40a-773ca7065341,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-e743fdd7-5ba3-4eb6-990c-5dbefb6ea954,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-21e879ab-349b-4e1d-b1c3-ad0cbee28182,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-b713942d-b9d7-47e4-92c5-8a865086494e,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-c063463c-0468-4a06-b738-954d3327cc73,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-c8bfee76-74a2-4d91-8a57-d5fd687de4a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102034709-172.17.0.12-1597136584590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38882,DS-475a6e01-ffdc-4138-8c07-ea5144b039bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-1c3864ca-463a-443f-beb9-ed6a60ed0df4,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-aac58227-904f-4083-94a2-a65aae62fc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-ea566476-91b4-4926-81ac-8b35bd5ff149,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-34cb43c4-3a46-4cdd-9d3f-ea58c76598e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-dc4fa225-a931-4efa-9dcd-ea0df3967f71,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-e14b214a-3cd1-4f75-924c-d9c4172d6af0,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-4ea90986-f3cc-49fa-870b-468276e478e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102034709-172.17.0.12-1597136584590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38882,DS-475a6e01-ffdc-4138-8c07-ea5144b039bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-1c3864ca-463a-443f-beb9-ed6a60ed0df4,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-aac58227-904f-4083-94a2-a65aae62fc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-ea566476-91b4-4926-81ac-8b35bd5ff149,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-34cb43c4-3a46-4cdd-9d3f-ea58c76598e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-dc4fa225-a931-4efa-9dcd-ea0df3967f71,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-e14b214a-3cd1-4f75-924c-d9c4172d6af0,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-4ea90986-f3cc-49fa-870b-468276e478e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566754600-172.17.0.12-1597136807280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34364,DS-964da425-1a76-4ceb-8a91-59ff11e1f607,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-10983600-24fa-453b-b29d-6d3b756fa092,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-87b6a7c4-e987-4cb3-b10e-81f323eeca24,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-633b3cc1-15f2-4454-aba4-80a71e17b9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-be40c833-2916-4c1f-b5d7-fc3798c1cc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-4d5708d5-1446-48bb-ae51-2a2c8071e920,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-db0ce9ca-c6f2-4ed2-9de4-a6879ed4a05a,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-84b8a821-f341-44e0-9123-a55b1bbe91d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566754600-172.17.0.12-1597136807280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34364,DS-964da425-1a76-4ceb-8a91-59ff11e1f607,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-10983600-24fa-453b-b29d-6d3b756fa092,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-87b6a7c4-e987-4cb3-b10e-81f323eeca24,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-633b3cc1-15f2-4454-aba4-80a71e17b9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-be40c833-2916-4c1f-b5d7-fc3798c1cc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-4d5708d5-1446-48bb-ae51-2a2c8071e920,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-db0ce9ca-c6f2-4ed2-9de4-a6879ed4a05a,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-84b8a821-f341-44e0-9123-a55b1bbe91d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145388886-172.17.0.12-1597136839855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37784,DS-5db4e64e-ee5a-4f0d-8357-5de1c00d62b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-75139596-a71d-4c60-9a9d-2c221df80d85,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-a56abdea-f75f-4c2c-9c7b-2486fb8bef39,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-7b8c68a7-356d-4694-ae20-659fa1e6ffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-da99c214-1a49-478f-b1d5-f3c8689db681,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-d856c141-a281-4bf6-bc3e-ed7f8d834819,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-125d0da4-d955-4050-8420-2b7d7bd6b0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-d70a194c-fac2-4e25-93ff-cee470df8e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145388886-172.17.0.12-1597136839855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37784,DS-5db4e64e-ee5a-4f0d-8357-5de1c00d62b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-75139596-a71d-4c60-9a9d-2c221df80d85,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-a56abdea-f75f-4c2c-9c7b-2486fb8bef39,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-7b8c68a7-356d-4694-ae20-659fa1e6ffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-da99c214-1a49-478f-b1d5-f3c8689db681,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-d856c141-a281-4bf6-bc3e-ed7f8d834819,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-125d0da4-d955-4050-8420-2b7d7bd6b0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-d70a194c-fac2-4e25-93ff-cee470df8e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852345248-172.17.0.12-1597136941143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-8b0b3952-bf86-4568-8191-42f4f37ce6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-af8bf474-79cc-444d-9217-9e454738967f,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-bd5fcd5b-9d56-4641-a83c-6ae620387cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-96779aeb-a15b-47cc-88d0-0ef3b9bdaff4,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-2f4e902d-802d-4eae-81c4-289c867d3790,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-5786ddcd-ed32-47e3-8e98-2c750c357ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-3833a549-9cc7-4caa-b504-3d57c7ac506a,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-8a13595b-cea0-4a72-bf7b-c1446473ef43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852345248-172.17.0.12-1597136941143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-8b0b3952-bf86-4568-8191-42f4f37ce6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-af8bf474-79cc-444d-9217-9e454738967f,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-bd5fcd5b-9d56-4641-a83c-6ae620387cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-96779aeb-a15b-47cc-88d0-0ef3b9bdaff4,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-2f4e902d-802d-4eae-81c4-289c867d3790,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-5786ddcd-ed32-47e3-8e98-2c750c357ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-3833a549-9cc7-4caa-b504-3d57c7ac506a,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-8a13595b-cea0-4a72-bf7b-c1446473ef43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142732064-172.17.0.12-1597136976183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34942,DS-57398e1a-0448-4095-a1eb-84cd5c31715f,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-9430c71a-4329-4728-b6ff-f1b6ba0ac54b,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-0380a630-6b6d-485e-8bf8-a47618f5615b,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-82406cbe-063b-473f-98ab-50d00aee4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-49c654c1-a7c0-4f0d-ac72-52750fc4ba89,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-ea36275e-65cd-4d0c-ad3c-88e7fb0e6b77,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-8bb5c079-1fa1-4ccc-859c-b3749ff238d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-0e4e5dec-7145-47af-804e-b24705a3a704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142732064-172.17.0.12-1597136976183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34942,DS-57398e1a-0448-4095-a1eb-84cd5c31715f,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-9430c71a-4329-4728-b6ff-f1b6ba0ac54b,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-0380a630-6b6d-485e-8bf8-a47618f5615b,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-82406cbe-063b-473f-98ab-50d00aee4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-49c654c1-a7c0-4f0d-ac72-52750fc4ba89,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-ea36275e-65cd-4d0c-ad3c-88e7fb0e6b77,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-8bb5c079-1fa1-4ccc-859c-b3749ff238d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-0e4e5dec-7145-47af-804e-b24705a3a704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032834468-172.17.0.12-1597137019276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43300,DS-b89d8675-6062-4cb8-b23d-5f20cf3ac267,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-380d8491-ab96-45d2-a61f-88b78e933de6,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-db42eb85-66ae-435b-b8f6-fe9038073056,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-cc84e13a-ff05-4628-832d-aecaf3c16c56,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-1aec1b12-a306-4056-8236-a32660359723,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-faf1c4e5-4cc6-46b4-bac9-b3f3a0151068,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-ea78b474-cfdb-4544-b383-e55580be5425,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-f14fec2f-db4e-4330-b311-646e2a1c928d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032834468-172.17.0.12-1597137019276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43300,DS-b89d8675-6062-4cb8-b23d-5f20cf3ac267,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-380d8491-ab96-45d2-a61f-88b78e933de6,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-db42eb85-66ae-435b-b8f6-fe9038073056,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-cc84e13a-ff05-4628-832d-aecaf3c16c56,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-1aec1b12-a306-4056-8236-a32660359723,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-faf1c4e5-4cc6-46b4-bac9-b3f3a0151068,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-ea78b474-cfdb-4544-b383-e55580be5425,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-f14fec2f-db4e-4330-b311-646e2a1c928d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933842653-172.17.0.12-1597137826061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42273,DS-ca53a3ad-e9a3-4512-b611-907f506aadbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-b8cba9dc-558f-4322-bcfb-441f51a69126,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-43fcfd1e-91cc-4247-901f-6f98828dca06,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-0baeb175-0bee-4f42-ab5d-f9dc1c79fbae,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-f0adeb09-f16c-455e-92d0-3cdeb5e345d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-e4fad600-9ffe-4616-965e-dac8f709dec1,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-904b9ae0-3361-4e78-9ccb-e32c113f9193,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-16ee2784-b944-46f9-a955-0b8ad812a019,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933842653-172.17.0.12-1597137826061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42273,DS-ca53a3ad-e9a3-4512-b611-907f506aadbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-b8cba9dc-558f-4322-bcfb-441f51a69126,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-43fcfd1e-91cc-4247-901f-6f98828dca06,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-0baeb175-0bee-4f42-ab5d-f9dc1c79fbae,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-f0adeb09-f16c-455e-92d0-3cdeb5e345d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-e4fad600-9ffe-4616-965e-dac8f709dec1,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-904b9ae0-3361-4e78-9ccb-e32c113f9193,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-16ee2784-b944-46f9-a955-0b8ad812a019,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439384858-172.17.0.12-1597138127163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43478,DS-b6383da4-299a-4388-b331-51ae04924f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-41fa4ec1-bd4e-4817-96de-a0c177007556,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-1556429f-d6ce-4f6b-9687-47ad4bbe39d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-fdbc79e3-3927-4364-bcca-5fac03ecf4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-f2f1d64e-4a01-43e5-8113-c9c33d85b279,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-185aee92-b66b-479a-a676-1871ccf95fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-85552a0a-e1ba-4e5d-bbe6-0eb4db5b04d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-829d8666-1aa6-46fb-b956-f07a0335c323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439384858-172.17.0.12-1597138127163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43478,DS-b6383da4-299a-4388-b331-51ae04924f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-41fa4ec1-bd4e-4817-96de-a0c177007556,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-1556429f-d6ce-4f6b-9687-47ad4bbe39d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-fdbc79e3-3927-4364-bcca-5fac03ecf4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-f2f1d64e-4a01-43e5-8113-c9c33d85b279,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-185aee92-b66b-479a-a676-1871ccf95fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-85552a0a-e1ba-4e5d-bbe6-0eb4db5b04d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-829d8666-1aa6-46fb-b956-f07a0335c323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766324812-172.17.0.12-1597138426239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46531,DS-0eecc676-a184-439d-bbca-25b2b82ab4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-7d022528-649e-41e9-a890-bc7b3d998fde,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-f5627d86-a8bc-4469-8739-f673f49aaf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-4c30efb1-dbfd-46fd-a8a3-dd1700c726a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-31592e9d-68eb-4d1a-a80e-4c74ecb2dbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-3e52acb2-36f6-4bb1-be0d-9c9be1712ead,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-825f6fad-9794-418d-8351-00c1dbdcaa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-c6e1c38b-fe30-4f4e-8ea7-7ad68c4e52f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766324812-172.17.0.12-1597138426239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46531,DS-0eecc676-a184-439d-bbca-25b2b82ab4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-7d022528-649e-41e9-a890-bc7b3d998fde,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-f5627d86-a8bc-4469-8739-f673f49aaf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-4c30efb1-dbfd-46fd-a8a3-dd1700c726a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-31592e9d-68eb-4d1a-a80e-4c74ecb2dbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-3e52acb2-36f6-4bb1-be0d-9c9be1712ead,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-825f6fad-9794-418d-8351-00c1dbdcaa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-c6e1c38b-fe30-4f4e-8ea7-7ad68c4e52f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973637846-172.17.0.12-1597138799332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34448,DS-e3c9d2ed-fba9-47f8-b1a6-0456ef20d133,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-07040553-6136-4ca4-8f0e-752dd08a7562,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-eff630e5-22b1-46ef-a446-1f4c74240fda,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-07fafcf8-1301-4dcd-a26e-6017b0cb6357,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-54237275-a174-40e3-b012-41cabbd9fa58,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-40cb19d5-8877-4928-9657-643e4cfd33ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-705d048f-f92c-4643-a250-c0086c160366,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-6364551a-0384-41c0-8829-43467f432352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973637846-172.17.0.12-1597138799332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34448,DS-e3c9d2ed-fba9-47f8-b1a6-0456ef20d133,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-07040553-6136-4ca4-8f0e-752dd08a7562,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-eff630e5-22b1-46ef-a446-1f4c74240fda,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-07fafcf8-1301-4dcd-a26e-6017b0cb6357,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-54237275-a174-40e3-b012-41cabbd9fa58,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-40cb19d5-8877-4928-9657-643e4cfd33ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-705d048f-f92c-4643-a250-c0086c160366,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-6364551a-0384-41c0-8829-43467f432352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427508922-172.17.0.12-1597138972012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35633,DS-2f4a6f98-2dfc-4a6b-9316-15598cafddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-89484bef-948d-40e8-b8b2-bb9db3224ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-bebf5b6d-8018-4782-bf1e-852a293e6747,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-50b1069d-2136-4c93-8c3c-75a4533f80b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-3374cb32-f31b-4a4d-80d7-85dbb8ff1c58,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-4ebafe8d-9d46-49ca-9f5d-c71adbdd868e,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-b1174b01-371e-4075-a27c-60719ea3c652,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-847ad14d-70f9-4edc-8f14-343ddaf23d3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427508922-172.17.0.12-1597138972012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35633,DS-2f4a6f98-2dfc-4a6b-9316-15598cafddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-89484bef-948d-40e8-b8b2-bb9db3224ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-bebf5b6d-8018-4782-bf1e-852a293e6747,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-50b1069d-2136-4c93-8c3c-75a4533f80b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-3374cb32-f31b-4a4d-80d7-85dbb8ff1c58,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-4ebafe8d-9d46-49ca-9f5d-c71adbdd868e,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-b1174b01-371e-4075-a27c-60719ea3c652,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-847ad14d-70f9-4edc-8f14-343ddaf23d3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722272255-172.17.0.12-1597139684083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45874,DS-cba6662c-31ba-4dcc-8d80-43527cc67984,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-1e555a42-a62a-4b68-9248-c3928aedcfac,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-74b93412-e69f-42b4-8e1d-a6e5a85d7990,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-e56814b4-b582-444e-b841-73fcbfd4551c,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-4806ab92-9d78-4f80-8052-fd93d45bd6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-d7876363-09c6-4e5f-87cd-87d1c5b47ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-2069d3c6-8986-4cbf-b817-4aa23c656781,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-93fa8422-c767-41cb-8643-a2f34adfb49b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722272255-172.17.0.12-1597139684083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45874,DS-cba6662c-31ba-4dcc-8d80-43527cc67984,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-1e555a42-a62a-4b68-9248-c3928aedcfac,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-74b93412-e69f-42b4-8e1d-a6e5a85d7990,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-e56814b4-b582-444e-b841-73fcbfd4551c,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-4806ab92-9d78-4f80-8052-fd93d45bd6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-d7876363-09c6-4e5f-87cd-87d1c5b47ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-2069d3c6-8986-4cbf-b817-4aa23c656781,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-93fa8422-c767-41cb-8643-a2f34adfb49b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508895282-172.17.0.12-1597140280363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43409,DS-9a8ed572-5d97-449c-8d81-bd302bf2eb27,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-03007bb3-1de3-4671-bf03-7789760818e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-093b0a09-f078-49bb-a39e-9c650353e4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-a64c41da-0215-48d3-973d-0d11b328fdec,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-67998d71-5597-463d-aa96-7dcd5cb80b29,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-1b550711-14b5-42c5-9dee-2e4afaee91d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-1afc76b1-2d29-4cd8-a918-078a762fa255,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-90499475-8a46-46e6-863f-1467b10fd9a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508895282-172.17.0.12-1597140280363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43409,DS-9a8ed572-5d97-449c-8d81-bd302bf2eb27,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-03007bb3-1de3-4671-bf03-7789760818e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-093b0a09-f078-49bb-a39e-9c650353e4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-a64c41da-0215-48d3-973d-0d11b328fdec,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-67998d71-5597-463d-aa96-7dcd5cb80b29,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-1b550711-14b5-42c5-9dee-2e4afaee91d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-1afc76b1-2d29-4cd8-a918-078a762fa255,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-90499475-8a46-46e6-863f-1467b10fd9a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351409821-172.17.0.12-1597140376627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43449,DS-cf4ceba6-b9d6-4e60-b8be-ba965cfcbb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-7d61648f-433d-4e09-8da9-64d70d7824ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-5f4dc9f6-eab6-461f-abd8-3b2cb2e18ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-d5213312-3ec5-483f-8708-d5e6a7277d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-d6a0d9d4-c6e9-4dcb-946f-623595115320,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-88b1f493-271c-44be-b636-3208a2032c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-2f723854-dc82-4d8c-844f-58ec671bed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-ace06358-b721-4957-bc18-797a636f8a2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351409821-172.17.0.12-1597140376627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43449,DS-cf4ceba6-b9d6-4e60-b8be-ba965cfcbb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-7d61648f-433d-4e09-8da9-64d70d7824ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-5f4dc9f6-eab6-461f-abd8-3b2cb2e18ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-d5213312-3ec5-483f-8708-d5e6a7277d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-d6a0d9d4-c6e9-4dcb-946f-623595115320,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-88b1f493-271c-44be-b636-3208a2032c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-2f723854-dc82-4d8c-844f-58ec671bed5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-ace06358-b721-4957-bc18-797a636f8a2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021661207-172.17.0.12-1597140414389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33302,DS-eae4507b-c650-4ce8-ad12-7a03e3502913,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-f12f8c4f-b745-4300-932a-0897cadd0cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-102d6534-fa9d-4f95-b0ff-86fa3a85e2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-607b08c8-91d6-45dc-a008-a63a5a556542,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-3421ba61-fe15-405e-a78e-570e2c97e9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-e7b99cac-533b-4d6d-961a-52b3a0d6c859,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-4276e514-b204-4bf1-b90b-1f3708f60509,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-3e403855-7785-412d-838e-0729b5d12a42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021661207-172.17.0.12-1597140414389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33302,DS-eae4507b-c650-4ce8-ad12-7a03e3502913,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-f12f8c4f-b745-4300-932a-0897cadd0cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-102d6534-fa9d-4f95-b0ff-86fa3a85e2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-607b08c8-91d6-45dc-a008-a63a5a556542,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-3421ba61-fe15-405e-a78e-570e2c97e9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-e7b99cac-533b-4d6d-961a-52b3a0d6c859,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-4276e514-b204-4bf1-b90b-1f3708f60509,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-3e403855-7785-412d-838e-0729b5d12a42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338500875-172.17.0.12-1597140534992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44884,DS-01f9d4d9-7540-4109-8dbd-f456ba07f690,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-930ee6d1-036f-4220-9865-d229df3141db,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-3622d739-8418-48a5-bb39-f21969e8d0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-f80f2a9b-d289-4bec-8352-68fbbefc1b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-3aaa3709-b0bc-4c44-8aa8-c98700eaa0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-40e1f326-6d94-4530-a02f-8f00702194f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-0a7413ba-0542-4d77-a5bf-be2296afa889,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-be12ab95-07b4-456c-8948-b4fbf1011b57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338500875-172.17.0.12-1597140534992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44884,DS-01f9d4d9-7540-4109-8dbd-f456ba07f690,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-930ee6d1-036f-4220-9865-d229df3141db,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-3622d739-8418-48a5-bb39-f21969e8d0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-f80f2a9b-d289-4bec-8352-68fbbefc1b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-3aaa3709-b0bc-4c44-8aa8-c98700eaa0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-40e1f326-6d94-4530-a02f-8f00702194f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-0a7413ba-0542-4d77-a5bf-be2296afa889,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-be12ab95-07b4-456c-8948-b4fbf1011b57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665659782-172.17.0.12-1597140736778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35363,DS-080565c5-1efd-4462-8ff4-b5f35c2f567d,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-38225afb-e08d-4a91-913e-249fac7cf6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-4530a440-aa5b-49cb-98bd-4a668e206a73,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-de77e670-7e96-4cea-b8d2-361d9a53e943,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-f8b46565-4726-4f2a-a1d5-a184e1b6f3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-f799cd28-fe82-4b75-bd9e-526c6ac25ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-ac61dbd2-42a7-4e24-a874-9f2a1ae57fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-bba8b9c6-b708-4049-9f4d-2c2ba86ba05a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665659782-172.17.0.12-1597140736778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35363,DS-080565c5-1efd-4462-8ff4-b5f35c2f567d,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-38225afb-e08d-4a91-913e-249fac7cf6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-4530a440-aa5b-49cb-98bd-4a668e206a73,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-de77e670-7e96-4cea-b8d2-361d9a53e943,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-f8b46565-4726-4f2a-a1d5-a184e1b6f3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-f799cd28-fe82-4b75-bd9e-526c6ac25ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-ac61dbd2-42a7-4e24-a874-9f2a1ae57fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-bba8b9c6-b708-4049-9f4d-2c2ba86ba05a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609692777-172.17.0.12-1597140954347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42457,DS-151623a4-8afd-4cf1-86c6-dba01380ac95,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-cdc9d78d-ca20-4a44-bb8a-1c5bd6b0f219,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-e7c4cb87-4936-47db-969d-b29c9596688a,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-d4ec1fd6-e262-4489-8521-ec3dda389337,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-ed39d258-be09-4ad8-91ab-0c782084a263,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-a723b631-1c60-4df8-beb1-aca4d5e784c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-749709d5-d86a-4225-a78c-091db38fc723,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-4f5a8781-12bd-4e10-a5f1-0299b364b178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609692777-172.17.0.12-1597140954347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42457,DS-151623a4-8afd-4cf1-86c6-dba01380ac95,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-cdc9d78d-ca20-4a44-bb8a-1c5bd6b0f219,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-e7c4cb87-4936-47db-969d-b29c9596688a,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-d4ec1fd6-e262-4489-8521-ec3dda389337,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-ed39d258-be09-4ad8-91ab-0c782084a263,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-a723b631-1c60-4df8-beb1-aca4d5e784c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-749709d5-d86a-4225-a78c-091db38fc723,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-4f5a8781-12bd-4e10-a5f1-0299b364b178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952970184-172.17.0.12-1597141019632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44253,DS-72c27372-f801-416c-858f-91f3642a1c79,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-60cef99c-9bec-4808-bae4-cf308d04aef3,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-699bbc11-95d9-4815-a4cf-e4d719c46b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-0a571bc6-cd1f-4041-8133-cba52c37504f,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-e6668752-f62b-4ace-a622-0a5e04001f56,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-e731f533-246f-4b96-b17c-3d56a67df124,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-b9f00cf7-cca6-4c00-b114-5ca242c579f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-bb61c53d-424f-42a3-8d6a-3028aedda8bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952970184-172.17.0.12-1597141019632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44253,DS-72c27372-f801-416c-858f-91f3642a1c79,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-60cef99c-9bec-4808-bae4-cf308d04aef3,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-699bbc11-95d9-4815-a4cf-e4d719c46b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-0a571bc6-cd1f-4041-8133-cba52c37504f,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-e6668752-f62b-4ace-a622-0a5e04001f56,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-e731f533-246f-4b96-b17c-3d56a67df124,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-b9f00cf7-cca6-4c00-b114-5ca242c579f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-bb61c53d-424f-42a3-8d6a-3028aedda8bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5141
