reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635962433-172.17.0.11-1597163027721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33750,DS-e2fb1a61-d599-44d2-99a1-bff1cbdc31e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-72439233-8d3c-4170-a750-ca4284943a04,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-8e22a5bc-4d67-4b3c-a09e-1cebb7f37ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-87f65a5d-01c2-4780-93a6-48a09bc24632,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-3dbae32c-a745-4ded-9e7a-f87c2d77a98e,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-e8eb8837-07e9-40db-93f0-690e0f28c09b,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-6006812a-9b24-4a3f-a638-5c688ee98299,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-8bfc1868-ac64-44b0-9a2d-3fed3df1ac5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635962433-172.17.0.11-1597163027721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33750,DS-e2fb1a61-d599-44d2-99a1-bff1cbdc31e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-72439233-8d3c-4170-a750-ca4284943a04,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-8e22a5bc-4d67-4b3c-a09e-1cebb7f37ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-87f65a5d-01c2-4780-93a6-48a09bc24632,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-3dbae32c-a745-4ded-9e7a-f87c2d77a98e,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-e8eb8837-07e9-40db-93f0-690e0f28c09b,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-6006812a-9b24-4a3f-a638-5c688ee98299,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-8bfc1868-ac64-44b0-9a2d-3fed3df1ac5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432376740-172.17.0.11-1597163235543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32864,DS-909a81a5-cd1c-48d8-be56-748cddb1661e,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-6acff0d1-503d-4e39-9e34-618c31918772,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-aebf2ada-c858-4c9d-8b56-88e3e437e2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-0890e4a3-dda9-46ef-98c9-427daf71a0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-95798cda-e207-4da5-97e3-372c02add772,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-ffb2fcf5-017e-4ba3-91d2-594aff537027,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-1fd16de6-2abb-4eaa-a583-ea85cf8d09c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-89177d18-3206-4487-8d01-3015d759c0ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432376740-172.17.0.11-1597163235543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32864,DS-909a81a5-cd1c-48d8-be56-748cddb1661e,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-6acff0d1-503d-4e39-9e34-618c31918772,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-aebf2ada-c858-4c9d-8b56-88e3e437e2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-0890e4a3-dda9-46ef-98c9-427daf71a0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-95798cda-e207-4da5-97e3-372c02add772,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-ffb2fcf5-017e-4ba3-91d2-594aff537027,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-1fd16de6-2abb-4eaa-a583-ea85cf8d09c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-89177d18-3206-4487-8d01-3015d759c0ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014980604-172.17.0.11-1597163304050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33076,DS-d0173d0d-4bdd-42e3-8161-012f5f3be65e,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-6cf40d57-521e-48b6-ae8e-4387622b2e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-cd4a98e9-043e-4656-a259-efc11a85d5de,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-28a54ae1-8792-4a84-88b7-0d12cd67c7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-63413fc5-b8da-471b-be71-b5f22a4fb03d,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-7fd75652-27f8-414d-afd0-6b68b251e6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-bdc0990b-1321-4e51-bca9-face84ef22c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-34d56428-f10c-4c37-be2f-71697c233b93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014980604-172.17.0.11-1597163304050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33076,DS-d0173d0d-4bdd-42e3-8161-012f5f3be65e,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-6cf40d57-521e-48b6-ae8e-4387622b2e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-cd4a98e9-043e-4656-a259-efc11a85d5de,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-28a54ae1-8792-4a84-88b7-0d12cd67c7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-63413fc5-b8da-471b-be71-b5f22a4fb03d,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-7fd75652-27f8-414d-afd0-6b68b251e6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-bdc0990b-1321-4e51-bca9-face84ef22c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-34d56428-f10c-4c37-be2f-71697c233b93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806498644-172.17.0.11-1597163538754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38243,DS-60249c2e-0e9b-497a-9f63-d559a72a6dee,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-e0f60140-707d-44d3-9859-333878a54c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-4cb7694a-3cb5-4778-a453-eeef3e88734a,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-872fd4ff-f1f6-4308-a4ef-74039d86e198,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-2c85700d-958d-46d5-bcb1-9ef3e50ad44d,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-a231719e-dca9-459c-8b84-e261845207bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-eeb84bec-8270-4752-b06e-c1c0d85b9031,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-2f040f5d-9c39-48a5-8bd5-bea2bc3a26c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806498644-172.17.0.11-1597163538754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38243,DS-60249c2e-0e9b-497a-9f63-d559a72a6dee,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-e0f60140-707d-44d3-9859-333878a54c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-4cb7694a-3cb5-4778-a453-eeef3e88734a,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-872fd4ff-f1f6-4308-a4ef-74039d86e198,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-2c85700d-958d-46d5-bcb1-9ef3e50ad44d,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-a231719e-dca9-459c-8b84-e261845207bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-eeb84bec-8270-4752-b06e-c1c0d85b9031,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-2f040f5d-9c39-48a5-8bd5-bea2bc3a26c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140030034-172.17.0.11-1597163846194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39342,DS-a3200aff-7d9a-4235-82f1-7604dd691884,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-e60f3f84-9faa-497f-a8ec-f7fbc9f52fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-5d1497b1-e929-431d-9f62-b53d0206bbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-23c7e498-92bb-402b-82b6-3ce7c3d72e20,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-f687c437-7397-4317-b042-f09544558c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-95fdd815-c832-4af5-a2c0-cba6096d9e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-735297dc-7ab9-497c-ab1f-39e7da7a3e88,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-1c49806d-02a8-4a4e-bd24-11e10da32eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140030034-172.17.0.11-1597163846194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39342,DS-a3200aff-7d9a-4235-82f1-7604dd691884,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-e60f3f84-9faa-497f-a8ec-f7fbc9f52fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-5d1497b1-e929-431d-9f62-b53d0206bbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-23c7e498-92bb-402b-82b6-3ce7c3d72e20,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-f687c437-7397-4317-b042-f09544558c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-95fdd815-c832-4af5-a2c0-cba6096d9e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-735297dc-7ab9-497c-ab1f-39e7da7a3e88,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-1c49806d-02a8-4a4e-bd24-11e10da32eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977574387-172.17.0.11-1597163911734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42286,DS-697f60e2-e5b7-4038-938d-e9c3b94efcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-bf7369f9-bce2-49aa-9c04-8f9c988a5378,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-4e7ec5d3-3a10-4b0a-ab9d-4137c552dda7,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-55f2c3d2-e074-4fd1-a96e-e1a2d8723867,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-3df26fa7-3244-4dd2-8b97-c735a48cbc48,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-d878e8c5-12d0-4167-9cf3-0928dda32dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-570a9f3a-cbb3-47e3-9487-9940565a7c97,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-bd50778b-1368-4d59-a314-bdaae0bcc8c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977574387-172.17.0.11-1597163911734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42286,DS-697f60e2-e5b7-4038-938d-e9c3b94efcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-bf7369f9-bce2-49aa-9c04-8f9c988a5378,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-4e7ec5d3-3a10-4b0a-ab9d-4137c552dda7,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-55f2c3d2-e074-4fd1-a96e-e1a2d8723867,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-3df26fa7-3244-4dd2-8b97-c735a48cbc48,DISK], DatanodeInfoWithStorage[127.0.0.1:42497,DS-d878e8c5-12d0-4167-9cf3-0928dda32dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-570a9f3a-cbb3-47e3-9487-9940565a7c97,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-bd50778b-1368-4d59-a314-bdaae0bcc8c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907729389-172.17.0.11-1597164118219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-7897aad4-1e32-428a-9926-d1125451be7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-1010e839-bac1-4285-8164-69fcd0378615,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-9aa6773b-29eb-4429-a681-540e0b689d64,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-69c2eefd-5fc7-4513-9d60-d49d880d5fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-8f4efc03-b5eb-4bda-b082-6ad2316398bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-567fed3d-c822-4ad9-8e93-c0309c4d4cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-dcaf1beb-d583-44dd-a2ab-6f517ed5f0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-e8b1fd2e-fed7-4999-b7ef-044460075d7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1907729389-172.17.0.11-1597164118219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-7897aad4-1e32-428a-9926-d1125451be7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-1010e839-bac1-4285-8164-69fcd0378615,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-9aa6773b-29eb-4429-a681-540e0b689d64,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-69c2eefd-5fc7-4513-9d60-d49d880d5fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-8f4efc03-b5eb-4bda-b082-6ad2316398bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-567fed3d-c822-4ad9-8e93-c0309c4d4cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-dcaf1beb-d583-44dd-a2ab-6f517ed5f0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-e8b1fd2e-fed7-4999-b7ef-044460075d7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-26842251-172.17.0.11-1597164846159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46162,DS-ab39c24b-e7a3-4eb7-b55d-a8604f3d7b62,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-b67df8a5-c97b-4937-886c-494830494f25,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-69cde5c6-3ad3-4fa5-9778-559a47b37b18,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-24f23f57-3ea0-4c25-865f-371e3c95cb98,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-a9b40186-183f-49d3-a787-1ea75e1fc66b,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-252afa0b-03e5-4d9f-ba4b-5c1348d90467,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-c28867bf-9314-4734-a2da-9549ec5950a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-368a4acf-fdca-4f4c-b54e-0c00d2532025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-26842251-172.17.0.11-1597164846159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46162,DS-ab39c24b-e7a3-4eb7-b55d-a8604f3d7b62,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-b67df8a5-c97b-4937-886c-494830494f25,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-69cde5c6-3ad3-4fa5-9778-559a47b37b18,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-24f23f57-3ea0-4c25-865f-371e3c95cb98,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-a9b40186-183f-49d3-a787-1ea75e1fc66b,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-252afa0b-03e5-4d9f-ba4b-5c1348d90467,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-c28867bf-9314-4734-a2da-9549ec5950a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-368a4acf-fdca-4f4c-b54e-0c00d2532025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332017874-172.17.0.11-1597164877226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36613,DS-3e3931cd-5e4e-4d60-a195-89cf7f17d01a,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-0a652b1e-775c-403b-96b6-4f1a9bb20a41,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-2ab91d90-4630-496b-b37d-ddf012e3f333,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-f57114ba-917e-4122-afd7-4c554bdc55ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-a787c2d2-f190-41fe-973a-a86269e42510,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-cd75cf28-a7d3-4ceb-9a91-754b76a05592,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-7af36db8-14b0-48ff-85fc-434d4bd0e270,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-84407b06-9dc6-4a01-a819-13e857887b2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332017874-172.17.0.11-1597164877226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36613,DS-3e3931cd-5e4e-4d60-a195-89cf7f17d01a,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-0a652b1e-775c-403b-96b6-4f1a9bb20a41,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-2ab91d90-4630-496b-b37d-ddf012e3f333,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-f57114ba-917e-4122-afd7-4c554bdc55ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-a787c2d2-f190-41fe-973a-a86269e42510,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-cd75cf28-a7d3-4ceb-9a91-754b76a05592,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-7af36db8-14b0-48ff-85fc-434d4bd0e270,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-84407b06-9dc6-4a01-a819-13e857887b2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665222113-172.17.0.11-1597165061631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45773,DS-96e8d759-ac80-40bc-bec7-c50bdff08290,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-7fb44ece-ac33-46cd-a644-baa6064bbc33,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-f0f0fab5-d5db-462e-97c8-695e16fe02c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-db4e20c8-005d-4a35-9bb5-514c230bfbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-3f60e6b1-f0a6-48dd-a213-dc39d12ad570,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-20ae0089-8d1f-4b24-89fa-3dfb7ab22d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-eb51d6dc-d0f3-4777-89d3-ed6b8f9cfb71,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-bed539b7-01a6-40fb-b960-abc41fd7c6a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665222113-172.17.0.11-1597165061631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45773,DS-96e8d759-ac80-40bc-bec7-c50bdff08290,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-7fb44ece-ac33-46cd-a644-baa6064bbc33,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-f0f0fab5-d5db-462e-97c8-695e16fe02c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-db4e20c8-005d-4a35-9bb5-514c230bfbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-3f60e6b1-f0a6-48dd-a213-dc39d12ad570,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-20ae0089-8d1f-4b24-89fa-3dfb7ab22d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-eb51d6dc-d0f3-4777-89d3-ed6b8f9cfb71,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-bed539b7-01a6-40fb-b960-abc41fd7c6a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448005421-172.17.0.11-1597165215587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35072,DS-4db8a98d-e82f-4aa8-a95f-d8fffb016aec,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-e7baf629-69ef-438c-b282-c2674a0513c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-bb950dbf-4db1-4354-b07e-7a68776bae53,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-05bf3b8f-7e58-4ef1-995d-2f99b97a4573,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-88d1e35b-45e0-4aca-9de3-c3866857df6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-24ca43b4-4dfe-422c-b00e-706e6916532e,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-499ef294-d571-4452-ba91-34a135ea40ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-0cea1ba7-bf00-4e8a-a2d1-52c390db1977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448005421-172.17.0.11-1597165215587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35072,DS-4db8a98d-e82f-4aa8-a95f-d8fffb016aec,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-e7baf629-69ef-438c-b282-c2674a0513c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-bb950dbf-4db1-4354-b07e-7a68776bae53,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-05bf3b8f-7e58-4ef1-995d-2f99b97a4573,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-88d1e35b-45e0-4aca-9de3-c3866857df6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-24ca43b4-4dfe-422c-b00e-706e6916532e,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-499ef294-d571-4452-ba91-34a135ea40ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-0cea1ba7-bf00-4e8a-a2d1-52c390db1977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006822445-172.17.0.11-1597165573864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39509,DS-a307dbc9-cb1e-409b-b3aa-d12cd643eade,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-eab56d2a-e12f-4d38-aa29-f296eb94ccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-9bcd42d0-c91b-4413-814e-50ae28826bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-cbfdaf27-1cd5-441f-8848-c4afd9b9a79f,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-26789542-ccca-4dfd-8ef6-fbbb37b0b557,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-e3aeea65-e22a-4092-926f-4f535092966b,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-adbbcec8-510d-4f8a-a27f-5fd157c80353,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-e0c27f5e-7dac-4eeb-9932-ae8e6bbcd4f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006822445-172.17.0.11-1597165573864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39509,DS-a307dbc9-cb1e-409b-b3aa-d12cd643eade,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-eab56d2a-e12f-4d38-aa29-f296eb94ccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-9bcd42d0-c91b-4413-814e-50ae28826bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-cbfdaf27-1cd5-441f-8848-c4afd9b9a79f,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-26789542-ccca-4dfd-8ef6-fbbb37b0b557,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-e3aeea65-e22a-4092-926f-4f535092966b,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-adbbcec8-510d-4f8a-a27f-5fd157c80353,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-e0c27f5e-7dac-4eeb-9932-ae8e6bbcd4f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253891504-172.17.0.11-1597165912312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37653,DS-277dc293-9305-4506-98f9-df31d69d06da,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-ece2ecad-96a8-435e-ab4c-9376855b29ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-5a71857f-43c7-41eb-a737-583747f39a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-0252ae14-200e-475d-b78f-493bafc43df2,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-e30ea68b-ef6f-41a1-b640-99c7250a1987,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-9d2dde32-5a98-4867-8927-69c0bccb3a06,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-138c9a49-bd4d-4288-a2ed-eb7363bbcc35,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-5ef1705e-aeb9-42c1-b26f-50589d07b9fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253891504-172.17.0.11-1597165912312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37653,DS-277dc293-9305-4506-98f9-df31d69d06da,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-ece2ecad-96a8-435e-ab4c-9376855b29ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-5a71857f-43c7-41eb-a737-583747f39a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-0252ae14-200e-475d-b78f-493bafc43df2,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-e30ea68b-ef6f-41a1-b640-99c7250a1987,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-9d2dde32-5a98-4867-8927-69c0bccb3a06,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-138c9a49-bd4d-4288-a2ed-eb7363bbcc35,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-5ef1705e-aeb9-42c1-b26f-50589d07b9fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147169972-172.17.0.11-1597166473045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40569,DS-22d6558e-256e-42b8-9ee9-caa8dbad31d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-44c55e40-a002-441e-a60f-554f8eaea543,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-0876d51a-e348-4628-8690-7e0d2c26271a,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-36426f8d-f94d-433c-bfb3-dd56d0a45b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-bce87ac6-1514-4d75-93b6-3f054c15616b,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-983a2bcd-0623-4d92-98da-aa7c53804fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-2b7b7aa6-b419-4f88-a27e-eff1ff835d09,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-83b21d4b-a6c6-414d-8d35-f1f8fbf038ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147169972-172.17.0.11-1597166473045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40569,DS-22d6558e-256e-42b8-9ee9-caa8dbad31d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-44c55e40-a002-441e-a60f-554f8eaea543,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-0876d51a-e348-4628-8690-7e0d2c26271a,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-36426f8d-f94d-433c-bfb3-dd56d0a45b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-bce87ac6-1514-4d75-93b6-3f054c15616b,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-983a2bcd-0623-4d92-98da-aa7c53804fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-2b7b7aa6-b419-4f88-a27e-eff1ff835d09,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-83b21d4b-a6c6-414d-8d35-f1f8fbf038ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756878031-172.17.0.11-1597166582880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45689,DS-3e687a35-470d-4bdd-a541-3302ef68089c,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-7c2bd4f9-5c9f-46a9-9482-89479d663a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-8fad3a94-6ae6-4567-ac31-7e44f93a4c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-e4a422c8-172a-47d8-a2a2-6c53d14341f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-e9507df7-476a-40e5-b1c9-2da776f39573,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-ef9aa9e1-249d-4e57-974e-78d1b5f29a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-e1331be7-99fd-478f-98c7-da6f41e58dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-81dc27ad-eff6-4d36-b96a-45f5208c9924,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756878031-172.17.0.11-1597166582880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45689,DS-3e687a35-470d-4bdd-a541-3302ef68089c,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-7c2bd4f9-5c9f-46a9-9482-89479d663a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-8fad3a94-6ae6-4567-ac31-7e44f93a4c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-e4a422c8-172a-47d8-a2a2-6c53d14341f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-e9507df7-476a-40e5-b1c9-2da776f39573,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-ef9aa9e1-249d-4e57-974e-78d1b5f29a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-e1331be7-99fd-478f-98c7-da6f41e58dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-81dc27ad-eff6-4d36-b96a-45f5208c9924,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487838342-172.17.0.11-1597166872041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42208,DS-e4f82fac-1967-49cd-b775-69968cf0db0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-67781c68-c28e-4e18-8918-d331d247c1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-af3085d6-63d1-44ba-b94d-91d79b25e030,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-ee866bad-6e0b-4550-9144-576b746ff7db,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-9ff75563-1479-46e3-92be-59838a1b1ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-516fc5d5-9ffb-40e2-ba65-348aa33fe44e,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-a9dc7831-a9ea-41c5-a829-06c31c0ee0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-231eb5a9-7e33-4aa0-a71f-fa2201fe15fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487838342-172.17.0.11-1597166872041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42208,DS-e4f82fac-1967-49cd-b775-69968cf0db0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-67781c68-c28e-4e18-8918-d331d247c1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-af3085d6-63d1-44ba-b94d-91d79b25e030,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-ee866bad-6e0b-4550-9144-576b746ff7db,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-9ff75563-1479-46e3-92be-59838a1b1ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-516fc5d5-9ffb-40e2-ba65-348aa33fe44e,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-a9dc7831-a9ea-41c5-a829-06c31c0ee0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-231eb5a9-7e33-4aa0-a71f-fa2201fe15fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767774006-172.17.0.11-1597167444703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37261,DS-20304a3b-65d3-4a8c-92bb-9140cfa946b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-c1e5be70-6ac2-42e4-af03-94b3ba2f317a,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-d7d1cd8c-8cfc-471d-a307-8c6e34a57486,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-93294c51-e0b5-45d5-8645-4e9724967a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-f0f5fab5-d28a-4a16-904a-04db2e2b6632,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-3724f63f-de53-4b23-a830-09fcc590eb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-e69d6034-3db0-4072-b242-4744df5db4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-33f1b70e-0471-4312-8f24-0a5015c254ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767774006-172.17.0.11-1597167444703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37261,DS-20304a3b-65d3-4a8c-92bb-9140cfa946b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-c1e5be70-6ac2-42e4-af03-94b3ba2f317a,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-d7d1cd8c-8cfc-471d-a307-8c6e34a57486,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-93294c51-e0b5-45d5-8645-4e9724967a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-f0f5fab5-d28a-4a16-904a-04db2e2b6632,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-3724f63f-de53-4b23-a830-09fcc590eb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-e69d6034-3db0-4072-b242-4744df5db4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-33f1b70e-0471-4312-8f24-0a5015c254ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992010738-172.17.0.11-1597167554731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35118,DS-99dcd209-7357-4c3a-93c6-88efdbf30c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-d1bb3898-a749-46ac-83d0-a5d539ce7c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-7609366a-7fa0-4000-8ad6-669ae2935fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-3fd4643e-7699-440d-a1dc-8f62ab883304,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-3768f8fa-2d5a-4a63-b1f0-b8188a418607,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-1d3141e4-3853-4b76-94fe-4fd82cd485a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-11cace3f-b643-46e0-874b-9d5d08a62fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-3af35897-aabf-46e8-b29c-808d4c7d8c21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992010738-172.17.0.11-1597167554731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35118,DS-99dcd209-7357-4c3a-93c6-88efdbf30c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-d1bb3898-a749-46ac-83d0-a5d539ce7c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-7609366a-7fa0-4000-8ad6-669ae2935fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-3fd4643e-7699-440d-a1dc-8f62ab883304,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-3768f8fa-2d5a-4a63-b1f0-b8188a418607,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-1d3141e4-3853-4b76-94fe-4fd82cd485a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-11cace3f-b643-46e0-874b-9d5d08a62fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-3af35897-aabf-46e8-b29c-808d4c7d8c21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113713417-172.17.0.11-1597167592139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36553,DS-70e788e5-77c3-4ccc-adc2-f92afe35bf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-5260449f-ee0e-4997-91d2-1a1bd6e21b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-ab92b899-1dab-4b7f-a72d-1bdd74244c72,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-914d037b-adaf-4a99-b0aa-23c19ee00fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-f3823f2b-0228-4201-a59d-578c292c9609,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-fd4a16d2-0712-4b44-a1a0-f56f9bcd7fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-686650ed-ea41-441a-9f50-5da06c313132,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-c5a9146b-dc3b-4a0d-a3da-21bfe1fefbcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113713417-172.17.0.11-1597167592139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36553,DS-70e788e5-77c3-4ccc-adc2-f92afe35bf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-5260449f-ee0e-4997-91d2-1a1bd6e21b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-ab92b899-1dab-4b7f-a72d-1bdd74244c72,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-914d037b-adaf-4a99-b0aa-23c19ee00fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-f3823f2b-0228-4201-a59d-578c292c9609,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-fd4a16d2-0712-4b44-a1a0-f56f9bcd7fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-686650ed-ea41-441a-9f50-5da06c313132,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-c5a9146b-dc3b-4a0d-a3da-21bfe1fefbcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712399724-172.17.0.11-1597167933200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45327,DS-90cf6be7-49e7-4e43-a71a-3ebac1f47829,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-8e6e45bb-2665-41f8-bd8b-2e71bf841a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-cae60b8d-2cf0-4643-9d41-75727274bde0,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-e3e0e9bf-35bb-4beb-836f-22ab5b63fb96,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-c52b1e34-fb4f-45b9-988d-0cb7616f29ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-fdf04f6c-116b-4bd5-9641-375589f0cc24,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-76f00ddb-ee18-4c81-98c3-a31429c509fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-9c6c3dc0-e16f-43f7-95bc-8b37fb152600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712399724-172.17.0.11-1597167933200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45327,DS-90cf6be7-49e7-4e43-a71a-3ebac1f47829,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-8e6e45bb-2665-41f8-bd8b-2e71bf841a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-cae60b8d-2cf0-4643-9d41-75727274bde0,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-e3e0e9bf-35bb-4beb-836f-22ab5b63fb96,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-c52b1e34-fb4f-45b9-988d-0cb7616f29ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-fdf04f6c-116b-4bd5-9641-375589f0cc24,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-76f00ddb-ee18-4c81-98c3-a31429c509fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-9c6c3dc0-e16f-43f7-95bc-8b37fb152600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 5106
