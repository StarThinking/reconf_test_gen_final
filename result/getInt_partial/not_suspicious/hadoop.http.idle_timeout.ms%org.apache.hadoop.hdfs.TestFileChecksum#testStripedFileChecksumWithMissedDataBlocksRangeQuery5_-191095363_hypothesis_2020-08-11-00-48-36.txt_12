reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170437607-172.17.0.7-1597106969251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-47ab9930-d41d-4595-91c5-1e82d1dc0b96,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-edfea96c-dd5c-484d-8268-fd6d1fcafd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-04ad8847-3bb7-4792-bf9c-46727e4ece3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-115307c6-57d3-48fc-a918-75176218fafd,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-6c32a952-cdc0-4886-8f9f-596c8715eb62,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-56967e61-92e5-42bd-8f3d-61f62c747d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-39f41357-138e-4be5-a146-7df5a727c779,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-3567fbf3-7724-43a7-9671-17b527eb5a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170437607-172.17.0.7-1597106969251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-47ab9930-d41d-4595-91c5-1e82d1dc0b96,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-edfea96c-dd5c-484d-8268-fd6d1fcafd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-04ad8847-3bb7-4792-bf9c-46727e4ece3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-115307c6-57d3-48fc-a918-75176218fafd,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-6c32a952-cdc0-4886-8f9f-596c8715eb62,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-56967e61-92e5-42bd-8f3d-61f62c747d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-39f41357-138e-4be5-a146-7df5a727c779,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-3567fbf3-7724-43a7-9671-17b527eb5a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706353733-172.17.0.7-1597107282784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41358,DS-b9a19819-fe29-4998-ac07-633f963e24c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-0ad38702-ba5c-49e8-8737-9920cdbd2541,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-b8da8396-c951-41d4-a0de-4723cecf14bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-0c37daa4-648e-482b-9ac4-1680a4b68a95,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-ca5be7bf-e584-4fc8-98ca-5cc7062421e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-5dec5e6c-3d3a-4375-8fca-6821f62d0119,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-90e0e16e-f247-4ff6-bd3f-91f6e780df0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-857b40b6-a6b5-4cfd-b756-f89248187920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706353733-172.17.0.7-1597107282784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41358,DS-b9a19819-fe29-4998-ac07-633f963e24c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-0ad38702-ba5c-49e8-8737-9920cdbd2541,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-b8da8396-c951-41d4-a0de-4723cecf14bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-0c37daa4-648e-482b-9ac4-1680a4b68a95,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-ca5be7bf-e584-4fc8-98ca-5cc7062421e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-5dec5e6c-3d3a-4375-8fca-6821f62d0119,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-90e0e16e-f247-4ff6-bd3f-91f6e780df0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-857b40b6-a6b5-4cfd-b756-f89248187920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10845790-172.17.0.7-1597107564729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44029,DS-5463dae8-e099-46de-8891-9a31edaa518e,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-e072ca6f-19e7-4e3b-8b03-19ca5e006c50,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-9a5c020a-70a4-4b97-bcc4-db0cdfc847ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-390a16a1-117a-45a0-84f5-cf383a23fbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-416fb282-f3cf-4799-bb39-a30c0c2ca9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-7d3365f4-30d0-4b46-a9c5-265df41e0cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-b5d4e160-03c5-458d-ac92-43f602afeaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-a99a0d6a-2f1c-42ed-940a-f528a6bcd2ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10845790-172.17.0.7-1597107564729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44029,DS-5463dae8-e099-46de-8891-9a31edaa518e,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-e072ca6f-19e7-4e3b-8b03-19ca5e006c50,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-9a5c020a-70a4-4b97-bcc4-db0cdfc847ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-390a16a1-117a-45a0-84f5-cf383a23fbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-416fb282-f3cf-4799-bb39-a30c0c2ca9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-7d3365f4-30d0-4b46-a9c5-265df41e0cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-b5d4e160-03c5-458d-ac92-43f602afeaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-a99a0d6a-2f1c-42ed-940a-f528a6bcd2ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895561103-172.17.0.7-1597107638519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45541,DS-485e1661-9e9e-48d7-bd30-6750cd675219,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-265376b2-22e5-4522-a2c8-6d8f27482e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-dcac89d9-48ec-4ee2-8afb-c07ab7cf969b,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-af118777-8783-40db-8130-47295d032882,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-e2f97f63-e74d-4777-b94e-91e84c5978e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-5baa1f3a-54b5-4688-ae6e-2e3991e09dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-018d1df2-c2ce-45d1-81d9-b5c6ddefd247,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-21275008-f904-4567-8d57-fccdaa98ac95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895561103-172.17.0.7-1597107638519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45541,DS-485e1661-9e9e-48d7-bd30-6750cd675219,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-265376b2-22e5-4522-a2c8-6d8f27482e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-dcac89d9-48ec-4ee2-8afb-c07ab7cf969b,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-af118777-8783-40db-8130-47295d032882,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-e2f97f63-e74d-4777-b94e-91e84c5978e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-5baa1f3a-54b5-4688-ae6e-2e3991e09dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-018d1df2-c2ce-45d1-81d9-b5c6ddefd247,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-21275008-f904-4567-8d57-fccdaa98ac95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313190825-172.17.0.7-1597108312055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45701,DS-add019b9-6720-4a0e-b8eb-387cf1b293c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-81c125f5-bbd0-46f4-b0aa-0d17727c8b24,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-f62f29e5-faa1-48ab-8f0a-895e97bc5567,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-67af110d-bc48-4527-8912-23c646e7425a,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-6d771b03-954e-4858-95ed-034a0ef3cd97,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-bea8b929-33ce-482f-90f0-93aa2965c09c,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-7bd26a62-95e3-4d26-8552-4a09d61e9a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-1ee66059-a8b4-44ae-bb55-5c09ba550d30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313190825-172.17.0.7-1597108312055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45701,DS-add019b9-6720-4a0e-b8eb-387cf1b293c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-81c125f5-bbd0-46f4-b0aa-0d17727c8b24,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-f62f29e5-faa1-48ab-8f0a-895e97bc5567,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-67af110d-bc48-4527-8912-23c646e7425a,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-6d771b03-954e-4858-95ed-034a0ef3cd97,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-bea8b929-33ce-482f-90f0-93aa2965c09c,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-7bd26a62-95e3-4d26-8552-4a09d61e9a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-1ee66059-a8b4-44ae-bb55-5c09ba550d30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293686978-172.17.0.7-1597108482784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39606,DS-ec5c520b-f91e-4185-90c6-ad80e5684e47,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-7cbd23e4-a91d-49d3-84fe-ab4b68b04b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-836b5320-1049-495b-90d4-e9110d2b34f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-4fbf8c46-5845-4e2d-bbfe-3e3bb48143e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-ebe19249-f5df-4c6d-a9e5-d112f97223cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-626129b0-fa3b-41d6-94e9-ff9483197078,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-36b5be93-44e8-45ee-a68c-1c3b549ede44,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-a1568755-7232-4ead-8d83-f19259bca2ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293686978-172.17.0.7-1597108482784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39606,DS-ec5c520b-f91e-4185-90c6-ad80e5684e47,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-7cbd23e4-a91d-49d3-84fe-ab4b68b04b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-836b5320-1049-495b-90d4-e9110d2b34f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-4fbf8c46-5845-4e2d-bbfe-3e3bb48143e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-ebe19249-f5df-4c6d-a9e5-d112f97223cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-626129b0-fa3b-41d6-94e9-ff9483197078,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-36b5be93-44e8-45ee-a68c-1c3b549ede44,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-a1568755-7232-4ead-8d83-f19259bca2ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628296505-172.17.0.7-1597108993411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40852,DS-e1472105-aee0-4c91-8dbe-22c1093e6a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-b7fe75b6-770f-433d-86f6-e817f0a9e3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-6296e158-e6cc-493d-a1d8-e84702aa06fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-92b89298-285e-41a2-b7c1-592de540f0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-02dc4d12-da61-4ebc-86ba-7a031de5569b,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-a2839236-d067-4f04-9e8e-3f728b9daa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-bc72d289-7f37-4433-a2c0-86644bf88cce,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-821d989a-b648-4892-bca6-396f4bbf7568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628296505-172.17.0.7-1597108993411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40852,DS-e1472105-aee0-4c91-8dbe-22c1093e6a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-b7fe75b6-770f-433d-86f6-e817f0a9e3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-6296e158-e6cc-493d-a1d8-e84702aa06fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-92b89298-285e-41a2-b7c1-592de540f0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-02dc4d12-da61-4ebc-86ba-7a031de5569b,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-a2839236-d067-4f04-9e8e-3f728b9daa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-bc72d289-7f37-4433-a2c0-86644bf88cce,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-821d989a-b648-4892-bca6-396f4bbf7568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572148940-172.17.0.7-1597109351362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-4484cdd9-f45d-468f-a1d1-3b78f693b594,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-cdbd45e6-16be-41e1-bc98-39651144719a,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-fd491b6e-7d92-4e39-bdce-a1a83bace4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-28b62bdf-5c6f-48cc-aac4-d316b3ce351a,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-8e053388-600e-41dd-84f1-94594ef8b19e,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-81e040a9-9d14-4efe-b55b-7bbd563ce209,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-b0bee987-d927-44fb-85a2-7256cd12eb64,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-781067f5-df87-407c-92d6-70cb9cf564dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572148940-172.17.0.7-1597109351362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-4484cdd9-f45d-468f-a1d1-3b78f693b594,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-cdbd45e6-16be-41e1-bc98-39651144719a,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-fd491b6e-7d92-4e39-bdce-a1a83bace4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-28b62bdf-5c6f-48cc-aac4-d316b3ce351a,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-8e053388-600e-41dd-84f1-94594ef8b19e,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-81e040a9-9d14-4efe-b55b-7bbd563ce209,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-b0bee987-d927-44fb-85a2-7256cd12eb64,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-781067f5-df87-407c-92d6-70cb9cf564dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827829910-172.17.0.7-1597109892536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40988,DS-ec033a7d-217e-499c-87b4-7b9857a8e963,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-9e253545-89d6-4f58-88cd-b85d9fc80ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-dec4e3d3-f77f-4e44-a268-4e926a320087,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-59faea06-71e0-48dc-815b-ae2b8a4fdb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-d4a96668-cebe-4ad4-af18-cda23747e7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-8a5b41d8-2dab-40ec-96c2-3fde5ec230c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-5c2f07e5-3ca2-402a-a0e4-c07a5e200b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-6be39a59-38d3-4e2b-95f6-e6225bc4a674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827829910-172.17.0.7-1597109892536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40988,DS-ec033a7d-217e-499c-87b4-7b9857a8e963,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-9e253545-89d6-4f58-88cd-b85d9fc80ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-dec4e3d3-f77f-4e44-a268-4e926a320087,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-59faea06-71e0-48dc-815b-ae2b8a4fdb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-d4a96668-cebe-4ad4-af18-cda23747e7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-8a5b41d8-2dab-40ec-96c2-3fde5ec230c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-5c2f07e5-3ca2-402a-a0e4-c07a5e200b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-6be39a59-38d3-4e2b-95f6-e6225bc4a674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661771043-172.17.0.7-1597110535990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40242,DS-5055d5c7-0184-4519-91d6-b7e6a3fd9365,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-29326822-92ef-4377-a675-879484912639,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-518f2a9b-e897-4f90-b485-476d78f45e39,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-141f0540-2fba-43e7-87ef-2e6c336b149d,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-94ada813-e9c2-47e7-aba8-7cdef28e92fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-2b149414-b008-4369-9b51-5dd47f11c18d,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-df5b7207-19b3-4820-8809-4e2509a6c3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-212ede7c-921b-4268-b775-eb82e8b3b946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661771043-172.17.0.7-1597110535990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40242,DS-5055d5c7-0184-4519-91d6-b7e6a3fd9365,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-29326822-92ef-4377-a675-879484912639,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-518f2a9b-e897-4f90-b485-476d78f45e39,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-141f0540-2fba-43e7-87ef-2e6c336b149d,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-94ada813-e9c2-47e7-aba8-7cdef28e92fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-2b149414-b008-4369-9b51-5dd47f11c18d,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-df5b7207-19b3-4820-8809-4e2509a6c3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-212ede7c-921b-4268-b775-eb82e8b3b946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408916358-172.17.0.7-1597110683537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39719,DS-dae90b12-a055-46a0-97ff-ca7cd1c7417c,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-535446c5-afd4-48e1-9b1c-91aed80811a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-f86679d8-022d-4797-80d2-9166396f4c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-0600da1b-852d-4abe-a5a7-809f24eede97,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-96d440d5-e7de-4e14-a3f7-8c3b160c02b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-f43c7220-fded-4021-ba91-90e583360867,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-fffbe7cc-348a-4eaa-82f9-c520ac5793be,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-d34a7364-536d-4bcb-a55a-9af28391d1f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408916358-172.17.0.7-1597110683537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39719,DS-dae90b12-a055-46a0-97ff-ca7cd1c7417c,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-535446c5-afd4-48e1-9b1c-91aed80811a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-f86679d8-022d-4797-80d2-9166396f4c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-0600da1b-852d-4abe-a5a7-809f24eede97,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-96d440d5-e7de-4e14-a3f7-8c3b160c02b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-f43c7220-fded-4021-ba91-90e583360867,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-fffbe7cc-348a-4eaa-82f9-c520ac5793be,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-d34a7364-536d-4bcb-a55a-9af28391d1f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115403983-172.17.0.7-1597111314345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42301,DS-4cc727ba-710b-4c94-9104-8fcb104aadee,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-ffcac36a-c9fc-4856-87d7-1c2c210b0aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-62c8859a-ccb1-4aee-a249-76e2ed63dba5,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-8631b3da-17a4-4ad1-803f-032dba14b62d,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-795157bb-c78a-4437-a88c-3fb8fcda1260,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-8e708abc-f6a7-49e5-877c-5e7560e4f702,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-63279793-3253-4609-81bd-33aa7e482cde,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-487e3f17-41bc-4ced-8d4e-7296dddf3997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115403983-172.17.0.7-1597111314345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42301,DS-4cc727ba-710b-4c94-9104-8fcb104aadee,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-ffcac36a-c9fc-4856-87d7-1c2c210b0aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-62c8859a-ccb1-4aee-a249-76e2ed63dba5,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-8631b3da-17a4-4ad1-803f-032dba14b62d,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-795157bb-c78a-4437-a88c-3fb8fcda1260,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-8e708abc-f6a7-49e5-877c-5e7560e4f702,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-63279793-3253-4609-81bd-33aa7e482cde,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-487e3f17-41bc-4ced-8d4e-7296dddf3997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458357371-172.17.0.7-1597111473239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41272,DS-74a17358-033d-42fb-ac6b-60fa99808686,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-d2a7c959-1cb1-4a73-86ba-bf694a122bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-27eaeedc-198e-4b57-9539-0f513d7c40b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-42fce4c2-6979-4f3a-97a1-2005e094524d,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-4e01862d-2616-4a71-b078-59f539c1ec53,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-8fa052bf-5fd2-4900-8b7e-b478276cfe56,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-c1f076d6-d5e7-4893-9ea9-f33b7f8e8840,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-f4c86704-c436-4279-8293-d2ccd5be3e0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458357371-172.17.0.7-1597111473239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41272,DS-74a17358-033d-42fb-ac6b-60fa99808686,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-d2a7c959-1cb1-4a73-86ba-bf694a122bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-27eaeedc-198e-4b57-9539-0f513d7c40b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-42fce4c2-6979-4f3a-97a1-2005e094524d,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-4e01862d-2616-4a71-b078-59f539c1ec53,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-8fa052bf-5fd2-4900-8b7e-b478276cfe56,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-c1f076d6-d5e7-4893-9ea9-f33b7f8e8840,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-f4c86704-c436-4279-8293-d2ccd5be3e0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 2000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535454042-172.17.0.7-1597112113377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42010,DS-e5c6789c-378d-49fc-aa13-68752a643323,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-b3cb2128-9069-4c74-a3ab-bb1046be04c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-f3b8d981-4bd5-4c86-8679-2700c2c3b5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-6826931e-7bbc-4d9f-8a05-0d6ea2205995,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-2613c534-9414-485e-b821-c075ee98e80d,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-a99deaf1-01f3-4b0d-9973-5771e25196dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-cd0decb8-c262-43b2-a604-eb563ef2f033,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-1212d7fb-ec3b-49cc-a5c1-28e632a8f0bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535454042-172.17.0.7-1597112113377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42010,DS-e5c6789c-378d-49fc-aa13-68752a643323,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-b3cb2128-9069-4c74-a3ab-bb1046be04c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-f3b8d981-4bd5-4c86-8679-2700c2c3b5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-6826931e-7bbc-4d9f-8a05-0d6ea2205995,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-2613c534-9414-485e-b821-c075ee98e80d,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-a99deaf1-01f3-4b0d-9973-5771e25196dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-cd0decb8-c262-43b2-a604-eb563ef2f033,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-1212d7fb-ec3b-49cc-a5c1-28e632a8f0bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5371
