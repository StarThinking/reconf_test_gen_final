reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178213971-172.17.0.5-1597191022067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35329,DS-7f99b5af-9bf4-4fdf-9eb5-a361dd00ba88,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-267b7e13-9d14-48bf-8a7a-0b618e6573a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-75dc1c68-d6ab-461a-8d4f-1943bf70772e,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-df5c7a05-977e-4218-a52b-728898d9aab0,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-dc06bdee-516d-434b-9ae3-5403520461a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-d74c0beb-b78d-4442-a4fe-0acdf8e94c06,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-e788d2d2-79ff-4983-a7cd-5fc303127363,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-432855c3-e915-4455-b9dc-5f747847c832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178213971-172.17.0.5-1597191022067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35329,DS-7f99b5af-9bf4-4fdf-9eb5-a361dd00ba88,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-267b7e13-9d14-48bf-8a7a-0b618e6573a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-75dc1c68-d6ab-461a-8d4f-1943bf70772e,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-df5c7a05-977e-4218-a52b-728898d9aab0,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-dc06bdee-516d-434b-9ae3-5403520461a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-d74c0beb-b78d-4442-a4fe-0acdf8e94c06,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-e788d2d2-79ff-4983-a7cd-5fc303127363,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-432855c3-e915-4455-b9dc-5f747847c832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742716226-172.17.0.5-1597191158633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37809,DS-1fe768da-df1c-418b-a069-2b59ba7b1fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-12602386-e456-47b0-9807-5a9b66c4cc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-df3db3ff-174a-4565-98cb-7fdf567d054b,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-f0154878-02a8-4382-b684-1588a74a4a36,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-54ccc677-763d-4353-a849-4767b2b856a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-63862cb6-f4e1-47c5-9e17-c2e922ebe6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-ea74dc7c-aa8d-44dc-9447-1f8f5c8e0f68,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-32f3ce9d-dfe6-4aff-b4ef-6562ec910fa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742716226-172.17.0.5-1597191158633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37809,DS-1fe768da-df1c-418b-a069-2b59ba7b1fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-12602386-e456-47b0-9807-5a9b66c4cc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-df3db3ff-174a-4565-98cb-7fdf567d054b,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-f0154878-02a8-4382-b684-1588a74a4a36,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-54ccc677-763d-4353-a849-4767b2b856a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-63862cb6-f4e1-47c5-9e17-c2e922ebe6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-ea74dc7c-aa8d-44dc-9447-1f8f5c8e0f68,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-32f3ce9d-dfe6-4aff-b4ef-6562ec910fa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565854076-172.17.0.5-1597191366354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-f07e6a44-f719-4e55-b12f-d755bad2b262,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-1b0a0b23-6172-434a-a475-8484c7fe282e,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-6c19a4e1-dbd2-4629-aa37-073802c4fdff,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-2505a157-4506-4b37-8a17-ce2b06ac2497,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-b84d6e67-ab5c-4ec4-a906-82a6ca8b437a,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-c13c9423-901d-4564-ae6d-3ca4baeb79ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-89367565-66a4-4189-b779-af55802e4ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-62576f5a-9628-421f-8a90-3bd69cf17022,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565854076-172.17.0.5-1597191366354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-f07e6a44-f719-4e55-b12f-d755bad2b262,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-1b0a0b23-6172-434a-a475-8484c7fe282e,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-6c19a4e1-dbd2-4629-aa37-073802c4fdff,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-2505a157-4506-4b37-8a17-ce2b06ac2497,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-b84d6e67-ab5c-4ec4-a906-82a6ca8b437a,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-c13c9423-901d-4564-ae6d-3ca4baeb79ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-89367565-66a4-4189-b779-af55802e4ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-62576f5a-9628-421f-8a90-3bd69cf17022,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527183381-172.17.0.5-1597191794496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42686,DS-17d165f0-e609-43c8-a0cf-c0e29cd48abf,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-4f2c7038-e4b1-4fb3-b813-9a0bcd891f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-153be162-68e1-484d-9428-2bcba730d469,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-9bfcec2a-c944-473a-9b0e-0be7ba07dda8,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-1931d845-25d0-4425-8196-121d445edda8,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-fa09b9b7-995a-44dd-adce-fe32ce8c399c,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-c86e6dda-94eb-45f4-920f-2fa477fb86e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-c54901f9-da89-456d-8aab-539658bf974c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527183381-172.17.0.5-1597191794496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42686,DS-17d165f0-e609-43c8-a0cf-c0e29cd48abf,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-4f2c7038-e4b1-4fb3-b813-9a0bcd891f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-153be162-68e1-484d-9428-2bcba730d469,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-9bfcec2a-c944-473a-9b0e-0be7ba07dda8,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-1931d845-25d0-4425-8196-121d445edda8,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-fa09b9b7-995a-44dd-adce-fe32ce8c399c,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-c86e6dda-94eb-45f4-920f-2fa477fb86e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-c54901f9-da89-456d-8aab-539658bf974c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292748080-172.17.0.5-1597191831435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45118,DS-e8bddf78-e13c-47c9-95bd-2bd092fcb588,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-5d666cc9-7bec-401a-9e97-59f57cb11bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-01817a04-74de-47e1-96a6-6e2ca0ceedd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-fdf2c1eb-9de3-467c-874e-374dc595e03d,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-01dca458-efd9-447f-8e13-ee6f8b48841b,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-7df4566c-a45e-4e7f-9ff8-b164a37a9cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-5c11001d-b967-4609-ac30-26b263c7576e,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-b89e3acf-6697-4259-81a2-dc4b83000427,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292748080-172.17.0.5-1597191831435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45118,DS-e8bddf78-e13c-47c9-95bd-2bd092fcb588,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-5d666cc9-7bec-401a-9e97-59f57cb11bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-01817a04-74de-47e1-96a6-6e2ca0ceedd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-fdf2c1eb-9de3-467c-874e-374dc595e03d,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-01dca458-efd9-447f-8e13-ee6f8b48841b,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-7df4566c-a45e-4e7f-9ff8-b164a37a9cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-5c11001d-b967-4609-ac30-26b263c7576e,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-b89e3acf-6697-4259-81a2-dc4b83000427,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668539325-172.17.0.5-1597191867477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-4a60527c-3944-4aa7-be5e-b0214133b77f,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-7da7f8ec-d8ca-483c-ae91-61f565e9948b,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-a125f5b9-4b47-4914-8b53-bc2a31dc03a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-13e58ddc-490d-47b9-9c99-6387ff99b406,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-11761671-9cf5-4f62-9a75-2a57595ccc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-59a1cafa-1d7d-467f-b9de-a021c2e39285,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-50c67393-b119-43a2-8911-eaa8a2458727,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-5ffa6a1b-de2a-41a4-bdca-ae93e50035f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668539325-172.17.0.5-1597191867477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-4a60527c-3944-4aa7-be5e-b0214133b77f,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-7da7f8ec-d8ca-483c-ae91-61f565e9948b,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-a125f5b9-4b47-4914-8b53-bc2a31dc03a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-13e58ddc-490d-47b9-9c99-6387ff99b406,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-11761671-9cf5-4f62-9a75-2a57595ccc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-59a1cafa-1d7d-467f-b9de-a021c2e39285,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-50c67393-b119-43a2-8911-eaa8a2458727,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-5ffa6a1b-de2a-41a4-bdca-ae93e50035f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603769581-172.17.0.5-1597192125976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38739,DS-834c06fd-05f7-44d5-820c-255ccd92ca4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-9a61bbbd-aaa2-4d8c-aa16-65297fa92731,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-7ffaa0cb-4fee-40a8-b352-fc36694b9995,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-ce0ab711-8ada-45d3-87f9-cbc71bd9ef36,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-fe7564f3-461d-4569-8972-a9c5a1553117,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-484e1250-5056-4718-b7ea-996c6d0c7b41,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-a560c1d9-6660-42e5-91f5-7c8b32779317,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-bf2088b3-cbb0-49c9-b219-730868817029,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603769581-172.17.0.5-1597192125976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38739,DS-834c06fd-05f7-44d5-820c-255ccd92ca4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-9a61bbbd-aaa2-4d8c-aa16-65297fa92731,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-7ffaa0cb-4fee-40a8-b352-fc36694b9995,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-ce0ab711-8ada-45d3-87f9-cbc71bd9ef36,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-fe7564f3-461d-4569-8972-a9c5a1553117,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-484e1250-5056-4718-b7ea-996c6d0c7b41,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-a560c1d9-6660-42e5-91f5-7c8b32779317,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-bf2088b3-cbb0-49c9-b219-730868817029,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408055018-172.17.0.5-1597192342830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41435,DS-9ed93dfb-31fc-47f2-bf13-c8474233278d,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-0947c277-b1dd-4fbc-9732-8bc115b8f9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-653c2e91-3487-4575-8e3e-d97063942924,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-846236bf-bc0c-4482-abcb-e6eb272740cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-dabbbd70-85f4-43cc-b28b-de5353b81c71,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-3f8c14d6-234f-42eb-b07d-b5b88cd452e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-2fc0f377-c894-454e-a94d-52ce840fe687,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-025b148c-2f36-444a-894c-d2053756edcb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408055018-172.17.0.5-1597192342830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41435,DS-9ed93dfb-31fc-47f2-bf13-c8474233278d,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-0947c277-b1dd-4fbc-9732-8bc115b8f9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-653c2e91-3487-4575-8e3e-d97063942924,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-846236bf-bc0c-4482-abcb-e6eb272740cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-dabbbd70-85f4-43cc-b28b-de5353b81c71,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-3f8c14d6-234f-42eb-b07d-b5b88cd452e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-2fc0f377-c894-454e-a94d-52ce840fe687,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-025b148c-2f36-444a-894c-d2053756edcb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472317973-172.17.0.5-1597192580163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41233,DS-c7c2c80f-6093-41c2-9652-999694e6c7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-597457f6-1b6f-46d7-847d-c6aeb30e6ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-a97f4dbe-eff0-4e1c-a918-73f6f74ce766,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-ae08a2fd-4e08-4295-8095-6995a430688a,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-47187679-0007-45bb-9c28-17879bc93fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-e9dfff7d-0972-4a89-921e-4bf3fabe26e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-2b01e2aa-30c0-405f-85e1-96120ea54ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-1b8f8e22-325f-47de-a3f1-db1c28e2a463,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472317973-172.17.0.5-1597192580163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41233,DS-c7c2c80f-6093-41c2-9652-999694e6c7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-597457f6-1b6f-46d7-847d-c6aeb30e6ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-a97f4dbe-eff0-4e1c-a918-73f6f74ce766,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-ae08a2fd-4e08-4295-8095-6995a430688a,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-47187679-0007-45bb-9c28-17879bc93fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-e9dfff7d-0972-4a89-921e-4bf3fabe26e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-2b01e2aa-30c0-405f-85e1-96120ea54ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-1b8f8e22-325f-47de-a3f1-db1c28e2a463,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899827912-172.17.0.5-1597192814953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33237,DS-33daa680-5741-4adf-83e8-b0048cae70aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-75ef1b06-09e5-4e1e-b5d2-f943a6a5b40c,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-0eb80fd4-e099-4a0a-ad12-ffef9d5dd997,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-a2647d19-780a-4d58-8ee9-f949dfa273d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-a15dbb17-b130-4137-bdb4-d1cc8c3e541d,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-5ba9aead-7e9a-4f6d-b8eb-ac8cd2eb43fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-12eab59b-ee15-4285-94af-431d1e4e0dff,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-8230e466-c417-45cc-9ffa-642816457850,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899827912-172.17.0.5-1597192814953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33237,DS-33daa680-5741-4adf-83e8-b0048cae70aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-75ef1b06-09e5-4e1e-b5d2-f943a6a5b40c,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-0eb80fd4-e099-4a0a-ad12-ffef9d5dd997,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-a2647d19-780a-4d58-8ee9-f949dfa273d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-a15dbb17-b130-4137-bdb4-d1cc8c3e541d,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-5ba9aead-7e9a-4f6d-b8eb-ac8cd2eb43fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-12eab59b-ee15-4285-94af-431d1e4e0dff,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-8230e466-c417-45cc-9ffa-642816457850,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186056586-172.17.0.5-1597192848044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42491,DS-1670bc1f-5a82-4f79-94b3-5ce9371c9e68,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-f09a325a-87ba-46ba-90a5-37f23afc7bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-2b75e790-bd86-4ab2-bcac-d50498d16a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-89da402d-1db2-47c5-bc6e-f7566f4a2064,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-6f9cfd54-ca9b-4ced-bdaa-0b8b048df500,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-42486680-bcba-49c0-b6ad-c6024c999612,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-d91848d1-ba69-4002-977f-d074454f80ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-d5db208f-490a-4742-8336-dc8ded60c602,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186056586-172.17.0.5-1597192848044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42491,DS-1670bc1f-5a82-4f79-94b3-5ce9371c9e68,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-f09a325a-87ba-46ba-90a5-37f23afc7bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-2b75e790-bd86-4ab2-bcac-d50498d16a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-89da402d-1db2-47c5-bc6e-f7566f4a2064,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-6f9cfd54-ca9b-4ced-bdaa-0b8b048df500,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-42486680-bcba-49c0-b6ad-c6024c999612,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-d91848d1-ba69-4002-977f-d074454f80ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-d5db208f-490a-4742-8336-dc8ded60c602,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905778474-172.17.0.5-1597192919411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43423,DS-312f79a0-4eef-4bb7-b1ed-bd92638b7557,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-9d3a6f30-faf3-4ea9-a6a0-2269a81b53cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-dd744539-3f13-4e1f-8ef8-d73e14eb3952,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-d2c402ae-6b36-485e-b493-7d23ce53e0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-aca341cc-6726-4b52-a8f4-a1a4d31fb7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-7d1a5495-3e87-44ed-b2be-2c63a8e1e445,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-7557343f-4340-421c-8b24-a8ff1b63f157,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-036154b4-dd96-4fce-a2e4-976240f746fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905778474-172.17.0.5-1597192919411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43423,DS-312f79a0-4eef-4bb7-b1ed-bd92638b7557,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-9d3a6f30-faf3-4ea9-a6a0-2269a81b53cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-dd744539-3f13-4e1f-8ef8-d73e14eb3952,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-d2c402ae-6b36-485e-b493-7d23ce53e0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-aca341cc-6726-4b52-a8f4-a1a4d31fb7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-7d1a5495-3e87-44ed-b2be-2c63a8e1e445,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-7557343f-4340-421c-8b24-a8ff1b63f157,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-036154b4-dd96-4fce-a2e4-976240f746fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192969260-172.17.0.5-1597192949932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43245,DS-259244e2-b4da-45f6-957a-d5029ac203ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-a5f32d9e-8744-4ffe-ba88-f12b9d45847f,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-4cf93c7d-6dfc-4914-aa75-fbefe66e3f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-a033c2fd-4b5a-49b6-a8c8-940e8dd30897,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-595281ba-fd23-40f3-be5f-cbeccacc98ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-7a79d409-f300-41b1-8aa5-0fa83df9f781,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-7e9a8207-fe18-48c8-915b-471560a3c105,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-15839a00-0f86-472a-bcf1-9bca7372f832,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192969260-172.17.0.5-1597192949932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43245,DS-259244e2-b4da-45f6-957a-d5029ac203ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-a5f32d9e-8744-4ffe-ba88-f12b9d45847f,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-4cf93c7d-6dfc-4914-aa75-fbefe66e3f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-a033c2fd-4b5a-49b6-a8c8-940e8dd30897,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-595281ba-fd23-40f3-be5f-cbeccacc98ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-7a79d409-f300-41b1-8aa5-0fa83df9f781,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-7e9a8207-fe18-48c8-915b-471560a3c105,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-15839a00-0f86-472a-bcf1-9bca7372f832,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227736030-172.17.0.5-1597193163680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39902,DS-00f2893a-a9e6-4aab-9e54-3c5204a2f421,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-bce50da3-fbd1-4253-a23c-e449f449d8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-bd21586f-fd90-40ff-9939-3d6517382457,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-629ef5af-4210-4c0c-b566-b3c24cce282e,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-1c0f912e-6e32-43b2-b7f2-92c358c60390,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-26f39735-5368-4f8a-be0a-6b97b9886eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-81a5f5cc-5ae8-4fed-b081-8fa4825704ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-59681d74-e600-4919-83e0-67bc8c16071d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227736030-172.17.0.5-1597193163680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39902,DS-00f2893a-a9e6-4aab-9e54-3c5204a2f421,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-bce50da3-fbd1-4253-a23c-e449f449d8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-bd21586f-fd90-40ff-9939-3d6517382457,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-629ef5af-4210-4c0c-b566-b3c24cce282e,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-1c0f912e-6e32-43b2-b7f2-92c358c60390,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-26f39735-5368-4f8a-be0a-6b97b9886eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-81a5f5cc-5ae8-4fed-b081-8fa4825704ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-59681d74-e600-4919-83e0-67bc8c16071d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136963955-172.17.0.5-1597193348974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46515,DS-a337ce21-6856-4363-9e9d-5f94e4a13997,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-70e3d0ce-0e43-422a-941d-760f80fc5fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-4b20d405-77ca-4b11-9df2-1b8bbf26c910,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-90bd8658-557c-4f7f-bcf6-bf1d4bc9c26e,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-383638da-6d4f-4fbe-9adf-536f992e996f,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-720e9e40-e01a-4488-997e-af0a1f794261,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-a7ca5286-17fa-422e-8163-b92fce132e08,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-e38d74de-614a-410b-ab24-97c475efedd1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136963955-172.17.0.5-1597193348974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46515,DS-a337ce21-6856-4363-9e9d-5f94e4a13997,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-70e3d0ce-0e43-422a-941d-760f80fc5fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-4b20d405-77ca-4b11-9df2-1b8bbf26c910,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-90bd8658-557c-4f7f-bcf6-bf1d4bc9c26e,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-383638da-6d4f-4fbe-9adf-536f992e996f,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-720e9e40-e01a-4488-997e-af0a1f794261,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-a7ca5286-17fa-422e-8163-b92fce132e08,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-e38d74de-614a-410b-ab24-97c475efedd1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980877444-172.17.0.5-1597193502920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38723,DS-30c6c429-9bb7-46b8-983c-8b46032eda6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-342ea775-2f04-492f-9bbe-a44235336e27,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-1f47546f-9c1b-432c-ad92-0d86547af84e,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-081efd3b-e90a-4c2d-a239-c6528f02c5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-83e487ca-f6f1-4e61-84cd-391310dc9411,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-409377f8-f580-4d82-ae6b-46e998df95bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-e108f163-1c1a-4aa0-962b-12bb8a6c4dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-25e93b1b-9de3-40d9-8c77-0c328c753d50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980877444-172.17.0.5-1597193502920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38723,DS-30c6c429-9bb7-46b8-983c-8b46032eda6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-342ea775-2f04-492f-9bbe-a44235336e27,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-1f47546f-9c1b-432c-ad92-0d86547af84e,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-081efd3b-e90a-4c2d-a239-c6528f02c5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-83e487ca-f6f1-4e61-84cd-391310dc9411,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-409377f8-f580-4d82-ae6b-46e998df95bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-e108f163-1c1a-4aa0-962b-12bb8a6c4dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-25e93b1b-9de3-40d9-8c77-0c328c753d50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341053824-172.17.0.5-1597193608295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-752e73e9-2937-4e2e-b3ff-5f8a6646a3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-11d2f389-7406-4c65-a32c-2e70cd6120d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-37b4c7b0-8c59-41d9-86aa-9e81ac96b762,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-f8fee1ff-d99f-4424-9ae8-1f60de95ec86,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-cbf89bca-5342-4a93-b8f5-105b053ecf34,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-3ff25b0b-47c6-4ddd-ba83-0d65b517d5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-3eb1af59-d38d-499f-b3da-8e3bfb5690a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-905a67e9-ae1c-4618-ac7a-206219439700,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341053824-172.17.0.5-1597193608295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-752e73e9-2937-4e2e-b3ff-5f8a6646a3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-11d2f389-7406-4c65-a32c-2e70cd6120d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-37b4c7b0-8c59-41d9-86aa-9e81ac96b762,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-f8fee1ff-d99f-4424-9ae8-1f60de95ec86,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-cbf89bca-5342-4a93-b8f5-105b053ecf34,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-3ff25b0b-47c6-4ddd-ba83-0d65b517d5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-3eb1af59-d38d-499f-b3da-8e3bfb5690a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-905a67e9-ae1c-4618-ac7a-206219439700,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266126927-172.17.0.5-1597193644097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38178,DS-6f744855-e8c8-4ac9-bdfb-955086cd446d,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-d5bf3f50-cdf8-4458-b18c-81108e98e958,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-8af878ac-9b77-49b8-8fe2-d3dbe813897d,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-ccb86774-7686-406c-bae8-178fe8e0caff,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-1253507f-978b-4175-9d7f-8e7e475eeb99,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-ed1d1731-61ad-4a34-a247-e6fc9dbfa664,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-fd24cbd7-c2db-43ce-86a3-52fb328932d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-5e1e0778-f78b-4267-b59b-05422a171f1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266126927-172.17.0.5-1597193644097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38178,DS-6f744855-e8c8-4ac9-bdfb-955086cd446d,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-d5bf3f50-cdf8-4458-b18c-81108e98e958,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-8af878ac-9b77-49b8-8fe2-d3dbe813897d,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-ccb86774-7686-406c-bae8-178fe8e0caff,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-1253507f-978b-4175-9d7f-8e7e475eeb99,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-ed1d1731-61ad-4a34-a247-e6fc9dbfa664,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-fd24cbd7-c2db-43ce-86a3-52fb328932d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-5e1e0778-f78b-4267-b59b-05422a171f1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54237473-172.17.0.5-1597194051792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35745,DS-311857d8-3fb5-4dc0-8b1c-c1aeb44c5fad,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-f3ed60d8-8363-427d-b0f9-6a6b50900ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-7dfe79f6-4cfc-4545-ab22-ee6ed5bd02d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-b2594b5a-d208-4744-9ce7-e58cc08cb102,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-b83e901d-97f1-4ea4-b4b6-0c13aab0fd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-3eb85a63-613b-4280-9a86-6079b4d9b2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-d4289ff9-d97d-479c-abc5-f88354229d29,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-65d46e02-ec7c-4883-85ba-006580829c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54237473-172.17.0.5-1597194051792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35745,DS-311857d8-3fb5-4dc0-8b1c-c1aeb44c5fad,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-f3ed60d8-8363-427d-b0f9-6a6b50900ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-7dfe79f6-4cfc-4545-ab22-ee6ed5bd02d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-b2594b5a-d208-4744-9ce7-e58cc08cb102,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-b83e901d-97f1-4ea4-b4b6-0c13aab0fd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-3eb85a63-613b-4280-9a86-6079b4d9b2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-d4289ff9-d97d-479c-abc5-f88354229d29,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-65d46e02-ec7c-4883-85ba-006580829c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949627889-172.17.0.5-1597194094053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38519,DS-397f68ad-6a97-4b6e-8f55-254f51bafc72,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-8d0c1019-adf4-444e-a749-0d5df7b09656,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-f3ff5f88-f86f-42ee-87fc-ec5793faff31,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-88d0b24b-461e-4642-a29f-77f56e282394,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-e053aea9-0298-41d5-9de8-d65a8864739a,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-031e035d-1d27-4031-9fc0-e0c960ebd257,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-6e55fd5f-de4d-4ada-aace-f344b6c9b880,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-95dbd414-cdd7-403c-8c73-ed6cea916fab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949627889-172.17.0.5-1597194094053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38519,DS-397f68ad-6a97-4b6e-8f55-254f51bafc72,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-8d0c1019-adf4-444e-a749-0d5df7b09656,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-f3ff5f88-f86f-42ee-87fc-ec5793faff31,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-88d0b24b-461e-4642-a29f-77f56e282394,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-e053aea9-0298-41d5-9de8-d65a8864739a,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-031e035d-1d27-4031-9fc0-e0c960ebd257,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-6e55fd5f-de4d-4ada-aace-f344b6c9b880,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-95dbd414-cdd7-403c-8c73-ed6cea916fab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112344979-172.17.0.5-1597194169836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42181,DS-890965c9-bb9e-4697-bc38-805b8a56fec5,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-5f4cd7e9-1017-4378-837a-d8e19ad19353,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-45e1caba-e883-49ab-8c94-bae7085fbf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-636e13a5-a69a-43e0-815d-d613a26058c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-a3e27fb1-d069-42ff-9675-110ed4ed30bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-6831380e-f45d-49de-a54e-fa822f63b5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-068cad67-4f3f-4a3e-a8b7-954a75e76b48,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-f3bdceea-c321-421d-9a80-0d09db00b2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112344979-172.17.0.5-1597194169836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42181,DS-890965c9-bb9e-4697-bc38-805b8a56fec5,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-5f4cd7e9-1017-4378-837a-d8e19ad19353,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-45e1caba-e883-49ab-8c94-bae7085fbf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-636e13a5-a69a-43e0-815d-d613a26058c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-a3e27fb1-d069-42ff-9675-110ed4ed30bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-6831380e-f45d-49de-a54e-fa822f63b5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-068cad67-4f3f-4a3e-a8b7-954a75e76b48,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-f3bdceea-c321-421d-9a80-0d09db00b2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072756283-172.17.0.5-1597194205321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46088,DS-2ce55ebe-b4d3-4229-a083-9fc94a127e31,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-e45fd29e-f36e-464f-a792-a52e26b62b97,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-f8a22eba-5281-4819-8bc3-c9ba0f453682,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-df0f7d8b-51e1-473d-b4fe-5390326191ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-f10733df-6224-4b4f-b6b9-422e5c5a59eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-7099dc65-201e-404f-af32-7c3510806667,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-05caa8af-78e6-4794-ada8-684c7aa6a24f,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-0b7c141b-6549-4f00-b7cb-b54f21b9d097,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072756283-172.17.0.5-1597194205321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46088,DS-2ce55ebe-b4d3-4229-a083-9fc94a127e31,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-e45fd29e-f36e-464f-a792-a52e26b62b97,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-f8a22eba-5281-4819-8bc3-c9ba0f453682,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-df0f7d8b-51e1-473d-b4fe-5390326191ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-f10733df-6224-4b4f-b6b9-422e5c5a59eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-7099dc65-201e-404f-af32-7c3510806667,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-05caa8af-78e6-4794-ada8-684c7aa6a24f,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-0b7c141b-6549-4f00-b7cb-b54f21b9d097,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648682541-172.17.0.5-1597194240429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42871,DS-9a5b3c3d-13b9-4bf1-8bed-f5a29eac9a59,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-3270386d-98ab-4929-a86e-ca871673851a,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-729c3386-9cad-40df-a575-084c555b6bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-4c54699c-62ec-4a6d-b8b1-0fd51e0034c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-3b9cd5e1-ea7b-4c86-a7a9-e5083dab794a,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-9b83f4ea-0244-4421-8cae-318089e4f5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-a680884d-c9a9-4647-a3d2-443715d9ddb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-a6445457-3262-4c58-bee5-50f630c0039a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648682541-172.17.0.5-1597194240429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42871,DS-9a5b3c3d-13b9-4bf1-8bed-f5a29eac9a59,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-3270386d-98ab-4929-a86e-ca871673851a,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-729c3386-9cad-40df-a575-084c555b6bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-4c54699c-62ec-4a6d-b8b1-0fd51e0034c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-3b9cd5e1-ea7b-4c86-a7a9-e5083dab794a,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-9b83f4ea-0244-4421-8cae-318089e4f5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-a680884d-c9a9-4647-a3d2-443715d9ddb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-a6445457-3262-4c58-bee5-50f630c0039a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204152073-172.17.0.5-1597194452496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45516,DS-f00bd9c0-cf8d-419b-a17b-cb0dd7dd56eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-39e3fdfc-3146-4255-88b8-9ead0ec2ad77,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-c3c5d5fa-b1a1-4898-a931-d575e3981006,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-4f855389-eaa5-4cf5-8c0b-719153949a01,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-2ff62f1d-455d-469f-a7e5-d4005960dea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-46ab067a-5755-4c1e-a39b-a9505b72cd88,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-e496679c-0a6d-45f4-aedb-a0d1fec8cfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-b86d386a-2b5e-4f1d-8b6e-bfb5733dd66d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204152073-172.17.0.5-1597194452496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45516,DS-f00bd9c0-cf8d-419b-a17b-cb0dd7dd56eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-39e3fdfc-3146-4255-88b8-9ead0ec2ad77,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-c3c5d5fa-b1a1-4898-a931-d575e3981006,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-4f855389-eaa5-4cf5-8c0b-719153949a01,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-2ff62f1d-455d-469f-a7e5-d4005960dea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-46ab067a-5755-4c1e-a39b-a9505b72cd88,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-e496679c-0a6d-45f4-aedb-a0d1fec8cfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-b86d386a-2b5e-4f1d-8b6e-bfb5733dd66d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307923246-172.17.0.5-1597194482615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33733,DS-d14f9b2a-980c-4065-b09b-9f4f5ace8d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-d035a928-80e6-4551-805e-f75cd9a6949a,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-8a398294-0273-4a55-8e09-e3bcf3c409a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-123a1eca-3821-4cdd-bb7f-40a48d449faa,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-b447c7a2-b230-464d-b50d-384be6643866,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-f7b90c8f-8c79-47b8-997f-03da5ab93b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-d5d13774-6ed4-4dc4-917e-5a3350cc9007,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-6a923f2a-dfc6-4f37-a431-22827adaa2d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307923246-172.17.0.5-1597194482615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33733,DS-d14f9b2a-980c-4065-b09b-9f4f5ace8d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-d035a928-80e6-4551-805e-f75cd9a6949a,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-8a398294-0273-4a55-8e09-e3bcf3c409a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-123a1eca-3821-4cdd-bb7f-40a48d449faa,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-b447c7a2-b230-464d-b50d-384be6643866,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-f7b90c8f-8c79-47b8-997f-03da5ab93b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-d5d13774-6ed4-4dc4-917e-5a3350cc9007,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-6a923f2a-dfc6-4f37-a431-22827adaa2d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927203897-172.17.0.5-1597194628682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37615,DS-df1a0aa6-b3bc-4fd0-9d1b-3e4e313f6634,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-984dd386-3029-4d7c-9275-bf9c70416da3,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-bbc80179-5a3c-4e10-93d7-18238ca0e700,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-d8b2057b-947d-40fb-b9fe-756fdd3844ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-0b58ea31-c951-49c2-bc29-97dbbcd424f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-11153438-554d-406a-a45f-0b6c1fff18f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-7b199b33-b1ea-4e96-a60e-ac9a9f9be356,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-26e43219-000a-46b5-ade6-1d722b9262dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927203897-172.17.0.5-1597194628682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37615,DS-df1a0aa6-b3bc-4fd0-9d1b-3e4e313f6634,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-984dd386-3029-4d7c-9275-bf9c70416da3,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-bbc80179-5a3c-4e10-93d7-18238ca0e700,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-d8b2057b-947d-40fb-b9fe-756fdd3844ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-0b58ea31-c951-49c2-bc29-97dbbcd424f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-11153438-554d-406a-a45f-0b6c1fff18f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-7b199b33-b1ea-4e96-a60e-ac9a9f9be356,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-26e43219-000a-46b5-ade6-1d722b9262dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140043304-172.17.0.5-1597194860757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43173,DS-cecbd399-3cdc-4fd2-ba60-ccf4599c4471,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-e15b39d6-f893-4f8c-b8dc-c96ccc270fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-fdb50db1-aedf-4353-8121-c9ab543837dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-c2e70ee1-a3d4-41db-91c7-345742c5b7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-43270faf-2906-4541-8c79-7ac4d3c943d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-d2227a83-cd5a-46b0-835b-2ec1a6913313,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-5547313c-92e1-4e94-8ccd-64540ba8a5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-d2d39e8b-fae3-4a95-9950-67d3c87a586d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140043304-172.17.0.5-1597194860757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43173,DS-cecbd399-3cdc-4fd2-ba60-ccf4599c4471,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-e15b39d6-f893-4f8c-b8dc-c96ccc270fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-fdb50db1-aedf-4353-8121-c9ab543837dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-c2e70ee1-a3d4-41db-91c7-345742c5b7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-43270faf-2906-4541-8c79-7ac4d3c943d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-d2227a83-cd5a-46b0-835b-2ec1a6913313,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-5547313c-92e1-4e94-8ccd-64540ba8a5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-d2d39e8b-fae3-4a95-9950-67d3c87a586d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889421972-172.17.0.5-1597194901817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44789,DS-75515ad4-83e7-4179-b310-7eb8190b4cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-b835ec91-f711-4a16-9f10-514d206edeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-1ed9ad9e-b4cf-48ee-8aa2-07394c3f8f05,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-153f65de-1212-4d43-9e90-9cc5930ad31b,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-471c17ab-6f5e-452b-922d-ad7d106ab875,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-4cbf1b7e-e7af-4f27-a45b-8ad3643da0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-00c863f3-de8b-4670-a0a3-44c03018b991,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-1056d1a2-790d-4c1f-8523-62a01c62f84c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889421972-172.17.0.5-1597194901817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44789,DS-75515ad4-83e7-4179-b310-7eb8190b4cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-b835ec91-f711-4a16-9f10-514d206edeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-1ed9ad9e-b4cf-48ee-8aa2-07394c3f8f05,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-153f65de-1212-4d43-9e90-9cc5930ad31b,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-471c17ab-6f5e-452b-922d-ad7d106ab875,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-4cbf1b7e-e7af-4f27-a45b-8ad3643da0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-00c863f3-de8b-4670-a0a3-44c03018b991,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-1056d1a2-790d-4c1f-8523-62a01c62f84c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770835815-172.17.0.5-1597195357051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33661,DS-c7739ede-c1ab-4ac8-b16e-252ac69440fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-c90438a8-7357-47cb-bb73-01a5ba062eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-adfc1f98-fe74-4d03-8021-678c05ca1202,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-f1d989cf-c618-4175-94a8-98f6b2ef90da,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-5427b462-3844-4ba0-97d5-0de38249068d,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-5aab355a-4924-4c60-8717-1f2dd78b328e,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-780a4b82-922d-409a-82f1-8f63f6e820ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-4843330e-756e-4ab2-8696-9e1faf2963a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770835815-172.17.0.5-1597195357051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33661,DS-c7739ede-c1ab-4ac8-b16e-252ac69440fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-c90438a8-7357-47cb-bb73-01a5ba062eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-adfc1f98-fe74-4d03-8021-678c05ca1202,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-f1d989cf-c618-4175-94a8-98f6b2ef90da,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-5427b462-3844-4ba0-97d5-0de38249068d,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-5aab355a-4924-4c60-8717-1f2dd78b328e,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-780a4b82-922d-409a-82f1-8f63f6e820ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-4843330e-756e-4ab2-8696-9e1faf2963a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992303868-172.17.0.5-1597195418983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37715,DS-44f69411-28b2-4502-bd91-b180f9487c16,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-1c12362a-3fd8-496b-885a-aa6ed9aee14d,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-dda20090-e152-43e2-9b7d-378d589b7e63,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-cd274230-1fa0-4210-b4bb-d8032e74d0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-9d5367e4-bca5-4137-b7df-6107adbd09e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-91a07e1b-81c3-4afa-af26-553efbb2ed69,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-de62b4c9-7b3f-4a7d-aa2d-881994bcfdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-538e4f3e-defe-45b3-b587-d6676bb3d03a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992303868-172.17.0.5-1597195418983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37715,DS-44f69411-28b2-4502-bd91-b180f9487c16,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-1c12362a-3fd8-496b-885a-aa6ed9aee14d,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-dda20090-e152-43e2-9b7d-378d589b7e63,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-cd274230-1fa0-4210-b4bb-d8032e74d0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-9d5367e4-bca5-4137-b7df-6107adbd09e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-91a07e1b-81c3-4afa-af26-553efbb2ed69,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-de62b4c9-7b3f-4a7d-aa2d-881994bcfdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-538e4f3e-defe-45b3-b587-d6676bb3d03a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247934137-172.17.0.5-1597195445462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46310,DS-10f7dc9c-f4a7-4658-951b-a7841b71c1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-407595e2-7233-42a2-9db2-80f60c972be8,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-c1748ae2-1f0b-4ea8-b471-a4ac43f60bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-1193e990-3a1c-43a9-9a76-36e91330786a,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-00444f87-6556-411b-bec0-6c8062f8f49f,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-eb73de53-ec53-4e44-a282-a321bd33798e,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-f36b6058-1762-40f9-bcea-e105176b6a86,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-2fac2147-2d29-4ff1-a9d0-105a8e89270b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247934137-172.17.0.5-1597195445462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46310,DS-10f7dc9c-f4a7-4658-951b-a7841b71c1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-407595e2-7233-42a2-9db2-80f60c972be8,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-c1748ae2-1f0b-4ea8-b471-a4ac43f60bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-1193e990-3a1c-43a9-9a76-36e91330786a,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-00444f87-6556-411b-bec0-6c8062f8f49f,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-eb73de53-ec53-4e44-a282-a321bd33798e,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-f36b6058-1762-40f9-bcea-e105176b6a86,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-2fac2147-2d29-4ff1-a9d0-105a8e89270b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937488041-172.17.0.5-1597195552760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33472,DS-d60bbe49-bf14-4deb-8b82-50a365cc24c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-95e46f51-d088-4ef5-901f-7c7eac66e6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-aa1d7013-ccf4-42ee-bcb9-96977063f2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-cefd2155-46c3-42a6-975f-68789f943021,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-07395727-c829-43d5-b6b4-d60736ae790d,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-452e70c6-b393-4c79-87ab-dd1bb366bc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-681aa8e1-ca31-4848-94b2-b45ab94812b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-f7810dc1-8470-4c81-945c-e0e2bedd8186,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937488041-172.17.0.5-1597195552760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33472,DS-d60bbe49-bf14-4deb-8b82-50a365cc24c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-95e46f51-d088-4ef5-901f-7c7eac66e6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-aa1d7013-ccf4-42ee-bcb9-96977063f2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-cefd2155-46c3-42a6-975f-68789f943021,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-07395727-c829-43d5-b6b4-d60736ae790d,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-452e70c6-b393-4c79-87ab-dd1bb366bc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-681aa8e1-ca31-4848-94b2-b45ab94812b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-f7810dc1-8470-4c81-945c-e0e2bedd8186,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004666655-172.17.0.5-1597195691117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38920,DS-82ad49d5-e162-4e81-8197-094dd0785cae,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-f159368a-856e-4444-bba0-3f8ffdb2a9da,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-acd13110-d860-4518-8fbc-efff693951bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-3a27d93d-e7be-4683-a9ba-21c10bcf399f,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-b5faa8a8-eef5-4637-add4-ef953292e149,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-a91561d3-fcf1-4e20-8397-14703721a0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-8d2ccfd3-83cc-45db-9114-acb0bc5c198f,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-3427b9b7-09b6-41c8-93db-aee958c37efd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004666655-172.17.0.5-1597195691117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38920,DS-82ad49d5-e162-4e81-8197-094dd0785cae,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-f159368a-856e-4444-bba0-3f8ffdb2a9da,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-acd13110-d860-4518-8fbc-efff693951bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-3a27d93d-e7be-4683-a9ba-21c10bcf399f,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-b5faa8a8-eef5-4637-add4-ef953292e149,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-a91561d3-fcf1-4e20-8397-14703721a0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-8d2ccfd3-83cc-45db-9114-acb0bc5c198f,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-3427b9b7-09b6-41c8-93db-aee958c37efd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2147483647
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109764077-172.17.0.5-1597196032066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34695,DS-0d556d6e-389a-416d-ae68-793d1fa56973,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-38b35f2e-aead-42eb-96aa-170872ef937f,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-3c8776e5-5942-46a0-b738-eae5f5a81229,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-4836dffe-9f96-4e64-996e-53bc856472aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-9498a6f0-656e-42ca-b080-4319b3908bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-73f970eb-9bef-45be-a58c-1dc4a4a24e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-fa247bd6-ba8e-4b43-97e5-7a727d0aae50,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-99cdf33f-fd24-4fea-a407-f2325e767290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109764077-172.17.0.5-1597196032066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34695,DS-0d556d6e-389a-416d-ae68-793d1fa56973,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-38b35f2e-aead-42eb-96aa-170872ef937f,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-3c8776e5-5942-46a0-b738-eae5f5a81229,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-4836dffe-9f96-4e64-996e-53bc856472aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-9498a6f0-656e-42ca-b080-4319b3908bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-73f970eb-9bef-45be-a58c-1dc4a4a24e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-fa247bd6-ba8e-4b43-97e5-7a727d0aae50,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-99cdf33f-fd24-4fea-a407-f2325e767290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5259
