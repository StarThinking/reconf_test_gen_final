reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124588496-172.17.0.19-1597120097663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33796,DS-54e3a5f4-0c23-4920-ab8c-10fb1c307ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-9667dda2-1552-4b97-9382-5be669d534b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-850a1590-0006-4b01-82a2-2dede7d95de5,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-58ed139c-6d99-4dbf-b8a6-6a9864988035,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-f58396b2-698c-4b86-bf4d-2a09447aa427,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-54fb1ad5-4088-48f4-b195-a615f61c506d,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-22d77433-6e4f-4e3a-9886-15173b0193a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-c2bd206d-6751-4588-9be6-ba3c38a773cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124588496-172.17.0.19-1597120097663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33796,DS-54e3a5f4-0c23-4920-ab8c-10fb1c307ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-9667dda2-1552-4b97-9382-5be669d534b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-850a1590-0006-4b01-82a2-2dede7d95de5,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-58ed139c-6d99-4dbf-b8a6-6a9864988035,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-f58396b2-698c-4b86-bf4d-2a09447aa427,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-54fb1ad5-4088-48f4-b195-a615f61c506d,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-22d77433-6e4f-4e3a-9886-15173b0193a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-c2bd206d-6751-4588-9be6-ba3c38a773cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263031298-172.17.0.19-1597120166888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45187,DS-ddb8a617-5d5a-4fe5-8344-ccc07719f020,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-efc2a5a5-470e-4c8c-91d2-0aa92c1df198,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-56c5f1c0-8a39-4429-b3d1-b9a8b4f8139a,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-9a053f23-3e37-483b-95ef-f58d10c477e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-d8320fd0-5d65-4b01-b491-7bb4f8243c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-2ab6d6ac-ff1d-4f6c-886a-d7b76d1280a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-6c3358b6-2173-485f-9471-74af9d7183e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-cd3aeeec-96bf-4195-b483-fc97e4146f67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263031298-172.17.0.19-1597120166888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45187,DS-ddb8a617-5d5a-4fe5-8344-ccc07719f020,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-efc2a5a5-470e-4c8c-91d2-0aa92c1df198,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-56c5f1c0-8a39-4429-b3d1-b9a8b4f8139a,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-9a053f23-3e37-483b-95ef-f58d10c477e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-d8320fd0-5d65-4b01-b491-7bb4f8243c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-2ab6d6ac-ff1d-4f6c-886a-d7b76d1280a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-6c3358b6-2173-485f-9471-74af9d7183e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-cd3aeeec-96bf-4195-b483-fc97e4146f67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134973162-172.17.0.19-1597120225696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34591,DS-e8a68d8c-7b79-451b-ab44-79673d2b1709,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-7f16c08f-98c3-4484-a0f1-59ced536a50c,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-91e154e6-b7cb-4f72-92a7-4ed029b392d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-5cdeb658-b14c-4ce5-99b9-339892814082,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-031f09a1-64de-47b7-b167-48cf1a51a51b,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-2842280f-7852-40c3-9252-73d76cef5c85,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-ae0ea13f-2263-4077-ae99-bceac298ca23,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-c3fe99f2-6a4a-406b-8253-0d280e9964b5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134973162-172.17.0.19-1597120225696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34591,DS-e8a68d8c-7b79-451b-ab44-79673d2b1709,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-7f16c08f-98c3-4484-a0f1-59ced536a50c,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-91e154e6-b7cb-4f72-92a7-4ed029b392d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-5cdeb658-b14c-4ce5-99b9-339892814082,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-031f09a1-64de-47b7-b167-48cf1a51a51b,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-2842280f-7852-40c3-9252-73d76cef5c85,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-ae0ea13f-2263-4077-ae99-bceac298ca23,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-c3fe99f2-6a4a-406b-8253-0d280e9964b5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410844420-172.17.0.19-1597120265663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46620,DS-a3e64fb7-60d9-4987-b6d3-6230a1ce4c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-7e75d919-4419-4c62-bbfe-4b73b41c27ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-a01d3cd7-94cf-4e71-9d7e-6750f12cb0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-88cf6574-ac3b-4546-a8a4-1eb1b9c6e142,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-c4f1baa8-a9ce-4b7d-abb9-3490aa8a3d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-abc7a3fb-7d12-48e7-a0c7-f64dc4e67784,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-cf0dd72a-18a9-4e0c-b45f-4c028be0a92c,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-52976852-1adc-4138-8cb4-c9a32848a5fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410844420-172.17.0.19-1597120265663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46620,DS-a3e64fb7-60d9-4987-b6d3-6230a1ce4c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-7e75d919-4419-4c62-bbfe-4b73b41c27ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-a01d3cd7-94cf-4e71-9d7e-6750f12cb0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-88cf6574-ac3b-4546-a8a4-1eb1b9c6e142,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-c4f1baa8-a9ce-4b7d-abb9-3490aa8a3d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-abc7a3fb-7d12-48e7-a0c7-f64dc4e67784,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-cf0dd72a-18a9-4e0c-b45f-4c028be0a92c,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-52976852-1adc-4138-8cb4-c9a32848a5fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062045850-172.17.0.19-1597120401346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35307,DS-c85a9943-ed4a-4197-a90f-2dfff0407b98,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-3c6938dd-50aa-423a-948a-1fc5c2fdd2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-33894952-b1a3-4ed5-8dfd-3616379e91c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-48d8c18d-f157-41de-8e57-4ccaf70c6564,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-3a356990-cc65-40fb-b4b4-8dbd9ea7bc50,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-fcdceb71-0b7a-4461-b8d3-4eca01740f67,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-dda3dc55-fa0a-4042-9715-b924476f1498,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-4024e936-3f82-45f1-834b-81cb062a0447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062045850-172.17.0.19-1597120401346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35307,DS-c85a9943-ed4a-4197-a90f-2dfff0407b98,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-3c6938dd-50aa-423a-948a-1fc5c2fdd2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-33894952-b1a3-4ed5-8dfd-3616379e91c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-48d8c18d-f157-41de-8e57-4ccaf70c6564,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-3a356990-cc65-40fb-b4b4-8dbd9ea7bc50,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-fcdceb71-0b7a-4461-b8d3-4eca01740f67,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-dda3dc55-fa0a-4042-9715-b924476f1498,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-4024e936-3f82-45f1-834b-81cb062a0447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777458406-172.17.0.19-1597120701268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40236,DS-7049826a-0b4d-4da2-ab5d-271e11e6cfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-26e704c1-ec36-4b1f-9d4a-00fb89ac2d26,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-dd5a8f9b-f498-4b08-bc5c-afd44e55c567,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-28881835-67d7-4183-9e09-0c0c465e7a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-4fe19ec4-8a53-4236-9c9e-e9e28120cbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-dee1da67-d1f6-4948-a2b1-a4365d32a715,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-f0da3b0c-1262-41ad-bbf4-237f66134020,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-8f089d85-ff7e-4700-ac18-385c5f8f3288,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777458406-172.17.0.19-1597120701268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40236,DS-7049826a-0b4d-4da2-ab5d-271e11e6cfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-26e704c1-ec36-4b1f-9d4a-00fb89ac2d26,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-dd5a8f9b-f498-4b08-bc5c-afd44e55c567,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-28881835-67d7-4183-9e09-0c0c465e7a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-4fe19ec4-8a53-4236-9c9e-e9e28120cbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-dee1da67-d1f6-4948-a2b1-a4365d32a715,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-f0da3b0c-1262-41ad-bbf4-237f66134020,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-8f089d85-ff7e-4700-ac18-385c5f8f3288,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786850917-172.17.0.19-1597120736461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38453,DS-c00bad66-6f72-4c67-97ea-6f3dc930d845,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-e6bec824-7539-48cc-bf2a-de9d3fe68fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-0b06fae5-fe4f-4ea6-b70d-e23941d36afc,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-3cb4f1ff-ded3-4c46-a58d-3649484c1893,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-ce00529c-fb62-4b3a-950a-b14cb8d23e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-79d6fe9b-b8e1-4867-9d2e-7f9766b96a25,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-8bb93678-21b4-454f-89ff-a11439b27cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-77cf7d6c-5a8f-45df-9276-4ddcbf3181c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786850917-172.17.0.19-1597120736461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38453,DS-c00bad66-6f72-4c67-97ea-6f3dc930d845,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-e6bec824-7539-48cc-bf2a-de9d3fe68fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-0b06fae5-fe4f-4ea6-b70d-e23941d36afc,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-3cb4f1ff-ded3-4c46-a58d-3649484c1893,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-ce00529c-fb62-4b3a-950a-b14cb8d23e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-79d6fe9b-b8e1-4867-9d2e-7f9766b96a25,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-8bb93678-21b4-454f-89ff-a11439b27cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-77cf7d6c-5a8f-45df-9276-4ddcbf3181c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360099277-172.17.0.19-1597120841562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33155,DS-87b2218f-b64c-4247-9c6e-70e2319a9f45,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-8782a7a1-ce72-4be6-8ae0-21a78a38365c,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-b0eebe30-1bbf-48f8-9be6-088ba0d28e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-7d9c03a4-343e-4eb6-9a6c-cdb09e12f59f,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-69ae0d18-9c5c-41bc-a78c-ff938df7fb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-052c3e38-2dde-4764-b6a7-5d7fdec2ff2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-40cdfdd8-6747-445f-9ab7-24b77c5c69a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-b0172397-bdcc-47d5-aecf-86616d1504b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360099277-172.17.0.19-1597120841562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33155,DS-87b2218f-b64c-4247-9c6e-70e2319a9f45,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-8782a7a1-ce72-4be6-8ae0-21a78a38365c,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-b0eebe30-1bbf-48f8-9be6-088ba0d28e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-7d9c03a4-343e-4eb6-9a6c-cdb09e12f59f,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-69ae0d18-9c5c-41bc-a78c-ff938df7fb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-052c3e38-2dde-4764-b6a7-5d7fdec2ff2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-40cdfdd8-6747-445f-9ab7-24b77c5c69a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-b0172397-bdcc-47d5-aecf-86616d1504b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050078827-172.17.0.19-1597120905127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41349,DS-67a4f96e-61ef-455d-ac11-29b6b32bb42d,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-915623ae-7520-45f2-956e-00589a838971,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-74dbfd10-8003-4fc2-90dc-b2e21fce3a59,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-aa5ebfe4-4526-477c-9ee0-f5a408fd0187,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-bbd817e6-0e5f-4630-ac9c-98628aaf741b,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-e802a676-4b26-455e-ad0c-72c24845c59f,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-40e1ecb9-4dcf-40c1-968e-a030bf7fd32f,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-403b75d3-2ce2-4371-afea-b8bb36c777f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050078827-172.17.0.19-1597120905127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41349,DS-67a4f96e-61ef-455d-ac11-29b6b32bb42d,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-915623ae-7520-45f2-956e-00589a838971,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-74dbfd10-8003-4fc2-90dc-b2e21fce3a59,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-aa5ebfe4-4526-477c-9ee0-f5a408fd0187,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-bbd817e6-0e5f-4630-ac9c-98628aaf741b,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-e802a676-4b26-455e-ad0c-72c24845c59f,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-40e1ecb9-4dcf-40c1-968e-a030bf7fd32f,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-403b75d3-2ce2-4371-afea-b8bb36c777f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56864876-172.17.0.19-1597121007847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43387,DS-6ef069e2-d5c6-4464-b0b5-bdf960531987,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-60140eef-762e-4799-a8f1-72b4013bd3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-ea793bda-6800-4597-a467-533ff35aac01,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-36d32d0e-e277-41db-9efe-fb72b577af4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-c2f316f6-9224-4fc8-a3bb-98f376a650bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-2d9aa8cd-ba99-4b26-a17a-261a89486f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-e17f766b-6c3b-4fff-82b5-f77d2632d967,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-bef59b7c-7c91-4a43-9940-a77504ba0292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56864876-172.17.0.19-1597121007847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43387,DS-6ef069e2-d5c6-4464-b0b5-bdf960531987,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-60140eef-762e-4799-a8f1-72b4013bd3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-ea793bda-6800-4597-a467-533ff35aac01,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-36d32d0e-e277-41db-9efe-fb72b577af4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-c2f316f6-9224-4fc8-a3bb-98f376a650bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-2d9aa8cd-ba99-4b26-a17a-261a89486f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-e17f766b-6c3b-4fff-82b5-f77d2632d967,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-bef59b7c-7c91-4a43-9940-a77504ba0292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659984562-172.17.0.19-1597121066615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33798,DS-61f77f0c-f1b0-45f6-930a-cabe0b33d053,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-2d24af59-15df-4750-8678-88535122193e,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-639e77f4-ab7f-4cbb-8f82-bdf995cc68dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-d327bf42-2711-4554-9e55-3522d8e528dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-a559ba03-8a38-48f0-a3f1-3a3ca47b5fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-e3234dd4-835f-4aee-8029-fe4cd494921c,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-2f7f9d7b-c08b-44d0-8c4e-1751da008ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-429b46fa-15b6-4a70-b87a-7eb3cc9ea1fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659984562-172.17.0.19-1597121066615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33798,DS-61f77f0c-f1b0-45f6-930a-cabe0b33d053,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-2d24af59-15df-4750-8678-88535122193e,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-639e77f4-ab7f-4cbb-8f82-bdf995cc68dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-d327bf42-2711-4554-9e55-3522d8e528dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-a559ba03-8a38-48f0-a3f1-3a3ca47b5fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-e3234dd4-835f-4aee-8029-fe4cd494921c,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-2f7f9d7b-c08b-44d0-8c4e-1751da008ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-429b46fa-15b6-4a70-b87a-7eb3cc9ea1fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844621761-172.17.0.19-1597121129793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33009,DS-4ffe006e-c7dc-4ab2-9cee-53ed38b024b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-5d2d8d42-cb6d-44c0-8165-a2050403cd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-4b311f61-09e9-427d-a5fc-2c65b26d1a70,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-25cffe85-13ea-4c84-9444-0a7855f06880,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-4ae5a09b-c7c3-47c6-a1c5-3f65f8e77a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-513ab0c0-342f-4052-aa9d-a2e8cfa93481,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-3c0e78b5-996a-4058-86e5-8f7b8d930994,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-8020ed7c-6065-402f-a819-1b78ebae4215,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844621761-172.17.0.19-1597121129793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33009,DS-4ffe006e-c7dc-4ab2-9cee-53ed38b024b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-5d2d8d42-cb6d-44c0-8165-a2050403cd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-4b311f61-09e9-427d-a5fc-2c65b26d1a70,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-25cffe85-13ea-4c84-9444-0a7855f06880,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-4ae5a09b-c7c3-47c6-a1c5-3f65f8e77a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-513ab0c0-342f-4052-aa9d-a2e8cfa93481,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-3c0e78b5-996a-4058-86e5-8f7b8d930994,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-8020ed7c-6065-402f-a819-1b78ebae4215,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938352758-172.17.0.19-1597121197064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45355,DS-14b803d3-7563-439b-ab6f-d21474359af8,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-642b4869-c059-41c3-9f53-757358d2a7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-261a06bb-c656-4bb5-b35f-08a898959446,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-013654d0-6422-466b-92df-3d912b6ebfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-97c53c2c-679a-4f95-b4c9-a3f876eeae07,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-874c4692-106f-4c5a-b00e-6e5502765955,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-de06a180-da5b-44e3-ac55-c6637f246ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-f3fc9a14-bedd-40a0-9d56-41fc11466e43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938352758-172.17.0.19-1597121197064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45355,DS-14b803d3-7563-439b-ab6f-d21474359af8,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-642b4869-c059-41c3-9f53-757358d2a7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-261a06bb-c656-4bb5-b35f-08a898959446,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-013654d0-6422-466b-92df-3d912b6ebfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-97c53c2c-679a-4f95-b4c9-a3f876eeae07,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-874c4692-106f-4c5a-b00e-6e5502765955,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-de06a180-da5b-44e3-ac55-c6637f246ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-f3fc9a14-bedd-40a0-9d56-41fc11466e43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726819775-172.17.0.19-1597121258068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33154,DS-8719726c-056e-4bc9-b54c-9c6a5e93c554,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-1284e73c-3294-429b-a8e0-007240c1ac7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-f0c224a5-7e87-4edd-95ac-25aca8fc7c91,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-51f7c2f4-0c3a-42f4-ab89-e2e79cfd6037,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-15d1f2ba-7762-43fb-bb7b-e7260a7b5c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-2368de99-4eb3-4295-b083-499466c5a533,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-473bc469-d9d0-48ea-8d14-c9dfd76bc134,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-b61e842a-61cb-444d-9e9a-2909da33302c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726819775-172.17.0.19-1597121258068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33154,DS-8719726c-056e-4bc9-b54c-9c6a5e93c554,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-1284e73c-3294-429b-a8e0-007240c1ac7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-f0c224a5-7e87-4edd-95ac-25aca8fc7c91,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-51f7c2f4-0c3a-42f4-ab89-e2e79cfd6037,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-15d1f2ba-7762-43fb-bb7b-e7260a7b5c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-2368de99-4eb3-4295-b083-499466c5a533,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-473bc469-d9d0-48ea-8d14-c9dfd76bc134,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-b61e842a-61cb-444d-9e9a-2909da33302c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781349063-172.17.0.19-1597121444935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42941,DS-26afb535-b798-4757-afe3-c4b1b375d3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-b525e900-f28f-4e9a-b2e8-3e382f41cb54,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-b077022d-fcc2-45f7-a4d5-357e2c454283,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-349dad21-bca1-422e-b575-91dd428e6af7,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-b8e480f0-a0f1-4c11-bf9d-c17eb5304ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-365e4030-6e52-40c1-b9e1-57f39d611ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-5feba64e-939f-4f32-9f33-075fbbede0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-5f8c8065-fe6d-4c7c-9130-4851a76c0b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781349063-172.17.0.19-1597121444935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42941,DS-26afb535-b798-4757-afe3-c4b1b375d3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-b525e900-f28f-4e9a-b2e8-3e382f41cb54,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-b077022d-fcc2-45f7-a4d5-357e2c454283,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-349dad21-bca1-422e-b575-91dd428e6af7,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-b8e480f0-a0f1-4c11-bf9d-c17eb5304ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-365e4030-6e52-40c1-b9e1-57f39d611ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-5feba64e-939f-4f32-9f33-075fbbede0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-5f8c8065-fe6d-4c7c-9130-4851a76c0b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340297600-172.17.0.19-1597121511947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38956,DS-15d1d9bb-86af-41d5-8e65-ad7e445c6dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-688665d8-0bf9-44bc-8d73-c55497400ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-e5e03a86-ac45-4395-b0e9-68a960f92f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-754198c2-39d9-4785-965a-14c84bdf6701,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-95f3d048-a012-4257-a910-2b9e1cad93f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-595d0f28-fade-49ef-91e3-3ed656198ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-df65a4b2-dee7-40f5-9f4e-04a0bd202ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-3e088b22-e1ef-42f0-bc86-1406267b1e82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340297600-172.17.0.19-1597121511947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38956,DS-15d1d9bb-86af-41d5-8e65-ad7e445c6dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-688665d8-0bf9-44bc-8d73-c55497400ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-e5e03a86-ac45-4395-b0e9-68a960f92f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-754198c2-39d9-4785-965a-14c84bdf6701,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-95f3d048-a012-4257-a910-2b9e1cad93f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-595d0f28-fade-49ef-91e3-3ed656198ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-df65a4b2-dee7-40f5-9f4e-04a0bd202ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-3e088b22-e1ef-42f0-bc86-1406267b1e82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1149399163-172.17.0.19-1597121548240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45853,DS-0701ae3c-d046-4482-8110-faa7080922ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-d1730dc7-ec52-4aca-88d6-af58309e36e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-cd56c147-df90-4924-a517-de6748de05a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-8c777aca-b763-4ca2-b255-804a3a0d6c14,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-9eb91dac-a5dc-41f2-bbce-09f3a576d455,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-85330693-4703-4aa2-a3a4-16b6c3a30f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-05ed178e-87a2-44c9-8219-af96feab0514,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-e7330394-9735-4df5-84f6-0c97bcb4077f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1149399163-172.17.0.19-1597121548240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45853,DS-0701ae3c-d046-4482-8110-faa7080922ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-d1730dc7-ec52-4aca-88d6-af58309e36e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-cd56c147-df90-4924-a517-de6748de05a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-8c777aca-b763-4ca2-b255-804a3a0d6c14,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-9eb91dac-a5dc-41f2-bbce-09f3a576d455,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-85330693-4703-4aa2-a3a4-16b6c3a30f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-05ed178e-87a2-44c9-8219-af96feab0514,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-e7330394-9735-4df5-84f6-0c97bcb4077f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061129736-172.17.0.19-1597121586509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37073,DS-9812e424-bf13-4b71-95fb-4f1902336431,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-7811b570-a727-4ca4-a9f0-b96838291a53,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-f44c3c68-bd46-4633-ab8b-693f08b9b0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-6bec4a56-9822-458e-9511-a1caa6197121,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-e931b998-47e6-4078-b51a-14ba32470ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-1382761a-8fbe-461f-863a-f019ba0e03f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-addd26b9-b1c3-4149-a3b7-2608e602f354,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-1ff3f946-a50b-4d6c-995a-bf2d7d1349ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061129736-172.17.0.19-1597121586509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37073,DS-9812e424-bf13-4b71-95fb-4f1902336431,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-7811b570-a727-4ca4-a9f0-b96838291a53,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-f44c3c68-bd46-4633-ab8b-693f08b9b0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-6bec4a56-9822-458e-9511-a1caa6197121,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-e931b998-47e6-4078-b51a-14ba32470ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-1382761a-8fbe-461f-863a-f019ba0e03f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-addd26b9-b1c3-4149-a3b7-2608e602f354,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-1ff3f946-a50b-4d6c-995a-bf2d7d1349ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453620806-172.17.0.19-1597121624656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40285,DS-127dcdb0-dd73-4801-9dc3-59a4fef6f2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-d377e8e3-486e-4aa2-ad66-70d65a7004ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-97f6fb17-2f6c-466f-a2fa-1750ad9e23a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-ac1569df-120e-48d6-b834-ce42e72ea429,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-fc3310a0-49f7-4ec3-886f-cf9d05f284ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-fd5bd2f0-2314-408c-9682-148f89d0c786,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-2dc9dea6-8bb7-4daf-bda8-786a8e5e5e22,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-cb826764-8919-4c50-83ed-c0f75a7aecad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453620806-172.17.0.19-1597121624656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40285,DS-127dcdb0-dd73-4801-9dc3-59a4fef6f2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-d377e8e3-486e-4aa2-ad66-70d65a7004ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-97f6fb17-2f6c-466f-a2fa-1750ad9e23a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-ac1569df-120e-48d6-b834-ce42e72ea429,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-fc3310a0-49f7-4ec3-886f-cf9d05f284ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-fd5bd2f0-2314-408c-9682-148f89d0c786,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-2dc9dea6-8bb7-4daf-bda8-786a8e5e5e22,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-cb826764-8919-4c50-83ed-c0f75a7aecad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93581246-172.17.0.19-1597121730062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40150,DS-7c07b08d-753a-49f0-9129-137d47452d32,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-ba4c9e60-e660-4003-8e35-15aaaf013610,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-e750f31a-4a40-4565-a9ed-80d4fc79b33e,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-3b28392f-7472-485f-8a26-60a6f3b3fe38,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-5f007d35-b339-41dd-8cb4-037f5325de6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-c412ab5c-ceb2-4158-ac15-733be31c83d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-04707a34-957c-4921-942d-f64e15a535ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-7142736c-418b-427c-8e8b-dd83a678626a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93581246-172.17.0.19-1597121730062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40150,DS-7c07b08d-753a-49f0-9129-137d47452d32,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-ba4c9e60-e660-4003-8e35-15aaaf013610,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-e750f31a-4a40-4565-a9ed-80d4fc79b33e,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-3b28392f-7472-485f-8a26-60a6f3b3fe38,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-5f007d35-b339-41dd-8cb4-037f5325de6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-c412ab5c-ceb2-4158-ac15-733be31c83d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-04707a34-957c-4921-942d-f64e15a535ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-7142736c-418b-427c-8e8b-dd83a678626a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924612223-172.17.0.19-1597121826381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33078,DS-f8c876fd-74d7-4134-a9fa-c2d21bfe95e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-78667dc1-83d5-4a85-bc0b-e136d665d32c,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-7bf7d9cb-84c9-4647-b6fc-ff6a629e6189,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-db0b27b8-92af-441d-a3dd-7a373e2491ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-f3ab2fdc-8233-4b14-ba87-ca9ca5138898,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-aeebda01-ff02-4f4c-8656-0801962fe4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-51c513f2-557d-4bd5-8bf8-292ddc43617a,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-fa5978a4-8a39-4bfd-aea0-6d845c5f7d4f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924612223-172.17.0.19-1597121826381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33078,DS-f8c876fd-74d7-4134-a9fa-c2d21bfe95e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-78667dc1-83d5-4a85-bc0b-e136d665d32c,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-7bf7d9cb-84c9-4647-b6fc-ff6a629e6189,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-db0b27b8-92af-441d-a3dd-7a373e2491ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-f3ab2fdc-8233-4b14-ba87-ca9ca5138898,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-aeebda01-ff02-4f4c-8656-0801962fe4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-51c513f2-557d-4bd5-8bf8-292ddc43617a,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-fa5978a4-8a39-4bfd-aea0-6d845c5f7d4f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443877878-172.17.0.19-1597121967288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42029,DS-934ac042-e779-4464-a44d-b6bee414dd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-55cf7edc-7e37-46bb-b4c5-2c6857addd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-e3da7938-b489-4ca9-b289-346f868b42fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-84e615d0-530d-4bea-b779-582d113fe83a,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-65a37fc7-692a-4c94-ab73-91990a9619b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-d78def16-d4f2-49a0-8683-5f67fa47ac34,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-c44f2235-0536-4040-87f4-576a294632ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-ae8c023b-767c-4ab8-b6b4-994bd608823a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443877878-172.17.0.19-1597121967288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42029,DS-934ac042-e779-4464-a44d-b6bee414dd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-55cf7edc-7e37-46bb-b4c5-2c6857addd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-e3da7938-b489-4ca9-b289-346f868b42fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-84e615d0-530d-4bea-b779-582d113fe83a,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-65a37fc7-692a-4c94-ab73-91990a9619b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-d78def16-d4f2-49a0-8683-5f67fa47ac34,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-c44f2235-0536-4040-87f4-576a294632ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-ae8c023b-767c-4ab8-b6b4-994bd608823a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158983907-172.17.0.19-1597122170609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37642,DS-eec27228-7de5-4a2b-a4bb-e3172a15e7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-c9d504b6-d311-4564-a04f-6b26b5554ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-6c8b3c85-a738-4cec-ab0c-bb0954a1bf91,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-4e4fa39c-b7b6-42e4-981a-c999e7bfd62f,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-46ebf2aa-fea0-4975-a253-979b5ad74288,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-a6603820-50df-4428-99c9-acfb9821f572,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-77f5e31d-ca1b-4ac2-b156-0b759bf25722,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-a89cd8bf-257f-4ad0-895b-279ed368f4b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158983907-172.17.0.19-1597122170609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37642,DS-eec27228-7de5-4a2b-a4bb-e3172a15e7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-c9d504b6-d311-4564-a04f-6b26b5554ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-6c8b3c85-a738-4cec-ab0c-bb0954a1bf91,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-4e4fa39c-b7b6-42e4-981a-c999e7bfd62f,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-46ebf2aa-fea0-4975-a253-979b5ad74288,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-a6603820-50df-4428-99c9-acfb9821f572,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-77f5e31d-ca1b-4ac2-b156-0b759bf25722,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-a89cd8bf-257f-4ad0-895b-279ed368f4b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736340552-172.17.0.19-1597122290594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34004,DS-25b5aab8-5c7a-40af-9a91-07ab76a9df04,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-d0ee5d0e-ef5c-4496-88a6-7c8cb2cc3ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-dcd4f7dd-0b56-4591-8461-b40facacd0de,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-b731bdbc-c090-484e-bb41-7740f1966fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-79974a36-2e75-4572-854f-a2bcd9c56586,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-235e2b9d-a9c3-46d3-acf4-d78d5e000da3,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-a81573a9-8d64-4c70-962a-f7c80ab2a4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-cb7b0efb-4d70-4954-a0f5-37737412ad01,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736340552-172.17.0.19-1597122290594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34004,DS-25b5aab8-5c7a-40af-9a91-07ab76a9df04,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-d0ee5d0e-ef5c-4496-88a6-7c8cb2cc3ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-dcd4f7dd-0b56-4591-8461-b40facacd0de,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-b731bdbc-c090-484e-bb41-7740f1966fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-79974a36-2e75-4572-854f-a2bcd9c56586,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-235e2b9d-a9c3-46d3-acf4-d78d5e000da3,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-a81573a9-8d64-4c70-962a-f7c80ab2a4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-cb7b0efb-4d70-4954-a0f5-37737412ad01,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410716823-172.17.0.19-1597122362141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45556,DS-d095c3aa-cee9-42a3-a396-3f39b44db11f,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-43911e0d-3210-464a-82b2-a0cffa8733b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-74fca86c-f634-4c05-850c-7613962fc530,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-4d2ed5cd-5054-4830-bad5-d712058c747f,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-14f61893-ed58-4d39-991a-dbe0d06066d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-2ecf7d3e-5049-429e-99e8-e9282c8d1e69,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-4d463ef7-f68e-4702-bd9b-d67aca570f35,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-98a7133f-189f-4cdf-9f7c-4abbdfa9150a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410716823-172.17.0.19-1597122362141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45556,DS-d095c3aa-cee9-42a3-a396-3f39b44db11f,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-43911e0d-3210-464a-82b2-a0cffa8733b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-74fca86c-f634-4c05-850c-7613962fc530,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-4d2ed5cd-5054-4830-bad5-d712058c747f,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-14f61893-ed58-4d39-991a-dbe0d06066d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-2ecf7d3e-5049-429e-99e8-e9282c8d1e69,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-4d463ef7-f68e-4702-bd9b-d67aca570f35,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-98a7133f-189f-4cdf-9f7c-4abbdfa9150a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582278862-172.17.0.19-1597122391396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40359,DS-586d09e1-1110-4041-8676-240650e649df,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-b23d9d54-fbf0-4d53-88b5-369f080ce3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-7e6c506d-a400-433b-8d54-0bffadc9c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-d6a05f42-765a-4ba5-8779-eb91989b65ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-8fa3b998-bda3-49ed-b0c8-b07239a0d04c,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-523fdf24-e202-4fb5-b66f-8de6117ea7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-587e4c62-f662-48df-9baf-52f3f3f48f23,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-f6128627-ef3a-4005-b844-e30f8860b84d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582278862-172.17.0.19-1597122391396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40359,DS-586d09e1-1110-4041-8676-240650e649df,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-b23d9d54-fbf0-4d53-88b5-369f080ce3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-7e6c506d-a400-433b-8d54-0bffadc9c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-d6a05f42-765a-4ba5-8779-eb91989b65ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-8fa3b998-bda3-49ed-b0c8-b07239a0d04c,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-523fdf24-e202-4fb5-b66f-8de6117ea7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-587e4c62-f662-48df-9baf-52f3f3f48f23,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-f6128627-ef3a-4005-b844-e30f8860b84d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254849394-172.17.0.19-1597122606080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35217,DS-2c123270-1da1-43b9-a958-392f62444b73,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-16cca38d-364f-4af6-885f-0c10046ff4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-26ab4c54-919e-42e9-ba0a-3675183c5a28,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-d12f3b2d-b61c-4c5a-8fa9-f2ee11dea6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-98cabdcd-4b63-47ba-99aa-49fa33fff9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-d7155be2-38d0-404d-9ea8-c0a8584ba1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-05dff179-f63a-4dbf-a98e-e1feb998ecd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-81e4c740-9cb1-431b-9ca1-377f830a4d4a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254849394-172.17.0.19-1597122606080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35217,DS-2c123270-1da1-43b9-a958-392f62444b73,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-16cca38d-364f-4af6-885f-0c10046ff4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-26ab4c54-919e-42e9-ba0a-3675183c5a28,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-d12f3b2d-b61c-4c5a-8fa9-f2ee11dea6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-98cabdcd-4b63-47ba-99aa-49fa33fff9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-d7155be2-38d0-404d-9ea8-c0a8584ba1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-05dff179-f63a-4dbf-a98e-e1feb998ecd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-81e4c740-9cb1-431b-9ca1-377f830a4d4a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416020311-172.17.0.19-1597122640023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35955,DS-5d9c01a8-7239-4194-9bff-4d7205f0d49e,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-f05969d5-00f3-437a-aed7-2ed7deaae4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-c5847cfb-fe77-4830-89b6-51e2ceb8e9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-95abef61-21c7-4d82-8372-9c2d71b760f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-aba95697-e4e1-40bd-bc14-71e8ef1d1393,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-ccb3ae95-2be7-4185-a3dc-1f2190fdd310,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-859706d3-03cc-4161-ae78-f39bba5345d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-310b9c63-2ea4-43f7-b285-b532f0ba12bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416020311-172.17.0.19-1597122640023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35955,DS-5d9c01a8-7239-4194-9bff-4d7205f0d49e,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-f05969d5-00f3-437a-aed7-2ed7deaae4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-c5847cfb-fe77-4830-89b6-51e2ceb8e9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-95abef61-21c7-4d82-8372-9c2d71b760f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-aba95697-e4e1-40bd-bc14-71e8ef1d1393,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-ccb3ae95-2be7-4185-a3dc-1f2190fdd310,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-859706d3-03cc-4161-ae78-f39bba5345d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-310b9c63-2ea4-43f7-b285-b532f0ba12bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021296318-172.17.0.19-1597122725778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44725,DS-bcfdc2ff-6de6-410a-8d61-9097330a6bab,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-d0c7ff9f-efc3-4639-a872-5ae1b3a688be,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-ed3a9c73-dc5b-4f15-ab23-bb938d4ce766,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-d2b1a131-7616-44e8-bc9d-17a3ed977f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-db4fba2e-3c34-48b0-a112-0c21d0b60a67,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-a06a9861-a8b9-41b8-806b-cdb2f3a053c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-8420a82b-05d7-42ab-b0fa-1b8cd08ab888,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-4d6c71b8-a480-49f3-9480-698844536cc9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021296318-172.17.0.19-1597122725778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44725,DS-bcfdc2ff-6de6-410a-8d61-9097330a6bab,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-d0c7ff9f-efc3-4639-a872-5ae1b3a688be,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-ed3a9c73-dc5b-4f15-ab23-bb938d4ce766,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-d2b1a131-7616-44e8-bc9d-17a3ed977f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-db4fba2e-3c34-48b0-a112-0c21d0b60a67,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-a06a9861-a8b9-41b8-806b-cdb2f3a053c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-8420a82b-05d7-42ab-b0fa-1b8cd08ab888,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-4d6c71b8-a480-49f3-9480-698844536cc9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428340935-172.17.0.19-1597122752984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44184,DS-5b3d0029-6c5a-4967-b470-89e2fbb1b913,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-462dd7e3-8af0-4194-8884-8feeb4c6983a,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-a97ab05c-6c51-4ea1-b238-574f34790a81,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-c5e57715-5205-4623-a0d8-7d6c907a36e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-b10a9a14-8937-4d97-b33a-567bbfaff4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-6f355b85-05a3-4162-a075-6dbee2d3bc52,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-ac19267c-ab34-41a5-ac03-4caaa314af6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-1cf59e00-1663-4b55-994e-983d1755c08e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428340935-172.17.0.19-1597122752984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44184,DS-5b3d0029-6c5a-4967-b470-89e2fbb1b913,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-462dd7e3-8af0-4194-8884-8feeb4c6983a,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-a97ab05c-6c51-4ea1-b238-574f34790a81,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-c5e57715-5205-4623-a0d8-7d6c907a36e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-b10a9a14-8937-4d97-b33a-567bbfaff4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-6f355b85-05a3-4162-a075-6dbee2d3bc52,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-ac19267c-ab34-41a5-ac03-4caaa314af6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-1cf59e00-1663-4b55-994e-983d1755c08e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262662445-172.17.0.19-1597122842726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41260,DS-d8950f55-ea41-4b13-b0a6-61c9314c0cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-13bd95f4-4767-4bf0-af6f-8c9022994e38,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-27a12840-725d-4f6e-9642-3ca86ff0c9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-18fd61d8-6d8c-4685-af15-4fc3da51d9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-108d08cb-ee51-463d-8e79-cad97cf9ff4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-b230d644-212a-4f09-963b-a1715afb6f20,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-4b60b47b-83a0-42f3-b0a0-3afedfeb0865,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-9abae775-4a66-4e9d-99b1-d56748b8407b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262662445-172.17.0.19-1597122842726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41260,DS-d8950f55-ea41-4b13-b0a6-61c9314c0cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-13bd95f4-4767-4bf0-af6f-8c9022994e38,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-27a12840-725d-4f6e-9642-3ca86ff0c9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-18fd61d8-6d8c-4685-af15-4fc3da51d9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-108d08cb-ee51-463d-8e79-cad97cf9ff4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-b230d644-212a-4f09-963b-a1715afb6f20,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-4b60b47b-83a0-42f3-b0a0-3afedfeb0865,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-9abae775-4a66-4e9d-99b1-d56748b8407b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325176933-172.17.0.19-1597122873386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-7f232a45-33f1-4e4f-97bc-c6fab945a177,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-b4b8010a-c88d-4dfc-81b1-c8936ce5c0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-ca98974a-0bf0-4630-ad56-6e54182877dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-a7fda630-64ee-4721-bc40-131da39390c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-9927a85e-b0b6-45c4-bb91-d8f48698e8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-a11e24af-00f8-430e-a3a0-36eb4a63b534,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-ecc6e2f9-ff3d-4507-a178-51f22377476a,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-4beb082e-435a-4349-9e44-b651c40c7cb2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325176933-172.17.0.19-1597122873386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-7f232a45-33f1-4e4f-97bc-c6fab945a177,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-b4b8010a-c88d-4dfc-81b1-c8936ce5c0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-ca98974a-0bf0-4630-ad56-6e54182877dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-a7fda630-64ee-4721-bc40-131da39390c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-9927a85e-b0b6-45c4-bb91-d8f48698e8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-a11e24af-00f8-430e-a3a0-36eb4a63b534,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-ecc6e2f9-ff3d-4507-a178-51f22377476a,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-4beb082e-435a-4349-9e44-b651c40c7cb2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768246333-172.17.0.19-1597122905326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36358,DS-cf348365-e61f-4de8-bd0c-48bf7e5bdca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-cc6b90a4-e9c8-4276-a2ed-5dfa3024666c,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-ab96593b-4f32-4a01-a075-36285fcc5b55,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-8bab422d-0eaa-4588-932f-39b71483750a,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-d1d5ff45-aac0-4ae9-8bb8-2d6ecccbb6be,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-02404215-17d7-4fd4-adb2-9efd344bfe37,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-159a7815-27e4-4bc9-a321-b19af19fabab,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-c09ba647-3efe-4d00-a8c3-636faa300f43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-768246333-172.17.0.19-1597122905326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36358,DS-cf348365-e61f-4de8-bd0c-48bf7e5bdca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-cc6b90a4-e9c8-4276-a2ed-5dfa3024666c,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-ab96593b-4f32-4a01-a075-36285fcc5b55,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-8bab422d-0eaa-4588-932f-39b71483750a,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-d1d5ff45-aac0-4ae9-8bb8-2d6ecccbb6be,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-02404215-17d7-4fd4-adb2-9efd344bfe37,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-159a7815-27e4-4bc9-a321-b19af19fabab,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-c09ba647-3efe-4d00-a8c3-636faa300f43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890146128-172.17.0.19-1597122993959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43925,DS-18df9de8-80e0-4215-8281-346e71e116ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-46e06c00-74b4-48cb-825c-5146f205b38a,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-ec317ae4-821e-4e22-b833-2de731e4a822,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-3b299670-43a7-4795-96a4-80581b5e6adf,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-2cba5460-a6b4-4040-b05a-16ec02422884,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-d6af1100-be83-46d4-97f1-d8204862b050,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-e5482725-af45-4c24-8e30-e4dff631cd66,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-fd5eaf37-ee49-4321-be85-f9b0b8633c72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890146128-172.17.0.19-1597122993959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43925,DS-18df9de8-80e0-4215-8281-346e71e116ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-46e06c00-74b4-48cb-825c-5146f205b38a,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-ec317ae4-821e-4e22-b833-2de731e4a822,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-3b299670-43a7-4795-96a4-80581b5e6adf,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-2cba5460-a6b4-4040-b05a-16ec02422884,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-d6af1100-be83-46d4-97f1-d8204862b050,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-e5482725-af45-4c24-8e30-e4dff631cd66,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-fd5eaf37-ee49-4321-be85-f9b0b8633c72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728832350-172.17.0.19-1597123396822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43623,DS-e7b6506d-a94f-4013-8ee1-38ea43df63af,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-d036798d-73bb-4157-bbac-1cd1558c4819,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-a28b11a7-0c0c-4b53-8b1c-d0c808286459,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-d0db245c-69f7-4901-88e6-4e8dd4f2336c,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-b2056d4b-1204-402b-b0a2-e09154f1e845,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-8295e2e6-ae0e-47fc-a05f-3557997fab85,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-8d3e9255-23b6-494e-aee8-5bb25257b99e,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-9d4118b1-1c4b-4c68-8778-634d24526a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728832350-172.17.0.19-1597123396822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43623,DS-e7b6506d-a94f-4013-8ee1-38ea43df63af,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-d036798d-73bb-4157-bbac-1cd1558c4819,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-a28b11a7-0c0c-4b53-8b1c-d0c808286459,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-d0db245c-69f7-4901-88e6-4e8dd4f2336c,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-b2056d4b-1204-402b-b0a2-e09154f1e845,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-8295e2e6-ae0e-47fc-a05f-3557997fab85,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-8d3e9255-23b6-494e-aee8-5bb25257b99e,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-9d4118b1-1c4b-4c68-8778-634d24526a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150037887-172.17.0.19-1597123703303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39622,DS-e6c5e3f0-609a-4582-88fc-57e7196af7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-e2897f89-353f-441c-9870-7b013abdab9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-4fcd28e4-4ea5-430b-b01d-ed8ffb357bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-4c2df5e7-94b9-4b90-aead-6ce7819ca124,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-55cfcb40-b004-4002-a770-e16f04659075,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-a6948ab7-c1f3-479e-871a-f4cf05afa361,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-b631fb8c-b78c-47cd-92b4-634a00ecfb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-cd2e0a31-b584-4439-b1ef-253bece24110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150037887-172.17.0.19-1597123703303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39622,DS-e6c5e3f0-609a-4582-88fc-57e7196af7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-e2897f89-353f-441c-9870-7b013abdab9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-4fcd28e4-4ea5-430b-b01d-ed8ffb357bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-4c2df5e7-94b9-4b90-aead-6ce7819ca124,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-55cfcb40-b004-4002-a770-e16f04659075,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-a6948ab7-c1f3-479e-871a-f4cf05afa361,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-b631fb8c-b78c-47cd-92b4-634a00ecfb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-cd2e0a31-b584-4439-b1ef-253bece24110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140230029-172.17.0.19-1597123976828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45496,DS-ca454dff-8999-4992-be1d-a4d2a5dea6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-fb52c726-f6fd-455a-902e-1299e370543b,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-cc679795-6b8c-472f-9016-67f85f0cb4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-3271cb42-e67b-4b73-8a1d-8f114bae8895,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-89da4984-a3b2-48c0-8921-38e2c86008c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-f4c8c7b5-16f7-4b5e-bc2b-e677482707ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-ced7880e-c3ef-42c0-a6de-628c276a02ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-b5814365-8414-483b-9327-c7628656af6c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140230029-172.17.0.19-1597123976828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45496,DS-ca454dff-8999-4992-be1d-a4d2a5dea6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-fb52c726-f6fd-455a-902e-1299e370543b,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-cc679795-6b8c-472f-9016-67f85f0cb4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-3271cb42-e67b-4b73-8a1d-8f114bae8895,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-89da4984-a3b2-48c0-8921-38e2c86008c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-f4c8c7b5-16f7-4b5e-bc2b-e677482707ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-ced7880e-c3ef-42c0-a6de-628c276a02ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-b5814365-8414-483b-9327-c7628656af6c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867519583-172.17.0.19-1597124011176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34727,DS-f9236670-ab7d-48fd-b1ca-143aaeb4831c,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-b2fe9b32-98d4-483e-8d3a-395e54d43bff,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-81f0b173-dbf9-4a67-a68d-6420b9ea9cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-bc01655f-f143-4eb0-b128-613b9bbaad8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-66bbe42c-0a2e-4ec1-b4dd-5b336f7762cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-a0d5efff-11f0-4769-8097-4d0bbed3f53a,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-f7ed95d2-ca02-4514-b26a-0065cef2e23c,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-d58c87ee-35e1-426a-9d1e-aeb0b1efcccd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867519583-172.17.0.19-1597124011176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34727,DS-f9236670-ab7d-48fd-b1ca-143aaeb4831c,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-b2fe9b32-98d4-483e-8d3a-395e54d43bff,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-81f0b173-dbf9-4a67-a68d-6420b9ea9cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-bc01655f-f143-4eb0-b128-613b9bbaad8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-66bbe42c-0a2e-4ec1-b4dd-5b336f7762cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-a0d5efff-11f0-4769-8097-4d0bbed3f53a,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-f7ed95d2-ca02-4514-b26a-0065cef2e23c,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-d58c87ee-35e1-426a-9d1e-aeb0b1efcccd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062444194-172.17.0.19-1597124040652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38181,DS-0fc419ce-1359-4e14-b458-507669b73fba,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-a79b1ed0-bafd-4785-b626-038980da5102,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-c4e90b7e-eb14-4224-8e22-f828a760bc45,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-5291d66f-70dd-4cd1-8392-c2026f254828,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-a85594a8-d40e-499f-9414-52f5b0ff09ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-63e31f87-c743-45ce-ad53-846aa21e30c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-4cc0fc84-dece-4b9b-88f4-7db7adbc2751,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-8abb6369-bc28-4e3d-8308-0a5249f80bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062444194-172.17.0.19-1597124040652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38181,DS-0fc419ce-1359-4e14-b458-507669b73fba,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-a79b1ed0-bafd-4785-b626-038980da5102,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-c4e90b7e-eb14-4224-8e22-f828a760bc45,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-5291d66f-70dd-4cd1-8392-c2026f254828,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-a85594a8-d40e-499f-9414-52f5b0ff09ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-63e31f87-c743-45ce-ad53-846aa21e30c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-4cc0fc84-dece-4b9b-88f4-7db7adbc2751,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-8abb6369-bc28-4e3d-8308-0a5249f80bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596633318-172.17.0.19-1597124111443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36482,DS-211aee16-a925-462d-9e2b-2ba0cfebe1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-21953d0e-8b70-44a3-ae2a-7cfbd4b129d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-7332f1e5-ef08-4787-b686-263ebb00b57d,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-cf8e9173-1ed9-46ee-bf25-30bc661d0457,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-ef8f0505-02d2-4c54-a7ff-0880fbe9557c,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-c608a85d-cf1e-4660-9d13-7d5798041201,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-f90794fe-5c5c-4360-97a4-4fe3bd4aa804,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-62b9e984-4bfc-433b-bac7-233c39614f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596633318-172.17.0.19-1597124111443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36482,DS-211aee16-a925-462d-9e2b-2ba0cfebe1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-21953d0e-8b70-44a3-ae2a-7cfbd4b129d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-7332f1e5-ef08-4787-b686-263ebb00b57d,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-cf8e9173-1ed9-46ee-bf25-30bc661d0457,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-ef8f0505-02d2-4c54-a7ff-0880fbe9557c,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-c608a85d-cf1e-4660-9d13-7d5798041201,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-f90794fe-5c5c-4360-97a4-4fe3bd4aa804,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-62b9e984-4bfc-433b-bac7-233c39614f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616524470-172.17.0.19-1597124328936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34902,DS-e5fc9fa7-3ebf-475d-9ac2-06f7c0c6ed46,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-d71e5b8b-5a10-4f0a-9e20-a8285b05c650,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-436bc7ef-7273-4d7b-9548-84292c77bfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-95892991-b57a-48fe-b559-c354cd5b6b76,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-d30a4240-445f-4b34-b3b3-511aeeadd66a,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-ac23048d-5057-42e6-be91-03467f263a42,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-901a156a-be04-40e1-af5c-cc08898d0c15,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-adb2eb6f-0ea8-4f05-8506-c55ce720b70c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616524470-172.17.0.19-1597124328936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34902,DS-e5fc9fa7-3ebf-475d-9ac2-06f7c0c6ed46,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-d71e5b8b-5a10-4f0a-9e20-a8285b05c650,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-436bc7ef-7273-4d7b-9548-84292c77bfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-95892991-b57a-48fe-b559-c354cd5b6b76,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-d30a4240-445f-4b34-b3b3-511aeeadd66a,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-ac23048d-5057-42e6-be91-03467f263a42,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-901a156a-be04-40e1-af5c-cc08898d0c15,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-adb2eb6f-0ea8-4f05-8506-c55ce720b70c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833271664-172.17.0.19-1597124433452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42673,DS-ea4ddb7c-56fa-4040-aec6-5d42172d2079,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-1db24fc2-b985-4456-b373-28e8bce6fcca,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-a29fca1d-540c-4515-af8b-67cfbc141251,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-cc3bb7ce-6482-461b-8bba-30b38cd3dd32,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-f16b8697-b472-44f7-9d98-a708662500cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-030e6c89-a92d-4fc2-8e71-b4d9a8e91d73,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-c8954e27-51ca-45b4-b16f-4b019d1036b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-2e1261a7-2d7a-44c9-90ed-217629bc8215,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833271664-172.17.0.19-1597124433452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42673,DS-ea4ddb7c-56fa-4040-aec6-5d42172d2079,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-1db24fc2-b985-4456-b373-28e8bce6fcca,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-a29fca1d-540c-4515-af8b-67cfbc141251,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-cc3bb7ce-6482-461b-8bba-30b38cd3dd32,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-f16b8697-b472-44f7-9d98-a708662500cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-030e6c89-a92d-4fc2-8e71-b4d9a8e91d73,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-c8954e27-51ca-45b4-b16f-4b019d1036b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-2e1261a7-2d7a-44c9-90ed-217629bc8215,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810243023-172.17.0.19-1597124681591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42876,DS-b5c73589-e000-48f8-a941-4592b978c006,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-e76d6774-820f-4ca2-a6b0-e8a51ebfaff9,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-a60671ca-2187-4c5b-b59b-f32b21dceb88,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-ffb25003-7145-40b7-a72c-665f36da7c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-e0d5fe10-5c09-41f1-af5f-7e14710fae22,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-4480f5f8-ab52-4a00-9048-e605ae2e2415,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-33b7c797-9550-4ef5-a251-a14371e82dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-8640f835-e009-4937-80db-f84b15312fe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810243023-172.17.0.19-1597124681591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42876,DS-b5c73589-e000-48f8-a941-4592b978c006,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-e76d6774-820f-4ca2-a6b0-e8a51ebfaff9,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-a60671ca-2187-4c5b-b59b-f32b21dceb88,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-ffb25003-7145-40b7-a72c-665f36da7c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-e0d5fe10-5c09-41f1-af5f-7e14710fae22,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-4480f5f8-ab52-4a00-9048-e605ae2e2415,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-33b7c797-9550-4ef5-a251-a14371e82dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-8640f835-e009-4937-80db-f84b15312fe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96012076-172.17.0.19-1597124965075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42133,DS-6b961ba1-3190-4a76-a666-1b1f6d535e15,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-69667b6c-14b4-437c-90dc-5ce57e5c14b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-9a1f87ac-0c3e-4bba-a895-576d3f05e3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-aefa5e05-18d0-42e0-9958-5e38520044fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-9dcefe7a-af58-4d20-945c-f53eecfa6dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-41065d5f-74bd-4ec9-8323-1811d87b13cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-7f80c924-7198-451a-8ba0-02d6141c6ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-7546ed4f-ce6f-412e-ae54-1948f1fc518f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96012076-172.17.0.19-1597124965075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42133,DS-6b961ba1-3190-4a76-a666-1b1f6d535e15,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-69667b6c-14b4-437c-90dc-5ce57e5c14b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-9a1f87ac-0c3e-4bba-a895-576d3f05e3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-aefa5e05-18d0-42e0-9958-5e38520044fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-9dcefe7a-af58-4d20-945c-f53eecfa6dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-41065d5f-74bd-4ec9-8323-1811d87b13cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-7f80c924-7198-451a-8ba0-02d6141c6ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-7546ed4f-ce6f-412e-ae54-1948f1fc518f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 26 out of 50
result: false positive !!!
Total execution time in seconds : 4903
