reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 128
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 128
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219886867-172.17.0.13-1597209253729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-7a37d332-ea82-41fb-b5e5-513de82fb121,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-73dcd483-35cc-47da-bde7-b2789336e90e,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-8ea92a54-969e-49bc-b446-ec10645e2db9,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-a8307824-3048-4bb1-b9e2-17fc480f9091,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-b66f2c17-dcb3-4bf8-95d8-45e4b4764c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-a617d4a0-6723-4c0f-897a-7c8faeebc067,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-e3a0e827-2e9c-4036-a5cb-b515e90927ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-c0c76aca-1eae-429a-8391-4cc67421327e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219886867-172.17.0.13-1597209253729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-7a37d332-ea82-41fb-b5e5-513de82fb121,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-73dcd483-35cc-47da-bde7-b2789336e90e,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-8ea92a54-969e-49bc-b446-ec10645e2db9,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-a8307824-3048-4bb1-b9e2-17fc480f9091,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-b66f2c17-dcb3-4bf8-95d8-45e4b4764c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-a617d4a0-6723-4c0f-897a-7c8faeebc067,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-e3a0e827-2e9c-4036-a5cb-b515e90927ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-c0c76aca-1eae-429a-8391-4cc67421327e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 128
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2104554201-172.17.0.13-1597209574901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36756,DS-9e789818-e590-4957-b450-01fcd8ffb336,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-d3975076-1c94-4a3f-bd3a-065545f8a7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-af0b8fa6-7216-42ce-8097-e245b24cebfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-379e6485-7149-45cb-81f4-ab51f5ce195d,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-45f360f3-9599-4b95-afeb-65c1130dd964,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-d79c8c26-c723-4ff7-9abd-d0db24986525,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-cf1b233b-3865-4bf1-a7a6-440fd6228caf,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-55c8b3d5-5cf7-4a63-9e31-9f16137866f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2104554201-172.17.0.13-1597209574901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36756,DS-9e789818-e590-4957-b450-01fcd8ffb336,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-d3975076-1c94-4a3f-bd3a-065545f8a7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-af0b8fa6-7216-42ce-8097-e245b24cebfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-379e6485-7149-45cb-81f4-ab51f5ce195d,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-45f360f3-9599-4b95-afeb-65c1130dd964,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-d79c8c26-c723-4ff7-9abd-d0db24986525,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-cf1b233b-3865-4bf1-a7a6-440fd6228caf,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-55c8b3d5-5cf7-4a63-9e31-9f16137866f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 128
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1151346424-172.17.0.13-1597209788078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39571,DS-bb10248a-b437-49ab-81fe-e0c68bbb2eae,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-9bf086ec-1ad6-4681-8384-23a146c77eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-bca3e44f-09b1-4a78-99ca-f379c8de995a,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-1a3c7f81-643d-4621-83f6-76c540880f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-714fb3d7-0a08-45db-a247-b413328f11c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-0993a97a-37bc-40c8-9e88-e8e93c46bf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-b616460b-c84f-46e0-bfd6-f095ba3f981d,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-b58151e1-dedf-4030-9166-b715d41d726d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1151346424-172.17.0.13-1597209788078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39571,DS-bb10248a-b437-49ab-81fe-e0c68bbb2eae,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-9bf086ec-1ad6-4681-8384-23a146c77eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-bca3e44f-09b1-4a78-99ca-f379c8de995a,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-1a3c7f81-643d-4621-83f6-76c540880f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-714fb3d7-0a08-45db-a247-b413328f11c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-0993a97a-37bc-40c8-9e88-e8e93c46bf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-b616460b-c84f-46e0-bfd6-f095ba3f981d,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-b58151e1-dedf-4030-9166-b715d41d726d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 128
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-300930938-172.17.0.13-1597210038227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43038,DS-043a69cf-8f07-4056-a0e0-f55df4652b14,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-3965aaed-8b6c-4b2d-92f7-d965947bfd34,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-8e30cb0a-c4f9-4b6f-9353-8ef08a785b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-7019fa9f-ef47-44d8-91e3-7fe59d6a7850,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-4de6804f-4398-4943-ae26-1ab345b211a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-9ffd6506-98ea-4042-967f-ba8dded7b6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-aeb31dc5-8fb7-4e1e-bee0-ca6a9595ce87,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-bb458a6c-fc1a-49c3-8bab-1a93fc7f75de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-300930938-172.17.0.13-1597210038227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43038,DS-043a69cf-8f07-4056-a0e0-f55df4652b14,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-3965aaed-8b6c-4b2d-92f7-d965947bfd34,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-8e30cb0a-c4f9-4b6f-9353-8ef08a785b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-7019fa9f-ef47-44d8-91e3-7fe59d6a7850,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-4de6804f-4398-4943-ae26-1ab345b211a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-9ffd6506-98ea-4042-967f-ba8dded7b6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-aeb31dc5-8fb7-4e1e-bee0-ca6a9595ce87,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-bb458a6c-fc1a-49c3-8bab-1a93fc7f75de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 128
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449423205-172.17.0.13-1597210305399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35916,DS-329b6624-a2b4-46c6-80d0-c27f1f98004c,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-75005ecb-2715-4aee-b452-da56a54dd7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-a6b8cf58-f443-4dfb-b16f-399fa932437c,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-7042399f-72dc-4a69-8c7d-308524c48d58,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-0b5ae1de-2d48-4e1d-83b2-9845b35f3cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-c0820865-2788-4e5c-af03-530025db551d,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-1e13ab65-4a8b-40f2-91d4-04b6fa5fdc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-91d4a844-dfad-4517-9365-f123af791c3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449423205-172.17.0.13-1597210305399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35916,DS-329b6624-a2b4-46c6-80d0-c27f1f98004c,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-75005ecb-2715-4aee-b452-da56a54dd7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-a6b8cf58-f443-4dfb-b16f-399fa932437c,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-7042399f-72dc-4a69-8c7d-308524c48d58,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-0b5ae1de-2d48-4e1d-83b2-9845b35f3cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-c0820865-2788-4e5c-af03-530025db551d,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-1e13ab65-4a8b-40f2-91d4-04b6fa5fdc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-91d4a844-dfad-4517-9365-f123af791c3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 128
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1151802952-172.17.0.13-1597210422966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40530,DS-2f4778a3-59ce-45d4-a874-cff8d3b4362e,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-c5b9b5e6-a01e-4ac9-84d2-80c6ce08253b,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-ffce5d20-e4a3-4f8d-9614-31cd7280b055,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-817e5fd7-42ec-4b61-aa70-38aa2fef845a,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-e9df52da-95a2-41c7-a1c7-6f7f939bca5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-52c9c850-65c5-4d46-81e3-a7d9cbc80453,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-230b90d6-5443-433a-bfeb-0d125df871f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-1d63b911-524b-4f07-b384-4e867d7d0287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1151802952-172.17.0.13-1597210422966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40530,DS-2f4778a3-59ce-45d4-a874-cff8d3b4362e,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-c5b9b5e6-a01e-4ac9-84d2-80c6ce08253b,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-ffce5d20-e4a3-4f8d-9614-31cd7280b055,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-817e5fd7-42ec-4b61-aa70-38aa2fef845a,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-e9df52da-95a2-41c7-a1c7-6f7f939bca5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-52c9c850-65c5-4d46-81e3-a7d9cbc80453,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-230b90d6-5443-433a-bfeb-0d125df871f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-1d63b911-524b-4f07-b384-4e867d7d0287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 128
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1171915437-172.17.0.13-1597211163847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43998,DS-178713e7-5f69-474a-bffe-c1bdeeaf3ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-1931e978-d44d-4baf-839e-dec9039775c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-15b44e26-b1a6-4e65-b8c8-aa622787fcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-28ec48c5-fa4c-4d67-bd56-750caca7b8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-0510d1d9-af59-4d59-b7b3-a774ac2d86f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-29fa37de-d343-4938-a08f-f5c842764a04,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-3d0dd4c6-9af2-4f57-963f-6786818b020a,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-db518392-269d-451b-9e52-edbe3ae7e45e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1171915437-172.17.0.13-1597211163847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43998,DS-178713e7-5f69-474a-bffe-c1bdeeaf3ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-1931e978-d44d-4baf-839e-dec9039775c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-15b44e26-b1a6-4e65-b8c8-aa622787fcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-28ec48c5-fa4c-4d67-bd56-750caca7b8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-0510d1d9-af59-4d59-b7b3-a774ac2d86f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-29fa37de-d343-4938-a08f-f5c842764a04,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-3d0dd4c6-9af2-4f57-963f-6786818b020a,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-db518392-269d-451b-9e52-edbe3ae7e45e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 128
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1833451415-172.17.0.13-1597211180320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41464,DS-2265a7ba-ed5a-4a57-bf7a-0e6f26d94da5,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-06f2ae2f-06e7-4ea5-8099-46dae28f813a,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-ccfa203f-3e2e-45b8-95a1-fce4a7ee649c,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-f5bc0b86-0091-4458-a8af-e820c5f818a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-ea3149e9-040b-4621-a07c-1a94409a8dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-5c554d73-886c-4e31-a20c-cf97910e9140,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-bd7a8f91-5928-4ee4-9dc3-e2270b6eb048,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-ebafdde5-4119-4276-b154-43216a7b7892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1833451415-172.17.0.13-1597211180320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41464,DS-2265a7ba-ed5a-4a57-bf7a-0e6f26d94da5,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-06f2ae2f-06e7-4ea5-8099-46dae28f813a,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-ccfa203f-3e2e-45b8-95a1-fce4a7ee649c,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-f5bc0b86-0091-4458-a8af-e820c5f818a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-ea3149e9-040b-4621-a07c-1a94409a8dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-5c554d73-886c-4e31-a20c-cf97910e9140,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-bd7a8f91-5928-4ee4-9dc3-e2270b6eb048,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-ebafdde5-4119-4276-b154-43216a7b7892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 128
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958224693-172.17.0.13-1597211344871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43156,DS-fbf16ce3-1e3a-4ab4-91ca-e6b365a5c88e,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-fa3c601a-09f0-4563-87b7-22e6600a3be8,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-b6b0c1e3-e883-408d-b512-4b390babb1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-aa12ff54-2cce-48e7-a1d9-2e326f9a94b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-f16aa876-0cca-4056-b6ca-1d61980a1819,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-55c45bdc-faa3-4335-863a-18342b6ab244,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-1f718b22-da8c-43b4-9e20-4724172dd207,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-aa1b5321-1536-4c3a-9cdd-c7fede0b97a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958224693-172.17.0.13-1597211344871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43156,DS-fbf16ce3-1e3a-4ab4-91ca-e6b365a5c88e,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-fa3c601a-09f0-4563-87b7-22e6600a3be8,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-b6b0c1e3-e883-408d-b512-4b390babb1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-aa12ff54-2cce-48e7-a1d9-2e326f9a94b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-f16aa876-0cca-4056-b6ca-1d61980a1819,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-55c45bdc-faa3-4335-863a-18342b6ab244,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-1f718b22-da8c-43b4-9e20-4724172dd207,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-aa1b5321-1536-4c3a-9cdd-c7fede0b97a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 128
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480360448-172.17.0.13-1597211475772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-27060cb4-ddea-4d71-b6aa-c6964561b2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-5b8dc755-dd10-418b-addf-9a6e23fb33d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-7f1e24c3-fa1f-4bb3-9aff-03d22f760bab,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-62add217-b583-43ef-a413-a7661ce5f7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-f3a53ac1-ca2f-463d-b7a1-58f37d32adbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-da71774f-232d-4de8-a147-e5dbaff3748b,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-e154533f-23e8-433b-8e42-cede2e5b11e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-6009ab1d-4f76-4bf6-a90e-2facdb0383b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480360448-172.17.0.13-1597211475772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-27060cb4-ddea-4d71-b6aa-c6964561b2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-5b8dc755-dd10-418b-addf-9a6e23fb33d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-7f1e24c3-fa1f-4bb3-9aff-03d22f760bab,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-62add217-b583-43ef-a413-a7661ce5f7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-f3a53ac1-ca2f-463d-b7a1-58f37d32adbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-da71774f-232d-4de8-a147-e5dbaff3748b,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-e154533f-23e8-433b-8e42-cede2e5b11e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-6009ab1d-4f76-4bf6-a90e-2facdb0383b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 128
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677626845-172.17.0.13-1597211541853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39463,DS-847b2c45-712a-44da-a3cc-b38d831e2d26,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-e4fc12f7-170d-4b73-96b8-122f3f6376df,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-826a9638-acaf-4bd6-a4c4-4fc8d4b0c3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-3bff0d1b-23de-48ac-a8d9-1934aaa9b808,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-5da75d50-043d-4c64-a39e-d853004509b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-b56767c7-a4af-419c-acab-35aa775521ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-690bb48a-3beb-4a1c-a760-ed8dd755e021,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-e26a258f-7e67-4dd9-82a3-aa6c7cd9368a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677626845-172.17.0.13-1597211541853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39463,DS-847b2c45-712a-44da-a3cc-b38d831e2d26,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-e4fc12f7-170d-4b73-96b8-122f3f6376df,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-826a9638-acaf-4bd6-a4c4-4fc8d4b0c3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-3bff0d1b-23de-48ac-a8d9-1934aaa9b808,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-5da75d50-043d-4c64-a39e-d853004509b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-b56767c7-a4af-419c-acab-35aa775521ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-690bb48a-3beb-4a1c-a760-ed8dd755e021,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-e26a258f-7e67-4dd9-82a3-aa6c7cd9368a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.blockreport.queue.size
component: hdfs:NameNode
v1: 128
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1425393051-172.17.0.13-1597211706024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42055,DS-6bfbc48b-b774-4ff8-b27a-e4dae76aa47b,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-d4ac10f1-35c2-433e-83c5-93ba91df40ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-c4600107-f08b-4abe-bca0-2cb4151fa9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-2b7a3703-e62b-4d6e-b1b6-0428ec86a470,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-b0863ea4-78f6-4ab0-86e3-9f998f4b06f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-27f2ed31-4bbe-4696-9add-9c80d847b856,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-bd8ba579-695e-4b66-9973-6064b6ba7994,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-62138b5d-a112-464f-afb1-92861a34effe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1425393051-172.17.0.13-1597211706024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42055,DS-6bfbc48b-b774-4ff8-b27a-e4dae76aa47b,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-d4ac10f1-35c2-433e-83c5-93ba91df40ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-c4600107-f08b-4abe-bca0-2cb4151fa9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-2b7a3703-e62b-4d6e-b1b6-0428ec86a470,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-b0863ea4-78f6-4ab0-86e3-9f998f4b06f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-27f2ed31-4bbe-4696-9add-9c80d847b856,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-bd8ba579-695e-4b66-9973-6064b6ba7994,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-62138b5d-a112-464f-afb1-92861a34effe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 2825
