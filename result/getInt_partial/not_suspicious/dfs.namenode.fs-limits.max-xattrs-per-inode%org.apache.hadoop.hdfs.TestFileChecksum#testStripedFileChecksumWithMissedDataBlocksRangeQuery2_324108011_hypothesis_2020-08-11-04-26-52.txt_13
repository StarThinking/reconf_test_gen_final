reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648283053-172.17.0.11-1597120397078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32970,DS-0ea2baad-476f-43e8-ad4d-f8a0b896ea95,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-bf898783-d80a-4d5b-9cb9-1a3cf476cf92,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-1482c40b-e7ce-48bd-a6b8-f7469f4aa132,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-bfb9c245-371b-4cc1-9cc6-c1e456cd9b67,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-38a7def2-c0fc-4038-ba55-c8e4203c4356,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-8af2a950-c1d8-47d5-ade1-bc22f8a53a71,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-3c9895a9-66fc-4a9c-8eb4-a95022d39136,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-0d84e685-48e1-4a44-bd37-5454276b0498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648283053-172.17.0.11-1597120397078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32970,DS-0ea2baad-476f-43e8-ad4d-f8a0b896ea95,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-bf898783-d80a-4d5b-9cb9-1a3cf476cf92,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-1482c40b-e7ce-48bd-a6b8-f7469f4aa132,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-bfb9c245-371b-4cc1-9cc6-c1e456cd9b67,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-38a7def2-c0fc-4038-ba55-c8e4203c4356,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-8af2a950-c1d8-47d5-ade1-bc22f8a53a71,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-3c9895a9-66fc-4a9c-8eb4-a95022d39136,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-0d84e685-48e1-4a44-bd37-5454276b0498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625639207-172.17.0.11-1597121029389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39556,DS-903dd7e8-60d9-44ff-8b3b-1aded65a9445,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-3fca5b37-a7a6-448c-b4d5-9408457e56f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-5e20d2b6-69a4-4b52-b4cd-d84449b0c2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-2888ca07-753d-47c7-8796-28f3f6fe30b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-55db2a57-5c99-46d7-906d-3f9abcbcf3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-6a8ef6b0-0218-47dd-8738-cbcdf061c0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-2c6db364-2f24-43e9-86a8-00a3f35d5afb,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-1fee403b-0c4f-42f8-a494-0508dcb521d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625639207-172.17.0.11-1597121029389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39556,DS-903dd7e8-60d9-44ff-8b3b-1aded65a9445,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-3fca5b37-a7a6-448c-b4d5-9408457e56f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-5e20d2b6-69a4-4b52-b4cd-d84449b0c2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-2888ca07-753d-47c7-8796-28f3f6fe30b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-55db2a57-5c99-46d7-906d-3f9abcbcf3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-6a8ef6b0-0218-47dd-8738-cbcdf061c0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-2c6db364-2f24-43e9-86a8-00a3f35d5afb,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-1fee403b-0c4f-42f8-a494-0508dcb521d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347975573-172.17.0.11-1597121128163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41441,DS-d0a84312-7bb3-4c80-affa-09d9a3e3ecf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-bc1440b6-36f5-4777-9b59-82be0064c6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-afe97d56-5ac4-4e2b-872c-ced51968c428,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-29d056b0-1128-475f-a5bf-86f79b6e93e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-c175819c-4752-4e31-b08c-2a43f2818105,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-f94afc94-5602-4725-8c88-92c5f7f3b306,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-6c6d6709-263a-475c-b4ea-8c65e23149ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-6db56a8d-a413-4dee-a84d-b7435c9423f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347975573-172.17.0.11-1597121128163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41441,DS-d0a84312-7bb3-4c80-affa-09d9a3e3ecf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-bc1440b6-36f5-4777-9b59-82be0064c6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-afe97d56-5ac4-4e2b-872c-ced51968c428,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-29d056b0-1128-475f-a5bf-86f79b6e93e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-c175819c-4752-4e31-b08c-2a43f2818105,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-f94afc94-5602-4725-8c88-92c5f7f3b306,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-6c6d6709-263a-475c-b4ea-8c65e23149ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-6db56a8d-a413-4dee-a84d-b7435c9423f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145504818-172.17.0.11-1597122027655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43676,DS-5a5b39e8-9a5f-4775-bc12-71d9aa42771b,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-b1ca4590-89b5-48df-a49b-e1550f5a5b46,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-a9d686bf-e7f4-4011-8dc3-512a84e25cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-afffe922-feda-42ea-83fb-df9754d92100,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-062db94b-1658-4df4-967b-6c5acc8b2943,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-9d4f88bf-2f96-4d32-852d-48a021dc6b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-77dde014-30e3-46ee-bac4-a749beb9c63d,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-12623ad1-3abd-41ae-b88d-260d13b6d994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145504818-172.17.0.11-1597122027655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43676,DS-5a5b39e8-9a5f-4775-bc12-71d9aa42771b,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-b1ca4590-89b5-48df-a49b-e1550f5a5b46,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-a9d686bf-e7f4-4011-8dc3-512a84e25cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-afffe922-feda-42ea-83fb-df9754d92100,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-062db94b-1658-4df4-967b-6c5acc8b2943,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-9d4f88bf-2f96-4d32-852d-48a021dc6b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-77dde014-30e3-46ee-bac4-a749beb9c63d,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-12623ad1-3abd-41ae-b88d-260d13b6d994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546240181-172.17.0.11-1597122630014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33495,DS-058c7363-b14a-40ff-a034-4a22e3c5220f,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-5274b9c3-0ed5-46de-abab-df7e18788cee,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-7bf0a1fb-358b-4b19-84ad-18e38f9ec7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-c7d4fe7c-d24b-40ca-b739-2feac7febe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-b50ff506-0127-4a1f-bf2a-5735c485fa75,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-da8501f8-a868-43c2-a6df-4ebf38bec919,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-94b7f985-7f6f-47cb-8dc5-18da7ded6c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-19de8488-2952-445f-842d-d845df7622a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546240181-172.17.0.11-1597122630014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33495,DS-058c7363-b14a-40ff-a034-4a22e3c5220f,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-5274b9c3-0ed5-46de-abab-df7e18788cee,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-7bf0a1fb-358b-4b19-84ad-18e38f9ec7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-c7d4fe7c-d24b-40ca-b739-2feac7febe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-b50ff506-0127-4a1f-bf2a-5735c485fa75,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-da8501f8-a868-43c2-a6df-4ebf38bec919,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-94b7f985-7f6f-47cb-8dc5-18da7ded6c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-19de8488-2952-445f-842d-d845df7622a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698771724-172.17.0.11-1597123218758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38716,DS-c7580490-aafd-42d3-989d-a53ba1b8eb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-1c219ba2-6330-4889-a0b4-983050dbefc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-ad3ab090-b9a4-42c3-ad59-43b4a155b141,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-6ab7bdfa-2082-4669-a1ae-945b7e52bf61,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-69c44acf-da29-41da-90c3-d6556a148976,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-310002d9-394b-4f91-a5d6-c6390e6d3227,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-e0d71bfc-ae07-4595-b26a-d6e19cd15cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-0372ef20-61e6-4a05-8dbe-7b374166511b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698771724-172.17.0.11-1597123218758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38716,DS-c7580490-aafd-42d3-989d-a53ba1b8eb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-1c219ba2-6330-4889-a0b4-983050dbefc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-ad3ab090-b9a4-42c3-ad59-43b4a155b141,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-6ab7bdfa-2082-4669-a1ae-945b7e52bf61,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-69c44acf-da29-41da-90c3-d6556a148976,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-310002d9-394b-4f91-a5d6-c6390e6d3227,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-e0d71bfc-ae07-4595-b26a-d6e19cd15cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-0372ef20-61e6-4a05-8dbe-7b374166511b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616603036-172.17.0.11-1597123408250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44659,DS-f93888aa-5ff9-4dcb-9bf3-045796e6abcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-581fd9d7-fb57-41af-9af0-e7a055437a04,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-4af85c9e-db85-4a11-8108-f219ea90e883,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-d6c34ff7-4330-4ad1-98a0-3ad1e2ced1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-96604ee9-c1c4-4603-a310-b1edd23d42e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-cad82075-b1e1-4d6b-a2d9-6c0a0dc135a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-e653df88-d94c-44d0-a8f0-3bde9d38f92e,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-05b8a584-1706-4e10-b75c-d56433e5e07b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616603036-172.17.0.11-1597123408250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44659,DS-f93888aa-5ff9-4dcb-9bf3-045796e6abcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-581fd9d7-fb57-41af-9af0-e7a055437a04,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-4af85c9e-db85-4a11-8108-f219ea90e883,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-d6c34ff7-4330-4ad1-98a0-3ad1e2ced1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-96604ee9-c1c4-4603-a310-b1edd23d42e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-cad82075-b1e1-4d6b-a2d9-6c0a0dc135a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-e653df88-d94c-44d0-a8f0-3bde9d38f92e,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-05b8a584-1706-4e10-b75c-d56433e5e07b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759064399-172.17.0.11-1597124101678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46722,DS-aaa5b7cb-4503-44a5-b75e-bb6f10c169f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-f1eb1fdc-97c5-46b8-8c23-03b029a3a8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-33775a63-118a-478c-a60e-ab7720ed683e,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-d9181e1e-21ca-4c23-b79c-e2029d07573d,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-a4333ad0-d40e-4add-a30d-d82bb3972efe,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-fba5581d-43f9-4315-850b-8d1113ee819d,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-9e2c26ff-4039-4b8a-8b18-1ebca78775ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-2031e66b-4008-4372-af9c-32e48b9f747a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759064399-172.17.0.11-1597124101678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46722,DS-aaa5b7cb-4503-44a5-b75e-bb6f10c169f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-f1eb1fdc-97c5-46b8-8c23-03b029a3a8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-33775a63-118a-478c-a60e-ab7720ed683e,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-d9181e1e-21ca-4c23-b79c-e2029d07573d,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-a4333ad0-d40e-4add-a30d-d82bb3972efe,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-fba5581d-43f9-4315-850b-8d1113ee819d,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-9e2c26ff-4039-4b8a-8b18-1ebca78775ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-2031e66b-4008-4372-af9c-32e48b9f747a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959631454-172.17.0.11-1597124570433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-0715b9db-defd-4c6a-aa05-7b38ded842ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-a658dc71-2837-4a5e-84a8-6d9e74f15c51,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-55015928-5ff7-4cff-a7c2-06397a4f4990,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-4331777c-b4ea-45f7-93d9-4fbaaa4db054,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-d92dedca-253a-4a88-ad4b-7730f557447c,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-025f16b5-4648-463a-a4b9-beb77ee4eaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-2fd41748-d835-4ff0-bdef-efd853d1574a,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-c8c2be35-d951-452f-824e-bc1dc9f19869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959631454-172.17.0.11-1597124570433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-0715b9db-defd-4c6a-aa05-7b38ded842ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-a658dc71-2837-4a5e-84a8-6d9e74f15c51,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-55015928-5ff7-4cff-a7c2-06397a4f4990,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-4331777c-b4ea-45f7-93d9-4fbaaa4db054,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-d92dedca-253a-4a88-ad4b-7730f557447c,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-025f16b5-4648-463a-a4b9-beb77ee4eaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-2fd41748-d835-4ff0-bdef-efd853d1574a,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-c8c2be35-d951-452f-824e-bc1dc9f19869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735034235-172.17.0.11-1597124671140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45603,DS-d1584f7a-6ef2-44c4-9b6c-d68555511f65,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-b6a70b81-4232-4171-90dc-4b1ce8d78651,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-d81b4e93-eb5c-4467-88a5-3fa9dafc4ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-7099b49e-5b7c-499f-8084-b525d2838121,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-a82038a3-cb76-4612-ba99-7705c3c36934,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-d09c661e-a2f5-4450-bd66-279aa1bfd92c,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-6aeb9a13-83ca-4c72-9d95-5c943bf65619,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-cf6a0221-521b-4db9-9d98-559556cdb8f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735034235-172.17.0.11-1597124671140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45603,DS-d1584f7a-6ef2-44c4-9b6c-d68555511f65,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-b6a70b81-4232-4171-90dc-4b1ce8d78651,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-d81b4e93-eb5c-4467-88a5-3fa9dafc4ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-7099b49e-5b7c-499f-8084-b525d2838121,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-a82038a3-cb76-4612-ba99-7705c3c36934,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-d09c661e-a2f5-4450-bd66-279aa1bfd92c,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-6aeb9a13-83ca-4c72-9d95-5c943bf65619,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-cf6a0221-521b-4db9-9d98-559556cdb8f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977753733-172.17.0.11-1597124730321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34830,DS-842c4042-700e-46c5-baa1-a2c077169fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-fcab731b-3db2-4893-8160-33f2f5c8f7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-62f2a915-8343-40dd-a0a8-e95a91d9d0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-f3e8efac-21ee-4011-8bf7-6adeeee0e37d,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-800ed25a-481b-4a62-8ef8-4675798e77d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-396036ae-41ba-426d-8b21-6ed81cfe2a38,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-9d768568-5c84-45f0-960d-554721f60710,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-07f470ae-a861-45cf-8ae8-02f371901d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977753733-172.17.0.11-1597124730321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34830,DS-842c4042-700e-46c5-baa1-a2c077169fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-fcab731b-3db2-4893-8160-33f2f5c8f7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-62f2a915-8343-40dd-a0a8-e95a91d9d0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-f3e8efac-21ee-4011-8bf7-6adeeee0e37d,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-800ed25a-481b-4a62-8ef8-4675798e77d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-396036ae-41ba-426d-8b21-6ed81cfe2a38,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-9d768568-5c84-45f0-960d-554721f60710,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-07f470ae-a861-45cf-8ae8-02f371901d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5044
