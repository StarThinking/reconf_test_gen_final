reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108735580-172.17.0.17-1597126177440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45931,DS-127ad5fa-b94f-4222-8f97-e49141a7d640,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-13b3662d-5a4c-4443-a76d-5431e82442c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-4b307b8b-46a7-4500-b264-d3d601b908a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-7b23a448-b659-4b60-a0cf-dd923767a753,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-64e037a9-b1e7-45cb-a74e-6f758eb32cae,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-19ad93c8-4057-4e31-9c6c-13897c2c191f,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-70d61e5c-2507-4869-8d21-1223f6aae89b,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-99be0de7-04f2-4126-8ad5-5fcf1066291e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108735580-172.17.0.17-1597126177440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45931,DS-127ad5fa-b94f-4222-8f97-e49141a7d640,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-13b3662d-5a4c-4443-a76d-5431e82442c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-4b307b8b-46a7-4500-b264-d3d601b908a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-7b23a448-b659-4b60-a0cf-dd923767a753,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-64e037a9-b1e7-45cb-a74e-6f758eb32cae,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-19ad93c8-4057-4e31-9c6c-13897c2c191f,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-70d61e5c-2507-4869-8d21-1223f6aae89b,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-99be0de7-04f2-4126-8ad5-5fcf1066291e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400471179-172.17.0.17-1597126506802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38758,DS-0c445af2-c61e-421c-a80f-6edd17f8bc40,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-01a4edb3-46e1-4588-ad36-0f7e7136df2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-4d907ad1-25e8-44cb-a12e-8079d03589f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-9febdf19-45c7-4c39-b8c6-99dcdb794404,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-77295658-09fa-437e-a7c0-d5a6c6201c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-9742a330-fda8-406e-8387-6d686fdc996d,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-f6838b26-5a0a-4093-93cd-19d4d18423cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-fb57a839-c1f6-4fe7-8d06-c2d28b9657b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400471179-172.17.0.17-1597126506802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38758,DS-0c445af2-c61e-421c-a80f-6edd17f8bc40,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-01a4edb3-46e1-4588-ad36-0f7e7136df2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-4d907ad1-25e8-44cb-a12e-8079d03589f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-9febdf19-45c7-4c39-b8c6-99dcdb794404,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-77295658-09fa-437e-a7c0-d5a6c6201c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-9742a330-fda8-406e-8387-6d686fdc996d,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-f6838b26-5a0a-4093-93cd-19d4d18423cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-fb57a839-c1f6-4fe7-8d06-c2d28b9657b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287401376-172.17.0.17-1597126949362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36327,DS-63a1114c-8c05-445d-a7a2-0524aed6941a,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-d7d3df61-e363-48bf-80c2-fe0bd0730a45,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-67557be0-a338-494b-be7f-a7938cdee59c,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-cd73f965-185f-4ad1-b0ba-b2dd2ce95d22,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-bb75d715-b325-4a45-a0e9-079e7be8d11d,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-d8691881-c138-4112-8375-c0e1e3c67749,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-709b66f1-61ae-4bce-845c-8355495e36c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-b70ccdc7-ad60-4c96-9260-2fbf9eb7d501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287401376-172.17.0.17-1597126949362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36327,DS-63a1114c-8c05-445d-a7a2-0524aed6941a,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-d7d3df61-e363-48bf-80c2-fe0bd0730a45,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-67557be0-a338-494b-be7f-a7938cdee59c,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-cd73f965-185f-4ad1-b0ba-b2dd2ce95d22,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-bb75d715-b325-4a45-a0e9-079e7be8d11d,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-d8691881-c138-4112-8375-c0e1e3c67749,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-709b66f1-61ae-4bce-845c-8355495e36c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-b70ccdc7-ad60-4c96-9260-2fbf9eb7d501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026549291-172.17.0.17-1597127025982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34178,DS-b7849776-4134-46d5-bee4-36ab90f93b01,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-c0711be9-200f-4275-a644-98e96f52c98f,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-12800468-fd66-4f25-ab80-1284c4ffa302,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-01256598-4192-4a88-aea3-665c6c7964f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-e38e0d56-0446-4be7-a472-36edb42f94d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-b4e487f2-c41d-4db6-bd0e-76bf73ee0ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-3e2dcf34-c8aa-4ee3-91e0-4d7e3cd9936c,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-45a000f2-af31-4b3c-aaf8-0d65cbf1dcb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026549291-172.17.0.17-1597127025982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34178,DS-b7849776-4134-46d5-bee4-36ab90f93b01,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-c0711be9-200f-4275-a644-98e96f52c98f,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-12800468-fd66-4f25-ab80-1284c4ffa302,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-01256598-4192-4a88-aea3-665c6c7964f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-e38e0d56-0446-4be7-a472-36edb42f94d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-b4e487f2-c41d-4db6-bd0e-76bf73ee0ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-3e2dcf34-c8aa-4ee3-91e0-4d7e3cd9936c,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-45a000f2-af31-4b3c-aaf8-0d65cbf1dcb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275355012-172.17.0.17-1597127126354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35123,DS-f8f43802-2bc3-4ffa-8acc-42f7c49a850d,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-c9ef3bff-be69-4b9e-8df8-d9a2fcf50d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-0717213d-c14b-44b4-bca9-ba27dd97183c,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-c20a1d81-2664-4223-8b92-414e24c2c4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-e75638b0-6b21-453d-ac04-1bc12e5623aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-24a4aa7e-cc71-49c0-941d-62c906a8a5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-d44b2fdd-ec62-4622-85b3-d17812f44487,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-407b9dce-7d36-4972-ada9-71cd338ec69a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275355012-172.17.0.17-1597127126354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35123,DS-f8f43802-2bc3-4ffa-8acc-42f7c49a850d,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-c9ef3bff-be69-4b9e-8df8-d9a2fcf50d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-0717213d-c14b-44b4-bca9-ba27dd97183c,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-c20a1d81-2664-4223-8b92-414e24c2c4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-e75638b0-6b21-453d-ac04-1bc12e5623aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-24a4aa7e-cc71-49c0-941d-62c906a8a5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-d44b2fdd-ec62-4622-85b3-d17812f44487,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-407b9dce-7d36-4972-ada9-71cd338ec69a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067213810-172.17.0.17-1597127447134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38829,DS-0e91131c-8e92-4553-8e29-bc0058eafb88,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-3d4b58b7-1acd-46d3-b040-06876e37356c,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-420b7e29-c856-49bd-a91e-778a0f91187c,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-73680e9b-e187-46e5-b14e-d525a2727654,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-2a292f7d-1839-4569-8c9c-89618678a3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-5f2f18de-03b4-4952-aadb-15022e0222c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-e9e87b26-9ebf-4446-bf9d-8ce45138ebd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-5a9a9baf-c75c-481b-b890-03c52f118e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067213810-172.17.0.17-1597127447134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38829,DS-0e91131c-8e92-4553-8e29-bc0058eafb88,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-3d4b58b7-1acd-46d3-b040-06876e37356c,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-420b7e29-c856-49bd-a91e-778a0f91187c,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-73680e9b-e187-46e5-b14e-d525a2727654,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-2a292f7d-1839-4569-8c9c-89618678a3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-5f2f18de-03b4-4952-aadb-15022e0222c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-e9e87b26-9ebf-4446-bf9d-8ce45138ebd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-5a9a9baf-c75c-481b-b890-03c52f118e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251859277-172.17.0.17-1597128359537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36895,DS-b883494c-6023-4b41-adb1-41d8f2da5200,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-56196cad-b253-4856-8e94-fb8d2a8a7f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-673db46b-4524-4243-ab3b-1479b5f131ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-8b1aeab8-e696-46de-87c5-648b6b72cdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-326759c3-2516-4a88-849d-8d1a0581970f,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-ae2e0560-da1f-4021-ad7f-c97f4035d8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-0b69793a-9797-4a46-b267-8e67755321b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-d5ca834a-1abc-4857-89fc-b130619f9b63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251859277-172.17.0.17-1597128359537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36895,DS-b883494c-6023-4b41-adb1-41d8f2da5200,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-56196cad-b253-4856-8e94-fb8d2a8a7f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-673db46b-4524-4243-ab3b-1479b5f131ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-8b1aeab8-e696-46de-87c5-648b6b72cdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-326759c3-2516-4a88-849d-8d1a0581970f,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-ae2e0560-da1f-4021-ad7f-c97f4035d8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-0b69793a-9797-4a46-b267-8e67755321b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-d5ca834a-1abc-4857-89fc-b130619f9b63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781441003-172.17.0.17-1597128627619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46086,DS-abe87965-c56e-4281-b73b-ee5e2221b99b,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-ae1fd2ff-56cd-4a77-aefc-26c2dccb2039,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-d29b6682-5b7b-4632-82a3-6ef76d1715ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-aa4afc9b-eb04-4556-bdf7-3849aac7bd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-407c61d5-9eca-4c98-8f5f-6b10901de62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-1f53364d-742c-478d-8664-30ff7a21914b,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-837c944d-525c-40b7-9793-5db72b24d7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-f7104ff4-76be-4fc6-80b9-32fca78436f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781441003-172.17.0.17-1597128627619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46086,DS-abe87965-c56e-4281-b73b-ee5e2221b99b,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-ae1fd2ff-56cd-4a77-aefc-26c2dccb2039,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-d29b6682-5b7b-4632-82a3-6ef76d1715ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-aa4afc9b-eb04-4556-bdf7-3849aac7bd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-407c61d5-9eca-4c98-8f5f-6b10901de62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-1f53364d-742c-478d-8664-30ff7a21914b,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-837c944d-525c-40b7-9793-5db72b24d7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-f7104ff4-76be-4fc6-80b9-32fca78436f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594104562-172.17.0.17-1597129371758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40123,DS-8c34e22d-b33e-40f3-98d0-3a9f1800afac,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-1eeca619-290c-464f-ac5e-8f9040104e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-d1cee30f-d031-41eb-9ac8-a8e92ba8bbae,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-5cc89348-3503-4355-93aa-819c6bed4838,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-00602547-74a8-487e-8ab2-f6c0207a08cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-104ab7e0-5c5a-4fba-85a3-fb6ad2266e11,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-bb47da54-5dae-4354-9414-b70f84f6497d,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-019c6f46-3798-4ab4-b9dd-7c0447a6884f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594104562-172.17.0.17-1597129371758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40123,DS-8c34e22d-b33e-40f3-98d0-3a9f1800afac,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-1eeca619-290c-464f-ac5e-8f9040104e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-d1cee30f-d031-41eb-9ac8-a8e92ba8bbae,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-5cc89348-3503-4355-93aa-819c6bed4838,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-00602547-74a8-487e-8ab2-f6c0207a08cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-104ab7e0-5c5a-4fba-85a3-fb6ad2266e11,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-bb47da54-5dae-4354-9414-b70f84f6497d,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-019c6f46-3798-4ab4-b9dd-7c0447a6884f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043737969-172.17.0.17-1597129902424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41112,DS-0f0bb097-9eb8-487a-8bc2-6ae924401225,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-fb31e6c5-cc93-4fb6-be51-14719e828791,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-85fad821-6b0a-43c6-8c9a-f76a38937442,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-709f1921-c36a-4594-8998-c2ef55e25aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-3746b746-9c35-4b1d-9f9e-42af5381e490,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-b557f697-b813-4191-b5de-68bbaac8427e,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-89e40e32-c629-4502-9c6b-b4bc03a579d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-08c9a88c-cc58-4fe9-9c30-7bb66fe6ff53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043737969-172.17.0.17-1597129902424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41112,DS-0f0bb097-9eb8-487a-8bc2-6ae924401225,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-fb31e6c5-cc93-4fb6-be51-14719e828791,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-85fad821-6b0a-43c6-8c9a-f76a38937442,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-709f1921-c36a-4594-8998-c2ef55e25aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-3746b746-9c35-4b1d-9f9e-42af5381e490,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-b557f697-b813-4191-b5de-68bbaac8427e,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-89e40e32-c629-4502-9c6b-b4bc03a579d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-08c9a88c-cc58-4fe9-9c30-7bb66fe6ff53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673566281-172.17.0.17-1597130257219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42074,DS-37038949-4e16-46b9-8743-24e97b899df3,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-e878b0ef-924f-4d70-a6c7-607f73c6e643,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-65a9ee66-cc10-40e6-8a70-10607f071713,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-7ad20ce5-83f0-4973-9310-6cf46bebbbce,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-84d4ac94-6ace-4456-87dc-7a60063be9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-0491e9dc-067b-4f64-bc26-fc382a83f5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-b78d6fd4-0869-49a4-ae85-27efe994ebbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-2a8517b4-77a1-4e47-bc0c-f4732710a07f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673566281-172.17.0.17-1597130257219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42074,DS-37038949-4e16-46b9-8743-24e97b899df3,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-e878b0ef-924f-4d70-a6c7-607f73c6e643,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-65a9ee66-cc10-40e6-8a70-10607f071713,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-7ad20ce5-83f0-4973-9310-6cf46bebbbce,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-84d4ac94-6ace-4456-87dc-7a60063be9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-0491e9dc-067b-4f64-bc26-fc382a83f5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-b78d6fd4-0869-49a4-ae85-27efe994ebbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-2a8517b4-77a1-4e47-bc0c-f4732710a07f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5160
