reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-825038705-172.17.0.3-1598129799332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43255,DS-ae9ecaf1-2998-45cf-aa14-0d0369d91b18,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-24056cdb-51ff-4b1e-96d9-bb3b3f404a21,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-6e2d80f3-a70a-475d-bb84-3ddc02d091cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-7c0465f1-18e8-411e-83a9-b32887d2d9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-498a665d-13c0-41e8-aef3-586fee5be772,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-b6681197-39aa-4f1f-bac5-b9c984f00a92,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-2a9d5b97-7351-40d6-80b5-41ec6af9f1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-e68d60ca-bcbf-4470-b27e-89ca02a7bc28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-825038705-172.17.0.3-1598129799332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43255,DS-ae9ecaf1-2998-45cf-aa14-0d0369d91b18,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-24056cdb-51ff-4b1e-96d9-bb3b3f404a21,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-6e2d80f3-a70a-475d-bb84-3ddc02d091cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-7c0465f1-18e8-411e-83a9-b32887d2d9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-498a665d-13c0-41e8-aef3-586fee5be772,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-b6681197-39aa-4f1f-bac5-b9c984f00a92,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-2a9d5b97-7351-40d6-80b5-41ec6af9f1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-e68d60ca-bcbf-4470-b27e-89ca02a7bc28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069687557-172.17.0.3-1598129859855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40858,DS-ca4b93ef-568e-49dd-91ba-5b08e16144bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-6eeb80b8-391f-46ab-8aad-dd938e78bbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-304d6b3f-58b5-4296-8448-ea14e1430666,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-ee552216-f29d-4b9e-a7e0-b4eb54811180,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-5ea4cc7a-d1b1-4b06-9570-d7f28836cfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-20eae44c-d244-4a5b-b8cd-4e8016340a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-268f2fa5-142b-4711-b096-1614989908a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-5582bca9-d7b4-41ae-8db2-51d67cf19a9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069687557-172.17.0.3-1598129859855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40858,DS-ca4b93ef-568e-49dd-91ba-5b08e16144bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-6eeb80b8-391f-46ab-8aad-dd938e78bbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-304d6b3f-58b5-4296-8448-ea14e1430666,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-ee552216-f29d-4b9e-a7e0-b4eb54811180,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-5ea4cc7a-d1b1-4b06-9570-d7f28836cfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-20eae44c-d244-4a5b-b8cd-4e8016340a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-268f2fa5-142b-4711-b096-1614989908a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-5582bca9-d7b4-41ae-8db2-51d67cf19a9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1898116058-172.17.0.3-1598129897119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38489,DS-ec086c84-816d-4900-87f0-1dd1e6dcd5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-4c4df62c-932b-44fb-8283-b75e90c52e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-590adc1f-f9dd-4c25-950c-1bf9b04fe63a,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-b372b289-c11d-45ba-bae9-95e72e5df7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-94d039e6-688b-487c-ac9c-e6f9b8f085fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-1284e46b-e08a-456e-b55a-82bb0504d9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-2c09bbbc-9d4d-4260-bd3c-227e43199d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-305552fc-58ce-41da-8f68-0b9bd3bd4530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1898116058-172.17.0.3-1598129897119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38489,DS-ec086c84-816d-4900-87f0-1dd1e6dcd5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-4c4df62c-932b-44fb-8283-b75e90c52e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-590adc1f-f9dd-4c25-950c-1bf9b04fe63a,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-b372b289-c11d-45ba-bae9-95e72e5df7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-94d039e6-688b-487c-ac9c-e6f9b8f085fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-1284e46b-e08a-456e-b55a-82bb0504d9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-2c09bbbc-9d4d-4260-bd3c-227e43199d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-305552fc-58ce-41da-8f68-0b9bd3bd4530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-734196366-172.17.0.3-1598130619681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38211,DS-49d73500-b7a7-4fcb-81e0-1c740d8ee6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-9c1e87ef-abb6-4e96-ae1b-e25fee09821b,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-1d8a4983-1429-4d6b-b1a4-a3895a4ee9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-42a72a67-e3d2-4de7-942f-379c45242f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-7990d8e6-a788-4731-98f9-d2199ead4e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-19cfbe1b-4f94-48e9-b70f-c1ff045df9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-c41b86a9-fe5e-4607-ac4c-6d2499502aba,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-896aa498-ffed-4bb8-b47b-bb85effeeb79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-734196366-172.17.0.3-1598130619681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38211,DS-49d73500-b7a7-4fcb-81e0-1c740d8ee6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-9c1e87ef-abb6-4e96-ae1b-e25fee09821b,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-1d8a4983-1429-4d6b-b1a4-a3895a4ee9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-42a72a67-e3d2-4de7-942f-379c45242f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-7990d8e6-a788-4731-98f9-d2199ead4e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-19cfbe1b-4f94-48e9-b70f-c1ff045df9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-c41b86a9-fe5e-4607-ac4c-6d2499502aba,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-896aa498-ffed-4bb8-b47b-bb85effeeb79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836518371-172.17.0.3-1598130889953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44429,DS-97c13090-6594-4bd6-a6d5-2d9376d786a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-c1eee15a-9c88-4cae-b031-9e56055dc908,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-27a71872-a094-4888-bc4d-f143e50a87af,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-7f9df251-8019-4be5-9468-0e964af57ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-f9834d6d-1b74-4c9e-b797-40bb1a4e6044,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-fabb1c36-0afc-4555-bb74-e8b833681043,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-cc3d2967-a9cc-4a3b-9cc0-aedbd5739bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-927f89da-625d-4506-a326-6d0251a70ec9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836518371-172.17.0.3-1598130889953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44429,DS-97c13090-6594-4bd6-a6d5-2d9376d786a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-c1eee15a-9c88-4cae-b031-9e56055dc908,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-27a71872-a094-4888-bc4d-f143e50a87af,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-7f9df251-8019-4be5-9468-0e964af57ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-f9834d6d-1b74-4c9e-b797-40bb1a4e6044,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-fabb1c36-0afc-4555-bb74-e8b833681043,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-cc3d2967-a9cc-4a3b-9cc0-aedbd5739bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-927f89da-625d-4506-a326-6d0251a70ec9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-922168194-172.17.0.3-1598130988860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-5a6cbe1f-181b-49d0-bd00-4593458ae6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-09aa1d84-0034-4baf-952b-8e3bb8206da5,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-7c1bde1e-2c20-438f-9f13-56357c5255ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-393c77a5-1857-4cf4-a365-ac4a20a7dd11,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-b2693e43-e5b2-4287-ae22-82da91982cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-9677213c-0505-485e-93be-68cb2b6ef94f,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-441ecef6-9e31-49d3-811e-cba6aec3242e,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-741cf2bc-cbb9-4ea1-9c27-150a24af779a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-922168194-172.17.0.3-1598130988860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-5a6cbe1f-181b-49d0-bd00-4593458ae6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-09aa1d84-0034-4baf-952b-8e3bb8206da5,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-7c1bde1e-2c20-438f-9f13-56357c5255ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-393c77a5-1857-4cf4-a365-ac4a20a7dd11,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-b2693e43-e5b2-4287-ae22-82da91982cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-9677213c-0505-485e-93be-68cb2b6ef94f,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-441ecef6-9e31-49d3-811e-cba6aec3242e,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-741cf2bc-cbb9-4ea1-9c27-150a24af779a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173349493-172.17.0.3-1598131020202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40180,DS-ce104185-b392-4df3-ba05-a497d81c4023,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-edbd1d72-0292-4402-a075-73371e0ff1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-cf29c34d-865c-462b-94c2-3e65167809cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-f6d337c3-0918-4dc5-83c1-e5d3abdd8ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-7f655257-91a4-457c-8710-c4161c792fff,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-a4c968d7-2d3c-46a8-9d31-536c88c393c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-0a120be5-e863-4b54-b39f-7e685399d2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-96225536-fada-4c01-a4bb-d0ee1925b64f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173349493-172.17.0.3-1598131020202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40180,DS-ce104185-b392-4df3-ba05-a497d81c4023,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-edbd1d72-0292-4402-a075-73371e0ff1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-cf29c34d-865c-462b-94c2-3e65167809cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-f6d337c3-0918-4dc5-83c1-e5d3abdd8ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-7f655257-91a4-457c-8710-c4161c792fff,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-a4c968d7-2d3c-46a8-9d31-536c88c393c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-0a120be5-e863-4b54-b39f-7e685399d2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-96225536-fada-4c01-a4bb-d0ee1925b64f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321655895-172.17.0.3-1598131098193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32781,DS-a985eca1-eebc-4ce1-9d64-a9095782b668,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-bd8bbb5f-23e4-4065-b1df-69a7d7fb6f18,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-afd330c4-d6b4-4936-9423-0f2408488c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-77b2a8f6-4fe9-4e62-b38b-a12a53d8db49,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-950f4b8a-5032-4a05-b121-b527087c1a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-04ff124b-7ba6-41f3-9aa8-2e2e65bd8abb,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-864e4cac-a019-425d-96aa-a44ce94eab6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-7727fcc0-9a61-472d-b610-47f510e91ab8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321655895-172.17.0.3-1598131098193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32781,DS-a985eca1-eebc-4ce1-9d64-a9095782b668,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-bd8bbb5f-23e4-4065-b1df-69a7d7fb6f18,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-afd330c4-d6b4-4936-9423-0f2408488c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-77b2a8f6-4fe9-4e62-b38b-a12a53d8db49,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-950f4b8a-5032-4a05-b121-b527087c1a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-04ff124b-7ba6-41f3-9aa8-2e2e65bd8abb,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-864e4cac-a019-425d-96aa-a44ce94eab6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-7727fcc0-9a61-472d-b610-47f510e91ab8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473873455-172.17.0.3-1598131510153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39841,DS-47c09df9-2fe1-4957-82c6-622d403d9239,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-eb7f64ae-64f9-46a1-a401-29b47af6b662,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-93d687f1-9492-4f40-849b-640d2e3abd80,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-0cd7360c-4720-4480-90b5-ba22ad939b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-2a1fe789-2eaf-4afe-9206-22beda12eca3,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-d9c48d96-6698-4810-9df3-785b5718b999,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-182fbb5b-54b5-4f01-bf39-d751c0b642cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-8712aee4-f39a-4ff1-af94-496191c2c185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473873455-172.17.0.3-1598131510153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39841,DS-47c09df9-2fe1-4957-82c6-622d403d9239,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-eb7f64ae-64f9-46a1-a401-29b47af6b662,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-93d687f1-9492-4f40-849b-640d2e3abd80,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-0cd7360c-4720-4480-90b5-ba22ad939b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-2a1fe789-2eaf-4afe-9206-22beda12eca3,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-d9c48d96-6698-4810-9df3-785b5718b999,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-182fbb5b-54b5-4f01-bf39-d751c0b642cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-8712aee4-f39a-4ff1-af94-496191c2c185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826427623-172.17.0.3-1598131838891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36064,DS-9397b7a0-4a9c-4409-9303-648bbac99812,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-8712034a-aa44-48c0-96c7-6ea227b012b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-5ff90e15-ec86-4f6b-a853-819ce9e6d7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-eafa89b5-a3fe-4654-a9b6-248f752d03b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-863c96da-85ca-43c1-b62e-df388c54b271,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-a79e88f8-0af0-4682-92e0-d1b84e7cf4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-ecd93eb4-040c-410f-b413-7f66027a1c50,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-dd6c4c6c-288e-4316-bc2e-bc571c83e73e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826427623-172.17.0.3-1598131838891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36064,DS-9397b7a0-4a9c-4409-9303-648bbac99812,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-8712034a-aa44-48c0-96c7-6ea227b012b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-5ff90e15-ec86-4f6b-a853-819ce9e6d7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-eafa89b5-a3fe-4654-a9b6-248f752d03b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-863c96da-85ca-43c1-b62e-df388c54b271,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-a79e88f8-0af0-4682-92e0-d1b84e7cf4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-ecd93eb4-040c-410f-b413-7f66027a1c50,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-dd6c4c6c-288e-4316-bc2e-bc571c83e73e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372870129-172.17.0.3-1598132369441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38989,DS-8c9ffdac-e5c7-403d-9338-93a4599be211,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-1f14e6ae-86b7-41f8-8509-481f12b2b02d,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-9b02b209-08e8-415b-ad12-268995c1b1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-844d0550-5123-4012-a993-f0946685fc18,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-9052907c-2546-4d3a-b409-2ad6d3ba7c73,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-5af24cc1-5ce9-4697-8cdc-2613f3bfcb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-248c1c9d-a5af-4ea7-a002-f15ee1c707a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-2c38dc6c-a3ca-4889-8d57-4e646699806e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372870129-172.17.0.3-1598132369441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38989,DS-8c9ffdac-e5c7-403d-9338-93a4599be211,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-1f14e6ae-86b7-41f8-8509-481f12b2b02d,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-9b02b209-08e8-415b-ad12-268995c1b1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-844d0550-5123-4012-a993-f0946685fc18,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-9052907c-2546-4d3a-b409-2ad6d3ba7c73,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-5af24cc1-5ce9-4697-8cdc-2613f3bfcb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-248c1c9d-a5af-4ea7-a002-f15ee1c707a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-2c38dc6c-a3ca-4889-8d57-4e646699806e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374043228-172.17.0.3-1598132657791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34384,DS-4c01518d-ae93-4865-af6c-ba9d0231b8de,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-6c968470-f4e4-4fe6-8267-f10f5dfdff1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-4934e968-e0d0-45e2-a778-35681250f4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-61b9ceac-436f-49fc-8bf8-bfd0b12a4de6,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-9905dad1-e406-480b-b987-9d9f72c11098,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-94b3d62c-9fcb-480d-9bfa-1b90552f6bec,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-8ab7be9c-b8f4-46f2-adaa-375acb86306e,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-ab80d47b-d80d-447e-956e-e3a50378c8bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374043228-172.17.0.3-1598132657791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34384,DS-4c01518d-ae93-4865-af6c-ba9d0231b8de,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-6c968470-f4e4-4fe6-8267-f10f5dfdff1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-4934e968-e0d0-45e2-a778-35681250f4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-61b9ceac-436f-49fc-8bf8-bfd0b12a4de6,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-9905dad1-e406-480b-b987-9d9f72c11098,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-94b3d62c-9fcb-480d-9bfa-1b90552f6bec,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-8ab7be9c-b8f4-46f2-adaa-375acb86306e,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-ab80d47b-d80d-447e-956e-e3a50378c8bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762108039-172.17.0.3-1598132954785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39762,DS-1d7f4e42-12f8-4fc2-b5f4-b9cf3978e618,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-d38b7749-2aa6-49c3-a59c-5ca273570497,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-13accfbc-d1be-4ed7-9621-5bde7c63424e,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-7e87d1c0-488e-431f-bb34-cd8b6897ae0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-6c7fe82e-a8ee-4a25-a1e3-e59203ce4f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-88a27985-221c-4c82-bd81-a58cece8f109,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-313063ec-af6b-4876-878a-6a3f62edc129,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-6810f8f9-ab88-47ad-83d3-5e0b0f8641b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1762108039-172.17.0.3-1598132954785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39762,DS-1d7f4e42-12f8-4fc2-b5f4-b9cf3978e618,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-d38b7749-2aa6-49c3-a59c-5ca273570497,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-13accfbc-d1be-4ed7-9621-5bde7c63424e,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-7e87d1c0-488e-431f-bb34-cd8b6897ae0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-6c7fe82e-a8ee-4a25-a1e3-e59203ce4f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-88a27985-221c-4c82-bd81-a58cece8f109,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-313063ec-af6b-4876-878a-6a3f62edc129,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-6810f8f9-ab88-47ad-83d3-5e0b0f8641b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619593130-172.17.0.3-1598134097097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44125,DS-a5a70e4d-ebe2-4177-aa83-eae04e83451d,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-d84781b9-e14d-4d47-9fc4-b1c65048fff9,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-f9e82ee2-d6c9-445d-a3e8-2eeab31d9bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-497373de-8073-4d66-8d23-c1be26b83283,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-3c8ce3c9-7283-4c8c-85de-51ddbea59d31,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-267489f2-16df-428e-996c-fcef545af0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-922af37b-d235-46a3-a34d-2578532e35f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-8230cdcd-19f5-4467-9a6a-2309c35cee48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619593130-172.17.0.3-1598134097097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44125,DS-a5a70e4d-ebe2-4177-aa83-eae04e83451d,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-d84781b9-e14d-4d47-9fc4-b1c65048fff9,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-f9e82ee2-d6c9-445d-a3e8-2eeab31d9bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-497373de-8073-4d66-8d23-c1be26b83283,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-3c8ce3c9-7283-4c8c-85de-51ddbea59d31,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-267489f2-16df-428e-996c-fcef545af0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-922af37b-d235-46a3-a34d-2578532e35f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-8230cdcd-19f5-4467-9a6a-2309c35cee48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 4936
