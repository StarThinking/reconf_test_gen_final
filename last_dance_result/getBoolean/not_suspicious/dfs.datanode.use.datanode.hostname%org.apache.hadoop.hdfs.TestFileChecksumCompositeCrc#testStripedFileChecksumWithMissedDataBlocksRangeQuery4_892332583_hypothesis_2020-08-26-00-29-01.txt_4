reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583923985-172.17.0.18-1598402076064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45966,DS-0e632c8d-7592-4b15-afeb-7468bc6ef32a,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-d3ad8534-29b2-49e6-b8a5-e64469b98c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-f64ad47c-450f-4b78-86a7-9a11b6488000,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-ec0e347b-4732-49e7-bcd0-d0e5ceb64a93,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-0d4406a8-a5c4-4ad6-83f5-f9ef82666c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-2d98aa84-de7e-4f06-86e4-095408c0dd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-22d392ee-1f21-4527-a4b9-1ba95581fd80,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-bfa1d7a2-ecaa-40d6-b255-7ab67d7a5c14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583923985-172.17.0.18-1598402076064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45966,DS-0e632c8d-7592-4b15-afeb-7468bc6ef32a,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-d3ad8534-29b2-49e6-b8a5-e64469b98c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-f64ad47c-450f-4b78-86a7-9a11b6488000,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-ec0e347b-4732-49e7-bcd0-d0e5ceb64a93,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-0d4406a8-a5c4-4ad6-83f5-f9ef82666c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-2d98aa84-de7e-4f06-86e4-095408c0dd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-22d392ee-1f21-4527-a4b9-1ba95581fd80,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-bfa1d7a2-ecaa-40d6-b255-7ab67d7a5c14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967220417-172.17.0.18-1598402344929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45353,DS-142c3acc-fc83-47dd-9fe5-b2dd8bd34284,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-cd9d0795-144f-49bc-bb81-14a5af5fdacf,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-a43b4a9e-250c-412b-a0e6-345125ff426a,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-6947724c-7fad-41ca-8b84-3a0f7e355d78,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-35b5a2e3-4316-4484-b6bb-ab53b3cc2fed,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-605e89b0-7b5a-4466-8289-71f28cc03b90,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-d9d4f08a-2a8c-4fd2-a643-79e0ffcc69f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-eaec1aa8-f2bd-4fcb-997e-fe01fd9e4ade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967220417-172.17.0.18-1598402344929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45353,DS-142c3acc-fc83-47dd-9fe5-b2dd8bd34284,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-cd9d0795-144f-49bc-bb81-14a5af5fdacf,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-a43b4a9e-250c-412b-a0e6-345125ff426a,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-6947724c-7fad-41ca-8b84-3a0f7e355d78,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-35b5a2e3-4316-4484-b6bb-ab53b3cc2fed,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-605e89b0-7b5a-4466-8289-71f28cc03b90,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-d9d4f08a-2a8c-4fd2-a643-79e0ffcc69f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-eaec1aa8-f2bd-4fcb-997e-fe01fd9e4ade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254082480-172.17.0.18-1598402600384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44261,DS-84c68ec9-8376-45f7-a6c3-25ac65420cef,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-36726f8c-ab9e-410f-8c86-a73b60f4f311,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-ed1a4420-04ec-427c-9465-d02baffe90c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-c22460b4-ddbc-449b-8686-8f54cb4ad006,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-a30d6f5b-e5c4-4b8f-a402-6e668ba0d50a,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-da294a87-ddda-4146-aeb3-e3429a58500a,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-c6ad09c7-ef19-4126-939d-49be43faca68,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-10bc1ecc-0b70-4143-897f-f3f3796f43c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254082480-172.17.0.18-1598402600384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44261,DS-84c68ec9-8376-45f7-a6c3-25ac65420cef,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-36726f8c-ab9e-410f-8c86-a73b60f4f311,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-ed1a4420-04ec-427c-9465-d02baffe90c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-c22460b4-ddbc-449b-8686-8f54cb4ad006,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-a30d6f5b-e5c4-4b8f-a402-6e668ba0d50a,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-da294a87-ddda-4146-aeb3-e3429a58500a,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-c6ad09c7-ef19-4126-939d-49be43faca68,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-10bc1ecc-0b70-4143-897f-f3f3796f43c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915687893-172.17.0.18-1598402633912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43736,DS-d8fcccdb-80aa-4fdb-9144-8ed4f398e668,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-7bc6871c-45b9-49f2-8d74-217d3a9440ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-72a92d2b-d58e-4d9e-9cc3-4e49b4402d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-52cf6063-bc0c-4ae4-b8fe-ec246b8d59f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-7abf7f07-9198-40c2-a130-e86d3f0b0ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-9ae8a288-8a54-4671-9568-b7f6a1e91ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-633b6717-a13a-4a72-a2a3-44ba367a04ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-55162e0c-407d-4b21-9260-be6b10fffeac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915687893-172.17.0.18-1598402633912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43736,DS-d8fcccdb-80aa-4fdb-9144-8ed4f398e668,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-7bc6871c-45b9-49f2-8d74-217d3a9440ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-72a92d2b-d58e-4d9e-9cc3-4e49b4402d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-52cf6063-bc0c-4ae4-b8fe-ec246b8d59f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-7abf7f07-9198-40c2-a130-e86d3f0b0ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-9ae8a288-8a54-4671-9568-b7f6a1e91ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-633b6717-a13a-4a72-a2a3-44ba367a04ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-55162e0c-407d-4b21-9260-be6b10fffeac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045036814-172.17.0.18-1598402665072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46061,DS-904d1392-7cf3-43c4-b33c-ce3f4f68fcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-a85fa7f0-a454-4dd4-96fa-4a3b5db982dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-b712365d-7bf8-4a6e-852f-667a3496da66,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-83539f30-d64c-46bf-b0ee-c8d58b46cf32,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-2a2f5061-1cfd-49b3-814b-9eb26d71afae,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-0f3dc1dc-4ef1-46a0-aec3-5a50b5a1c3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-ea2c3baf-6c56-4db4-b6b2-9053ede0cf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-0ad87ed6-1180-43fc-b5f3-24bf793155d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045036814-172.17.0.18-1598402665072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46061,DS-904d1392-7cf3-43c4-b33c-ce3f4f68fcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-a85fa7f0-a454-4dd4-96fa-4a3b5db982dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-b712365d-7bf8-4a6e-852f-667a3496da66,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-83539f30-d64c-46bf-b0ee-c8d58b46cf32,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-2a2f5061-1cfd-49b3-814b-9eb26d71afae,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-0f3dc1dc-4ef1-46a0-aec3-5a50b5a1c3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-ea2c3baf-6c56-4db4-b6b2-9053ede0cf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-0ad87ed6-1180-43fc-b5f3-24bf793155d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301021960-172.17.0.18-1598402977427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46347,DS-6ad53bdf-e270-47ae-a159-f3ab921e4293,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-b961f8ec-62d3-4906-a006-3a567fff8d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-ae88236e-132b-4ee8-b70a-2d0dbb6d7a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-df9e7d0d-9ac0-4498-b4b8-35dcd30875d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-20d758f6-2e1e-4994-8829-abdbc42f1dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-80c39e11-3fa1-46ad-b16e-5d1ca07532a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-a825575e-24b1-479d-8e50-cde8ab946829,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-e721cc52-b1b7-4cdc-aaad-67a5a3f32822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301021960-172.17.0.18-1598402977427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46347,DS-6ad53bdf-e270-47ae-a159-f3ab921e4293,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-b961f8ec-62d3-4906-a006-3a567fff8d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-ae88236e-132b-4ee8-b70a-2d0dbb6d7a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-df9e7d0d-9ac0-4498-b4b8-35dcd30875d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-20d758f6-2e1e-4994-8829-abdbc42f1dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-80c39e11-3fa1-46ad-b16e-5d1ca07532a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-a825575e-24b1-479d-8e50-cde8ab946829,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-e721cc52-b1b7-4cdc-aaad-67a5a3f32822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061058057-172.17.0.18-1598403118086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43407,DS-776249ac-c21f-4653-8cc6-0ca7137f1673,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-f915c0fe-d97f-4f0f-bd13-959950ce6868,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-593cd284-708c-45e3-aeda-4af6a1c377ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-f18fd21d-4a72-486c-829d-93d1f46c3e95,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-71689c3d-e7be-4117-958b-9eb30b00176f,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-35f84196-b401-4941-bfc3-13aa73651bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-5d964fc8-198a-4fac-8d24-1d2bf937e278,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-3350a432-fa3f-4d14-9b96-7cdbfb82e901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061058057-172.17.0.18-1598403118086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43407,DS-776249ac-c21f-4653-8cc6-0ca7137f1673,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-f915c0fe-d97f-4f0f-bd13-959950ce6868,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-593cd284-708c-45e3-aeda-4af6a1c377ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-f18fd21d-4a72-486c-829d-93d1f46c3e95,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-71689c3d-e7be-4117-958b-9eb30b00176f,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-35f84196-b401-4941-bfc3-13aa73651bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-5d964fc8-198a-4fac-8d24-1d2bf937e278,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-3350a432-fa3f-4d14-9b96-7cdbfb82e901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168836225-172.17.0.18-1598403414295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33000,DS-a6e43cd7-0b25-499c-8161-cbfe4be55f00,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-d311bf0c-e10e-4934-9105-c5930f58566a,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-7ebb1841-a477-43ef-a548-50ae891b7900,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-e8d8ebfc-a019-4017-b765-05f0c4d7d189,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-d4351faf-92a0-4a37-bf29-665e50473dba,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-753109b9-a91e-4305-a5b9-e431b8234ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-e0725b61-0968-4697-a82a-e008ee7c5925,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-dbb7bdde-e86e-4d06-9a81-39560063828b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168836225-172.17.0.18-1598403414295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33000,DS-a6e43cd7-0b25-499c-8161-cbfe4be55f00,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-d311bf0c-e10e-4934-9105-c5930f58566a,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-7ebb1841-a477-43ef-a548-50ae891b7900,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-e8d8ebfc-a019-4017-b765-05f0c4d7d189,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-d4351faf-92a0-4a37-bf29-665e50473dba,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-753109b9-a91e-4305-a5b9-e431b8234ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-e0725b61-0968-4697-a82a-e008ee7c5925,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-dbb7bdde-e86e-4d06-9a81-39560063828b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294570932-172.17.0.18-1598404352922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41103,DS-4eaa4559-871d-4fb8-9c5f-1dab1925c1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-ded41c56-3190-42d7-a0f9-c8728653c86c,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-0e2a4024-b76c-406d-9047-7fee5638cf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-56392df1-7534-4437-b72c-c16c29760f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-f3367c23-64e1-483c-8357-2ff6016d2783,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-0df007dc-5924-42b5-b728-a44ff9d373df,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-b0386f25-fcca-4f33-b645-74223e5ecd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-dec00c36-16fa-47c8-9b83-91aa01cada77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294570932-172.17.0.18-1598404352922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41103,DS-4eaa4559-871d-4fb8-9c5f-1dab1925c1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-ded41c56-3190-42d7-a0f9-c8728653c86c,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-0e2a4024-b76c-406d-9047-7fee5638cf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-56392df1-7534-4437-b72c-c16c29760f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-f3367c23-64e1-483c-8357-2ff6016d2783,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-0df007dc-5924-42b5-b728-a44ff9d373df,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-b0386f25-fcca-4f33-b645-74223e5ecd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-dec00c36-16fa-47c8-9b83-91aa01cada77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43393980-172.17.0.18-1598404740404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36998,DS-96b783c4-c4f3-4a4d-a983-a6abd3a83849,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-b87cb11a-3c9f-4c01-9b4f-039ab0049435,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-abea6f28-9fa6-440e-8c42-8568fb396797,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-9a68511d-d0f9-4d82-b53d-5cc9bea5eb98,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-03b7460c-5e2f-48d3-b62b-a78960cd9483,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-4a438b02-e214-4f77-9fda-77bcc892eb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-8571c97c-4054-4765-882b-3b97dda8fa04,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-58035303-6f08-4128-b682-e4c619e66f93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43393980-172.17.0.18-1598404740404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36998,DS-96b783c4-c4f3-4a4d-a983-a6abd3a83849,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-b87cb11a-3c9f-4c01-9b4f-039ab0049435,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-abea6f28-9fa6-440e-8c42-8568fb396797,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-9a68511d-d0f9-4d82-b53d-5cc9bea5eb98,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-03b7460c-5e2f-48d3-b62b-a78960cd9483,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-4a438b02-e214-4f77-9fda-77bcc892eb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-8571c97c-4054-4765-882b-3b97dda8fa04,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-58035303-6f08-4128-b682-e4c619e66f93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12498382-172.17.0.18-1598404920431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40416,DS-20d0d4fb-a1b1-47cd-9460-e33a8e5d4a63,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-663d7e3c-81f0-4c11-91ef-a4cfae99be54,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-1b33a5cd-d4b1-48a7-940a-0536b4450d49,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-dbaeda24-b791-47f1-bbb6-9d5155f18823,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-30521b91-0e3a-479b-a01e-a3998c4953ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-ae874bf2-f2fb-415f-94dc-248d240de9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-e8bd7cb5-8959-4107-a1e8-17da18f3839f,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-36e55269-c748-491e-9161-c1c621181e3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12498382-172.17.0.18-1598404920431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40416,DS-20d0d4fb-a1b1-47cd-9460-e33a8e5d4a63,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-663d7e3c-81f0-4c11-91ef-a4cfae99be54,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-1b33a5cd-d4b1-48a7-940a-0536b4450d49,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-dbaeda24-b791-47f1-bbb6-9d5155f18823,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-30521b91-0e3a-479b-a01e-a3998c4953ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-ae874bf2-f2fb-415f-94dc-248d240de9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-e8bd7cb5-8959-4107-a1e8-17da18f3839f,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-36e55269-c748-491e-9161-c1c621181e3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902043610-172.17.0.18-1598405121463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40389,DS-b3973312-8542-4b7c-a299-c92eb0c61a58,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-8b28c661-4b4d-4202-9567-2b7e7831a284,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-73aa4779-a890-4e3c-ac2c-07bdb7994450,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-f8e1bf31-ff8c-4d25-b4c6-f4268b6e4707,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-6324f4ce-83b9-4c22-a6b1-4114c25b9b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-e41ed974-a1b3-41a6-9c36-ccde04d86d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-eaffcbc7-5cad-4c42-ba74-dba7528a232e,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-e7b25220-e4ed-4f98-81d7-0ee6114ba9ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902043610-172.17.0.18-1598405121463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40389,DS-b3973312-8542-4b7c-a299-c92eb0c61a58,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-8b28c661-4b4d-4202-9567-2b7e7831a284,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-73aa4779-a890-4e3c-ac2c-07bdb7994450,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-f8e1bf31-ff8c-4d25-b4c6-f4268b6e4707,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-6324f4ce-83b9-4c22-a6b1-4114c25b9b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-e41ed974-a1b3-41a6-9c36-ccde04d86d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-eaffcbc7-5cad-4c42-ba74-dba7528a232e,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-e7b25220-e4ed-4f98-81d7-0ee6114ba9ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071315457-172.17.0.18-1598405308477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33382,DS-4af48193-fbad-49b2-ba7e-0c4f1a3a68bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-1e56dc5b-652c-48fa-88dc-ab0e59c82cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-2b1aa823-006f-4c5f-90f3-837e84b041b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-02a17bf3-0573-4430-8b4f-2b3b68698bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-87ebe6ad-4654-49cd-b00b-496b3c321e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-7adf0667-5355-4d7e-9567-60383b4216df,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-2ef564cb-8cbd-4ff7-8c5d-d665d0b66042,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-9a3c705a-4b6f-4af6-9dd1-f786f7c4070c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071315457-172.17.0.18-1598405308477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33382,DS-4af48193-fbad-49b2-ba7e-0c4f1a3a68bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-1e56dc5b-652c-48fa-88dc-ab0e59c82cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-2b1aa823-006f-4c5f-90f3-837e84b041b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-02a17bf3-0573-4430-8b4f-2b3b68698bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-87ebe6ad-4654-49cd-b00b-496b3c321e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-7adf0667-5355-4d7e-9567-60383b4216df,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-2ef564cb-8cbd-4ff7-8c5d-d665d0b66042,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-9a3c705a-4b6f-4af6-9dd1-f786f7c4070c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574673975-172.17.0.18-1598405383264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33053,DS-acad0017-ace8-4d1f-9a6f-208ae5521e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-36d4ad77-3e20-4e78-ba87-89319ad69377,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-8d3f29ec-071a-49fe-a6b5-64f298ce8ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-5bb93907-249f-46a8-ac8e-235887ce7e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-bb9e9cf7-54f9-491a-9a04-3430a60bb397,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-c8460163-f39c-4932-b97c-f6dc30aeb727,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-be4b557c-8c4b-44a9-bcdc-3b5d29130498,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-9e93b673-b2aa-418c-9d6b-0ccd7dd88c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574673975-172.17.0.18-1598405383264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33053,DS-acad0017-ace8-4d1f-9a6f-208ae5521e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-36d4ad77-3e20-4e78-ba87-89319ad69377,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-8d3f29ec-071a-49fe-a6b5-64f298ce8ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-5bb93907-249f-46a8-ac8e-235887ce7e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-bb9e9cf7-54f9-491a-9a04-3430a60bb397,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-c8460163-f39c-4932-b97c-f6dc30aeb727,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-be4b557c-8c4b-44a9-bcdc-3b5d29130498,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-9e93b673-b2aa-418c-9d6b-0ccd7dd88c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517962241-172.17.0.18-1598405725221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41888,DS-e9ff1384-89af-4e0b-a82b-d625110d95af,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-d48a99db-2766-494c-ba01-e7d64fa0d271,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-3bf776f4-c694-4b8c-b644-b2a0ce0d4a50,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-f08d4896-7194-4506-abc6-d072c61312ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-4ba1c0dc-6cf9-4a98-b40e-a64b5d7792cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-e23c24f8-7787-403e-a68b-d7c7a53d59a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-44306203-e21c-4294-9cec-488f1094ffe5,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-b3ed8885-7263-4269-9e96-4ab9e9143dd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517962241-172.17.0.18-1598405725221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41888,DS-e9ff1384-89af-4e0b-a82b-d625110d95af,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-d48a99db-2766-494c-ba01-e7d64fa0d271,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-3bf776f4-c694-4b8c-b644-b2a0ce0d4a50,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-f08d4896-7194-4506-abc6-d072c61312ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-4ba1c0dc-6cf9-4a98-b40e-a64b5d7792cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-e23c24f8-7787-403e-a68b-d7c7a53d59a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-44306203-e21c-4294-9cec-488f1094ffe5,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-b3ed8885-7263-4269-9e96-4ab9e9143dd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769817160-172.17.0.18-1598405756290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43618,DS-e562a265-3cde-4595-b5ad-a12b47b93fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-12722c9b-261e-4e38-8323-d1246cd06607,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-6de0f155-5096-4642-b8c1-0d8bac9f5e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-360c09c1-0d62-41bd-b5ba-7bc21b82e05f,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-4dab9d8b-f932-4cc2-b697-f0da7b15da8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-109b8934-1d7b-47bf-b1da-7aae8e370f79,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-90884f0d-6475-47d8-895c-59ff7802a92b,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-4fbe4dfb-137d-4021-a9e5-bd8dff0a17d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769817160-172.17.0.18-1598405756290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43618,DS-e562a265-3cde-4595-b5ad-a12b47b93fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-12722c9b-261e-4e38-8323-d1246cd06607,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-6de0f155-5096-4642-b8c1-0d8bac9f5e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-360c09c1-0d62-41bd-b5ba-7bc21b82e05f,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-4dab9d8b-f932-4cc2-b697-f0da7b15da8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-109b8934-1d7b-47bf-b1da-7aae8e370f79,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-90884f0d-6475-47d8-895c-59ff7802a92b,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-4fbe4dfb-137d-4021-a9e5-bd8dff0a17d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446576635-172.17.0.18-1598405795135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43032,DS-8fa1de2f-225d-4c0c-9869-2352814b90be,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-52403e9b-6ba6-4db9-a494-1592414e165d,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-ad54679d-2249-4334-81df-9a3effd2577e,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-03f81613-0dff-4727-a9f5-03c189b32ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-22ffd774-7390-482a-96c7-615b39076382,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-93020bad-a0f2-4f28-a295-4e545b54acae,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-967c5f81-4843-4dd0-babb-63922c3bc4db,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-aa175003-ec12-4a51-bd02-6617cb0b65cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446576635-172.17.0.18-1598405795135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43032,DS-8fa1de2f-225d-4c0c-9869-2352814b90be,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-52403e9b-6ba6-4db9-a494-1592414e165d,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-ad54679d-2249-4334-81df-9a3effd2577e,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-03f81613-0dff-4727-a9f5-03c189b32ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-22ffd774-7390-482a-96c7-615b39076382,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-93020bad-a0f2-4f28-a295-4e545b54acae,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-967c5f81-4843-4dd0-babb-63922c3bc4db,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-aa175003-ec12-4a51-bd02-6617cb0b65cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477529420-172.17.0.18-1598406234353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41865,DS-d4baaf39-e7ed-426e-8c76-e718bef28ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-c79d205e-2bf1-45ec-aaa5-fc20cf51fe68,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-bfd3ebce-392a-4ffb-9c07-753a09f3e822,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-cfd7539f-cb5c-4175-8fa6-a22986117deb,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-a3f76e22-7897-4b7f-a6fd-c154a7db1176,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-4ee12fcb-6d82-4302-b769-047bad47137b,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-a2fd8d56-88b6-48e3-b036-9ed785f88771,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-6ca0daaa-8227-470d-94f0-699f14ecd388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477529420-172.17.0.18-1598406234353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41865,DS-d4baaf39-e7ed-426e-8c76-e718bef28ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-c79d205e-2bf1-45ec-aaa5-fc20cf51fe68,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-bfd3ebce-392a-4ffb-9c07-753a09f3e822,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-cfd7539f-cb5c-4175-8fa6-a22986117deb,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-a3f76e22-7897-4b7f-a6fd-c154a7db1176,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-4ee12fcb-6d82-4302-b769-047bad47137b,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-a2fd8d56-88b6-48e3-b036-9ed785f88771,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-6ca0daaa-8227-470d-94f0-699f14ecd388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754645574-172.17.0.18-1598406367013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37413,DS-bac3e852-9cdc-4d7a-aa1e-613c09b34dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-8248b63c-1b81-46b1-af88-8926f2bd4200,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-d4c51630-7b46-4891-ae0f-dcebcfca02eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-4cc6c368-248a-486d-adf4-109050a68e27,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-9974c214-3b9a-4cc9-a100-5d6e5bc0d793,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-cb299ebe-44c4-4cac-978b-e653734096e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-f74c1a1d-e450-4fa2-b0b2-daf849df37a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-377b1200-8f52-4923-b1c9-b7624e2d69bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754645574-172.17.0.18-1598406367013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37413,DS-bac3e852-9cdc-4d7a-aa1e-613c09b34dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-8248b63c-1b81-46b1-af88-8926f2bd4200,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-d4c51630-7b46-4891-ae0f-dcebcfca02eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-4cc6c368-248a-486d-adf4-109050a68e27,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-9974c214-3b9a-4cc9-a100-5d6e5bc0d793,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-cb299ebe-44c4-4cac-978b-e653734096e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-f74c1a1d-e450-4fa2-b0b2-daf849df37a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-377b1200-8f52-4923-b1c9-b7624e2d69bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841289511-172.17.0.18-1598406438996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42960,DS-f062d025-80a1-41a2-a0a6-bfba187f903e,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-212f31ce-85a7-485b-8f2a-c58f1beed0be,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-2ceaf694-528b-43d1-b006-69a94628b56f,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-973a8920-865b-49cd-997c-8e5789a138ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-a4425b6d-929f-479a-844b-b37e150ee283,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-a43958b6-554c-4a77-97d5-64783f9d4db8,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-c1719d61-5e7d-4c14-ba86-589e8e11ec03,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-91c718a9-119a-4f15-9f97-94339af3a5ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841289511-172.17.0.18-1598406438996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42960,DS-f062d025-80a1-41a2-a0a6-bfba187f903e,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-212f31ce-85a7-485b-8f2a-c58f1beed0be,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-2ceaf694-528b-43d1-b006-69a94628b56f,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-973a8920-865b-49cd-997c-8e5789a138ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-a4425b6d-929f-479a-844b-b37e150ee283,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-a43958b6-554c-4a77-97d5-64783f9d4db8,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-c1719d61-5e7d-4c14-ba86-589e8e11ec03,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-91c718a9-119a-4f15-9f97-94339af3a5ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457636470-172.17.0.18-1598406688625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42669,DS-1f093994-e451-45ba-a20d-69ae905dde0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-106ed9ea-aaca-4a68-b944-73ff665b890c,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-964be13c-9105-4811-a57a-899025589de9,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-192b2e6f-a846-4e38-953e-cb7e372992bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-7accbe28-2db5-4a24-a327-50d45adba44b,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-e93fc0a4-9f2d-4173-bc16-b4cbe7807e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-dfc8ef72-42c7-48fe-a65e-7bf9a8a67b11,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-8bb4ffcc-d2f5-424b-8255-6110a02c55d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457636470-172.17.0.18-1598406688625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42669,DS-1f093994-e451-45ba-a20d-69ae905dde0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-106ed9ea-aaca-4a68-b944-73ff665b890c,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-964be13c-9105-4811-a57a-899025589de9,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-192b2e6f-a846-4e38-953e-cb7e372992bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-7accbe28-2db5-4a24-a327-50d45adba44b,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-e93fc0a4-9f2d-4173-bc16-b4cbe7807e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-dfc8ef72-42c7-48fe-a65e-7bf9a8a67b11,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-8bb4ffcc-d2f5-424b-8255-6110a02c55d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5221
