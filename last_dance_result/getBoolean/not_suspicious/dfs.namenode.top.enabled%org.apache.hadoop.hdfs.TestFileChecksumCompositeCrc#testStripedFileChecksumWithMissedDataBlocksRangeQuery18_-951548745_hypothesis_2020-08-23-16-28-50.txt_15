reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-527647879-172.17.0.17-1598200321218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41352,DS-471692f5-064c-4f35-94f7-7e163a350c58,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-3c25c03b-1d79-4ee1-b8e8-40abc639f30e,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-c5980084-77f5-402e-8537-641fa8829bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-a6624fd4-5b2b-40e1-a0e4-83ddb9f35f34,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-2fab7146-191a-4b73-a973-88a51a57188b,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-dce08260-4e17-4310-bf8a-22e5bc9f0e55,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-c01be1f7-baf3-4d25-b84f-bdea0faef8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-32f02a3d-d042-4f03-8d75-dcbf52d0bbc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-527647879-172.17.0.17-1598200321218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41352,DS-471692f5-064c-4f35-94f7-7e163a350c58,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-3c25c03b-1d79-4ee1-b8e8-40abc639f30e,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-c5980084-77f5-402e-8537-641fa8829bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-a6624fd4-5b2b-40e1-a0e4-83ddb9f35f34,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-2fab7146-191a-4b73-a973-88a51a57188b,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-dce08260-4e17-4310-bf8a-22e5bc9f0e55,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-c01be1f7-baf3-4d25-b84f-bdea0faef8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-32f02a3d-d042-4f03-8d75-dcbf52d0bbc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483453952-172.17.0.17-1598200457329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37094,DS-cee73dae-c2b6-4830-9d2e-28f748f057cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-2599edd8-16f8-4b11-b624-56dcf3ef890f,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-12e76568-34c6-43c0-bbeb-3a49da981494,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-ed19bc2d-d76a-4581-a460-604b4686e16c,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-07f7baf6-5d32-4496-8bb0-b830e6260c52,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-370e97a3-2e8d-483b-9444-34cf71f817ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-272ee3d4-4fd4-4c36-bf33-ec6ccd884ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-4b2fb1c8-dcc9-401d-99df-10e7d8497ba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483453952-172.17.0.17-1598200457329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37094,DS-cee73dae-c2b6-4830-9d2e-28f748f057cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-2599edd8-16f8-4b11-b624-56dcf3ef890f,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-12e76568-34c6-43c0-bbeb-3a49da981494,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-ed19bc2d-d76a-4581-a460-604b4686e16c,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-07f7baf6-5d32-4496-8bb0-b830e6260c52,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-370e97a3-2e8d-483b-9444-34cf71f817ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-272ee3d4-4fd4-4c36-bf33-ec6ccd884ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-4b2fb1c8-dcc9-401d-99df-10e7d8497ba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-85415637-172.17.0.17-1598200571618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34634,DS-c8f6e60c-8888-4cc7-b718-c1827faf8437,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-8d2f5077-ba04-47de-8ff6-514b443b9489,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-a8de480a-ddfc-428a-885b-c719ced6831c,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-122e26ef-b81d-4803-bf8d-efb5085b300d,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-76c3b409-1d88-4f54-9fd4-f7ca4f1d65d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-fdc5fa3e-463a-4e36-9aa5-71bc66004bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-3e62ecd8-8314-4dbe-a779-3db2d1b2cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-fe31e4fa-0816-4dae-8d92-38c9bc0f35f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-85415637-172.17.0.17-1598200571618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34634,DS-c8f6e60c-8888-4cc7-b718-c1827faf8437,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-8d2f5077-ba04-47de-8ff6-514b443b9489,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-a8de480a-ddfc-428a-885b-c719ced6831c,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-122e26ef-b81d-4803-bf8d-efb5085b300d,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-76c3b409-1d88-4f54-9fd4-f7ca4f1d65d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-fdc5fa3e-463a-4e36-9aa5-71bc66004bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-3e62ecd8-8314-4dbe-a779-3db2d1b2cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-fe31e4fa-0816-4dae-8d92-38c9bc0f35f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504068396-172.17.0.17-1598200604789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40235,DS-efe87948-7169-430f-bc64-f209890ffdac,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-60fee04f-2dd8-45ad-b0c1-32f7caa796aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-573b09d8-7f27-4fd4-89d4-00c812a60f69,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-177179eb-a4ff-4a4d-a26f-69e1bdf309ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-299b5d70-05ab-45ce-b8ee-8ad838bc3c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-e6d54e9d-c449-41dd-857a-95a0c9561c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-69749ede-f06c-4df5-a23b-6dea3702242d,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-590bef62-9829-4dd3-9917-3c17973841f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504068396-172.17.0.17-1598200604789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40235,DS-efe87948-7169-430f-bc64-f209890ffdac,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-60fee04f-2dd8-45ad-b0c1-32f7caa796aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-573b09d8-7f27-4fd4-89d4-00c812a60f69,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-177179eb-a4ff-4a4d-a26f-69e1bdf309ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-299b5d70-05ab-45ce-b8ee-8ad838bc3c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-e6d54e9d-c449-41dd-857a-95a0c9561c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-69749ede-f06c-4df5-a23b-6dea3702242d,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-590bef62-9829-4dd3-9917-3c17973841f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-815676771-172.17.0.17-1598200686750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34870,DS-16dcdd4a-f88d-44ba-9b70-f9d4ea4c132e,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-78ef1e32-b851-4909-8b12-fb535a045b99,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-9c1ba6e5-00cb-4410-82a1-6a861177277c,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-d3d62705-3e7b-4b0e-a11a-9dd6078b6d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-6c2a8161-c9c1-4a87-adec-0f4c67179274,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-7db2358b-5e99-4103-b0e6-72a009ed2b14,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-926a20c6-c84c-4224-8c8e-a8f1ee64198e,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-115af41f-a7d2-4d1e-a760-9708319349a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-815676771-172.17.0.17-1598200686750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34870,DS-16dcdd4a-f88d-44ba-9b70-f9d4ea4c132e,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-78ef1e32-b851-4909-8b12-fb535a045b99,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-9c1ba6e5-00cb-4410-82a1-6a861177277c,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-d3d62705-3e7b-4b0e-a11a-9dd6078b6d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-6c2a8161-c9c1-4a87-adec-0f4c67179274,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-7db2358b-5e99-4103-b0e6-72a009ed2b14,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-926a20c6-c84c-4224-8c8e-a8f1ee64198e,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-115af41f-a7d2-4d1e-a760-9708319349a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1247399084-172.17.0.17-1598200719753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40869,DS-3991c55c-07f9-48da-9732-fe18231fd3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-eaae3843-3fd9-4916-b4cd-9b471bb4424f,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-322456c5-2863-4b27-9ac5-54007521e5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-99584cdc-2be8-428b-8af9-177d76309fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-c56a76b5-e506-424f-93cd-b58ae7287318,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-7e7788f3-f9bc-4e99-ab74-d64d7180d74d,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-0622e250-b93e-4aa2-ba8d-a9a31ad6c03f,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-89a4aae9-85a8-45d0-b781-449f7f5e4ec5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1247399084-172.17.0.17-1598200719753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40869,DS-3991c55c-07f9-48da-9732-fe18231fd3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-eaae3843-3fd9-4916-b4cd-9b471bb4424f,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-322456c5-2863-4b27-9ac5-54007521e5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-99584cdc-2be8-428b-8af9-177d76309fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-c56a76b5-e506-424f-93cd-b58ae7287318,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-7e7788f3-f9bc-4e99-ab74-d64d7180d74d,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-0622e250-b93e-4aa2-ba8d-a9a31ad6c03f,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-89a4aae9-85a8-45d0-b781-449f7f5e4ec5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-946861042-172.17.0.17-1598200801278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39594,DS-6ff1a563-e8e4-4101-9264-8c9176b10276,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-dcf2c189-9f17-48cb-b682-67a22b25f4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-abba8f34-fbf8-425e-8abc-7021749f7ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-9d0b888f-fbec-4f74-8446-9c871665cea0,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-2d39b114-c591-4081-be8c-5c9310ff6d85,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-4370f52c-ad8e-40af-8ea1-aa4df0b59a98,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-ec008655-217e-487b-b7ae-00d00e8d29a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-f1c1da29-69a6-4fc3-9b63-7a1d14523c4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-946861042-172.17.0.17-1598200801278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39594,DS-6ff1a563-e8e4-4101-9264-8c9176b10276,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-dcf2c189-9f17-48cb-b682-67a22b25f4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-abba8f34-fbf8-425e-8abc-7021749f7ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-9d0b888f-fbec-4f74-8446-9c871665cea0,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-2d39b114-c591-4081-be8c-5c9310ff6d85,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-4370f52c-ad8e-40af-8ea1-aa4df0b59a98,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-ec008655-217e-487b-b7ae-00d00e8d29a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-f1c1da29-69a6-4fc3-9b63-7a1d14523c4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199259560-172.17.0.17-1598201015474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36879,DS-cae5ea95-5568-4635-b8cb-988e9ea29d56,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-60bd8b7b-37cc-4603-9693-e7d10fbf99c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-dba64942-3f89-45da-9937-3be228fdcc97,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-c4ee7927-f6a4-4cf3-a70f-cb76e428b652,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-3aee7bb3-520c-4e28-a095-4fff58391794,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-02104189-fde3-4a9e-9b78-08ecd606ea7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-cedb40d3-0135-4081-add5-1dbae5b19acd,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-477ef466-b4d9-48e4-a302-2471654bb91a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199259560-172.17.0.17-1598201015474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36879,DS-cae5ea95-5568-4635-b8cb-988e9ea29d56,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-60bd8b7b-37cc-4603-9693-e7d10fbf99c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-dba64942-3f89-45da-9937-3be228fdcc97,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-c4ee7927-f6a4-4cf3-a70f-cb76e428b652,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-3aee7bb3-520c-4e28-a095-4fff58391794,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-02104189-fde3-4a9e-9b78-08ecd606ea7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-cedb40d3-0135-4081-add5-1dbae5b19acd,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-477ef466-b4d9-48e4-a302-2471654bb91a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621167027-172.17.0.17-1598201081924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33149,DS-086d985b-d402-4ff9-bb3c-9ca211ff19b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-096fc874-18e5-41d9-b21d-61a173f1d76c,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-1e94bfa4-3721-462a-aca2-499f793e18a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-3e2cffd3-a5e0-43da-a25d-d14e190c18d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-92d24add-4ae1-456d-b9b4-5639c791b66c,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-de9f35b9-2a42-45ed-b61e-937701d9067d,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-103d861e-d93f-4fc2-b4cd-cd7150f7f57c,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-8165da53-3706-4b9d-b134-0cd419354c0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621167027-172.17.0.17-1598201081924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33149,DS-086d985b-d402-4ff9-bb3c-9ca211ff19b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-096fc874-18e5-41d9-b21d-61a173f1d76c,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-1e94bfa4-3721-462a-aca2-499f793e18a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-3e2cffd3-a5e0-43da-a25d-d14e190c18d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-92d24add-4ae1-456d-b9b4-5639c791b66c,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-de9f35b9-2a42-45ed-b61e-937701d9067d,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-103d861e-d93f-4fc2-b4cd-cd7150f7f57c,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-8165da53-3706-4b9d-b134-0cd419354c0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134166181-172.17.0.17-1598201098536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43636,DS-2beea189-b7b8-47d7-b8c5-9967f6cf25e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-6330a7e7-7625-4fec-a8a8-2f0cf3f5734a,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-0996c872-f19e-4b58-9d27-037fe5f8af5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-002031b0-2905-4f36-9e51-20924b7d25fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-230d5015-181b-4391-90eb-8862f997030c,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-92d8512c-1edf-40d1-a38e-e6a70462f4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-b3d0e783-113c-4ed7-9a01-8d0d89033a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-19e2d7ac-eac6-4d53-ae40-755f2b4d7a0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134166181-172.17.0.17-1598201098536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43636,DS-2beea189-b7b8-47d7-b8c5-9967f6cf25e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-6330a7e7-7625-4fec-a8a8-2f0cf3f5734a,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-0996c872-f19e-4b58-9d27-037fe5f8af5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-002031b0-2905-4f36-9e51-20924b7d25fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-230d5015-181b-4391-90eb-8862f997030c,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-92d8512c-1edf-40d1-a38e-e6a70462f4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-b3d0e783-113c-4ed7-9a01-8d0d89033a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-19e2d7ac-eac6-4d53-ae40-755f2b4d7a0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1441829507-172.17.0.17-1598201181167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39741,DS-74919512-37f0-4263-939c-600b9d7c7c48,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-14ac3a14-2525-4b5a-acf1-860311ffe39e,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-83e12139-f7a6-4bc1-af1c-2517885d2b32,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-851fdbc5-21e6-4790-9f07-39dd55dfb963,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-3881e9db-2fe4-4232-946d-298bea5685d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-6390bb4d-3a6d-4574-9490-fbcfc565de6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-62dd7d5b-7f6f-4791-b03a-4eac2e07bf29,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-eb4f5d2e-e36b-4f8f-9f66-c488b300df33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1441829507-172.17.0.17-1598201181167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39741,DS-74919512-37f0-4263-939c-600b9d7c7c48,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-14ac3a14-2525-4b5a-acf1-860311ffe39e,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-83e12139-f7a6-4bc1-af1c-2517885d2b32,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-851fdbc5-21e6-4790-9f07-39dd55dfb963,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-3881e9db-2fe4-4232-946d-298bea5685d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-6390bb4d-3a6d-4574-9490-fbcfc565de6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-62dd7d5b-7f6f-4791-b03a-4eac2e07bf29,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-eb4f5d2e-e36b-4f8f-9f66-c488b300df33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1179962986-172.17.0.17-1598201393187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41981,DS-c7e15fa7-8f86-4154-a234-b4e31cd69c88,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-5e02b97a-b9c8-444e-a693-c6c3d0149c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-f4ca779a-6ded-4dd6-93be-ddbe441917d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-5f528ee3-9850-42cb-904e-ce620856ca8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-047d494e-f496-49a2-9914-1663adaf3609,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-c5917c6e-5d08-4c64-808c-6485b5cba64c,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-42778f3c-aadb-4d79-9375-f18abd712289,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-cb7cbd88-da6a-4e43-bc04-b714d483a3e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1179962986-172.17.0.17-1598201393187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41981,DS-c7e15fa7-8f86-4154-a234-b4e31cd69c88,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-5e02b97a-b9c8-444e-a693-c6c3d0149c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-f4ca779a-6ded-4dd6-93be-ddbe441917d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-5f528ee3-9850-42cb-904e-ce620856ca8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-047d494e-f496-49a2-9914-1663adaf3609,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-c5917c6e-5d08-4c64-808c-6485b5cba64c,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-42778f3c-aadb-4d79-9375-f18abd712289,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-cb7cbd88-da6a-4e43-bc04-b714d483a3e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202845228-172.17.0.17-1598201492315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41335,DS-f98f3d60-2bd5-4649-8500-56bd84ef1bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-0e6c095a-3f55-43d7-8658-352f37c5b188,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-393c9ce6-62d6-4c50-a65c-2fc60f728688,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-b2809407-281e-4747-8822-682e7fdb6fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-918eb3e8-4c9f-46e7-a9f6-23ba102e4fac,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-389ffc4a-7260-4ba5-8fd3-9313f5f3f6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-88f7007a-b1f1-4664-91d5-7617e130969a,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-94d648d7-c996-4185-8fdd-f0536d03af22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202845228-172.17.0.17-1598201492315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41335,DS-f98f3d60-2bd5-4649-8500-56bd84ef1bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-0e6c095a-3f55-43d7-8658-352f37c5b188,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-393c9ce6-62d6-4c50-a65c-2fc60f728688,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-b2809407-281e-4747-8822-682e7fdb6fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-918eb3e8-4c9f-46e7-a9f6-23ba102e4fac,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-389ffc4a-7260-4ba5-8fd3-9313f5f3f6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-88f7007a-b1f1-4664-91d5-7617e130969a,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-94d648d7-c996-4185-8fdd-f0536d03af22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504043138-172.17.0.17-1598201590851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34294,DS-b3286f85-485d-43ac-9e36-9361ab7ba4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-ff7ee649-60fc-4a18-9a58-b46cd92a5c20,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-1eaa92ab-c762-4587-b6f9-ae08074f82e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-413e8199-cec9-424c-b09a-58588f9446e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-aec214b5-0ecf-41b3-a915-77d36e92c234,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-57176120-2fc2-4cb0-9937-cfb2b5dc2302,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-be8909e2-e476-4da5-9cda-3790f6243027,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-247e6f79-f580-4b47-a047-ca43fdbab96a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504043138-172.17.0.17-1598201590851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34294,DS-b3286f85-485d-43ac-9e36-9361ab7ba4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-ff7ee649-60fc-4a18-9a58-b46cd92a5c20,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-1eaa92ab-c762-4587-b6f9-ae08074f82e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-413e8199-cec9-424c-b09a-58588f9446e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-aec214b5-0ecf-41b3-a915-77d36e92c234,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-57176120-2fc2-4cb0-9937-cfb2b5dc2302,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-be8909e2-e476-4da5-9cda-3790f6243027,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-247e6f79-f580-4b47-a047-ca43fdbab96a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370393532-172.17.0.17-1598201853627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40735,DS-a35be4ed-a950-45d7-b5fe-eb17338de371,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-00bb8369-f8b1-4d01-b25b-9300e1892f88,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-8c60c437-bfd8-4c7a-a3be-351cd8aa7774,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-5c94e169-a74f-4379-b936-3b7ee7d38048,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-f992ee6d-79a1-4841-980a-141782055d98,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-ab830343-33aa-4c44-9a5c-2cb6283bdeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-4948e65c-00b0-4750-afe3-a64d7e7390c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-523ad87f-3c00-41d3-b273-7d55ddcb603b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370393532-172.17.0.17-1598201853627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40735,DS-a35be4ed-a950-45d7-b5fe-eb17338de371,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-00bb8369-f8b1-4d01-b25b-9300e1892f88,DISK], DatanodeInfoWithStorage[127.0.0.1:43379,DS-8c60c437-bfd8-4c7a-a3be-351cd8aa7774,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-5c94e169-a74f-4379-b936-3b7ee7d38048,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-f992ee6d-79a1-4841-980a-141782055d98,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-ab830343-33aa-4c44-9a5c-2cb6283bdeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-4948e65c-00b0-4750-afe3-a64d7e7390c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-523ad87f-3c00-41d3-b273-7d55ddcb603b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966161805-172.17.0.17-1598202100204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41269,DS-3ec6a210-1bc0-4602-8557-d53bff4d06f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-49bc8117-daa8-40aa-ba92-9223960b4a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-2248ff71-448f-4701-9c74-203d02857cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-b2deea07-533c-43ec-8c44-6e6e54b82a46,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-da1bc461-5aa8-455e-b539-47be7b2de9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-0980e1c1-06ef-4821-a5e0-a43826fd10cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-8cebd5b8-58fa-4a88-a907-a84b0f7ec662,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-a93f63ac-b715-4ff6-9c7a-6b9943ca78b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966161805-172.17.0.17-1598202100204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41269,DS-3ec6a210-1bc0-4602-8557-d53bff4d06f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-49bc8117-daa8-40aa-ba92-9223960b4a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-2248ff71-448f-4701-9c74-203d02857cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-b2deea07-533c-43ec-8c44-6e6e54b82a46,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-da1bc461-5aa8-455e-b539-47be7b2de9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-0980e1c1-06ef-4821-a5e0-a43826fd10cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-8cebd5b8-58fa-4a88-a907-a84b0f7ec662,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-a93f63ac-b715-4ff6-9c7a-6b9943ca78b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-524139867-172.17.0.17-1598202429055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36242,DS-2fa23fa9-f4ba-4af8-bbf3-56e5a619f988,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-d4069923-40c7-46ad-8096-e9cf72635bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-d31e8da0-5b2a-4e5a-8a47-377e1bede843,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-8b07a444-dce9-43ed-bee2-607f6960ec7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-f0796140-cca5-456e-a285-24626a662452,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-4e8dc88a-49bb-4521-a539-08e211da5642,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-77a4b062-a6a6-43fb-a992-a43f4a258be4,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-c141dee6-32ff-4d8c-9e1a-4fc66fdaef0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-524139867-172.17.0.17-1598202429055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36242,DS-2fa23fa9-f4ba-4af8-bbf3-56e5a619f988,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-d4069923-40c7-46ad-8096-e9cf72635bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-d31e8da0-5b2a-4e5a-8a47-377e1bede843,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-8b07a444-dce9-43ed-bee2-607f6960ec7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-f0796140-cca5-456e-a285-24626a662452,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-4e8dc88a-49bb-4521-a539-08e211da5642,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-77a4b062-a6a6-43fb-a992-a43f4a258be4,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-c141dee6-32ff-4d8c-9e1a-4fc66fdaef0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912992922-172.17.0.17-1598202461266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33272,DS-a8246c9d-cf3e-4492-ac65-705b6d375613,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-1d06f4ab-82c8-4e05-9021-e3edea11eda3,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-35e4271a-2412-4750-bcb1-eb812dfa547c,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-25012046-c03a-4bfe-9087-bf73044e8cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-2311ab4d-f97a-4616-b84e-e3da26221d04,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-eeb421d4-4bfc-4484-be02-2e30cd47f407,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-d1dd7f18-650f-44cc-b809-af7f2bf9351b,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-941387d0-be07-46fd-a92a-6e754a5d0b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912992922-172.17.0.17-1598202461266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33272,DS-a8246c9d-cf3e-4492-ac65-705b6d375613,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-1d06f4ab-82c8-4e05-9021-e3edea11eda3,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-35e4271a-2412-4750-bcb1-eb812dfa547c,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-25012046-c03a-4bfe-9087-bf73044e8cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-2311ab4d-f97a-4616-b84e-e3da26221d04,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-eeb421d4-4bfc-4484-be02-2e30cd47f407,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-d1dd7f18-650f-44cc-b809-af7f2bf9351b,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-941387d0-be07-46fd-a92a-6e754a5d0b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114212193-172.17.0.17-1598202707898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40405,DS-b5a928b7-0ad2-416c-b49a-2a99931df2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-820f08e2-fc70-42af-8d40-6638219f49c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-2c67c388-3193-4a15-a838-00d7855eeaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-2c9f90b2-c1dd-4291-b220-18b24fcb6286,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-c9df7244-a06d-4299-82dc-3a6fdc2cd457,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-d77303bc-b3de-43f6-bfa5-a2ed52796783,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-af77f00d-1e95-4658-bef3-7c947f7b412c,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-0016a583-2420-4d4d-b325-23c381f65490,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114212193-172.17.0.17-1598202707898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40405,DS-b5a928b7-0ad2-416c-b49a-2a99931df2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-820f08e2-fc70-42af-8d40-6638219f49c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-2c67c388-3193-4a15-a838-00d7855eeaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-2c9f90b2-c1dd-4291-b220-18b24fcb6286,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-c9df7244-a06d-4299-82dc-3a6fdc2cd457,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-d77303bc-b3de-43f6-bfa5-a2ed52796783,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-af77f00d-1e95-4658-bef3-7c947f7b412c,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-0016a583-2420-4d4d-b325-23c381f65490,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 2587
