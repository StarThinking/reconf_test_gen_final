reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655289644-172.17.0.10-1598147983240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36195,DS-05a209a8-732e-4e38-ae41-8dd9dede5bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-db66afae-5ed0-4fb1-829d-f26598bc941c,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-c7254cc0-4d3a-40f6-b08f-7ddb82f7a96b,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-9056d1e3-779a-4847-a59e-cc0cf6cad492,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-bcca71b0-5d2b-472e-9c5a-e807a1427900,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-4f727d4f-44a8-4efd-a58f-b261b39edd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-8d0a7871-9b90-479e-891a-52b27021e534,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-8ac9c33b-51d2-4272-86c7-76f14cd2cd1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655289644-172.17.0.10-1598147983240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36195,DS-05a209a8-732e-4e38-ae41-8dd9dede5bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-db66afae-5ed0-4fb1-829d-f26598bc941c,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-c7254cc0-4d3a-40f6-b08f-7ddb82f7a96b,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-9056d1e3-779a-4847-a59e-cc0cf6cad492,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-bcca71b0-5d2b-472e-9c5a-e807a1427900,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-4f727d4f-44a8-4efd-a58f-b261b39edd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-8d0a7871-9b90-479e-891a-52b27021e534,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-8ac9c33b-51d2-4272-86c7-76f14cd2cd1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298719164-172.17.0.10-1598149209019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45573,DS-8ec87e59-0ad1-4322-9e76-c1d067e390a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-ff1dc087-3146-4175-903a-ef0830a1f2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-dfcdcda7-4a01-45b3-bdcb-7e06d24462e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-3684ad14-73c7-417a-a8ed-1f871f4429d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-08328229-e340-4f95-b4bc-2341d7af2acb,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-f5e7fa1f-2ae0-4f9b-b417-5748af0d1ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-812ab927-78d9-4b31-947e-12c432937515,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-ec73fe62-0dee-49e5-a951-2f4f7699b51c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298719164-172.17.0.10-1598149209019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45573,DS-8ec87e59-0ad1-4322-9e76-c1d067e390a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-ff1dc087-3146-4175-903a-ef0830a1f2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-dfcdcda7-4a01-45b3-bdcb-7e06d24462e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-3684ad14-73c7-417a-a8ed-1f871f4429d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-08328229-e340-4f95-b4bc-2341d7af2acb,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-f5e7fa1f-2ae0-4f9b-b417-5748af0d1ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-812ab927-78d9-4b31-947e-12c432937515,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-ec73fe62-0dee-49e5-a951-2f4f7699b51c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1240459450-172.17.0.10-1598149433973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36501,DS-e35e4069-abf6-4049-a3fc-447be57dd0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-b1e65636-d6f6-45c4-897c-031aa9f4e684,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-17e78823-454b-47de-85c6-b008250b9c48,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-f7f8b5ce-c213-4f88-be8f-179bfe25338f,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-4fac2ddd-70dd-454b-a65c-68b3cb161e47,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-96e145f4-874a-4ddb-addb-3c624d41e30d,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-92916903-a9b1-4382-8496-ab4ad958a5df,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-4d160927-f1e6-4c3c-b553-a2f4b91925e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1240459450-172.17.0.10-1598149433973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36501,DS-e35e4069-abf6-4049-a3fc-447be57dd0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-b1e65636-d6f6-45c4-897c-031aa9f4e684,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-17e78823-454b-47de-85c6-b008250b9c48,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-f7f8b5ce-c213-4f88-be8f-179bfe25338f,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-4fac2ddd-70dd-454b-a65c-68b3cb161e47,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-96e145f4-874a-4ddb-addb-3c624d41e30d,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-92916903-a9b1-4382-8496-ab4ad958a5df,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-4d160927-f1e6-4c3c-b553-a2f4b91925e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270832876-172.17.0.10-1598149581464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38184,DS-6ff2fcd8-4fba-48e9-aa3e-77e84348e93b,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-2e22e09b-f39b-49a2-a9c0-bbe3ad8648d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-e88ad0ee-6802-4874-98a9-8e6e8bf09af9,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-a70be056-8b46-46ba-a064-74b8172b98b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-a644c6ca-45ac-45f5-a592-d981e14fa914,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-1ef72687-3ee2-4d46-aad8-05ddf9668812,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-7f14bf1a-e9b3-45f8-89db-d61a5222725f,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-b2da7a3c-0462-4021-8474-d82ef316bea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270832876-172.17.0.10-1598149581464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38184,DS-6ff2fcd8-4fba-48e9-aa3e-77e84348e93b,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-2e22e09b-f39b-49a2-a9c0-bbe3ad8648d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-e88ad0ee-6802-4874-98a9-8e6e8bf09af9,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-a70be056-8b46-46ba-a064-74b8172b98b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-a644c6ca-45ac-45f5-a592-d981e14fa914,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-1ef72687-3ee2-4d46-aad8-05ddf9668812,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-7f14bf1a-e9b3-45f8-89db-d61a5222725f,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-b2da7a3c-0462-4021-8474-d82ef316bea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017755072-172.17.0.10-1598149740459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35446,DS-601c64ba-0da0-4fe8-ab1a-7ac42f6fae9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-68ef281d-2be0-4ddd-8d8d-fd1060510afe,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-b55bb299-b398-4fd4-aa67-78872abc0edc,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-4da81282-b1fa-47e1-8987-35c6a2edb400,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-204db3ea-4b34-44bc-824d-9244f73843b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-9e2d4971-ce54-4a80-ae16-012915f2d92c,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-56672150-e8e3-4103-b4ce-79bad05f662a,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-acf9d131-52ba-4181-8cf5-a81fb6f7add7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017755072-172.17.0.10-1598149740459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35446,DS-601c64ba-0da0-4fe8-ab1a-7ac42f6fae9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-68ef281d-2be0-4ddd-8d8d-fd1060510afe,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-b55bb299-b398-4fd4-aa67-78872abc0edc,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-4da81282-b1fa-47e1-8987-35c6a2edb400,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-204db3ea-4b34-44bc-824d-9244f73843b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-9e2d4971-ce54-4a80-ae16-012915f2d92c,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-56672150-e8e3-4103-b4ce-79bad05f662a,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-acf9d131-52ba-4181-8cf5-a81fb6f7add7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041906297-172.17.0.10-1598150457566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36904,DS-e52687d3-8cf1-4497-a46c-a4db34d13bac,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-0b016ae6-1282-43b4-88c2-ef22baee0df4,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-2115db18-ce8f-4337-a91d-934f59edd4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-594ffd50-efbe-4805-ab90-391156524a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-ab02216b-f15f-4f46-aa6f-f2846db31287,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-84d84655-ae52-4e0f-82a3-bb0f39f69229,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-f769354a-c8cc-4c3e-ad0e-7af6ebb8f464,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-c09a1e29-bde9-4210-9de7-6171b3e6eb37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041906297-172.17.0.10-1598150457566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36904,DS-e52687d3-8cf1-4497-a46c-a4db34d13bac,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-0b016ae6-1282-43b4-88c2-ef22baee0df4,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-2115db18-ce8f-4337-a91d-934f59edd4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-594ffd50-efbe-4805-ab90-391156524a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-ab02216b-f15f-4f46-aa6f-f2846db31287,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-84d84655-ae52-4e0f-82a3-bb0f39f69229,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-f769354a-c8cc-4c3e-ad0e-7af6ebb8f464,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-c09a1e29-bde9-4210-9de7-6171b3e6eb37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711236914-172.17.0.10-1598150618987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-cf7401b9-f197-456d-a640-1a91324b150f,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-ed0d1d0a-4269-4712-823f-24c2bcd46201,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-fbb20714-43f6-4356-9bdb-09e6ba7fa334,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-13e76045-3a50-46ee-aaa0-c64b48e2c88f,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-65224d86-62dc-44bd-8012-81517f32e2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-951f137d-e3f9-45ab-aa9a-69f6bfa525de,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-cd3d7979-940f-40fc-9b53-920e89ebf1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-9ef241f9-9d9e-4acf-a437-2a44fda96fd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711236914-172.17.0.10-1598150618987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-cf7401b9-f197-456d-a640-1a91324b150f,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-ed0d1d0a-4269-4712-823f-24c2bcd46201,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-fbb20714-43f6-4356-9bdb-09e6ba7fa334,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-13e76045-3a50-46ee-aaa0-c64b48e2c88f,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-65224d86-62dc-44bd-8012-81517f32e2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-951f137d-e3f9-45ab-aa9a-69f6bfa525de,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-cd3d7979-940f-40fc-9b53-920e89ebf1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-9ef241f9-9d9e-4acf-a437-2a44fda96fd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071303137-172.17.0.10-1598151041864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39370,DS-d2c427d7-faf4-44a8-9646-8fd2f4af902a,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-9d68f78c-ec1d-45f8-a7d8-c448305edb41,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-28849c22-2366-487a-9940-64fe68f51f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-636b02a2-1186-44db-9a56-7ddaa8700bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-ca82c749-99e0-49bb-9d5f-379cc913ff4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-7dc9acc9-f63d-4ce4-96f2-1727acfb7986,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-abe15a24-6949-4da4-8dac-8d4f1569f6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-9feb914d-d0b9-4e93-a185-bc235ddb2b90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071303137-172.17.0.10-1598151041864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39370,DS-d2c427d7-faf4-44a8-9646-8fd2f4af902a,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-9d68f78c-ec1d-45f8-a7d8-c448305edb41,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-28849c22-2366-487a-9940-64fe68f51f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-636b02a2-1186-44db-9a56-7ddaa8700bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-ca82c749-99e0-49bb-9d5f-379cc913ff4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-7dc9acc9-f63d-4ce4-96f2-1727acfb7986,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-abe15a24-6949-4da4-8dac-8d4f1569f6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-9feb914d-d0b9-4e93-a185-bc235ddb2b90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818910129-172.17.0.10-1598151625197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42447,DS-6a4ad467-4022-47c1-928d-9d4a53e7d693,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-bc5c9c2f-eab1-4f99-b103-b66848b0711b,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-b2e7150d-c1c5-491d-ac8a-2d1bcc89c70c,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-08bd73bd-81a0-460e-95e0-c14a5a3c130a,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-bfa6ddf3-512d-422b-826c-6b925f80b75d,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-3b4ed007-60af-40f0-805f-71d0d55b8bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-0d67b27c-cd15-4937-8456-52378a4fda4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-22e58df2-04fc-4e33-8c55-e7cd6cc6cec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818910129-172.17.0.10-1598151625197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42447,DS-6a4ad467-4022-47c1-928d-9d4a53e7d693,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-bc5c9c2f-eab1-4f99-b103-b66848b0711b,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-b2e7150d-c1c5-491d-ac8a-2d1bcc89c70c,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-08bd73bd-81a0-460e-95e0-c14a5a3c130a,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-bfa6ddf3-512d-422b-826c-6b925f80b75d,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-3b4ed007-60af-40f0-805f-71d0d55b8bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-0d67b27c-cd15-4937-8456-52378a4fda4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-22e58df2-04fc-4e33-8c55-e7cd6cc6cec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338987438-172.17.0.10-1598151664747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46260,DS-22f1c679-9658-4c20-ac7a-33858639e92f,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-2036f06f-d74a-4ced-96e8-64bd087115cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-9c8452e4-ee98-4785-827d-8a296d0c7003,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-d5b6a6d8-26f5-4bd7-aa5f-6630ff219039,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-8b5664c0-ec9e-4854-bd81-38fea709e02a,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-36db5106-d67d-41f7-be5e-7fb21ad73102,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-b7af303b-1b8a-4d9a-b5fb-24ef91a9e614,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-49935017-c4aa-4411-825f-25e94cbad318,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338987438-172.17.0.10-1598151664747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46260,DS-22f1c679-9658-4c20-ac7a-33858639e92f,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-2036f06f-d74a-4ced-96e8-64bd087115cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-9c8452e4-ee98-4785-827d-8a296d0c7003,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-d5b6a6d8-26f5-4bd7-aa5f-6630ff219039,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-8b5664c0-ec9e-4854-bd81-38fea709e02a,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-36db5106-d67d-41f7-be5e-7fb21ad73102,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-b7af303b-1b8a-4d9a-b5fb-24ef91a9e614,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-49935017-c4aa-4411-825f-25e94cbad318,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513848212-172.17.0.10-1598151919239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-5b437c21-8440-479a-8bd2-91c10c91885d,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-ffbdbc65-6168-4eae-a965-4c8f5e8eaa23,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-6381891e-8abf-4659-a3b0-ea7e644431dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-0731005d-bab1-480e-b261-9c962f736d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-fb8f6b5a-7d24-44f1-b1d6-84baf949d13f,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-7ee83930-7050-4c6d-974e-a90ebfbbe3de,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-c86d1fd5-514d-4a7f-83e3-bcf624c1a316,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-f81f478e-f1bb-466d-952f-d96b605e5621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513848212-172.17.0.10-1598151919239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-5b437c21-8440-479a-8bd2-91c10c91885d,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-ffbdbc65-6168-4eae-a965-4c8f5e8eaa23,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-6381891e-8abf-4659-a3b0-ea7e644431dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-0731005d-bab1-480e-b261-9c962f736d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-fb8f6b5a-7d24-44f1-b1d6-84baf949d13f,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-7ee83930-7050-4c6d-974e-a90ebfbbe3de,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-c86d1fd5-514d-4a7f-83e3-bcf624c1a316,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-f81f478e-f1bb-466d-952f-d96b605e5621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805460549-172.17.0.10-1598152744601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42054,DS-7e913121-51f6-4010-8738-860de0f58a83,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-5801f97a-a6b2-4797-ae64-e5d85a39e96b,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-15caae0a-a1a8-433c-bd13-fcc8e4d09043,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-529953de-d98f-4e20-a97f-807e0077772d,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-7ab0fc36-3a18-4a66-9cd8-f3881c78e84d,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-cd27be77-9c27-4375-be3a-6f61539263c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-5c31f6fe-4b24-4bf5-8d2a-38d610559f36,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-0675b7a4-2c2f-4d1c-86b6-8fd1d7480775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805460549-172.17.0.10-1598152744601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42054,DS-7e913121-51f6-4010-8738-860de0f58a83,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-5801f97a-a6b2-4797-ae64-e5d85a39e96b,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-15caae0a-a1a8-433c-bd13-fcc8e4d09043,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-529953de-d98f-4e20-a97f-807e0077772d,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-7ab0fc36-3a18-4a66-9cd8-f3881c78e84d,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-cd27be77-9c27-4375-be3a-6f61539263c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-5c31f6fe-4b24-4bf5-8d2a-38d610559f36,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-0675b7a4-2c2f-4d1c-86b6-8fd1d7480775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323474376-172.17.0.10-1598153327724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32908,DS-8526f385-8ff4-4243-b406-64f0bbd8b9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-2a23ae8e-6915-4e49-bcf1-adfdc265d158,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-01cbe481-bc48-44eb-99b5-d82d17ed0e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-264972a8-769f-481c-bd6b-47fe6b73677d,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-feceaedb-2834-42db-bce4-f2cf016e1960,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-5e43edd5-bbe5-4390-bbde-1a6bc6e1374b,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-d4ae1fd1-6d5e-4c6f-99b6-f3ba25353180,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-76203bed-19e9-4dab-a726-23768d835075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323474376-172.17.0.10-1598153327724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32908,DS-8526f385-8ff4-4243-b406-64f0bbd8b9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-2a23ae8e-6915-4e49-bcf1-adfdc265d158,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-01cbe481-bc48-44eb-99b5-d82d17ed0e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-264972a8-769f-481c-bd6b-47fe6b73677d,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-feceaedb-2834-42db-bce4-f2cf016e1960,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-5e43edd5-bbe5-4390-bbde-1a6bc6e1374b,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-d4ae1fd1-6d5e-4c6f-99b6-f3ba25353180,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-76203bed-19e9-4dab-a726-23768d835075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655075942-172.17.0.10-1598153448693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42483,DS-94498537-f7ad-4dec-801a-97924970b67d,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-55eb16ef-9eb6-4847-a112-462f9dd966b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-dd348270-e22d-4916-9947-abd0250969da,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-d190e8b7-4378-4e9f-b686-bf494e95556b,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-22e0bc58-a72d-4931-9a4b-579df96c760f,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-b3e8ceda-3d6a-4284-9540-65bb0216f8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-873a26e7-ef6f-4901-b532-8e4ebc4da649,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-0dae5f7e-1d21-444d-b296-804045c74c9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655075942-172.17.0.10-1598153448693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42483,DS-94498537-f7ad-4dec-801a-97924970b67d,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-55eb16ef-9eb6-4847-a112-462f9dd966b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-dd348270-e22d-4916-9947-abd0250969da,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-d190e8b7-4378-4e9f-b686-bf494e95556b,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-22e0bc58-a72d-4931-9a4b-579df96c760f,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-b3e8ceda-3d6a-4284-9540-65bb0216f8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-873a26e7-ef6f-4901-b532-8e4ebc4da649,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-0dae5f7e-1d21-444d-b296-804045c74c9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5650
