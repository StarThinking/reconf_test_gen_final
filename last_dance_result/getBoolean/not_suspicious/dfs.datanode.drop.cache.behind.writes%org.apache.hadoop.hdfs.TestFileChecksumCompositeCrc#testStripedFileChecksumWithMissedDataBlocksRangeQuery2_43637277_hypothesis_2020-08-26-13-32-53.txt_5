reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122833149-172.17.0.13-1598448861664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37559,DS-967b0cca-d861-4fcf-b30f-c2711d4bed97,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-35838657-7942-4953-b85e-3f1db69c9723,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-c83ed3d6-0674-490e-bca9-5feb51600840,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-ac1bd805-b11b-4be1-9e3c-7018c86b252c,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-84c6d18b-6f8f-4f1e-ba3d-567b5cb01f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-0ae8781f-38fb-4b81-9b12-1c29871bebf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-83b2c15b-dda4-4d2f-91d8-5af2e4764a02,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-67487189-f4a7-4d75-a51c-fdd3460e6184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122833149-172.17.0.13-1598448861664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37559,DS-967b0cca-d861-4fcf-b30f-c2711d4bed97,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-35838657-7942-4953-b85e-3f1db69c9723,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-c83ed3d6-0674-490e-bca9-5feb51600840,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-ac1bd805-b11b-4be1-9e3c-7018c86b252c,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-84c6d18b-6f8f-4f1e-ba3d-567b5cb01f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-0ae8781f-38fb-4b81-9b12-1c29871bebf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-83b2c15b-dda4-4d2f-91d8-5af2e4764a02,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-67487189-f4a7-4d75-a51c-fdd3460e6184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262368224-172.17.0.13-1598450868078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42467,DS-ef57297a-3c40-497d-8c6a-a5f2f935dced,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-dee71120-25f3-418b-9408-667451ce6cab,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-649b4386-080a-459d-9b16-a1730f327a57,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-8dbe415a-d1f1-4220-8df8-743e85238665,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-f24971c6-8034-4135-8c0c-f55aa5a43959,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-03fe1ac7-6ffc-47b3-b820-43c64eb01b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-42b3f590-0b06-41a1-a5d8-2e3616b4c508,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-808ace85-7538-4c60-a3fa-cf8e378bc520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262368224-172.17.0.13-1598450868078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42467,DS-ef57297a-3c40-497d-8c6a-a5f2f935dced,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-dee71120-25f3-418b-9408-667451ce6cab,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-649b4386-080a-459d-9b16-a1730f327a57,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-8dbe415a-d1f1-4220-8df8-743e85238665,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-f24971c6-8034-4135-8c0c-f55aa5a43959,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-03fe1ac7-6ffc-47b3-b820-43c64eb01b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-42b3f590-0b06-41a1-a5d8-2e3616b4c508,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-808ace85-7538-4c60-a3fa-cf8e378bc520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773955976-172.17.0.13-1598451588413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34028,DS-567e070f-f1f8-4791-9561-b1b6c40ecd98,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-c4386925-cac8-4070-a53b-b87042365ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-bf291010-88ab-4ed4-931d-f6f70e393b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-599eb08a-d44f-4bc0-b005-eddd6a219f21,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-71eed4d9-e7f0-41e4-9fe8-6126d29bff6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-77af099a-7016-4898-a664-57c22c725593,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-f1fc3de6-2546-4c39-8cc0-d9d319e5238a,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-1a3d8cc9-fea2-474a-9931-8a1400a94d24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773955976-172.17.0.13-1598451588413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34028,DS-567e070f-f1f8-4791-9561-b1b6c40ecd98,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-c4386925-cac8-4070-a53b-b87042365ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-bf291010-88ab-4ed4-931d-f6f70e393b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-599eb08a-d44f-4bc0-b005-eddd6a219f21,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-71eed4d9-e7f0-41e4-9fe8-6126d29bff6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-77af099a-7016-4898-a664-57c22c725593,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-f1fc3de6-2546-4c39-8cc0-d9d319e5238a,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-1a3d8cc9-fea2-474a-9931-8a1400a94d24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-590017374-172.17.0.13-1598451760862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45580,DS-ccb4d2ac-dbf9-46ed-9aae-1f5aa73ad9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-a93e506f-6db0-460d-bb43-6a6a5c4af1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-e22dfd43-6b17-40f7-880c-65afec73eaef,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-4f77bb93-ba2f-434c-bd1f-6cb6f8ae9767,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-a1ea44b8-42d3-4fad-9486-f822d8a4da3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-e5a46217-39c9-464a-95fa-3a6f3fa6b51a,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-0863f309-0f2d-476e-b473-03ba08973abd,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-fcab3fa2-688f-4250-9e48-7f793ebc78ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-590017374-172.17.0.13-1598451760862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45580,DS-ccb4d2ac-dbf9-46ed-9aae-1f5aa73ad9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-a93e506f-6db0-460d-bb43-6a6a5c4af1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-e22dfd43-6b17-40f7-880c-65afec73eaef,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-4f77bb93-ba2f-434c-bd1f-6cb6f8ae9767,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-a1ea44b8-42d3-4fad-9486-f822d8a4da3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-e5a46217-39c9-464a-95fa-3a6f3fa6b51a,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-0863f309-0f2d-476e-b473-03ba08973abd,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-fcab3fa2-688f-4250-9e48-7f793ebc78ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438260413-172.17.0.13-1598452208683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39627,DS-2bc0b600-266d-49ad-a73c-15f8125a02dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-1690ce78-97ef-4896-bf3a-49f18df157ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-855ab6b0-7a97-4521-955c-65cf260467b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-8ab7eab5-2d51-4cc4-b49a-f2981e3f2843,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-dc53f86d-46fa-4556-9dba-580a11283207,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-5660ad97-09b8-486c-8deb-5737f04e10cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-3dd13b5f-b025-4534-b86e-966f4394bfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-b178253c-de4b-483b-bf20-213f746e8cc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438260413-172.17.0.13-1598452208683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39627,DS-2bc0b600-266d-49ad-a73c-15f8125a02dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-1690ce78-97ef-4896-bf3a-49f18df157ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-855ab6b0-7a97-4521-955c-65cf260467b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-8ab7eab5-2d51-4cc4-b49a-f2981e3f2843,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-dc53f86d-46fa-4556-9dba-580a11283207,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-5660ad97-09b8-486c-8deb-5737f04e10cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-3dd13b5f-b025-4534-b86e-966f4394bfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-b178253c-de4b-483b-bf20-213f746e8cc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778404459-172.17.0.13-1598452249003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44126,DS-28bf6018-9d4c-4d62-9b46-2411abb86778,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-8e062f88-61e7-4f17-a3e5-e4782d66dc77,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-90b69624-8e61-4c46-9e3a-04f84806d145,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-0ce34b32-c561-4adb-8cc6-786c58169c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-c2113383-e1de-4beb-bb64-2e493e59ab52,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-007c390e-269f-4f88-91a7-9be15f799b65,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-6c8927b8-2be1-4ad0-a515-802c0fb59e51,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-bfb6122a-cf91-46cd-8034-b04dcc317ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778404459-172.17.0.13-1598452249003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44126,DS-28bf6018-9d4c-4d62-9b46-2411abb86778,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-8e062f88-61e7-4f17-a3e5-e4782d66dc77,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-90b69624-8e61-4c46-9e3a-04f84806d145,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-0ce34b32-c561-4adb-8cc6-786c58169c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-c2113383-e1de-4beb-bb64-2e493e59ab52,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-007c390e-269f-4f88-91a7-9be15f799b65,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-6c8927b8-2be1-4ad0-a515-802c0fb59e51,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-bfb6122a-cf91-46cd-8034-b04dcc317ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551993600-172.17.0.13-1598452469665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46440,DS-40c9d8ca-c014-4e27-84fc-993a4afc1a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-d4b7f358-924b-4ccb-afee-c2a9bf28090e,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-78a662ec-c132-4782-a06e-774279a353cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-983648ac-e116-413f-a241-20266bcfbb13,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-c3b1a5b9-ee4c-43ba-b28d-13637507fd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-208e1488-302b-42a8-9c17-d1a08aeae642,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-5b98b8ce-241e-498d-9110-e2792e68c3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-44c2b250-3813-4346-b882-73b30f5b1193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551993600-172.17.0.13-1598452469665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46440,DS-40c9d8ca-c014-4e27-84fc-993a4afc1a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-d4b7f358-924b-4ccb-afee-c2a9bf28090e,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-78a662ec-c132-4782-a06e-774279a353cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-983648ac-e116-413f-a241-20266bcfbb13,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-c3b1a5b9-ee4c-43ba-b28d-13637507fd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-208e1488-302b-42a8-9c17-d1a08aeae642,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-5b98b8ce-241e-498d-9110-e2792e68c3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-44c2b250-3813-4346-b882-73b30f5b1193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500088732-172.17.0.13-1598452741617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37469,DS-a906b0a8-2029-49f4-bcfd-24d47b3ba3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-3a47d817-34a7-4f76-9ded-084fff3c3cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-f3433e43-4bf2-43c9-a22a-d8b7e564dfca,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-221410aa-2842-4f25-8627-62a375ef3b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-d69b6d49-9e43-40ab-8191-19da6593b516,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-2929de98-ebec-4685-9253-9f5b70946711,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-13fe5fbf-a1d7-4a47-8a7d-a600d6cf7b17,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-b90739c5-73d0-45dc-865a-4e2781317e2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500088732-172.17.0.13-1598452741617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37469,DS-a906b0a8-2029-49f4-bcfd-24d47b3ba3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-3a47d817-34a7-4f76-9ded-084fff3c3cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-f3433e43-4bf2-43c9-a22a-d8b7e564dfca,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-221410aa-2842-4f25-8627-62a375ef3b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-d69b6d49-9e43-40ab-8191-19da6593b516,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-2929de98-ebec-4685-9253-9f5b70946711,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-13fe5fbf-a1d7-4a47-8a7d-a600d6cf7b17,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-b90739c5-73d0-45dc-865a-4e2781317e2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302748168-172.17.0.13-1598452892890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33072,DS-ed188763-8ddd-4139-a5de-a96f08255989,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-c0e30341-d40c-4f50-91c9-f045adf07bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-ee9f12fd-7e47-4e3c-8bd6-f4bb0a02ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-08a182c1-76d0-4161-a505-1f45351d7f61,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-d0d52e3b-1d6b-48c3-81bd-d6b363bc129c,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-443a0c68-893c-4606-b476-2960631d1bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-58648d84-144a-4434-a247-ecdfe3ccd71e,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-538cc1b5-9ad7-49e8-bd7e-7acc87e8f668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302748168-172.17.0.13-1598452892890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33072,DS-ed188763-8ddd-4139-a5de-a96f08255989,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-c0e30341-d40c-4f50-91c9-f045adf07bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-ee9f12fd-7e47-4e3c-8bd6-f4bb0a02ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-08a182c1-76d0-4161-a505-1f45351d7f61,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-d0d52e3b-1d6b-48c3-81bd-d6b363bc129c,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-443a0c68-893c-4606-b476-2960631d1bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-58648d84-144a-4434-a247-ecdfe3ccd71e,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-538cc1b5-9ad7-49e8-bd7e-7acc87e8f668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392966692-172.17.0.13-1598452920037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43293,DS-d675e9b8-ed3f-4071-903f-52c5f45efd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-fa3ab243-6c5a-4677-86ac-69f70ef8d950,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-3ddce0b7-7f66-41b2-9005-83cdf59db44d,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-c75e5943-c5cf-4629-bb3a-d28239fa38a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-620f134d-1427-4592-8698-aaeae31a4332,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-4b74a29e-2965-49e0-a922-741e7226e103,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-b4b4c623-2bdf-4f34-8fea-2ca28f149363,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-2edd96a8-e323-4c19-96e2-935166c09faa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392966692-172.17.0.13-1598452920037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43293,DS-d675e9b8-ed3f-4071-903f-52c5f45efd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-fa3ab243-6c5a-4677-86ac-69f70ef8d950,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-3ddce0b7-7f66-41b2-9005-83cdf59db44d,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-c75e5943-c5cf-4629-bb3a-d28239fa38a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-620f134d-1427-4592-8698-aaeae31a4332,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-4b74a29e-2965-49e0-a922-741e7226e103,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-b4b4c623-2bdf-4f34-8fea-2ca28f149363,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-2edd96a8-e323-4c19-96e2-935166c09faa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401030530-172.17.0.13-1598453283042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39373,DS-ccc6ed46-94bc-427b-b8d4-e0ae44170d44,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-4acc3c0a-e391-4156-b3a9-092c858f4f64,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-9397ba25-3888-4dff-8cd1-497d82f456f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-00a623c3-fc73-4c35-ae39-1ab6502c1571,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-b660fadb-6995-43b4-be77-ad10d7ec86ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-232db296-51d3-4f8e-8c8f-5e3f357b9570,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-aaebc62c-9b4e-47e2-a15c-bac0f084ad98,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-84330f5c-dcae-4a05-94e1-d2dc27f58444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401030530-172.17.0.13-1598453283042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39373,DS-ccc6ed46-94bc-427b-b8d4-e0ae44170d44,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-4acc3c0a-e391-4156-b3a9-092c858f4f64,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-9397ba25-3888-4dff-8cd1-497d82f456f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-00a623c3-fc73-4c35-ae39-1ab6502c1571,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-b660fadb-6995-43b4-be77-ad10d7ec86ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-232db296-51d3-4f8e-8c8f-5e3f357b9570,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-aaebc62c-9b4e-47e2-a15c-bac0f084ad98,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-84330f5c-dcae-4a05-94e1-d2dc27f58444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075931122-172.17.0.13-1598453352521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42662,DS-2a9bb567-5698-41cf-866d-6de7cd7d5129,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-70d13808-5923-40f3-9c55-ead33ddbe07e,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-af5594b2-ed0b-4ca9-8186-196da7fe3976,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-22c9abaf-c0d5-452c-968b-f56f4de779bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-a46a1312-8248-4120-a933-bf1ccb20d80b,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-d49fbcf9-ecf5-42e7-90ab-9edb5420d61e,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-1a0ce587-b0c8-4cc2-aee6-20a84ad61863,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-b097c335-a028-4336-8730-33321c3b7089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075931122-172.17.0.13-1598453352521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42662,DS-2a9bb567-5698-41cf-866d-6de7cd7d5129,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-70d13808-5923-40f3-9c55-ead33ddbe07e,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-af5594b2-ed0b-4ca9-8186-196da7fe3976,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-22c9abaf-c0d5-452c-968b-f56f4de779bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-a46a1312-8248-4120-a933-bf1ccb20d80b,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-d49fbcf9-ecf5-42e7-90ab-9edb5420d61e,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-1a0ce587-b0c8-4cc2-aee6-20a84ad61863,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-b097c335-a028-4336-8730-33321c3b7089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1198569870-172.17.0.13-1598453569476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43196,DS-040ec6f6-a0e3-4e0b-99db-9801dac8cfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-2a2deaea-f971-41b9-98e4-4a038255d5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-1a8e0544-7e43-4907-9080-d5bf5f4ada48,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-a5800175-2f23-474a-b1db-bb4d5518c3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-0d4ba1b3-99ae-4384-808b-8ca09ba05914,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-ea75a195-e181-4a9e-810d-15b98e0008a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-75e9eef5-347f-4b66-9196-d4af69dee209,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-27ce403a-eaf1-4865-9fed-feb18171eac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1198569870-172.17.0.13-1598453569476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43196,DS-040ec6f6-a0e3-4e0b-99db-9801dac8cfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-2a2deaea-f971-41b9-98e4-4a038255d5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-1a8e0544-7e43-4907-9080-d5bf5f4ada48,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-a5800175-2f23-474a-b1db-bb4d5518c3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-0d4ba1b3-99ae-4384-808b-8ca09ba05914,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-ea75a195-e181-4a9e-810d-15b98e0008a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-75e9eef5-347f-4b66-9196-d4af69dee209,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-27ce403a-eaf1-4865-9fed-feb18171eac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5281
