reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660281504-172.17.0.7-1598385552195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33663,DS-2884553d-cf59-462e-8e19-d0999264a588,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-724fa912-8dad-4922-9505-24d9eaa076ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-95143438-62bd-442a-b8e4-f0212c6abf19,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-d97471c0-d7f1-4924-b000-b13e168a84db,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-e738bc53-4545-4377-9a7b-706ccd70eda2,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-8c7107e2-1c0e-4d42-bda9-80c6548eb4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-800caee9-c3a7-4e85-9344-8f3462df738b,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-26ebba3b-0487-4bba-8a14-b3f18e963f35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660281504-172.17.0.7-1598385552195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33663,DS-2884553d-cf59-462e-8e19-d0999264a588,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-724fa912-8dad-4922-9505-24d9eaa076ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-95143438-62bd-442a-b8e4-f0212c6abf19,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-d97471c0-d7f1-4924-b000-b13e168a84db,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-e738bc53-4545-4377-9a7b-706ccd70eda2,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-8c7107e2-1c0e-4d42-bda9-80c6548eb4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-800caee9-c3a7-4e85-9344-8f3462df738b,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-26ebba3b-0487-4bba-8a14-b3f18e963f35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523852190-172.17.0.7-1598385582061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40607,DS-e1772503-5358-416c-bdca-1d493b6cb402,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-b2e03bfc-9740-4134-88f0-b1d7d77f9baf,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-63cfbf4f-99e1-40b8-83e7-7a8cb68f67d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-dc9a9546-3170-4859-851a-50696ca0a2da,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-6e864041-c052-4ead-9044-42efb995943d,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-b20a9900-a768-40d1-b82f-3c2723a14f72,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-564ed1fb-4206-4139-88e4-28dcabb55a09,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-8b4ca7a7-40b7-40ef-b4b9-d17c6bf222ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523852190-172.17.0.7-1598385582061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40607,DS-e1772503-5358-416c-bdca-1d493b6cb402,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-b2e03bfc-9740-4134-88f0-b1d7d77f9baf,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-63cfbf4f-99e1-40b8-83e7-7a8cb68f67d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-dc9a9546-3170-4859-851a-50696ca0a2da,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-6e864041-c052-4ead-9044-42efb995943d,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-b20a9900-a768-40d1-b82f-3c2723a14f72,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-564ed1fb-4206-4139-88e4-28dcabb55a09,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-8b4ca7a7-40b7-40ef-b4b9-d17c6bf222ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392039173-172.17.0.7-1598385695825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40082,DS-cc688db2-2780-40aa-bdb0-f5fe70bf1a85,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-462bb4ab-3f93-4891-b1bc-f17c60d91d23,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-8c493ae9-bfec-4290-9e85-323e88a36568,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-de077897-3171-48e9-8351-1a815b12c329,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-7f881e3c-b96c-4760-8f28-c7e784ed922b,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-a63cfa3e-a112-4b70-96d5-73b205a2707a,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-5bbda516-6790-4c94-85ac-3a9b90b795aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-55eea47c-d55c-42bd-a6de-1ec22c2670ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392039173-172.17.0.7-1598385695825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40082,DS-cc688db2-2780-40aa-bdb0-f5fe70bf1a85,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-462bb4ab-3f93-4891-b1bc-f17c60d91d23,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-8c493ae9-bfec-4290-9e85-323e88a36568,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-de077897-3171-48e9-8351-1a815b12c329,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-7f881e3c-b96c-4760-8f28-c7e784ed922b,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-a63cfa3e-a112-4b70-96d5-73b205a2707a,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-5bbda516-6790-4c94-85ac-3a9b90b795aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-55eea47c-d55c-42bd-a6de-1ec22c2670ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266734169-172.17.0.7-1598385739089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43542,DS-bec97cf7-3276-4f93-8476-051cde87b76e,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-76bee2ca-1db0-43c3-a88f-7cefe72b37e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-397583c9-0ba7-48dc-9c2e-3b3b28044806,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-24cf1572-ab88-4750-87e5-8d303bbc8384,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-e86b7f35-f2ce-4b90-8b87-5ea0f0375ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-9cce44a4-b79f-41f5-a41a-842010d56c75,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-32c89526-3e50-45ec-8bef-d48458ab6bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-acb3d0af-9e5c-4c17-b626-16c6b48d7089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266734169-172.17.0.7-1598385739089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43542,DS-bec97cf7-3276-4f93-8476-051cde87b76e,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-76bee2ca-1db0-43c3-a88f-7cefe72b37e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-397583c9-0ba7-48dc-9c2e-3b3b28044806,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-24cf1572-ab88-4750-87e5-8d303bbc8384,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-e86b7f35-f2ce-4b90-8b87-5ea0f0375ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-9cce44a4-b79f-41f5-a41a-842010d56c75,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-32c89526-3e50-45ec-8bef-d48458ab6bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-acb3d0af-9e5c-4c17-b626-16c6b48d7089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996955959-172.17.0.7-1598385769028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44887,DS-c156c4bb-39ad-4919-bc83-6bdd2134b5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-e65d7eeb-4c42-4b0c-b7db-a57dd78eb985,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-64a3d3bf-cb42-473a-a521-8007c8d7a42f,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-089c6f2f-4b3a-4348-b69e-10307874a85f,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-123ecdbd-1f97-435b-a67d-725d82c16249,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-ecef8185-448f-4e7c-b49a-dc8e6da7a943,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-dd380c19-dafc-4984-bf8d-57397870f7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-9f1ba525-aef6-4c55-ad6a-4c9cec6f6d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996955959-172.17.0.7-1598385769028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44887,DS-c156c4bb-39ad-4919-bc83-6bdd2134b5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-e65d7eeb-4c42-4b0c-b7db-a57dd78eb985,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-64a3d3bf-cb42-473a-a521-8007c8d7a42f,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-089c6f2f-4b3a-4348-b69e-10307874a85f,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-123ecdbd-1f97-435b-a67d-725d82c16249,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-ecef8185-448f-4e7c-b49a-dc8e6da7a943,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-dd380c19-dafc-4984-bf8d-57397870f7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-9f1ba525-aef6-4c55-ad6a-4c9cec6f6d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28278202-172.17.0.7-1598385839562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37191,DS-f7d90f4e-fc7a-4ec5-bf7e-e0a23670dc14,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-840e3cd9-986f-4df3-bb1c-c083f6fb1256,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-b1672afb-607c-4434-b674-a0f8fb5c620f,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-fc1d8c89-d938-4a72-9633-87fdeec61082,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-35c707d1-4218-42c5-ab3d-5c111ac26e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-3f528ee1-8fbe-4351-aaba-d01eb5658082,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-844b320b-0f72-4c49-9bfa-af45d57ff011,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-f91596e7-3e2f-4754-a831-2c681436c731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28278202-172.17.0.7-1598385839562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37191,DS-f7d90f4e-fc7a-4ec5-bf7e-e0a23670dc14,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-840e3cd9-986f-4df3-bb1c-c083f6fb1256,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-b1672afb-607c-4434-b674-a0f8fb5c620f,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-fc1d8c89-d938-4a72-9633-87fdeec61082,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-35c707d1-4218-42c5-ab3d-5c111ac26e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-3f528ee1-8fbe-4351-aaba-d01eb5658082,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-844b320b-0f72-4c49-9bfa-af45d57ff011,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-f91596e7-3e2f-4754-a831-2c681436c731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516973182-172.17.0.7-1598386941367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42205,DS-943c5e33-98cd-49f0-8f9b-021d81ce0c16,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-84459e8c-8a70-444e-b401-d26170f6ac03,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-c063eb79-d8fa-4e0f-bcf7-43b4566b4075,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-27c859a0-dce0-463a-9de8-eb4f2c5e51bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-f6d71dca-e538-4c8e-9892-833aa2fa9671,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-3d8e77e1-7174-432d-9d06-acc67481bf46,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-41964a76-983c-4b6b-953a-65a6c836f322,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-23ffa590-29a1-4653-ba51-0e61b6c68fa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516973182-172.17.0.7-1598386941367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42205,DS-943c5e33-98cd-49f0-8f9b-021d81ce0c16,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-84459e8c-8a70-444e-b401-d26170f6ac03,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-c063eb79-d8fa-4e0f-bcf7-43b4566b4075,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-27c859a0-dce0-463a-9de8-eb4f2c5e51bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-f6d71dca-e538-4c8e-9892-833aa2fa9671,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-3d8e77e1-7174-432d-9d06-acc67481bf46,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-41964a76-983c-4b6b-953a-65a6c836f322,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-23ffa590-29a1-4653-ba51-0e61b6c68fa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034496830-172.17.0.7-1598387320541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43367,DS-ae6ec959-2653-4769-8860-d07cd77884c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-86da30b1-f4ca-40bd-a9ba-8a4c86963b37,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-b49d432f-035c-413f-856d-6d997b081f40,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-a2dc8b60-2691-4a34-bb4f-6718e386e1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-6c38093b-7b72-448b-a428-4006843724bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-13565c27-47ce-4c80-87f0-2d6de5c1780d,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-96cb95c9-092d-438a-83ae-a2577dd39331,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-c6d60a8a-9e66-4f88-818d-fd345cd1aad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034496830-172.17.0.7-1598387320541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43367,DS-ae6ec959-2653-4769-8860-d07cd77884c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-86da30b1-f4ca-40bd-a9ba-8a4c86963b37,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-b49d432f-035c-413f-856d-6d997b081f40,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-a2dc8b60-2691-4a34-bb4f-6718e386e1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-6c38093b-7b72-448b-a428-4006843724bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-13565c27-47ce-4c80-87f0-2d6de5c1780d,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-96cb95c9-092d-438a-83ae-a2577dd39331,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-c6d60a8a-9e66-4f88-818d-fd345cd1aad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074241505-172.17.0.7-1598388464539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43151,DS-7628ddf5-43dc-4ea7-897c-e3196c190525,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-dfcfe842-dfcc-4d34-bbaf-5a08d396b10d,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-047afc7e-4f97-4837-a66e-d4f6231054b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-69958848-c4fb-4924-9757-6b085f8dfd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-db5f0d49-bd46-47af-9017-4b05e6cad969,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-cc64d409-a170-4b74-b8cd-3598b4d2d775,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-0d87d227-b422-4a99-9544-173802a4f770,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-6fb6a0e6-741f-4207-9190-4e0166ab5b45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074241505-172.17.0.7-1598388464539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43151,DS-7628ddf5-43dc-4ea7-897c-e3196c190525,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-dfcfe842-dfcc-4d34-bbaf-5a08d396b10d,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-047afc7e-4f97-4837-a66e-d4f6231054b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-69958848-c4fb-4924-9757-6b085f8dfd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-db5f0d49-bd46-47af-9017-4b05e6cad969,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-cc64d409-a170-4b74-b8cd-3598b4d2d775,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-0d87d227-b422-4a99-9544-173802a4f770,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-6fb6a0e6-741f-4207-9190-4e0166ab5b45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398774601-172.17.0.7-1598388607730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41358,DS-fce8bcc8-48e7-4a0f-9835-2a6e6dc96b40,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-b03ce621-f173-4eda-8bfa-defaeefc1bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-4945f5f6-9ec2-4cb9-9f67-a717eda84781,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-b3a81a64-38c4-474a-b27c-78ea595987b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-cb1f480b-32ab-43e1-9c25-c6433f04efcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-483356b3-cd9d-44b0-b1e1-34f6c55cc6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-c5c437f9-e719-46fb-a015-421c2b236649,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-a58c0a49-3d03-4cb4-9845-dfec50208e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398774601-172.17.0.7-1598388607730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41358,DS-fce8bcc8-48e7-4a0f-9835-2a6e6dc96b40,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-b03ce621-f173-4eda-8bfa-defaeefc1bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-4945f5f6-9ec2-4cb9-9f67-a717eda84781,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-b3a81a64-38c4-474a-b27c-78ea595987b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-cb1f480b-32ab-43e1-9c25-c6433f04efcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-483356b3-cd9d-44b0-b1e1-34f6c55cc6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-c5c437f9-e719-46fb-a015-421c2b236649,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-a58c0a49-3d03-4cb4-9845-dfec50208e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471680836-172.17.0.7-1598388786612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37968,DS-88f1e562-b1d7-49f8-af43-81ae2174841f,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-a58b464e-5765-4e1f-97da-966e78c02b31,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-fafdcf62-558b-49be-92a5-0fc1c2f1ae21,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-88c13caa-c65a-48b5-8aff-166786ab679b,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-74ff52f3-5858-42ba-bfd5-98758107b1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-14220bd7-1e1b-4224-9c8c-d45eb1124cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-a9e2648c-b9f0-44cb-9884-d3777cac7049,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-82062f2d-ad6a-4375-bf82-8ccb19a3cf68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471680836-172.17.0.7-1598388786612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37968,DS-88f1e562-b1d7-49f8-af43-81ae2174841f,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-a58b464e-5765-4e1f-97da-966e78c02b31,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-fafdcf62-558b-49be-92a5-0fc1c2f1ae21,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-88c13caa-c65a-48b5-8aff-166786ab679b,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-74ff52f3-5858-42ba-bfd5-98758107b1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-14220bd7-1e1b-4224-9c8c-d45eb1124cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-a9e2648c-b9f0-44cb-9884-d3777cac7049,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-82062f2d-ad6a-4375-bf82-8ccb19a3cf68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010059795-172.17.0.7-1598389041450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37684,DS-f2094d69-2134-4cc8-a531-a15182e5bcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-d1c37326-53c2-4846-aed9-7c40ae8232e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-c25880f0-f6a8-4424-9084-a607a1eedeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-318f59a2-835b-4e37-9193-387d51a2460f,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-3f49161b-b81e-4553-9ad9-fcfdf245f200,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-07da9ec1-b5b3-4727-9c75-4a12571d506b,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-154debf7-e95a-4fbe-9357-2ea6d9468bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-17eebbf4-8eed-498c-bb69-ef01e1bea5c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010059795-172.17.0.7-1598389041450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37684,DS-f2094d69-2134-4cc8-a531-a15182e5bcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-d1c37326-53c2-4846-aed9-7c40ae8232e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-c25880f0-f6a8-4424-9084-a607a1eedeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-318f59a2-835b-4e37-9193-387d51a2460f,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-3f49161b-b81e-4553-9ad9-fcfdf245f200,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-07da9ec1-b5b3-4727-9c75-4a12571d506b,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-154debf7-e95a-4fbe-9357-2ea6d9468bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-17eebbf4-8eed-498c-bb69-ef01e1bea5c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722213662-172.17.0.7-1598389273242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35435,DS-ecf7e554-b074-49ff-9413-1fcd8c44ed51,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-cb1d0685-7855-4329-8dfa-dd2a1d4eab7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-2acbd438-e6cf-465d-8190-788f7fc3ae11,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-6c054385-19de-41a9-9ec4-16f12f71b0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-f9903198-1935-4c32-8c09-d6cda8368181,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-0d1ecd1b-0708-4182-b820-539b80766908,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-46ad593f-8d13-4615-9ca3-dde169e58bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-81a47b35-b56c-4c08-ae9f-baba14715c5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722213662-172.17.0.7-1598389273242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35435,DS-ecf7e554-b074-49ff-9413-1fcd8c44ed51,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-cb1d0685-7855-4329-8dfa-dd2a1d4eab7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-2acbd438-e6cf-465d-8190-788f7fc3ae11,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-6c054385-19de-41a9-9ec4-16f12f71b0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-f9903198-1935-4c32-8c09-d6cda8368181,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-0d1ecd1b-0708-4182-b820-539b80766908,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-46ad593f-8d13-4615-9ca3-dde169e58bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-81a47b35-b56c-4c08-ae9f-baba14715c5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52648793-172.17.0.7-1598389406327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38907,DS-5b3f9af7-f0f0-472d-a477-3437b34c3d52,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-58166566-ad85-46cd-b9ee-c2aeb01d6651,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-a62c319b-0f84-4d8c-86c5-77be3d7bfc16,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-1d416107-f7ca-45de-9214-5ef75ffb7ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-a603984e-0754-48a1-9e7a-3d8db4cdbafe,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-335f7895-c858-4784-8c09-51d012179337,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-a70a047d-ea88-4cbb-be61-2030f981625d,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-678d7c35-0535-4caa-81f1-575c53a9084f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52648793-172.17.0.7-1598389406327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38907,DS-5b3f9af7-f0f0-472d-a477-3437b34c3d52,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-58166566-ad85-46cd-b9ee-c2aeb01d6651,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-a62c319b-0f84-4d8c-86c5-77be3d7bfc16,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-1d416107-f7ca-45de-9214-5ef75ffb7ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-a603984e-0754-48a1-9e7a-3d8db4cdbafe,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-335f7895-c858-4784-8c09-51d012179337,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-a70a047d-ea88-4cbb-be61-2030f981625d,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-678d7c35-0535-4caa-81f1-575c53a9084f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152731676-172.17.0.7-1598389699468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33429,DS-740b266e-885b-4910-8e97-2c8877b77679,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-01c2a7b5-ba74-4885-b3b3-c626fd19aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-2b0035b0-df44-4ced-8060-a552aa0baae0,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-b0916e19-14a4-404d-92c7-9c2f1b59cf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-ed646bbe-ed7a-4544-a031-f4da306d415d,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-37f9e806-a955-423f-a614-a431950e439b,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-7c08d424-f44c-4828-a4b5-850736467ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-e318b743-92b7-462a-b8e6-4b4eafe4eda8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152731676-172.17.0.7-1598389699468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33429,DS-740b266e-885b-4910-8e97-2c8877b77679,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-01c2a7b5-ba74-4885-b3b3-c626fd19aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-2b0035b0-df44-4ced-8060-a552aa0baae0,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-b0916e19-14a4-404d-92c7-9c2f1b59cf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-ed646bbe-ed7a-4544-a031-f4da306d415d,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-37f9e806-a955-423f-a614-a431950e439b,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-7c08d424-f44c-4828-a4b5-850736467ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-e318b743-92b7-462a-b8e6-4b4eafe4eda8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5311
