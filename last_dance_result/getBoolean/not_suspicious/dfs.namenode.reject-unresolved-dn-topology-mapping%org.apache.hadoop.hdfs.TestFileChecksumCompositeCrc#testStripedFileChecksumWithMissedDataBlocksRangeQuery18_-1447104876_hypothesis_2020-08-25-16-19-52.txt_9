reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862064854-172.17.0.17-1598372602167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46697,DS-c3b9bfe7-f0d3-4e26-a2fd-49c9b21c0e45,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-99dd068f-96dc-4fb1-9dcd-ffeaafb7de2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-57c376e9-a46a-42e2-b546-32e58fd2f28c,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-33d1cd3c-e999-4212-a588-2d526c6b4a19,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-a21560a3-0e6f-46a4-b478-668db04dff0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-cefda27d-7077-4226-a452-c1da61ae35db,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-fa4b3bfa-5f19-4e5a-97fe-14409e20d6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-bf7ecb25-5927-4465-ac78-2a21e4e292b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862064854-172.17.0.17-1598372602167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46697,DS-c3b9bfe7-f0d3-4e26-a2fd-49c9b21c0e45,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-99dd068f-96dc-4fb1-9dcd-ffeaafb7de2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-57c376e9-a46a-42e2-b546-32e58fd2f28c,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-33d1cd3c-e999-4212-a588-2d526c6b4a19,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-a21560a3-0e6f-46a4-b478-668db04dff0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-cefda27d-7077-4226-a452-c1da61ae35db,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-fa4b3bfa-5f19-4e5a-97fe-14409e20d6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-bf7ecb25-5927-4465-ac78-2a21e4e292b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328802873-172.17.0.17-1598372960897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39108,DS-5f999eb6-1387-4882-9503-a7867ae611db,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-81161617-7a73-46d2-bd72-11e94000f6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-a70bb855-3994-4c64-9a7d-b2132d839ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-dcc5a1ee-76b4-417c-a565-ef7d59f5fbac,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-98274f68-0161-4ef4-998c-4758c9282482,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-c97a2c78-0d81-4ec2-ba1e-870cb649f4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-cf477fea-aae7-4bc9-85aa-0ebde6f0e23d,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-965cfaaa-2a5a-47c6-a97b-4ff00f6c6f56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328802873-172.17.0.17-1598372960897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39108,DS-5f999eb6-1387-4882-9503-a7867ae611db,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-81161617-7a73-46d2-bd72-11e94000f6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-a70bb855-3994-4c64-9a7d-b2132d839ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-dcc5a1ee-76b4-417c-a565-ef7d59f5fbac,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-98274f68-0161-4ef4-998c-4758c9282482,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-c97a2c78-0d81-4ec2-ba1e-870cb649f4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-cf477fea-aae7-4bc9-85aa-0ebde6f0e23d,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-965cfaaa-2a5a-47c6-a97b-4ff00f6c6f56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-814136380-172.17.0.17-1598373052654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33688,DS-22842c90-efff-4963-829e-086e60828c65,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-103e8173-ff7e-4b3b-8faf-7e3275452c90,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-5d90597c-6161-4a1f-a743-e5d47516fa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-eb6e7442-0d56-46fa-868d-d28aba1a4170,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-8d843fce-a40d-4d3c-913a-bf19bdc4bbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-2b8fffdb-6613-4891-882e-0534b0969cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-bd2d2eef-3b67-4665-9e14-d875446630f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-766a4e91-9b6f-45b3-9da7-777a31fbfef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-814136380-172.17.0.17-1598373052654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33688,DS-22842c90-efff-4963-829e-086e60828c65,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-103e8173-ff7e-4b3b-8faf-7e3275452c90,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-5d90597c-6161-4a1f-a743-e5d47516fa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-eb6e7442-0d56-46fa-868d-d28aba1a4170,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-8d843fce-a40d-4d3c-913a-bf19bdc4bbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-2b8fffdb-6613-4891-882e-0534b0969cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-bd2d2eef-3b67-4665-9e14-d875446630f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-766a4e91-9b6f-45b3-9da7-777a31fbfef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-181750131-172.17.0.17-1598373124045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35062,DS-cfe1e569-66b1-442c-a69f-e3998604eb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-c2bceeb2-c744-4d39-8483-0095d69c8ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-fe895f15-3882-4ba3-b040-4b31b5403bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-9cce26c6-4aed-47dc-a4df-04e78cd34088,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-f52f9cd8-9fd2-421a-947f-dca00f2ac868,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-870829c3-e4c6-48d1-97b5-04ab4341c98e,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-72420639-31e9-4b5e-b915-01e47077c56b,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-85996ede-2dd3-4e2a-ae7e-b7ea7642d265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-181750131-172.17.0.17-1598373124045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35062,DS-cfe1e569-66b1-442c-a69f-e3998604eb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-c2bceeb2-c744-4d39-8483-0095d69c8ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-fe895f15-3882-4ba3-b040-4b31b5403bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-9cce26c6-4aed-47dc-a4df-04e78cd34088,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-f52f9cd8-9fd2-421a-947f-dca00f2ac868,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-870829c3-e4c6-48d1-97b5-04ab4341c98e,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-72420639-31e9-4b5e-b915-01e47077c56b,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-85996ede-2dd3-4e2a-ae7e-b7ea7642d265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1857155972-172.17.0.17-1598373155989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46188,DS-1c0186b9-5478-4f0f-8317-791a5ac2d498,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-ee2777db-8711-475d-a953-949c37031c08,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-7568e1c1-9862-46fc-8d67-4fbcbe68bf50,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-9d91fe8c-565d-4274-81c4-6f9f4840e91b,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-9f1e0d5b-f5a9-43f8-81ba-90aa1b52a0de,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-f3b3cde8-2814-4736-a2dd-29a03eeda47c,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-fa9d182c-bc56-4268-902b-f8e6f33d523d,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-749471cf-ab1f-4673-a372-233262339526,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1857155972-172.17.0.17-1598373155989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46188,DS-1c0186b9-5478-4f0f-8317-791a5ac2d498,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-ee2777db-8711-475d-a953-949c37031c08,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-7568e1c1-9862-46fc-8d67-4fbcbe68bf50,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-9d91fe8c-565d-4274-81c4-6f9f4840e91b,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-9f1e0d5b-f5a9-43f8-81ba-90aa1b52a0de,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-f3b3cde8-2814-4736-a2dd-29a03eeda47c,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-fa9d182c-bc56-4268-902b-f8e6f33d523d,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-749471cf-ab1f-4673-a372-233262339526,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181506655-172.17.0.17-1598373361118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46631,DS-31c8133d-671a-4d3f-9301-5314362d526b,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-cea44f6c-20b2-4479-b8aa-54a5ad8fe27f,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-387bb92b-eb2b-4bb9-a53f-c6664b748e44,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-a26152f0-6481-4219-a066-057ed99bf4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-0c91a7ca-708b-4564-9cd5-79d0654eab3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-3c754763-408d-417d-a694-125e1354709b,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-9180f0d1-b14e-4554-bf9c-e47aa1344a39,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-5d2f2495-6657-4670-96a6-6190866e251b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181506655-172.17.0.17-1598373361118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46631,DS-31c8133d-671a-4d3f-9301-5314362d526b,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-cea44f6c-20b2-4479-b8aa-54a5ad8fe27f,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-387bb92b-eb2b-4bb9-a53f-c6664b748e44,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-a26152f0-6481-4219-a066-057ed99bf4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-0c91a7ca-708b-4564-9cd5-79d0654eab3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-3c754763-408d-417d-a694-125e1354709b,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-9180f0d1-b14e-4554-bf9c-e47aa1344a39,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-5d2f2495-6657-4670-96a6-6190866e251b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1949608648-172.17.0.17-1598373465239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40327,DS-de849126-cadf-4aa8-9511-b30ee9f1c94b,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-b96624fd-3ad6-4dd6-a77e-cd4dc397ba6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-28869154-72d5-4116-a9b8-6822b6fd9899,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-de09c6e3-f461-4ff3-add1-792ebc2b966e,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-84f57200-3722-416e-a3dd-d9c4e775b37b,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-5fff3490-18d8-42b8-b2a8-4d4d6f0ac0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-d29b08f1-7217-4c87-baa2-16ad9d5387cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-9babbaca-ea99-4e85-ae61-0b0c75aebbe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1949608648-172.17.0.17-1598373465239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40327,DS-de849126-cadf-4aa8-9511-b30ee9f1c94b,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-b96624fd-3ad6-4dd6-a77e-cd4dc397ba6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-28869154-72d5-4116-a9b8-6822b6fd9899,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-de09c6e3-f461-4ff3-add1-792ebc2b966e,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-84f57200-3722-416e-a3dd-d9c4e775b37b,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-5fff3490-18d8-42b8-b2a8-4d4d6f0ac0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-d29b08f1-7217-4c87-baa2-16ad9d5387cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-9babbaca-ea99-4e85-ae61-0b0c75aebbe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577101961-172.17.0.17-1598373639654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38258,DS-0f88ac44-8d55-43ff-bb73-143d94575eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-744cc11b-8a85-44aa-9291-c51b087af171,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-d48f5a02-c990-4900-be15-38a7ae3f73a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-b88b41cf-ef2d-4fd3-bab8-20835611b0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-ce8b1be5-524e-45bd-82fb-a7d001981ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-9707efdc-9d43-4c53-8c6e-bde250d67607,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-1b7053a5-3c93-41d0-b867-3a2f6c155426,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-d3f930f5-8eb7-4b77-8490-6633b7284321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577101961-172.17.0.17-1598373639654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38258,DS-0f88ac44-8d55-43ff-bb73-143d94575eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-744cc11b-8a85-44aa-9291-c51b087af171,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-d48f5a02-c990-4900-be15-38a7ae3f73a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-b88b41cf-ef2d-4fd3-bab8-20835611b0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-ce8b1be5-524e-45bd-82fb-a7d001981ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-9707efdc-9d43-4c53-8c6e-bde250d67607,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-1b7053a5-3c93-41d0-b867-3a2f6c155426,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-d3f930f5-8eb7-4b77-8490-6633b7284321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124826441-172.17.0.17-1598373873736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45768,DS-b7d2f7c2-a0de-4463-b040-1e97a601af2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-fd4a768e-1a82-4f1a-a36c-f5a12176aa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-3c3a2d95-119b-446b-9ba3-837038594285,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-7733e95b-3ef3-4c56-9101-7655994d9b69,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-e22f9390-9af0-4852-aa13-9e04d8cfc3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-c9dec882-1417-483b-85de-ca5a0438a897,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-c37d136c-2774-4300-ac67-f0fc81a78137,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-4cfc9328-7568-4720-b3f7-6598660a5624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124826441-172.17.0.17-1598373873736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45768,DS-b7d2f7c2-a0de-4463-b040-1e97a601af2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-fd4a768e-1a82-4f1a-a36c-f5a12176aa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-3c3a2d95-119b-446b-9ba3-837038594285,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-7733e95b-3ef3-4c56-9101-7655994d9b69,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-e22f9390-9af0-4852-aa13-9e04d8cfc3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-c9dec882-1417-483b-85de-ca5a0438a897,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-c37d136c-2774-4300-ac67-f0fc81a78137,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-4cfc9328-7568-4720-b3f7-6598660a5624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607724171-172.17.0.17-1598374250488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37630,DS-3d466a32-ae7c-4221-a3e9-67c1aee4122d,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-aa7c587b-7ebd-423b-b384-032b02c8fc45,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-eac56a7b-9e1c-4959-82f6-00fcc57f9679,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-b4a786c1-ea6d-434e-9419-2765461f3e98,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-4cd1b43d-6ea3-4bb2-8df8-eaaec6ecf4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-9e255d2e-65b6-423c-b145-813c1ed83aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-dfb7a04f-ff60-4285-b90a-2340abe9d8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-70e21b28-0a4b-4e0e-a931-1089c427cb39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607724171-172.17.0.17-1598374250488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37630,DS-3d466a32-ae7c-4221-a3e9-67c1aee4122d,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-aa7c587b-7ebd-423b-b384-032b02c8fc45,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-eac56a7b-9e1c-4959-82f6-00fcc57f9679,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-b4a786c1-ea6d-434e-9419-2765461f3e98,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-4cd1b43d-6ea3-4bb2-8df8-eaaec6ecf4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-9e255d2e-65b6-423c-b145-813c1ed83aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-dfb7a04f-ff60-4285-b90a-2340abe9d8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-70e21b28-0a4b-4e0e-a931-1089c427cb39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413974734-172.17.0.17-1598374656950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40533,DS-71c811e8-5909-4101-87d0-81eacf657b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-509400cb-afdb-4898-9759-77f59a476dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-6cbf04c7-82bc-4fba-abbb-ad6a039a65b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-339747d0-df18-4c3f-b800-581b408971f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-9d7b251d-8615-403e-a0e8-8e8f52c51766,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-cfd8b5d3-d8d5-47a6-9f15-7536679e8746,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-4ce08a50-f489-43e1-9b45-b20cb4f2fcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-b4b8d59e-a321-47f6-999a-8eee55a8ec20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413974734-172.17.0.17-1598374656950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40533,DS-71c811e8-5909-4101-87d0-81eacf657b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-509400cb-afdb-4898-9759-77f59a476dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-6cbf04c7-82bc-4fba-abbb-ad6a039a65b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-339747d0-df18-4c3f-b800-581b408971f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-9d7b251d-8615-403e-a0e8-8e8f52c51766,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-cfd8b5d3-d8d5-47a6-9f15-7536679e8746,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-4ce08a50-f489-43e1-9b45-b20cb4f2fcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-b4b8d59e-a321-47f6-999a-8eee55a8ec20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-410691336-172.17.0.17-1598375405202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35998,DS-a55cc6b2-fa55-49dd-b4d9-d09eaba6d55d,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-dd43ba93-d695-448a-8ff5-a8f4fccec2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-98f4e23a-0406-4c60-838f-c0f30285a74b,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-5d64e505-bda2-413c-b948-fdc895cc48ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-bc0863f6-9fd7-4475-91e8-5535a149e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-52126857-fa13-4faf-b0d8-2f1770c6c40d,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-264a69c5-f890-4c20-af83-e46bff50bdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-0d0f8f00-028c-4a0f-a105-12631fc2b84c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-410691336-172.17.0.17-1598375405202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35998,DS-a55cc6b2-fa55-49dd-b4d9-d09eaba6d55d,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-dd43ba93-d695-448a-8ff5-a8f4fccec2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-98f4e23a-0406-4c60-838f-c0f30285a74b,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-5d64e505-bda2-413c-b948-fdc895cc48ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-bc0863f6-9fd7-4475-91e8-5535a149e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-52126857-fa13-4faf-b0d8-2f1770c6c40d,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-264a69c5-f890-4c20-af83-e46bff50bdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-0d0f8f00-028c-4a0f-a105-12631fc2b84c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2122730252-172.17.0.17-1598375470838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42692,DS-f823ab2e-a57d-4b1b-8485-25e67151405b,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-6c2cf1bf-6019-44f8-bc1e-41b0f8c09a70,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-5019e747-e01c-4cf7-8813-ef912540cb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-00261347-45fd-46ff-86db-56188a14335c,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-4c631a2e-8be1-4319-a1d9-c75049700ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-992453ba-5b6f-4a22-854d-f8c4abd10964,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-92f9ab40-af44-47ce-b57c-045f031d0a42,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-54ccd6d8-023e-4cc9-b448-229ab3a4db40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2122730252-172.17.0.17-1598375470838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42692,DS-f823ab2e-a57d-4b1b-8485-25e67151405b,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-6c2cf1bf-6019-44f8-bc1e-41b0f8c09a70,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-5019e747-e01c-4cf7-8813-ef912540cb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-00261347-45fd-46ff-86db-56188a14335c,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-4c631a2e-8be1-4319-a1d9-c75049700ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-992453ba-5b6f-4a22-854d-f8c4abd10964,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-92f9ab40-af44-47ce-b57c-045f031d0a42,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-54ccd6d8-023e-4cc9-b448-229ab3a4db40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279736958-172.17.0.17-1598375503134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34864,DS-0bd13e80-883b-4c92-8bc9-81b6793dd6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-eda39c7c-5273-4e72-a552-fa10eed6cf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-50693096-2e74-42c8-b8df-078d4a6f02af,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-08ee777c-2816-4f77-ae76-794a5da66893,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-7dfeee93-3c5d-4b58-a598-6b0fb90a3920,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-95b01708-b1a5-43c2-b050-d3306884db09,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-e82fe35c-a90b-4813-900b-4a834752914c,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-7886c080-c383-4d49-adce-c83d8a605818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279736958-172.17.0.17-1598375503134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34864,DS-0bd13e80-883b-4c92-8bc9-81b6793dd6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-eda39c7c-5273-4e72-a552-fa10eed6cf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-50693096-2e74-42c8-b8df-078d4a6f02af,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-08ee777c-2816-4f77-ae76-794a5da66893,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-7dfeee93-3c5d-4b58-a598-6b0fb90a3920,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-95b01708-b1a5-43c2-b050-d3306884db09,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-e82fe35c-a90b-4813-900b-4a834752914c,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-7886c080-c383-4d49-adce-c83d8a605818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027595657-172.17.0.17-1598375731449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41403,DS-7bffefff-90b1-4085-9df5-3f5839d7d0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-2a0cc9e1-5282-46be-8024-f9225b99f1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-e01e6b95-5f6e-4c56-adef-1fcc951ea692,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-57452c15-959a-422a-812c-cd16c63aa623,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-f8fd288a-432c-4005-b2a2-2e80c96774ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-0720cdbd-9606-4954-8fd0-2b91770fa797,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-a6762b34-2e48-48cf-8c85-7685f793b22c,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-e97ce8ed-a7d6-41f0-83b1-2a649d91d98a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027595657-172.17.0.17-1598375731449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41403,DS-7bffefff-90b1-4085-9df5-3f5839d7d0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-2a0cc9e1-5282-46be-8024-f9225b99f1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-e01e6b95-5f6e-4c56-adef-1fcc951ea692,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-57452c15-959a-422a-812c-cd16c63aa623,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-f8fd288a-432c-4005-b2a2-2e80c96774ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-0720cdbd-9606-4954-8fd0-2b91770fa797,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-a6762b34-2e48-48cf-8c85-7685f793b22c,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-e97ce8ed-a7d6-41f0-83b1-2a649d91d98a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624367992-172.17.0.17-1598376405551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39586,DS-4d2e6586-2ff2-422f-8693-8067d3396117,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-c9b4c949-88c5-48dc-b141-0ec2f6fc0a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-31fe5f5d-ecab-4c6d-ab24-462d29268719,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-40837840-d5e0-4921-9c4f-d521c0fa5d47,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-eda412e9-386d-42fa-a4e7-82f28505b84d,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-9247cbb5-608f-43de-ab28-0e3380bba547,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-aaf6274b-1abc-4cd4-9daf-cad1cd6a8813,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-27a506a3-8bdd-48a5-8108-819950bddde7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624367992-172.17.0.17-1598376405551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39586,DS-4d2e6586-2ff2-422f-8693-8067d3396117,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-c9b4c949-88c5-48dc-b141-0ec2f6fc0a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-31fe5f5d-ecab-4c6d-ab24-462d29268719,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-40837840-d5e0-4921-9c4f-d521c0fa5d47,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-eda412e9-386d-42fa-a4e7-82f28505b84d,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-9247cbb5-608f-43de-ab28-0e3380bba547,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-aaf6274b-1abc-4cd4-9daf-cad1cd6a8813,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-27a506a3-8bdd-48a5-8108-819950bddde7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575819364-172.17.0.17-1598376736690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35688,DS-7d74fbb2-d9ad-45f8-9237-c629ab70227c,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-5418316a-f57b-423c-82b3-212980848742,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-9975941e-6979-40a3-a01c-04c2e0a3ca79,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-a247d89f-e102-4e01-bc22-31e0265e99b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-c050fed9-1fe7-4915-9f51-5740b27016a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-90efac4e-0767-4168-bcb6-6a0a454cb429,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-4ab5f141-0d98-477b-8c87-3193632ebe01,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-6b2a7c45-7606-48e5-8ae7-3748a36a9f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575819364-172.17.0.17-1598376736690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35688,DS-7d74fbb2-d9ad-45f8-9237-c629ab70227c,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-5418316a-f57b-423c-82b3-212980848742,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-9975941e-6979-40a3-a01c-04c2e0a3ca79,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-a247d89f-e102-4e01-bc22-31e0265e99b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-c050fed9-1fe7-4915-9f51-5740b27016a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-90efac4e-0767-4168-bcb6-6a0a454cb429,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-4ab5f141-0d98-477b-8c87-3193632ebe01,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-6b2a7c45-7606-48e5-8ae7-3748a36a9f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693957537-172.17.0.17-1598376763522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-09cdd550-e65f-4198-9b23-d0e17a4dda02,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-fa75d80e-58fc-499f-bc5f-b811f5f08a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-b1ca3acc-295f-4a6f-8273-5782d4770ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-e6d1e0f3-17ee-4b1e-bc2a-5a0a7c9f0898,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-c43f35c7-2501-45ec-80ad-e7df0e943436,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-966b9e51-d371-49f6-bc9d-2b24aa3e096b,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-8e4ed4ba-2c95-45c9-9c27-273c528590b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-664286b5-1bfe-4d97-b537-f5e2058468ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693957537-172.17.0.17-1598376763522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-09cdd550-e65f-4198-9b23-d0e17a4dda02,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-fa75d80e-58fc-499f-bc5f-b811f5f08a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-b1ca3acc-295f-4a6f-8273-5782d4770ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-e6d1e0f3-17ee-4b1e-bc2a-5a0a7c9f0898,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-c43f35c7-2501-45ec-80ad-e7df0e943436,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-966b9e51-d371-49f6-bc9d-2b24aa3e096b,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-8e4ed4ba-2c95-45c9-9c27-273c528590b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-664286b5-1bfe-4d97-b537-f5e2058468ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5111
