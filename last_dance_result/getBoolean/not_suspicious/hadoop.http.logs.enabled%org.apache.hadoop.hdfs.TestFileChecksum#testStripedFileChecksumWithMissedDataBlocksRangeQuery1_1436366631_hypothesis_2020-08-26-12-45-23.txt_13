reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707689762-172.17.0.13-1598446048936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41722,DS-6ad90847-728e-423c-ad68-bd8d37c77ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-1adb8f00-4d93-4b4d-b0b9-cb548641f107,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-bc36b402-bc55-4375-adde-cdefcd7dfa62,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-e28cf54b-7ddd-42cc-89bb-2b78b45e0992,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-d1577c6e-2e46-414c-b44b-88c6f7c75928,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-9e79e614-7598-4536-b8e5-a828df8ec32e,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-06c1c8f9-00ef-4e43-8323-60e5d4e2a651,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-847600d5-694e-411e-ac83-2627ff475c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707689762-172.17.0.13-1598446048936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41722,DS-6ad90847-728e-423c-ad68-bd8d37c77ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-1adb8f00-4d93-4b4d-b0b9-cb548641f107,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-bc36b402-bc55-4375-adde-cdefcd7dfa62,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-e28cf54b-7ddd-42cc-89bb-2b78b45e0992,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-d1577c6e-2e46-414c-b44b-88c6f7c75928,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-9e79e614-7598-4536-b8e5-a828df8ec32e,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-06c1c8f9-00ef-4e43-8323-60e5d4e2a651,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-847600d5-694e-411e-ac83-2627ff475c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544031059-172.17.0.13-1598446278613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36146,DS-c8b91f95-3d02-401d-9a0f-9383be5ff062,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-913be04f-1f19-4c88-9455-e8309bdf615e,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-df55a598-a3aa-4c5f-914d-65e72a2ecd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-80b1f4f3-ed1b-42e5-82b0-55e600a55c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-be8e4631-189e-419f-b801-a941c0262c69,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-0584c858-832b-4015-a319-8498202a6960,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-dfb4a9b1-9f34-43d4-ab36-ccd30299b4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-4c09a416-b57a-445e-8375-ae2bd5522eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544031059-172.17.0.13-1598446278613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36146,DS-c8b91f95-3d02-401d-9a0f-9383be5ff062,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-913be04f-1f19-4c88-9455-e8309bdf615e,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-df55a598-a3aa-4c5f-914d-65e72a2ecd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-80b1f4f3-ed1b-42e5-82b0-55e600a55c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-be8e4631-189e-419f-b801-a941c0262c69,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-0584c858-832b-4015-a319-8498202a6960,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-dfb4a9b1-9f34-43d4-ab36-ccd30299b4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-4c09a416-b57a-445e-8375-ae2bd5522eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1179442173-172.17.0.13-1598447275189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42480,DS-b150395f-6a0e-4f6e-8409-dc043996987d,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-93b362c8-5b57-44d2-90f6-c30b598165e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-6f17453d-0b33-4dc1-b0d5-8042450a86c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-7292522c-24d6-4ffe-bfb1-e1a7fb6d6442,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-53a073aa-714a-43f4-9db3-44fa8b45197f,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-9e1d9ccb-e027-42c7-936e-df4cf2f9e454,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-2de43f64-34d0-49ef-8019-91c479840e57,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-30c59291-ddd2-4b8f-8d5e-7966e8836281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1179442173-172.17.0.13-1598447275189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42480,DS-b150395f-6a0e-4f6e-8409-dc043996987d,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-93b362c8-5b57-44d2-90f6-c30b598165e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-6f17453d-0b33-4dc1-b0d5-8042450a86c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-7292522c-24d6-4ffe-bfb1-e1a7fb6d6442,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-53a073aa-714a-43f4-9db3-44fa8b45197f,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-9e1d9ccb-e027-42c7-936e-df4cf2f9e454,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-2de43f64-34d0-49ef-8019-91c479840e57,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-30c59291-ddd2-4b8f-8d5e-7966e8836281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307661512-172.17.0.13-1598447819359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45250,DS-7eb2106e-fc38-49f5-b119-2a2236a1631e,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-dd29650f-d95a-4689-8f34-d00edeb2dc16,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-c97bf7ab-146b-40e5-bf3a-8b7af718679b,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-35a15cf9-5b8b-461f-acee-5550486cbfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-0be111f9-9ed4-469f-8e91-6ba11249d247,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-de0fc66b-c663-41a9-8d11-3de308aed7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-d9ea1416-4b08-4a1c-be6a-1cbc707f38e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-5d231b77-9023-4c98-9b28-030f60942f4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307661512-172.17.0.13-1598447819359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45250,DS-7eb2106e-fc38-49f5-b119-2a2236a1631e,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-dd29650f-d95a-4689-8f34-d00edeb2dc16,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-c97bf7ab-146b-40e5-bf3a-8b7af718679b,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-35a15cf9-5b8b-461f-acee-5550486cbfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-0be111f9-9ed4-469f-8e91-6ba11249d247,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-de0fc66b-c663-41a9-8d11-3de308aed7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-d9ea1416-4b08-4a1c-be6a-1cbc707f38e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-5d231b77-9023-4c98-9b28-030f60942f4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647213136-172.17.0.13-1598448290449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35171,DS-ada91ad0-c9e8-4308-8648-ec26c6b5a4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-4effaf10-194c-4ca1-81b0-18a3f32e052e,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-74f51475-7ad7-4705-9e94-90597803ee8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-ec16297e-e746-495b-931f-6414861b63b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-425aaadf-e15b-41e2-84cf-75a88e703e61,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-94d70653-daa5-4764-ad9c-e63ecdd1c22f,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-cf8d3c84-8bb6-4b62-936a-c7e09da0fa93,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-1f0014cc-52f3-4aa3-9d4e-49dc5ee9ab14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647213136-172.17.0.13-1598448290449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35171,DS-ada91ad0-c9e8-4308-8648-ec26c6b5a4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-4effaf10-194c-4ca1-81b0-18a3f32e052e,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-74f51475-7ad7-4705-9e94-90597803ee8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-ec16297e-e746-495b-931f-6414861b63b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-425aaadf-e15b-41e2-84cf-75a88e703e61,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-94d70653-daa5-4764-ad9c-e63ecdd1c22f,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-cf8d3c84-8bb6-4b62-936a-c7e09da0fa93,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-1f0014cc-52f3-4aa3-9d4e-49dc5ee9ab14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141846826-172.17.0.13-1598448425327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44683,DS-bfbd94f0-60f5-49c7-9ff2-7ec420c1641c,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-e2f966d6-2e28-4e1e-8a59-43b1c8fc4448,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-bd26382e-af5b-4078-a551-485eaacc4a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-dcbf0f10-0f25-4aa4-b2dc-52b4ed430cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-a824d771-f1c8-47b5-9285-4a22879f4c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-19f44d60-3979-46f3-b01b-af4743a2e61a,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-0c75bb0e-aea6-407d-8e3a-0c2b6b818f78,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-ef30ace9-8095-4554-bc0c-b65c7b9bc874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141846826-172.17.0.13-1598448425327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44683,DS-bfbd94f0-60f5-49c7-9ff2-7ec420c1641c,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-e2f966d6-2e28-4e1e-8a59-43b1c8fc4448,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-bd26382e-af5b-4078-a551-485eaacc4a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-dcbf0f10-0f25-4aa4-b2dc-52b4ed430cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-a824d771-f1c8-47b5-9285-4a22879f4c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-19f44d60-3979-46f3-b01b-af4743a2e61a,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-0c75bb0e-aea6-407d-8e3a-0c2b6b818f78,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-ef30ace9-8095-4554-bc0c-b65c7b9bc874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079591464-172.17.0.13-1598448701981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37317,DS-a617d256-57cc-447a-a52b-782e4f4878c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-998d137d-ab3b-483e-a74a-9d8da5cdd5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-f31493f5-a7d6-466f-95e1-1643caeea470,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-acd64f24-ba67-45a8-9794-96f950199b92,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-915808ac-81e7-43e5-a3a2-6ff273d1312d,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-557dbba3-55d0-4b38-87dc-bc893da7c5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-73fb070e-8d55-4a72-88ea-1edea170bdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-6c6353c2-4ab9-4752-85a0-5e54574cb177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079591464-172.17.0.13-1598448701981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37317,DS-a617d256-57cc-447a-a52b-782e4f4878c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-998d137d-ab3b-483e-a74a-9d8da5cdd5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-f31493f5-a7d6-466f-95e1-1643caeea470,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-acd64f24-ba67-45a8-9794-96f950199b92,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-915808ac-81e7-43e5-a3a2-6ff273d1312d,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-557dbba3-55d0-4b38-87dc-bc893da7c5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-73fb070e-8d55-4a72-88ea-1edea170bdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-6c6353c2-4ab9-4752-85a0-5e54574cb177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984548104-172.17.0.13-1598448808613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32953,DS-5219fb06-d6ca-4cb5-9e44-e2317ec4711d,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-5b535364-202e-4f51-8074-384f73001d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-4a29d257-e10e-46eb-9321-b770a81de86b,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-0af5341f-8c2c-49cc-bb89-3ff2b98b8aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-1da19b41-4d1f-4563-9ac7-b5db1ef55a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-d87279f8-74b2-447d-8219-d33ffea4599f,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-bfbc96ed-6448-4fc7-a8b7-c0ca9ee584c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-2c2cb78f-aaca-40cf-a693-b7cdf28935fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984548104-172.17.0.13-1598448808613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32953,DS-5219fb06-d6ca-4cb5-9e44-e2317ec4711d,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-5b535364-202e-4f51-8074-384f73001d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-4a29d257-e10e-46eb-9321-b770a81de86b,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-0af5341f-8c2c-49cc-bb89-3ff2b98b8aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-1da19b41-4d1f-4563-9ac7-b5db1ef55a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-d87279f8-74b2-447d-8219-d33ffea4599f,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-bfbc96ed-6448-4fc7-a8b7-c0ca9ee584c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-2c2cb78f-aaca-40cf-a693-b7cdf28935fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282462886-172.17.0.13-1598449080558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44077,DS-c386e3af-f3c8-4a59-b69a-da462d5c0a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-bbdcc993-e29a-4412-b63b-e82291312c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-e7151053-9150-49d8-9fa3-42f4e3c219de,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-87b70e83-e188-4fa0-8362-729be6eade70,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-2bf4d89c-c8a7-4638-91e5-e046e19a9c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-fe639c92-23d3-43e6-b957-f4cfb7d364b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-f03d5e60-4f88-43a4-a85c-a2d5b402eec2,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-ca32d9f3-e82c-4eb4-afd2-142ceff4fe7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282462886-172.17.0.13-1598449080558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44077,DS-c386e3af-f3c8-4a59-b69a-da462d5c0a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-bbdcc993-e29a-4412-b63b-e82291312c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-e7151053-9150-49d8-9fa3-42f4e3c219de,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-87b70e83-e188-4fa0-8362-729be6eade70,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-2bf4d89c-c8a7-4638-91e5-e046e19a9c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-fe639c92-23d3-43e6-b957-f4cfb7d364b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-f03d5e60-4f88-43a4-a85c-a2d5b402eec2,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-ca32d9f3-e82c-4eb4-afd2-142ceff4fe7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978613425-172.17.0.13-1598449867302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37775,DS-7e760ede-16d0-4524-a919-0c3caa0a7ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-29deea80-2b66-487e-a841-bbba81f2b7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-54bb31f5-5f32-4a00-ac4f-a5f5b0711efd,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-4ad4663e-2cdf-4908-8c0b-3ea6e05eb035,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-ad0dc88f-64d5-482d-8c50-14939ded5edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-02c7ac42-a2c5-4aac-9737-2a43d98f461e,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-7b68395a-5ab1-45cd-8866-b7207999ec04,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-24264b1d-1a84-493c-9b0d-88fe85ab6e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978613425-172.17.0.13-1598449867302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37775,DS-7e760ede-16d0-4524-a919-0c3caa0a7ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-29deea80-2b66-487e-a841-bbba81f2b7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-54bb31f5-5f32-4a00-ac4f-a5f5b0711efd,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-4ad4663e-2cdf-4908-8c0b-3ea6e05eb035,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-ad0dc88f-64d5-482d-8c50-14939ded5edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-02c7ac42-a2c5-4aac-9737-2a43d98f461e,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-7b68395a-5ab1-45cd-8866-b7207999ec04,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-24264b1d-1a84-493c-9b0d-88fe85ab6e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381516198-172.17.0.13-1598449903325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37660,DS-c1b7b963-7738-46dc-909e-a75629151a70,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-333bdeff-6d30-4974-87aa-d1759aa55ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-73c1f286-c4e5-4499-96e3-bfe7fe31bd13,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-ea82e64a-2484-4f29-872b-4aeb52a47d71,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-616283f3-e9bc-4749-8120-5ff9fb617209,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-c2feb3a4-9511-42a4-b9a0-5f2b7c584cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-487a301e-1844-4f9f-8ed5-e21108e1da4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-6da61d8c-8d8f-4d6c-ad5f-11ca9262f3a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381516198-172.17.0.13-1598449903325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37660,DS-c1b7b963-7738-46dc-909e-a75629151a70,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-333bdeff-6d30-4974-87aa-d1759aa55ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-73c1f286-c4e5-4499-96e3-bfe7fe31bd13,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-ea82e64a-2484-4f29-872b-4aeb52a47d71,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-616283f3-e9bc-4749-8120-5ff9fb617209,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-c2feb3a4-9511-42a4-b9a0-5f2b7c584cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-487a301e-1844-4f9f-8ed5-e21108e1da4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-6da61d8c-8d8f-4d6c-ad5f-11ca9262f3a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004247668-172.17.0.13-1598450152566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41852,DS-2321c12a-4186-4c08-b762-b8c87ab8b844,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-74fda706-7ee4-4a93-be89-2c94b6767087,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-fc0f7010-5bc8-4f26-bc3a-5d6a677aa72f,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-7704ac3e-1351-44ec-8d8a-055b07fdd834,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-78d6d222-1015-4784-a0eb-0d68b2d17a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-d2679ebe-d4bc-4f47-b197-4bdba7ed6e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-5ca5c4a3-84d6-46ff-935a-34c6a01a8398,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-c5bac2fd-2275-48cd-8279-d146c5559866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004247668-172.17.0.13-1598450152566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41852,DS-2321c12a-4186-4c08-b762-b8c87ab8b844,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-74fda706-7ee4-4a93-be89-2c94b6767087,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-fc0f7010-5bc8-4f26-bc3a-5d6a677aa72f,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-7704ac3e-1351-44ec-8d8a-055b07fdd834,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-78d6d222-1015-4784-a0eb-0d68b2d17a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-d2679ebe-d4bc-4f47-b197-4bdba7ed6e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-5ca5c4a3-84d6-46ff-935a-34c6a01a8398,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-c5bac2fd-2275-48cd-8279-d146c5559866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566737024-172.17.0.13-1598450883092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45860,DS-86e1e127-d0c6-4841-9175-7bab3f15b63f,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-6f06a467-fe22-45bf-91bc-2ca7ceeb90ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-9910f1fd-0972-42b3-9979-c71146af19db,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-0f3d6280-dd32-46c8-bfae-1fec1004fddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-30987eac-c86c-4339-94a3-096d45deb466,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-1dd77d13-1e85-4c0e-b413-b20a90dc042f,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-a02c1f09-f673-4f02-83cf-3366bfbd2a92,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-f88ab17e-b8d0-4680-a22f-eb1ba7643097,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566737024-172.17.0.13-1598450883092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45860,DS-86e1e127-d0c6-4841-9175-7bab3f15b63f,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-6f06a467-fe22-45bf-91bc-2ca7ceeb90ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-9910f1fd-0972-42b3-9979-c71146af19db,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-0f3d6280-dd32-46c8-bfae-1fec1004fddf,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-30987eac-c86c-4339-94a3-096d45deb466,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-1dd77d13-1e85-4c0e-b413-b20a90dc042f,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-a02c1f09-f673-4f02-83cf-3366bfbd2a92,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-f88ab17e-b8d0-4680-a22f-eb1ba7643097,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-858043254-172.17.0.13-1598451141402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37242,DS-d31aea14-a881-470e-8f2a-5d50b6f9a0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-bd36e195-6b6b-4daa-980a-e36f4ee7f622,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-2c2d3bfe-6fe0-4f4e-98d6-d7a8684de2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-6d3236ad-e82f-4e2e-959b-c02bef3f76a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-4c1e2182-daab-451f-b1b1-2d6e90bf7f08,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-85540216-3584-4d7f-8a28-89275fe3b735,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-13a1bc14-9f1d-4876-a21f-d353857e762c,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-a71a321c-4643-4e3a-be5e-8409e8a360a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-858043254-172.17.0.13-1598451141402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37242,DS-d31aea14-a881-470e-8f2a-5d50b6f9a0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-bd36e195-6b6b-4daa-980a-e36f4ee7f622,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-2c2d3bfe-6fe0-4f4e-98d6-d7a8684de2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-6d3236ad-e82f-4e2e-959b-c02bef3f76a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-4c1e2182-daab-451f-b1b1-2d6e90bf7f08,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-85540216-3584-4d7f-8a28-89275fe3b735,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-13a1bc14-9f1d-4876-a21f-d353857e762c,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-a71a321c-4643-4e3a-be5e-8409e8a360a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994694498-172.17.0.13-1598451176884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37877,DS-9542180e-574a-4863-b8bf-430b890a1dab,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-7d5e0f5c-97e8-40ef-9c1e-440f73d2047f,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-88a6b2ed-6516-4a53-8b79-0e0d8acb577d,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-bac5fd42-d4ff-4a3d-967b-6631d7c4e13a,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-418c85cc-3648-43eb-a4f1-fe79d99a0d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-ac2b0d16-e164-4e22-8b0d-d4862c0ecfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-7ac1ad70-bd91-4551-a954-645e4c75eb65,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-53de3ec4-95a7-41f4-8c8e-04b58ea974f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994694498-172.17.0.13-1598451176884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37877,DS-9542180e-574a-4863-b8bf-430b890a1dab,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-7d5e0f5c-97e8-40ef-9c1e-440f73d2047f,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-88a6b2ed-6516-4a53-8b79-0e0d8acb577d,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-bac5fd42-d4ff-4a3d-967b-6631d7c4e13a,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-418c85cc-3648-43eb-a4f1-fe79d99a0d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-ac2b0d16-e164-4e22-8b0d-d4862c0ecfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-7ac1ad70-bd91-4551-a954-645e4c75eb65,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-53de3ec4-95a7-41f4-8c8e-04b58ea974f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5345
