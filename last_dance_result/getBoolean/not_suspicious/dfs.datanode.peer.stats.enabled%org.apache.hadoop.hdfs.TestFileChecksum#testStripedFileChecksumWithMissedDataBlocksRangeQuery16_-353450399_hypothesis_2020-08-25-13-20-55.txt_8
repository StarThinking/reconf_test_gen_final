reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686758632-172.17.0.6-1598361740149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46165,DS-8a30615e-0768-4e4e-aa50-8fab23760d26,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-fea476cc-e13d-42d5-8f23-d1d77fdb66b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-0343f286-89e5-4560-a7b8-ea38334391f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-45a28849-f4ef-4b01-9b40-94cdc7519a90,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-0b401f16-5519-44b2-8f55-9887c5b44344,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-1b11a607-c791-46fb-9d54-f68ff8123805,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-28eea874-81c6-496f-ac11-bd11681024c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-19db9569-7d7c-4aa3-98f2-43ab4dac9252,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686758632-172.17.0.6-1598361740149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46165,DS-8a30615e-0768-4e4e-aa50-8fab23760d26,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-fea476cc-e13d-42d5-8f23-d1d77fdb66b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-0343f286-89e5-4560-a7b8-ea38334391f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-45a28849-f4ef-4b01-9b40-94cdc7519a90,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-0b401f16-5519-44b2-8f55-9887c5b44344,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-1b11a607-c791-46fb-9d54-f68ff8123805,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-28eea874-81c6-496f-ac11-bd11681024c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-19db9569-7d7c-4aa3-98f2-43ab4dac9252,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371558086-172.17.0.6-1598362308298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45010,DS-126c46ad-f0af-4d1a-af17-16735a983cea,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-bab5517a-58aa-4444-a19b-0c214937c3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-a9084297-242c-47ff-bf02-7a0232e6dad5,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-58f2690b-6a09-4455-b801-790e3ca4a21d,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-a412dcbc-7fa4-4e26-9f5d-89ddcc399d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-f574c066-4bdc-4117-bc3f-ab51c5d53231,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-b52584ce-b932-43e2-b01e-aeb2dc5f9647,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-8c0486b4-1784-4225-bed3-4b6ffb56ef8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371558086-172.17.0.6-1598362308298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45010,DS-126c46ad-f0af-4d1a-af17-16735a983cea,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-bab5517a-58aa-4444-a19b-0c214937c3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-a9084297-242c-47ff-bf02-7a0232e6dad5,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-58f2690b-6a09-4455-b801-790e3ca4a21d,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-a412dcbc-7fa4-4e26-9f5d-89ddcc399d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-f574c066-4bdc-4117-bc3f-ab51c5d53231,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-b52584ce-b932-43e2-b01e-aeb2dc5f9647,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-8c0486b4-1784-4225-bed3-4b6ffb56ef8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968785557-172.17.0.6-1598362569301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44902,DS-638e58a2-bcdd-47c0-b083-b31e76a46e36,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-e25777ee-5de2-4211-ab49-0602a5a3cf85,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-c2c97744-9825-4c18-996b-b9f42d5848cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-57614f58-1197-4532-8e6c-5923b83f6eed,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-10560da5-4393-438e-982f-55cf0d572f08,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-fb980c16-38be-4bba-8adc-7d1d2fe94b06,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-c9cd9e79-7eb2-4e8a-b37a-5e9e753aa7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-0e4c064c-b7bb-4ed9-8dcd-762eaf4cda3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968785557-172.17.0.6-1598362569301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44902,DS-638e58a2-bcdd-47c0-b083-b31e76a46e36,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-e25777ee-5de2-4211-ab49-0602a5a3cf85,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-c2c97744-9825-4c18-996b-b9f42d5848cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-57614f58-1197-4532-8e6c-5923b83f6eed,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-10560da5-4393-438e-982f-55cf0d572f08,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-fb980c16-38be-4bba-8adc-7d1d2fe94b06,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-c9cd9e79-7eb2-4e8a-b37a-5e9e753aa7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-0e4c064c-b7bb-4ed9-8dcd-762eaf4cda3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1122269802-172.17.0.6-1598362848479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39302,DS-5844711a-eb82-41d4-a0c7-a4e8ad8ffde2,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-445d4292-07a1-4518-be98-eb4ac25eaa64,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-013d7839-9e11-4b50-9571-00c88e8b0746,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-13888019-bd56-41e5-a8b5-7830ab9be260,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-acfe828f-8cfd-4d22-a49f-b97a61b13d97,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-989460fd-56a1-46a0-9f02-eb2530e0a184,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-09230232-b0d7-45d3-89e7-6862e2f1d791,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-f4d28120-5d32-4271-a686-fc219985c49d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1122269802-172.17.0.6-1598362848479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39302,DS-5844711a-eb82-41d4-a0c7-a4e8ad8ffde2,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-445d4292-07a1-4518-be98-eb4ac25eaa64,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-013d7839-9e11-4b50-9571-00c88e8b0746,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-13888019-bd56-41e5-a8b5-7830ab9be260,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-acfe828f-8cfd-4d22-a49f-b97a61b13d97,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-989460fd-56a1-46a0-9f02-eb2530e0a184,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-09230232-b0d7-45d3-89e7-6862e2f1d791,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-f4d28120-5d32-4271-a686-fc219985c49d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451390838-172.17.0.6-1598362884731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46204,DS-1e34bb32-22fa-4271-9f12-e21e0d8a0479,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-9cd70495-2f6f-4514-933b-f68868a0967d,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-9a48e2d6-dd8f-4505-9309-966102e9beca,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-a65187e2-ae61-408a-9eb9-f6c4bd883709,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-e63f8548-6e41-4955-9f19-4dcb5c1974bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-42bf9983-3245-40bf-a6ac-633ebc40f20d,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-dbe98335-b452-47a7-b1c9-9ee4f75bff27,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-cb100abc-48f3-4ae4-8f83-c54da441cd1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451390838-172.17.0.6-1598362884731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46204,DS-1e34bb32-22fa-4271-9f12-e21e0d8a0479,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-9cd70495-2f6f-4514-933b-f68868a0967d,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-9a48e2d6-dd8f-4505-9309-966102e9beca,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-a65187e2-ae61-408a-9eb9-f6c4bd883709,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-e63f8548-6e41-4955-9f19-4dcb5c1974bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-42bf9983-3245-40bf-a6ac-633ebc40f20d,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-dbe98335-b452-47a7-b1c9-9ee4f75bff27,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-cb100abc-48f3-4ae4-8f83-c54da441cd1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1517735802-172.17.0.6-1598363305480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33019,DS-52d448ca-dfb9-49e5-a13e-64f5924c0b25,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-911c579f-7788-4fbe-a5c3-0ef7987507ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-7806e804-f0cd-40a1-8f5b-5a84f16bc413,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-45639feb-0bc6-44f5-b0b9-a00de8edccd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-56749a05-45fb-4070-a231-c080620d0e01,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-03eb2570-69ad-47a3-9b0b-b8bff1fc54c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-8abb089a-b2d5-449f-9f73-2c95383bb463,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-c245aac9-fe40-4473-b57a-dd8f005ab440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1517735802-172.17.0.6-1598363305480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33019,DS-52d448ca-dfb9-49e5-a13e-64f5924c0b25,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-911c579f-7788-4fbe-a5c3-0ef7987507ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-7806e804-f0cd-40a1-8f5b-5a84f16bc413,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-45639feb-0bc6-44f5-b0b9-a00de8edccd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-56749a05-45fb-4070-a231-c080620d0e01,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-03eb2570-69ad-47a3-9b0b-b8bff1fc54c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-8abb089a-b2d5-449f-9f73-2c95383bb463,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-c245aac9-fe40-4473-b57a-dd8f005ab440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272912383-172.17.0.6-1598363380977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44886,DS-9e6b2ad2-e86c-4020-991f-f35a5477a54b,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-dbee30b3-23ec-452f-8d92-153ced400704,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-6e9b04b8-54d0-4e17-977d-68e86677b616,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-646bcb23-00ac-444b-9d26-46ca7a78366f,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-7b31fe2e-42a9-4ffb-9fd9-0b8d82a4f345,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-8301e958-b542-4086-a3e8-050fa116f509,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-6f8e00ec-20c4-4ee5-8cd8-2b45db985135,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-183a2fc8-c030-43cb-9040-9039bae05b41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272912383-172.17.0.6-1598363380977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44886,DS-9e6b2ad2-e86c-4020-991f-f35a5477a54b,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-dbee30b3-23ec-452f-8d92-153ced400704,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-6e9b04b8-54d0-4e17-977d-68e86677b616,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-646bcb23-00ac-444b-9d26-46ca7a78366f,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-7b31fe2e-42a9-4ffb-9fd9-0b8d82a4f345,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-8301e958-b542-4086-a3e8-050fa116f509,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-6f8e00ec-20c4-4ee5-8cd8-2b45db985135,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-183a2fc8-c030-43cb-9040-9039bae05b41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363575199-172.17.0.6-1598363563332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42473,DS-5f2fb459-8cc9-44db-a0bb-1db607d10f84,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-afaa95c6-705f-4cc1-8912-78e84ebb1993,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-413c7152-894c-4be3-bb08-3b3a938bd293,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-f2f6aa0c-27e7-4c6d-9466-bfa213e370b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-2ffd29a4-8f32-4bac-961e-376ca0c538a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-343c371e-373f-47b7-a8ac-e5199444cacc,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-d07b7107-4908-4f1e-81b4-0f1339c994ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-89c42e68-8524-46a3-bd92-7dcbd79a9220,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363575199-172.17.0.6-1598363563332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42473,DS-5f2fb459-8cc9-44db-a0bb-1db607d10f84,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-afaa95c6-705f-4cc1-8912-78e84ebb1993,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-413c7152-894c-4be3-bb08-3b3a938bd293,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-f2f6aa0c-27e7-4c6d-9466-bfa213e370b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-2ffd29a4-8f32-4bac-961e-376ca0c538a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-343c371e-373f-47b7-a8ac-e5199444cacc,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-d07b7107-4908-4f1e-81b4-0f1339c994ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-89c42e68-8524-46a3-bd92-7dcbd79a9220,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-833983922-172.17.0.6-1598363629400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46719,DS-be21e574-8c5b-40ea-8eba-805e1a2ea98d,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-a13e86e7-7daf-4758-b790-258761fe07cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-f925fd72-2b13-43d0-aa06-1134acb597d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-bce858a3-a99d-407c-83e3-9d7b6b1af8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-b2e01c43-ea55-4cb9-862f-b9a0ef1bbb97,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-26ddb391-d9af-4ed5-9f57-40dc724afc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-6c74b902-c876-45f2-a93c-6daf5be587b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-33809f91-3bbc-42db-a7b0-65d6ba97f9f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-833983922-172.17.0.6-1598363629400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46719,DS-be21e574-8c5b-40ea-8eba-805e1a2ea98d,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-a13e86e7-7daf-4758-b790-258761fe07cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-f925fd72-2b13-43d0-aa06-1134acb597d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-bce858a3-a99d-407c-83e3-9d7b6b1af8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-b2e01c43-ea55-4cb9-862f-b9a0ef1bbb97,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-26ddb391-d9af-4ed5-9f57-40dc724afc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-6c74b902-c876-45f2-a93c-6daf5be587b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-33809f91-3bbc-42db-a7b0-65d6ba97f9f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890056917-172.17.0.6-1598363986729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45871,DS-18235eee-1ae3-4aaf-83f6-e25dc2636f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-6fb6b68a-c055-47d4-adc2-e51131d9cf82,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-7a244f2b-b8ab-4d53-be31-f233cb480c98,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-99435c09-f656-447c-b1e2-ceb754238d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-f7996648-5577-4ef8-a3cd-75afc1fe87e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-56204209-da3a-4fd7-9d14-3bcb9141b807,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-0d49df5c-e1b5-43e0-b6df-76ea87a0b0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-dfc0fe56-5dc1-4f8b-aede-24f2df3c5be4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890056917-172.17.0.6-1598363986729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45871,DS-18235eee-1ae3-4aaf-83f6-e25dc2636f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-6fb6b68a-c055-47d4-adc2-e51131d9cf82,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-7a244f2b-b8ab-4d53-be31-f233cb480c98,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-99435c09-f656-447c-b1e2-ceb754238d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-f7996648-5577-4ef8-a3cd-75afc1fe87e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-56204209-da3a-4fd7-9d14-3bcb9141b807,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-0d49df5c-e1b5-43e0-b6df-76ea87a0b0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-dfc0fe56-5dc1-4f8b-aede-24f2df3c5be4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774809016-172.17.0.6-1598364307746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39877,DS-5a6a6410-74a1-4efc-81e6-4e3000bb7f99,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-a4c8c476-def4-4463-a93e-b536a9fd5500,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-8aa129c1-9564-41a9-83ec-f43d269960c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-35811cc3-dc87-4bc0-a3c3-624abf24025d,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-427439e5-1cd9-438f-a77d-d8eb7a2aa031,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-58d71a0d-9c83-49ff-9a84-88f5038b02a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-b79bdc7f-b349-41af-8154-fd16504ccb24,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-e94bcbf0-c585-4037-86e2-159566fc842f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774809016-172.17.0.6-1598364307746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39877,DS-5a6a6410-74a1-4efc-81e6-4e3000bb7f99,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-a4c8c476-def4-4463-a93e-b536a9fd5500,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-8aa129c1-9564-41a9-83ec-f43d269960c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-35811cc3-dc87-4bc0-a3c3-624abf24025d,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-427439e5-1cd9-438f-a77d-d8eb7a2aa031,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-58d71a0d-9c83-49ff-9a84-88f5038b02a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-b79bdc7f-b349-41af-8154-fd16504ccb24,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-e94bcbf0-c585-4037-86e2-159566fc842f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505526994-172.17.0.6-1598364414868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41537,DS-99de6b37-97eb-489a-8e6b-f5303d36a66b,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-e87bdb5e-8ccd-4a4e-911b-74718c0c504a,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-529c29c8-01e4-4582-b6a0-3ff5ccbbf334,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-fc05cad8-338f-4d0b-881e-5ae6f3992263,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-e439b61f-e366-48ad-a1cd-29bfc4834319,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-97dea73f-da22-464c-ae05-289ad0d1e562,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-f8252ae0-f778-480b-bbfa-61e0b84d0c98,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-3dc8924f-6d9b-4454-8abd-8192ac154173,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505526994-172.17.0.6-1598364414868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41537,DS-99de6b37-97eb-489a-8e6b-f5303d36a66b,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-e87bdb5e-8ccd-4a4e-911b-74718c0c504a,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-529c29c8-01e4-4582-b6a0-3ff5ccbbf334,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-fc05cad8-338f-4d0b-881e-5ae6f3992263,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-e439b61f-e366-48ad-a1cd-29bfc4834319,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-97dea73f-da22-464c-ae05-289ad0d1e562,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-f8252ae0-f778-480b-bbfa-61e0b84d0c98,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-3dc8924f-6d9b-4454-8abd-8192ac154173,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308325490-172.17.0.6-1598364526169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34744,DS-dea3f733-6099-4f7e-a275-af17fb1b13f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-55d78607-7f67-4fc5-96a2-daaa0c088ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-660aa2d5-3790-4ab2-9608-16707bb1d9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-e1212446-a0b3-4699-a7f4-f1e74c486e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-79523547-e3a3-42f5-a92a-dd2f6a773fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-0845fc81-18f3-47bb-afd8-f45029993142,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-e94c52f9-6608-4602-b146-8954a2fee119,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-18f86ff5-9317-46a4-8796-ae1f0b5a9e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308325490-172.17.0.6-1598364526169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34744,DS-dea3f733-6099-4f7e-a275-af17fb1b13f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-55d78607-7f67-4fc5-96a2-daaa0c088ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-660aa2d5-3790-4ab2-9608-16707bb1d9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-e1212446-a0b3-4699-a7f4-f1e74c486e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-79523547-e3a3-42f5-a92a-dd2f6a773fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-0845fc81-18f3-47bb-afd8-f45029993142,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-e94c52f9-6608-4602-b146-8954a2fee119,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-18f86ff5-9317-46a4-8796-ae1f0b5a9e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1600979258-172.17.0.6-1598364939855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39338,DS-308529f0-80ba-48ab-a748-24108579e90b,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-66ea67bc-60e6-409e-ab92-94b0dab8badb,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-2b56fe23-c140-45f8-922f-ff7c13c1c159,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-8dd39321-b254-404f-9ac3-05badae9b3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-42b6a85e-7446-4e72-8e7e-4df3fe269943,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-4e63300f-ef15-4bed-9086-87bfb3c37f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-1cd7d701-4214-4dd0-915b-55afec65214f,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-c6231918-fb99-4bfb-b369-166d58531f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1600979258-172.17.0.6-1598364939855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39338,DS-308529f0-80ba-48ab-a748-24108579e90b,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-66ea67bc-60e6-409e-ab92-94b0dab8badb,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-2b56fe23-c140-45f8-922f-ff7c13c1c159,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-8dd39321-b254-404f-9ac3-05badae9b3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-42b6a85e-7446-4e72-8e7e-4df3fe269943,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-4e63300f-ef15-4bed-9086-87bfb3c37f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-1cd7d701-4214-4dd0-915b-55afec65214f,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-c6231918-fb99-4bfb-b369-166d58531f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830564089-172.17.0.6-1598365253218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46877,DS-547e3b40-f2c6-4aa1-8a8b-4d8614edf052,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-efeedfc5-0757-4afc-ace8-bce8c4e27095,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-311f253e-1472-4d63-9adc-2816179d32ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-4356afa6-b693-4764-a012-cb0ac6f45882,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-6a5dca0e-eb00-4b8c-a929-284e34ea220a,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-7b5728ea-4172-46f0-8c84-6a2c75ce1505,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-09ea5e2f-d8a7-4210-b6c9-987ca2d12dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-0b047c14-c48c-4fb3-a17b-acf4b8083d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830564089-172.17.0.6-1598365253218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46877,DS-547e3b40-f2c6-4aa1-8a8b-4d8614edf052,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-efeedfc5-0757-4afc-ace8-bce8c4e27095,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-311f253e-1472-4d63-9adc-2816179d32ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-4356afa6-b693-4764-a012-cb0ac6f45882,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-6a5dca0e-eb00-4b8c-a929-284e34ea220a,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-7b5728ea-4172-46f0-8c84-6a2c75ce1505,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-09ea5e2f-d8a7-4210-b6c9-987ca2d12dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-0b047c14-c48c-4fb3-a17b-acf4b8083d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-591244884-172.17.0.6-1598365385682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44769,DS-f200751e-4a3b-4afc-8f7b-9e90a74c09dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-aa13e12d-892f-48c0-a8db-c4d51ba04fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-8576f642-e1d3-4721-b825-8a0f6a656079,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-115071e4-5c88-44bb-b859-dd761158d2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-94579f61-2c35-4f02-8acb-1e4450d65e52,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-dc9db49b-19ef-43c9-af0e-7e5d1c956e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-b26262f3-99ec-47e2-8e24-a225804592a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-670984bd-6c45-410e-be8c-00e96e58bfdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-591244884-172.17.0.6-1598365385682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44769,DS-f200751e-4a3b-4afc-8f7b-9e90a74c09dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-aa13e12d-892f-48c0-a8db-c4d51ba04fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-8576f642-e1d3-4721-b825-8a0f6a656079,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-115071e4-5c88-44bb-b859-dd761158d2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-94579f61-2c35-4f02-8acb-1e4450d65e52,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-dc9db49b-19ef-43c9-af0e-7e5d1c956e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-b26262f3-99ec-47e2-8e24-a225804592a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-670984bd-6c45-410e-be8c-00e96e58bfdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1893936777-172.17.0.6-1598366050348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43712,DS-216d8051-c156-4419-9075-b34ae0ec51d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-dc484f47-38c1-4852-91ab-509dc3cdef38,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-215bfc43-2516-405f-8d96-37516ab54288,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-f89db93c-b9c6-4c1d-9299-54911e219f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-c9b4a4dd-dc54-4e48-9d9a-e4fbcaf87736,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-37809396-ae1c-4610-a4dd-3438a302edee,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-4f32b26e-76e6-4913-a810-4617327f204a,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-9f326f8a-9d59-4d0e-a118-14e986b111aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1893936777-172.17.0.6-1598366050348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43712,DS-216d8051-c156-4419-9075-b34ae0ec51d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-dc484f47-38c1-4852-91ab-509dc3cdef38,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-215bfc43-2516-405f-8d96-37516ab54288,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-f89db93c-b9c6-4c1d-9299-54911e219f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-c9b4a4dd-dc54-4e48-9d9a-e4fbcaf87736,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-37809396-ae1c-4610-a4dd-3438a302edee,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-4f32b26e-76e6-4913-a810-4617327f204a,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-9f326f8a-9d59-4d0e-a118-14e986b111aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710477691-172.17.0.6-1598366155180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33364,DS-35989843-eff4-4b1d-8d64-f9660c78f15d,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-5d1a56e2-b5b2-48c6-8ab1-245d56ed3a77,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-56d74c94-566d-4e94-b4ee-a6f2f366b95c,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-81ce022d-b101-4269-b427-e94faaf4d30a,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-3a7f98fd-620f-4d67-8915-e52e6c9a8a68,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-618b8595-2aca-4a6b-9664-a4a04ff0ff53,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-e9471894-672d-4ad8-8d34-60e263ca9906,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-f1150e2f-228f-469a-99b1-f69dde04254d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710477691-172.17.0.6-1598366155180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33364,DS-35989843-eff4-4b1d-8d64-f9660c78f15d,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-5d1a56e2-b5b2-48c6-8ab1-245d56ed3a77,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-56d74c94-566d-4e94-b4ee-a6f2f366b95c,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-81ce022d-b101-4269-b427-e94faaf4d30a,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-3a7f98fd-620f-4d67-8915-e52e6c9a8a68,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-618b8595-2aca-4a6b-9664-a4a04ff0ff53,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-e9471894-672d-4ad8-8d34-60e263ca9906,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-f1150e2f-228f-469a-99b1-f69dde04254d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464907885-172.17.0.6-1598366504668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35799,DS-b44ef8a9-2e54-45ec-b792-3466c168bc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-3790bc8f-507d-425b-8d52-058aa7d6c90f,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-c230a412-5d97-421f-9494-621ab07eb1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-4707c44e-b031-4952-b462-c0a4577b3f14,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-a130159b-bad1-4e83-a620-964f5d504953,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-bc2c32cb-c4d1-42f8-9748-3271e21e8860,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-ea0a903d-fe9d-45f9-80af-22f257051b27,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-8a814a6e-cd5c-4956-9243-88d9c6f45caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464907885-172.17.0.6-1598366504668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35799,DS-b44ef8a9-2e54-45ec-b792-3466c168bc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-3790bc8f-507d-425b-8d52-058aa7d6c90f,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-c230a412-5d97-421f-9494-621ab07eb1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-4707c44e-b031-4952-b462-c0a4577b3f14,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-a130159b-bad1-4e83-a620-964f5d504953,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-bc2c32cb-c4d1-42f8-9748-3271e21e8860,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-ea0a903d-fe9d-45f9-80af-22f257051b27,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-8a814a6e-cd5c-4956-9243-88d9c6f45caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 5229
