reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928940144-172.17.0.2-1598463337295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34381,DS-304d0ab2-d37d-4fa2-a565-8307a0506e57,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-1a8a361c-4596-4a90-bcc1-a320f18fd503,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-063ad0ed-b110-4139-9165-a12ab1c33a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-379bc58d-a1ac-46c6-9bd8-4c7c6f73802a,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-942c75db-391d-45b6-9da1-7d46bd708f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-bb46d2a4-98c2-408b-af0f-361b1fc49a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-5d20bd86-c637-4c01-b0f6-5768dfce8a27,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-06434006-9887-40d8-b4b3-29df6b589c71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928940144-172.17.0.2-1598463337295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34381,DS-304d0ab2-d37d-4fa2-a565-8307a0506e57,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-1a8a361c-4596-4a90-bcc1-a320f18fd503,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-063ad0ed-b110-4139-9165-a12ab1c33a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-379bc58d-a1ac-46c6-9bd8-4c7c6f73802a,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-942c75db-391d-45b6-9da1-7d46bd708f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-bb46d2a4-98c2-408b-af0f-361b1fc49a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-5d20bd86-c637-4c01-b0f6-5768dfce8a27,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-06434006-9887-40d8-b4b3-29df6b589c71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230673858-172.17.0.2-1598463375312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38288,DS-be99d824-7b46-44bf-a105-13c5deab47ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-a26d355c-b26d-4fed-803e-4f203a3a4bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-54297c5b-daf6-4988-800f-b234c5b3baa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-16481576-4dac-4e6e-8702-decb98bb2cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-c5a12111-90eb-4a0f-8cc4-d819e13c8197,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-238250c9-03fb-49ec-a33d-0c0fbc66d479,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-de0e5e0c-e48a-4be4-a6e1-29a0f0ddf586,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-f189b1cd-1ae4-4fbd-87fd-ad2cd8a76787,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230673858-172.17.0.2-1598463375312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38288,DS-be99d824-7b46-44bf-a105-13c5deab47ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-a26d355c-b26d-4fed-803e-4f203a3a4bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-54297c5b-daf6-4988-800f-b234c5b3baa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-16481576-4dac-4e6e-8702-decb98bb2cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-c5a12111-90eb-4a0f-8cc4-d819e13c8197,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-238250c9-03fb-49ec-a33d-0c0fbc66d479,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-de0e5e0c-e48a-4be4-a6e1-29a0f0ddf586,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-f189b1cd-1ae4-4fbd-87fd-ad2cd8a76787,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071106222-172.17.0.2-1598463608436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44796,DS-709530b3-22cf-4cf9-adeb-063c02a58571,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-54d5d795-e32e-43b5-a3f5-4ecb2ada74b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-a45f6c38-fc6a-461e-9e06-1c1862a24fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-1af8b625-6e69-453e-85d8-b26553f052f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-5dce7c59-006c-454b-9e0d-f95b7d857151,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-7319d227-7419-4c4a-b165-e098e8b239b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-1613831a-9552-494d-befe-929c9fb5bb86,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-6ee6c55b-4252-425e-924d-4a68d31834f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071106222-172.17.0.2-1598463608436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44796,DS-709530b3-22cf-4cf9-adeb-063c02a58571,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-54d5d795-e32e-43b5-a3f5-4ecb2ada74b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-a45f6c38-fc6a-461e-9e06-1c1862a24fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-1af8b625-6e69-453e-85d8-b26553f052f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-5dce7c59-006c-454b-9e0d-f95b7d857151,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-7319d227-7419-4c4a-b165-e098e8b239b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-1613831a-9552-494d-befe-929c9fb5bb86,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-6ee6c55b-4252-425e-924d-4a68d31834f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915803182-172.17.0.2-1598463641667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33632,DS-7c000a29-1763-456b-b0ef-5ae8632b9668,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-646aaf1e-cca1-49a6-995f-737f7c3307da,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-fe872466-d2cd-492e-9931-2e5524dcc9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-8d6ce771-7eb1-4f21-83df-53aadab73953,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-e92c7585-7f67-4b12-910c-9b5d1a49590c,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-1c732f08-3242-4c45-be07-c94726e2dcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-e0635c54-4bfa-4069-b835-649151b6aef6,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-a7a1d019-6bdf-427e-890d-999dde891eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915803182-172.17.0.2-1598463641667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33632,DS-7c000a29-1763-456b-b0ef-5ae8632b9668,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-646aaf1e-cca1-49a6-995f-737f7c3307da,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-fe872466-d2cd-492e-9931-2e5524dcc9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-8d6ce771-7eb1-4f21-83df-53aadab73953,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-e92c7585-7f67-4b12-910c-9b5d1a49590c,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-1c732f08-3242-4c45-be07-c94726e2dcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-e0635c54-4bfa-4069-b835-649151b6aef6,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-a7a1d019-6bdf-427e-890d-999dde891eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341162091-172.17.0.2-1598464534051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38582,DS-8dc8d418-c6d1-4eb1-84ae-00e3baf64739,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-cf98ac52-df41-4247-9586-f7ec584f6e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-314949b1-9acf-4bf5-b7a2-5ffba804e0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-8486ded1-700d-4fa0-8b1e-e5257b46b36a,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-314eea1c-e3f2-4314-8a68-802a80b19fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-ce1d7802-7a08-4426-99a4-62566bcf03f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-f3bd3b55-37ab-44ee-80b1-109029c2a817,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-9f252b4f-248a-4712-a7f7-c9163f16757f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341162091-172.17.0.2-1598464534051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38582,DS-8dc8d418-c6d1-4eb1-84ae-00e3baf64739,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-cf98ac52-df41-4247-9586-f7ec584f6e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-314949b1-9acf-4bf5-b7a2-5ffba804e0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-8486ded1-700d-4fa0-8b1e-e5257b46b36a,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-314eea1c-e3f2-4314-8a68-802a80b19fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-ce1d7802-7a08-4426-99a4-62566bcf03f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-f3bd3b55-37ab-44ee-80b1-109029c2a817,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-9f252b4f-248a-4712-a7f7-c9163f16757f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412053090-172.17.0.2-1598464563300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45485,DS-dd6ae6e9-c823-4120-938e-671439ef0387,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-32e35865-f51d-464f-901b-96d39dcf1a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-d305e671-dbf7-4e9e-97fc-2ebd9bc59ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-cc9e8fdb-0176-47bd-8ac7-f5ca98a67585,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-b6ee7d81-87a1-4755-8472-13f503fb49ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-1c273c52-ad62-47b4-9177-82675b8b89be,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-66088cbb-cd03-4545-aeab-d2773a8cbe21,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-fa53e556-03b4-461d-8947-81dc81c9efc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412053090-172.17.0.2-1598464563300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45485,DS-dd6ae6e9-c823-4120-938e-671439ef0387,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-32e35865-f51d-464f-901b-96d39dcf1a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-d305e671-dbf7-4e9e-97fc-2ebd9bc59ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-cc9e8fdb-0176-47bd-8ac7-f5ca98a67585,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-b6ee7d81-87a1-4755-8472-13f503fb49ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-1c273c52-ad62-47b4-9177-82675b8b89be,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-66088cbb-cd03-4545-aeab-d2773a8cbe21,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-fa53e556-03b4-461d-8947-81dc81c9efc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035733349-172.17.0.2-1598464952283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44942,DS-57c62686-69fe-4d21-9826-42269d01afad,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-c33d0beb-4c36-4e6d-ac30-56b557fdf1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-69f9a0ad-c499-4cea-a6d9-7b764b90a946,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-d15e9a7b-f9c3-4b03-a8cf-b3aaccf38b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-ddcf301e-ec97-46b1-9651-0ffb8ecbe199,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-6d674cf2-89e6-4f8a-8bbc-e7f88907e69e,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-13b36ae7-6e80-4205-841b-3cc25842871e,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-60a8fcc4-43a6-4992-813b-49d6e20984cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035733349-172.17.0.2-1598464952283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44942,DS-57c62686-69fe-4d21-9826-42269d01afad,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-c33d0beb-4c36-4e6d-ac30-56b557fdf1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-69f9a0ad-c499-4cea-a6d9-7b764b90a946,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-d15e9a7b-f9c3-4b03-a8cf-b3aaccf38b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-ddcf301e-ec97-46b1-9651-0ffb8ecbe199,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-6d674cf2-89e6-4f8a-8bbc-e7f88907e69e,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-13b36ae7-6e80-4205-841b-3cc25842871e,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-60a8fcc4-43a6-4992-813b-49d6e20984cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128577665-172.17.0.2-1598465068624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41017,DS-fa4c0f4f-fe8f-4d57-9cc9-7e6e9b40f8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-1c009490-2e25-4705-99cf-9c7699932618,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-5f206dd1-a5d7-461c-b7b7-e9b7e6414797,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-67e466a4-5b42-4c05-87cf-3fd9b254c551,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-c67af511-a341-4b35-a9a1-35b6d2ec81ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-fac37550-48a8-4815-938b-b2a7ffffb6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-33dff71c-a6b4-4992-87ef-cc0d7c8ec419,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-067db44a-5d17-4d37-9ead-9702e12919d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128577665-172.17.0.2-1598465068624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41017,DS-fa4c0f4f-fe8f-4d57-9cc9-7e6e9b40f8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-1c009490-2e25-4705-99cf-9c7699932618,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-5f206dd1-a5d7-461c-b7b7-e9b7e6414797,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-67e466a4-5b42-4c05-87cf-3fd9b254c551,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-c67af511-a341-4b35-a9a1-35b6d2ec81ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-fac37550-48a8-4815-938b-b2a7ffffb6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-33dff71c-a6b4-4992-87ef-cc0d7c8ec419,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-067db44a-5d17-4d37-9ead-9702e12919d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909014342-172.17.0.2-1598465106439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41970,DS-62d38d81-0b8c-4f8e-95f7-5e80147549a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-422249f7-6394-4484-a0de-5ee16bb1c9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-c7ac2f01-a6d8-45be-a14b-9b5ab8f7dfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-374eb00d-dc91-446a-a8c6-1aaf39581498,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-53136ee6-3754-4b57-b4ed-0cd22266393d,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-75d83b39-853f-48e2-8a5c-f348b9110571,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-e51d13c6-1e9d-4828-ad38-c6149d790308,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-442075a2-e280-459c-8ddc-c8b0827a6cc0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909014342-172.17.0.2-1598465106439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41970,DS-62d38d81-0b8c-4f8e-95f7-5e80147549a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-422249f7-6394-4484-a0de-5ee16bb1c9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-c7ac2f01-a6d8-45be-a14b-9b5ab8f7dfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-374eb00d-dc91-446a-a8c6-1aaf39581498,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-53136ee6-3754-4b57-b4ed-0cd22266393d,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-75d83b39-853f-48e2-8a5c-f348b9110571,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-e51d13c6-1e9d-4828-ad38-c6149d790308,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-442075a2-e280-459c-8ddc-c8b0827a6cc0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605714757-172.17.0.2-1598465212141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43406,DS-5e4ca558-4a96-4017-9bba-31abb859d9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-9da9c14c-2ec3-4f0e-bb59-58586c026735,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-86bbb47d-5121-4668-860c-0573d7f77388,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-e1c902e7-f109-44db-b826-0e57210c5865,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-de83d573-46de-4c75-a08e-5d840db95c36,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-341fd305-7950-4575-98ef-5bfecc1529a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-2f093c1b-ce65-44d4-a30c-32f2255646bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-b38229ec-984f-422e-ae84-f435c1afa300,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605714757-172.17.0.2-1598465212141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43406,DS-5e4ca558-4a96-4017-9bba-31abb859d9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-9da9c14c-2ec3-4f0e-bb59-58586c026735,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-86bbb47d-5121-4668-860c-0573d7f77388,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-e1c902e7-f109-44db-b826-0e57210c5865,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-de83d573-46de-4c75-a08e-5d840db95c36,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-341fd305-7950-4575-98ef-5bfecc1529a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-2f093c1b-ce65-44d4-a30c-32f2255646bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-b38229ec-984f-422e-ae84-f435c1afa300,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529415865-172.17.0.2-1598465565926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35766,DS-043036bd-0fd5-4871-bc2f-6d545e3c1d31,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-f25cd763-7731-4dfe-beee-dd53f6d8a47a,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-3be89e2d-7134-4633-9dbd-9486ec63a017,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-2a60de4c-6c51-407c-913b-0cf75ad89f43,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-fba95247-b6f4-4033-86d7-bb8ef72d286f,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-75977d5a-e468-401d-b5a9-4f8fc449de2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-4588492b-ad1d-465b-91ea-48e092973f38,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-5808cdd8-751c-460b-9068-dcc06c682078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529415865-172.17.0.2-1598465565926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35766,DS-043036bd-0fd5-4871-bc2f-6d545e3c1d31,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-f25cd763-7731-4dfe-beee-dd53f6d8a47a,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-3be89e2d-7134-4633-9dbd-9486ec63a017,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-2a60de4c-6c51-407c-913b-0cf75ad89f43,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-fba95247-b6f4-4033-86d7-bb8ef72d286f,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-75977d5a-e468-401d-b5a9-4f8fc449de2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-4588492b-ad1d-465b-91ea-48e092973f38,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-5808cdd8-751c-460b-9068-dcc06c682078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596806973-172.17.0.2-1598465603783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38136,DS-cb87caf3-1363-44e3-91ca-4a24fd02fadd,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-f990c58b-679a-49b8-9afd-19c67b89f79b,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-436c7218-f5c5-41c7-bc67-9fbcbfebf859,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-6a327e51-5405-49c9-9580-e4787a2c45ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-881dbc2e-c117-4939-a4ea-1c9ece7c0400,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-56ebbcb4-fd79-46d0-863f-f0d417b23152,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-728a1adb-18c0-46db-8abd-a6dfbb57f963,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-fccc5354-5079-4ea2-8dc1-2205aa3351e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596806973-172.17.0.2-1598465603783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38136,DS-cb87caf3-1363-44e3-91ca-4a24fd02fadd,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-f990c58b-679a-49b8-9afd-19c67b89f79b,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-436c7218-f5c5-41c7-bc67-9fbcbfebf859,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-6a327e51-5405-49c9-9580-e4787a2c45ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-881dbc2e-c117-4939-a4ea-1c9ece7c0400,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-56ebbcb4-fd79-46d0-863f-f0d417b23152,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-728a1adb-18c0-46db-8abd-a6dfbb57f963,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-fccc5354-5079-4ea2-8dc1-2205aa3351e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622575820-172.17.0.2-1598465800876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41282,DS-65a33873-ca63-416f-aec5-8bd0b2a458c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-69710db8-81e1-49b4-87cb-bf3be8db3f27,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-00dc002b-bfd4-4274-a0e6-17937126b860,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-6d5d99d6-a7e0-4f75-9913-5c5c163eb689,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-32587b28-6ef1-4878-9a79-a0dfce37a068,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-88e1a8b9-5200-430c-8bb6-ee11774cf70f,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-a9c496f7-539d-4f79-936d-af1b925c7e58,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-2fe46976-2afe-4769-aa12-f56e83eac0b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622575820-172.17.0.2-1598465800876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41282,DS-65a33873-ca63-416f-aec5-8bd0b2a458c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-69710db8-81e1-49b4-87cb-bf3be8db3f27,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-00dc002b-bfd4-4274-a0e6-17937126b860,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-6d5d99d6-a7e0-4f75-9913-5c5c163eb689,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-32587b28-6ef1-4878-9a79-a0dfce37a068,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-88e1a8b9-5200-430c-8bb6-ee11774cf70f,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-a9c496f7-539d-4f79-936d-af1b925c7e58,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-2fe46976-2afe-4769-aa12-f56e83eac0b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469865911-172.17.0.2-1598466090339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43121,DS-66f49d5e-d445-4881-afea-30623998021f,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-7294ba37-a9a9-4818-a692-a5d45b62263e,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-307affae-5b05-4d85-b8c3-5895f01340ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-dd08b587-0f7c-4685-8e32-6f67e93b014c,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-14916bb7-a922-42fa-9b54-58773359038d,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-b0b7d66e-ae21-4d58-ad6f-f312e05a34be,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-ccbea471-078f-4d94-929f-5f71b5ecba9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-c842302c-f87f-4b37-ac67-923b5303734e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469865911-172.17.0.2-1598466090339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43121,DS-66f49d5e-d445-4881-afea-30623998021f,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-7294ba37-a9a9-4818-a692-a5d45b62263e,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-307affae-5b05-4d85-b8c3-5895f01340ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-dd08b587-0f7c-4685-8e32-6f67e93b014c,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-14916bb7-a922-42fa-9b54-58773359038d,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-b0b7d66e-ae21-4d58-ad6f-f312e05a34be,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-ccbea471-078f-4d94-929f-5f71b5ecba9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-c842302c-f87f-4b37-ac67-923b5303734e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293596981-172.17.0.2-1598466159220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43179,DS-640930db-1c30-462d-89a6-161657f1380f,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-0a55a28b-acd9-4600-a3ef-8188b9e6f779,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-b3c7b1d0-a228-4994-adda-4ceee8109483,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-f1308e72-8420-4834-bb2d-c703270880e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-80057610-3876-4f50-b165-e59fdb178b57,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-14f7d08b-bc18-4fa0-a8e6-79e5c778de3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-2f52687a-da51-4156-b8ba-7c2dfaa7e7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-22e57f3c-e6d4-492d-85f2-4a3ee97b0c72,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293596981-172.17.0.2-1598466159220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43179,DS-640930db-1c30-462d-89a6-161657f1380f,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-0a55a28b-acd9-4600-a3ef-8188b9e6f779,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-b3c7b1d0-a228-4994-adda-4ceee8109483,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-f1308e72-8420-4834-bb2d-c703270880e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-80057610-3876-4f50-b165-e59fdb178b57,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-14f7d08b-bc18-4fa0-a8e6-79e5c778de3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-2f52687a-da51-4156-b8ba-7c2dfaa7e7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-22e57f3c-e6d4-492d-85f2-4a3ee97b0c72,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063101840-172.17.0.2-1598466450822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45229,DS-41c9933a-d6bd-406a-a67a-dd27e8ce1deb,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-e5ad4000-0fde-44da-89a5-b55c6daa7ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-9a33661e-64c8-428c-9875-837cfb5094ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-6d30a94d-7d5e-431c-af9f-97a598590e18,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-801714ab-3f4e-441d-bddb-b1e89cd84340,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-bf895733-198d-44fe-b5ae-537a7fb73195,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-2365de62-3ad9-427a-8b5e-bbbf0a80387e,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-98d06872-f174-4e28-84ab-02ed07816697,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063101840-172.17.0.2-1598466450822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45229,DS-41c9933a-d6bd-406a-a67a-dd27e8ce1deb,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-e5ad4000-0fde-44da-89a5-b55c6daa7ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-9a33661e-64c8-428c-9875-837cfb5094ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-6d30a94d-7d5e-431c-af9f-97a598590e18,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-801714ab-3f4e-441d-bddb-b1e89cd84340,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-bf895733-198d-44fe-b5ae-537a7fb73195,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-2365de62-3ad9-427a-8b5e-bbbf0a80387e,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-98d06872-f174-4e28-84ab-02ed07816697,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345926032-172.17.0.2-1598466616521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33791,DS-4382f0b7-70bf-498b-8c5b-242566711641,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-87233f0e-18f1-4ca0-a083-abedfd011e16,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-78170e52-fe8d-4cb2-a91e-a56a19552776,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-a73b1d15-0601-4e4c-9a50-e70875d32975,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-b80b7305-651c-482f-8b33-8135a2bfddaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-51b8e797-629a-4384-9672-966f27e8a272,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-9f7faecb-1a21-4aa2-ab00-e17741d45aae,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-45e4d305-1965-43b9-8483-9ac60a8b3945,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345926032-172.17.0.2-1598466616521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33791,DS-4382f0b7-70bf-498b-8c5b-242566711641,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-87233f0e-18f1-4ca0-a083-abedfd011e16,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-78170e52-fe8d-4cb2-a91e-a56a19552776,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-a73b1d15-0601-4e4c-9a50-e70875d32975,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-b80b7305-651c-482f-8b33-8135a2bfddaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-51b8e797-629a-4384-9672-966f27e8a272,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-9f7faecb-1a21-4aa2-ab00-e17741d45aae,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-45e4d305-1965-43b9-8483-9ac60a8b3945,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106283959-172.17.0.2-1598466754821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36182,DS-7b62d884-fb9f-430b-8307-b4695fe4e82d,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-7df0df52-a908-47fc-a497-42ac4cd598e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-4a09cb44-3361-4cc5-bf79-1cd488cf0223,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-4c694de8-b554-4494-a9bc-ae70e5209eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-3c082af4-a39a-4ab3-b872-a5c2018dad5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-7196c3ee-6468-4fa6-80a2-ffb5d1ac9599,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-6f9936de-96d4-49de-95c3-7fbe695a6c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-a9f1ce61-a97c-43da-a9db-b7cd57103838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106283959-172.17.0.2-1598466754821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36182,DS-7b62d884-fb9f-430b-8307-b4695fe4e82d,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-7df0df52-a908-47fc-a497-42ac4cd598e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-4a09cb44-3361-4cc5-bf79-1cd488cf0223,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-4c694de8-b554-4494-a9bc-ae70e5209eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-3c082af4-a39a-4ab3-b872-a5c2018dad5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-7196c3ee-6468-4fa6-80a2-ffb5d1ac9599,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-6f9936de-96d4-49de-95c3-7fbe695a6c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-a9f1ce61-a97c-43da-a9db-b7cd57103838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-726960623-172.17.0.2-1598466966750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36069,DS-7474932d-e4c5-4920-8824-cad6d74758c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-07aa33dd-5675-4e5d-8dfe-cbccb8c1b2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-1fb752b4-e76c-4128-9a1c-82f783c69609,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-3699d2d5-c028-4f61-9298-01c858fa9e01,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-d455cca7-6c8d-4dc8-8718-2c919f9aad90,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-e3e2ee8c-f7ba-49e6-bdcd-3931ffe51e69,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-ee95238b-5f9f-4a4b-aedf-af637e861ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-39de4294-a986-4a7e-9747-06ebc33d2104,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-726960623-172.17.0.2-1598466966750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36069,DS-7474932d-e4c5-4920-8824-cad6d74758c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-07aa33dd-5675-4e5d-8dfe-cbccb8c1b2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-1fb752b4-e76c-4128-9a1c-82f783c69609,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-3699d2d5-c028-4f61-9298-01c858fa9e01,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-d455cca7-6c8d-4dc8-8718-2c919f9aad90,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-e3e2ee8c-f7ba-49e6-bdcd-3931ffe51e69,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-ee95238b-5f9f-4a4b-aedf-af637e861ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-39de4294-a986-4a7e-9747-06ebc33d2104,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086252856-172.17.0.2-1598467211818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42366,DS-35f84c44-456d-4146-94e2-e68f6720cea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-01d71984-ad2f-40eb-be5e-86d08e0a31f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-0e230aee-b1b7-4b90-a44b-53f62b3556d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-01d88a59-991e-4518-86f2-72040cb8c629,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-52607e1f-d0b1-4c54-a177-232eb7656284,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-1608c680-0b74-4859-92f8-39cbad6c04f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-09b1bed3-344d-4956-a4ed-8ec31139ba45,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-4f71704a-f9e8-4d1e-a416-7bdafed1d4d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086252856-172.17.0.2-1598467211818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42366,DS-35f84c44-456d-4146-94e2-e68f6720cea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-01d71984-ad2f-40eb-be5e-86d08e0a31f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-0e230aee-b1b7-4b90-a44b-53f62b3556d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-01d88a59-991e-4518-86f2-72040cb8c629,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-52607e1f-d0b1-4c54-a177-232eb7656284,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-1608c680-0b74-4859-92f8-39cbad6c04f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-09b1bed3-344d-4956-a4ed-8ec31139ba45,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-4f71704a-f9e8-4d1e-a416-7bdafed1d4d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130204466-172.17.0.2-1598467711509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40184,DS-36955fd1-a7ba-4300-a2b9-0753e42b34e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-ae450b20-10f8-4a5d-9840-d0084aea1c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-4ea4ffec-886d-4b31-b1c3-14e243e8d5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-cb528ba1-978a-4310-a708-1a42872c9694,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-82a1c330-dd9d-4195-af6c-06a61f993911,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-6f9f22fa-b38d-4b58-99f2-6c82eae4ad5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-801a9b23-2a36-484f-bfaa-1d44794edc94,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-eb3a1e13-04a5-4a3a-b612-56f6e58965fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130204466-172.17.0.2-1598467711509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40184,DS-36955fd1-a7ba-4300-a2b9-0753e42b34e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-ae450b20-10f8-4a5d-9840-d0084aea1c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-4ea4ffec-886d-4b31-b1c3-14e243e8d5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-cb528ba1-978a-4310-a708-1a42872c9694,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-82a1c330-dd9d-4195-af6c-06a61f993911,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-6f9f22fa-b38d-4b58-99f2-6c82eae4ad5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-801a9b23-2a36-484f-bfaa-1d44794edc94,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-eb3a1e13-04a5-4a3a-b612-56f6e58965fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880538279-172.17.0.2-1598467779886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35986,DS-a1440b57-52ca-4c1e-996c-ce1fd5f995bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-b5bc8902-db9b-478c-a0e9-ee971a89d888,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-e578f769-d0ec-4c11-88fb-1acf92d0a433,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-f80f16d2-bddc-4799-8eb4-a032b5513640,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-d2b4d294-66fe-44f3-93da-18d75cf44f50,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-13771587-03b5-415f-ac38-73138dcbc5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-b4f04833-9ae6-4530-bd6c-b3fd0ec0ad74,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-884859b6-1a94-46ee-a18e-3065aeb0683b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880538279-172.17.0.2-1598467779886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35986,DS-a1440b57-52ca-4c1e-996c-ce1fd5f995bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-b5bc8902-db9b-478c-a0e9-ee971a89d888,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-e578f769-d0ec-4c11-88fb-1acf92d0a433,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-f80f16d2-bddc-4799-8eb4-a032b5513640,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-d2b4d294-66fe-44f3-93da-18d75cf44f50,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-13771587-03b5-415f-ac38-73138dcbc5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-b4f04833-9ae6-4530-bd6c-b3fd0ec0ad74,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-884859b6-1a94-46ee-a18e-3065aeb0683b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282172486-172.17.0.2-1598467849240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46192,DS-0878c7fb-1ce7-43ff-b654-b5412d870380,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-0ad553da-cdcb-4786-84af-03e8dacaf065,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-bf51f422-6915-42e1-9653-3919f8101adf,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-7ddc8cc8-7135-4522-81b4-6b324c9b5596,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-58da8331-f8bc-41d9-bc4c-380e916b7287,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-d7bde1ab-9dab-45ae-9878-2fb4bf2d3ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-80c54306-9e02-450e-9ee2-baec3955104e,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-a8df7513-2f3a-49f5-a87c-a79460c2f893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282172486-172.17.0.2-1598467849240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46192,DS-0878c7fb-1ce7-43ff-b654-b5412d870380,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-0ad553da-cdcb-4786-84af-03e8dacaf065,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-bf51f422-6915-42e1-9653-3919f8101adf,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-7ddc8cc8-7135-4522-81b4-6b324c9b5596,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-58da8331-f8bc-41d9-bc4c-380e916b7287,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-d7bde1ab-9dab-45ae-9878-2fb4bf2d3ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-80c54306-9e02-450e-9ee2-baec3955104e,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-a8df7513-2f3a-49f5-a87c-a79460c2f893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435933243-172.17.0.2-1598467916643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45167,DS-51b3ec36-4918-4907-b835-c9549f62caa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-a78438b8-0385-49cd-8145-1c1b7e801a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-2914e039-6332-4c49-875a-c2688b37cfab,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-98881463-cc7a-40b9-8486-59f417f81af0,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-2a62f17d-2eff-4a86-8df7-d98a45bc6632,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-2d37a5b3-3700-48e9-9240-ea5daa7bb6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-3995df96-3017-4dd9-9e30-a6adcbb75e32,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-6fce7820-2f30-422e-8598-ce3d1a18c1cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435933243-172.17.0.2-1598467916643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45167,DS-51b3ec36-4918-4907-b835-c9549f62caa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-a78438b8-0385-49cd-8145-1c1b7e801a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-2914e039-6332-4c49-875a-c2688b37cfab,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-98881463-cc7a-40b9-8486-59f417f81af0,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-2a62f17d-2eff-4a86-8df7-d98a45bc6632,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-2d37a5b3-3700-48e9-9240-ea5daa7bb6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-3995df96-3017-4dd9-9e30-a6adcbb75e32,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-6fce7820-2f30-422e-8598-ce3d1a18c1cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5151
