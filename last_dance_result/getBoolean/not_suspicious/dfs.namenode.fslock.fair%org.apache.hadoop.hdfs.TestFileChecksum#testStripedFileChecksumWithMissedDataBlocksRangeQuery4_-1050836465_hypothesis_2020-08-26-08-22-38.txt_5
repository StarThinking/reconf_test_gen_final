reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729866243-172.17.0.15-1598430173596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37425,DS-4633f3f0-69f7-42c2-9315-2381eeeb9786,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-f07108bf-0aac-46eb-ac32-284173d0458c,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-3ed47bcc-7c09-4fc6-9565-87febd59eee7,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-520c42ab-d9a2-4421-8a94-6dbb4f7e3ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-29ef697c-7d47-47b0-a59a-ff817f16fde2,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-3cbc2e3e-6a33-48f7-bcfe-d1b642a95b45,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-7da40db9-f4bf-4021-ac13-136a19e18d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-87baef74-15f8-4905-9480-1d14e8a19dff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729866243-172.17.0.15-1598430173596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37425,DS-4633f3f0-69f7-42c2-9315-2381eeeb9786,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-f07108bf-0aac-46eb-ac32-284173d0458c,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-3ed47bcc-7c09-4fc6-9565-87febd59eee7,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-520c42ab-d9a2-4421-8a94-6dbb4f7e3ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-29ef697c-7d47-47b0-a59a-ff817f16fde2,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-3cbc2e3e-6a33-48f7-bcfe-d1b642a95b45,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-7da40db9-f4bf-4021-ac13-136a19e18d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-87baef74-15f8-4905-9480-1d14e8a19dff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886406703-172.17.0.15-1598430546758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33093,DS-8d42fb10-fbb4-4e74-9cf1-6e9a93ed749d,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-a974fd40-ee77-4ea9-abc9-6a72a9406db0,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-cf36ab9e-e4db-4c6b-8048-ca7ca8f94840,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-63a2aedf-333d-4c8b-95e3-d5c083529af2,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-d6e290d7-ec6f-4a3c-bf6c-a098d1d84414,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-2e5eaec3-d057-46d1-b3dd-da0fd247dc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-ab10b8a5-0549-4d43-848d-555f90feb941,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-df789708-8df1-4838-872a-6d906bd367af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886406703-172.17.0.15-1598430546758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33093,DS-8d42fb10-fbb4-4e74-9cf1-6e9a93ed749d,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-a974fd40-ee77-4ea9-abc9-6a72a9406db0,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-cf36ab9e-e4db-4c6b-8048-ca7ca8f94840,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-63a2aedf-333d-4c8b-95e3-d5c083529af2,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-d6e290d7-ec6f-4a3c-bf6c-a098d1d84414,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-2e5eaec3-d057-46d1-b3dd-da0fd247dc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-ab10b8a5-0549-4d43-848d-555f90feb941,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-df789708-8df1-4838-872a-6d906bd367af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707363169-172.17.0.15-1598431101355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40468,DS-35c856a1-1e0b-4559-abc3-c2d32b9f652f,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-f68dbcb2-50cd-4636-95af-df3d0d9a28a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-2a6563d8-a750-4dcb-b3f6-945f91454bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-303a1850-7996-4ce0-a8c7-77c1f5791029,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-3a97a5dc-998c-48a4-b6ae-1682f1f1b458,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-56810590-f3e5-4350-91cc-3d3495848f58,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-f6aa299e-a491-48df-b4b8-d45f3c9466ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-30c8012a-cbe9-4762-af10-01591dc306d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707363169-172.17.0.15-1598431101355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40468,DS-35c856a1-1e0b-4559-abc3-c2d32b9f652f,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-f68dbcb2-50cd-4636-95af-df3d0d9a28a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-2a6563d8-a750-4dcb-b3f6-945f91454bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-303a1850-7996-4ce0-a8c7-77c1f5791029,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-3a97a5dc-998c-48a4-b6ae-1682f1f1b458,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-56810590-f3e5-4350-91cc-3d3495848f58,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-f6aa299e-a491-48df-b4b8-d45f3c9466ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-30c8012a-cbe9-4762-af10-01591dc306d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988900351-172.17.0.15-1598431414615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37909,DS-a9d8d417-ccc8-4854-8df1-8f1085dc898f,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-f17e1c3d-8f8f-43af-a63b-7ede40c17a26,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-c49bf176-d7d4-468c-8bac-7d1702042722,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-35aa9f51-3018-4eeb-8b07-408cfaed789d,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-57a2b34d-0253-46d2-8ddc-8317da9de339,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-7a91f307-bc3d-4e26-852c-a62283affb59,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-63504f27-9e44-4fd8-b633-bccb7e626cac,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-4eda1398-8fcc-4641-8163-0c6a92eff937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988900351-172.17.0.15-1598431414615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37909,DS-a9d8d417-ccc8-4854-8df1-8f1085dc898f,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-f17e1c3d-8f8f-43af-a63b-7ede40c17a26,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-c49bf176-d7d4-468c-8bac-7d1702042722,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-35aa9f51-3018-4eeb-8b07-408cfaed789d,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-57a2b34d-0253-46d2-8ddc-8317da9de339,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-7a91f307-bc3d-4e26-852c-a62283affb59,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-63504f27-9e44-4fd8-b633-bccb7e626cac,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-4eda1398-8fcc-4641-8163-0c6a92eff937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825206842-172.17.0.15-1598431717498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36376,DS-9a9b6806-789f-4b1c-8a5a-7be85a576385,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-e707a350-8b4e-445a-8f3a-3ec520f63415,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-03ae956e-e176-45a5-b05f-d7514a912116,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-521e55e7-523a-4d98-99b5-029249fd7803,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-f7eabeba-724c-4a15-b758-28f2e92c69fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-c38701ed-f7ac-4209-9dc2-89fe6bc448a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-1f34c5ca-d3ff-420d-8114-d5586d37d4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-f34f68ff-fe99-4e03-95bb-850924836d6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825206842-172.17.0.15-1598431717498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36376,DS-9a9b6806-789f-4b1c-8a5a-7be85a576385,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-e707a350-8b4e-445a-8f3a-3ec520f63415,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-03ae956e-e176-45a5-b05f-d7514a912116,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-521e55e7-523a-4d98-99b5-029249fd7803,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-f7eabeba-724c-4a15-b758-28f2e92c69fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-c38701ed-f7ac-4209-9dc2-89fe6bc448a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-1f34c5ca-d3ff-420d-8114-d5586d37d4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-f34f68ff-fe99-4e03-95bb-850924836d6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5867616-172.17.0.15-1598431906452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43686,DS-afd441a9-d762-45a1-8809-a44d056889ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-9818c14e-8afa-4beb-9e3a-86dcba0fa83f,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-7923099c-b3d8-4bcf-9879-afcaff10f420,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-f081513e-6ec4-4ed0-bd76-8c008fac0595,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-1c8b8eb1-5190-4cdc-90e3-8c72240e716e,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-a186ad00-cb1b-4d0b-b76f-19d7c8089af5,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-b8be3bc8-ebf8-46f0-8ab0-48b591d79a96,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-fda66d4c-fb25-420d-8bfa-dbe5e49c5a30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5867616-172.17.0.15-1598431906452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43686,DS-afd441a9-d762-45a1-8809-a44d056889ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-9818c14e-8afa-4beb-9e3a-86dcba0fa83f,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-7923099c-b3d8-4bcf-9879-afcaff10f420,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-f081513e-6ec4-4ed0-bd76-8c008fac0595,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-1c8b8eb1-5190-4cdc-90e3-8c72240e716e,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-a186ad00-cb1b-4d0b-b76f-19d7c8089af5,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-b8be3bc8-ebf8-46f0-8ab0-48b591d79a96,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-fda66d4c-fb25-420d-8bfa-dbe5e49c5a30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862345343-172.17.0.15-1598432347981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38231,DS-dddbecbc-6cf0-435a-b0f1-8c2f4c629aec,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-15459dcc-ad11-4b45-880a-1172d37e13ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-5b996b9b-1503-4bdb-9dbb-f8deb3d0d965,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-0a5d6521-890e-417a-86c0-a8a4fb0e7d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-02812d6b-2890-4154-bf6a-6d513eac8f64,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-0e2317d7-956b-4137-a24a-9f487ae8c538,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-4d6d9531-8e8e-4039-bfd0-cf60bbf556e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-d5481b47-5cde-499e-a2c2-58d0df0a7aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862345343-172.17.0.15-1598432347981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38231,DS-dddbecbc-6cf0-435a-b0f1-8c2f4c629aec,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-15459dcc-ad11-4b45-880a-1172d37e13ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-5b996b9b-1503-4bdb-9dbb-f8deb3d0d965,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-0a5d6521-890e-417a-86c0-a8a4fb0e7d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-02812d6b-2890-4154-bf6a-6d513eac8f64,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-0e2317d7-956b-4137-a24a-9f487ae8c538,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-4d6d9531-8e8e-4039-bfd0-cf60bbf556e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-d5481b47-5cde-499e-a2c2-58d0df0a7aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53128960-172.17.0.15-1598432750211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42631,DS-6ec6d7b0-c75d-4a52-8421-b8281261c801,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-35da7c25-c5b8-4234-b8e8-e19e727aff36,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-f4d9b690-70eb-40a6-a17a-411d7b369140,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-4b010b39-3c18-4853-bc22-a9f6904ce4de,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-c44af267-6474-47b5-9926-3ffe75095f12,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-d601bfc0-3186-4f06-89f7-c59eb111ec8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-774c2db0-fb5c-4be0-aaec-6b0aba9a56cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-e2a05d05-a18a-4faf-abb0-c3cf013218b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53128960-172.17.0.15-1598432750211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42631,DS-6ec6d7b0-c75d-4a52-8421-b8281261c801,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-35da7c25-c5b8-4234-b8e8-e19e727aff36,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-f4d9b690-70eb-40a6-a17a-411d7b369140,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-4b010b39-3c18-4853-bc22-a9f6904ce4de,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-c44af267-6474-47b5-9926-3ffe75095f12,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-d601bfc0-3186-4f06-89f7-c59eb111ec8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-774c2db0-fb5c-4be0-aaec-6b0aba9a56cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-e2a05d05-a18a-4faf-abb0-c3cf013218b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969684959-172.17.0.15-1598433655810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41787,DS-511b056d-6874-4d29-8cd2-edbfe6694aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-03ef9035-ecc6-43c2-a429-23bc100c55de,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-f1d8efa1-aa8e-47d7-87ba-bfba861b44a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-1477c2a8-e95a-4400-9f1b-5b19cbbca71f,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-eea1429b-96e6-4e30-a498-9cbaa4ec9b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-bb91c532-963c-4d68-b2ad-440436285dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-d784e214-da9e-480a-ae21-f97b18e39725,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-ce2271a8-ffa4-448d-929e-efa128e47fc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969684959-172.17.0.15-1598433655810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41787,DS-511b056d-6874-4d29-8cd2-edbfe6694aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-03ef9035-ecc6-43c2-a429-23bc100c55de,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-f1d8efa1-aa8e-47d7-87ba-bfba861b44a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-1477c2a8-e95a-4400-9f1b-5b19cbbca71f,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-eea1429b-96e6-4e30-a498-9cbaa4ec9b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-bb91c532-963c-4d68-b2ad-440436285dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-d784e214-da9e-480a-ae21-f97b18e39725,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-ce2271a8-ffa4-448d-929e-efa128e47fc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-201100215-172.17.0.15-1598434102985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42501,DS-6308a07f-744b-436f-8a0e-d30bd6048661,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-3f551e3e-e454-43d3-b6b3-ad500cddb946,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-7556cb90-302b-419b-b210-2c93de4cf127,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-173be9d0-6158-4562-93fd-4a115e2b4df2,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-13e30421-3ee3-4427-ad21-ddedb6640c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-b58e185a-15d7-4d02-a71a-8bd77d7b684a,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-fef6c8bd-3511-456d-9de4-ac83c141d384,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-ad5be483-56ec-4e1a-a693-846dbdea09eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-201100215-172.17.0.15-1598434102985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42501,DS-6308a07f-744b-436f-8a0e-d30bd6048661,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-3f551e3e-e454-43d3-b6b3-ad500cddb946,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-7556cb90-302b-419b-b210-2c93de4cf127,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-173be9d0-6158-4562-93fd-4a115e2b4df2,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-13e30421-3ee3-4427-ad21-ddedb6640c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-b58e185a-15d7-4d02-a71a-8bd77d7b684a,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-fef6c8bd-3511-456d-9de4-ac83c141d384,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-ad5be483-56ec-4e1a-a693-846dbdea09eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059392550-172.17.0.15-1598434788658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41253,DS-3490788c-a26d-4809-954d-0f760d1e3dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-acae9f42-c5c6-4c51-b9e9-43d053456d20,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-e5ae5f7f-7045-4d9c-a2d1-8f30147c0a93,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-f60272a2-03e5-41e0-a9cf-b803cd8c9924,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-33258561-7043-4d79-867b-3cf985adf500,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-854662a3-9a4a-4ab9-9969-1d4c1c603f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-c6fe3d71-dbbd-44aa-82f7-4af958a6f5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-87900c6c-c7d6-4c6e-aec2-ae93eb609afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059392550-172.17.0.15-1598434788658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41253,DS-3490788c-a26d-4809-954d-0f760d1e3dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-acae9f42-c5c6-4c51-b9e9-43d053456d20,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-e5ae5f7f-7045-4d9c-a2d1-8f30147c0a93,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-f60272a2-03e5-41e0-a9cf-b803cd8c9924,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-33258561-7043-4d79-867b-3cf985adf500,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-854662a3-9a4a-4ab9-9969-1d4c1c603f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-c6fe3d71-dbbd-44aa-82f7-4af958a6f5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-87900c6c-c7d6-4c6e-aec2-ae93eb609afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967651515-172.17.0.15-1598434986480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33974,DS-531278bd-cd64-4c85-a436-a31c10b90af9,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-2584fabf-ad11-46fc-bd31-3150fee6a5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-19da1667-a52d-468d-b3cb-a3a0c6c35e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-cb524794-afed-4dae-a9ff-e870c886e186,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-c3654429-9823-4777-ab8e-b324cffe68dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-4d18a28e-2584-4f60-931d-29de461307eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-37b56c5c-2f9f-40ef-8af9-7fd130235142,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-fb72e372-aadd-49dc-8496-eed30a15357f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967651515-172.17.0.15-1598434986480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33974,DS-531278bd-cd64-4c85-a436-a31c10b90af9,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-2584fabf-ad11-46fc-bd31-3150fee6a5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-19da1667-a52d-468d-b3cb-a3a0c6c35e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-cb524794-afed-4dae-a9ff-e870c886e186,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-c3654429-9823-4777-ab8e-b324cffe68dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-4d18a28e-2584-4f60-931d-29de461307eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-37b56c5c-2f9f-40ef-8af9-7fd130235142,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-fb72e372-aadd-49dc-8496-eed30a15357f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5326
