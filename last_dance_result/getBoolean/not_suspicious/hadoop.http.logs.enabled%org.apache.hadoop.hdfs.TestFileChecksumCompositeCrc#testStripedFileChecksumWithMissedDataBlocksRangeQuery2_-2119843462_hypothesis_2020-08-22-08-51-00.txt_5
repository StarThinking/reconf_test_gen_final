reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586139739-172.17.0.2-1598086445783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45683,DS-77b2e2d4-ee80-46cc-98ed-86dc806d1cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-3305373b-fce9-4ebb-bdb2-d2394e0ae4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-7d7480e9-7bf5-492f-86ae-2de228f56a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-d27c345f-8c5e-46fb-83ba-058153d147c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-fe8f6ecb-a280-49a3-8a46-bde9d78ff3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-1c267100-2553-4476-b69f-831685f80874,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-4ca7a8bb-3eae-4b3d-8fa7-18f6b8b67820,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-37fad2fc-888d-4f84-87e7-51a372d84293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586139739-172.17.0.2-1598086445783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45683,DS-77b2e2d4-ee80-46cc-98ed-86dc806d1cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-3305373b-fce9-4ebb-bdb2-d2394e0ae4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-7d7480e9-7bf5-492f-86ae-2de228f56a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-d27c345f-8c5e-46fb-83ba-058153d147c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-fe8f6ecb-a280-49a3-8a46-bde9d78ff3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-1c267100-2553-4476-b69f-831685f80874,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-4ca7a8bb-3eae-4b3d-8fa7-18f6b8b67820,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-37fad2fc-888d-4f84-87e7-51a372d84293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841935072-172.17.0.2-1598087031256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46557,DS-a25c5721-aaed-4bd8-a896-9ab638ce2286,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-1a0779e6-1607-44e0-ae3f-11f68a758647,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-9c4e9155-eb2b-42d8-b7bf-6199606e92e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-8d9c66c8-bc60-4869-991d-ed213e90bba8,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-30454cf2-7c0d-4c0c-8b72-2849f68ec0db,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-5b5752fb-f104-4d09-973b-a86d07b80f26,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-24b59483-6e78-4669-8ced-d6db72cbd42d,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-1a95c5aa-3d73-4785-83fb-9e5cf4d7b1a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841935072-172.17.0.2-1598087031256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46557,DS-a25c5721-aaed-4bd8-a896-9ab638ce2286,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-1a0779e6-1607-44e0-ae3f-11f68a758647,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-9c4e9155-eb2b-42d8-b7bf-6199606e92e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-8d9c66c8-bc60-4869-991d-ed213e90bba8,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-30454cf2-7c0d-4c0c-8b72-2849f68ec0db,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-5b5752fb-f104-4d09-973b-a86d07b80f26,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-24b59483-6e78-4669-8ced-d6db72cbd42d,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-1a95c5aa-3d73-4785-83fb-9e5cf4d7b1a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019423173-172.17.0.2-1598087457066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41357,DS-50d68fa2-8553-4129-b1a1-4264df53bbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-75f01616-b7f3-4e07-ae45-16821d7dd1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-bddf3d75-b9e2-4d41-89af-04790ea651d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-26d96bc4-66a5-48be-b9f0-b0eeb08cdf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-35ae393e-2d9b-4a7d-8851-c4c027b16b00,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-49ba2f67-7485-4379-97fa-72cef6c69fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-787c7a01-0480-41cd-afc1-0d961c684d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-a976efe0-9dc8-4c45-bd49-0ed24c7f348c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019423173-172.17.0.2-1598087457066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41357,DS-50d68fa2-8553-4129-b1a1-4264df53bbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-75f01616-b7f3-4e07-ae45-16821d7dd1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-bddf3d75-b9e2-4d41-89af-04790ea651d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-26d96bc4-66a5-48be-b9f0-b0eeb08cdf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-35ae393e-2d9b-4a7d-8851-c4c027b16b00,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-49ba2f67-7485-4379-97fa-72cef6c69fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-787c7a01-0480-41cd-afc1-0d961c684d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-a976efe0-9dc8-4c45-bd49-0ed24c7f348c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127394342-172.17.0.2-1598087847712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39944,DS-a9622052-71fc-4d03-8f9c-eca4db36459c,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-99d45bff-faed-447b-bf46-4284c45939de,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-51f64987-ed49-449a-ba8b-57f7d90b78a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-00aa056e-062e-4bb6-9bb4-d429a9371c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-b1eabe0e-c6d9-46d2-8fa2-963d600fc2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-e42c1482-cfec-4e17-a7d0-8184db3f76c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-4f567f59-d442-47e3-91d1-78e7706c19a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-a7adb3f4-dde5-4142-8449-f6c42f02a8ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127394342-172.17.0.2-1598087847712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39944,DS-a9622052-71fc-4d03-8f9c-eca4db36459c,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-99d45bff-faed-447b-bf46-4284c45939de,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-51f64987-ed49-449a-ba8b-57f7d90b78a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-00aa056e-062e-4bb6-9bb4-d429a9371c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-b1eabe0e-c6d9-46d2-8fa2-963d600fc2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-e42c1482-cfec-4e17-a7d0-8184db3f76c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-4f567f59-d442-47e3-91d1-78e7706c19a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-a7adb3f4-dde5-4142-8449-f6c42f02a8ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199342953-172.17.0.2-1598088128340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40307,DS-54f1a654-3877-42a1-a507-128a807ad67f,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-2d1b0a56-89b8-45fa-ab02-25fae90644c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-8d9ebced-721f-4160-a6c8-33d08abf7429,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-2845ff2a-9778-4834-9478-dd23c6e5de92,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-99688e94-e10f-4654-b993-84ced45b86d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-c28f8afc-120d-4c22-ac6f-049986edd041,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-e371e92f-c0d3-4c5a-bc3a-2878c937afac,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-2cce68c3-1fe6-42ef-89d0-c3252e476c5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199342953-172.17.0.2-1598088128340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40307,DS-54f1a654-3877-42a1-a507-128a807ad67f,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-2d1b0a56-89b8-45fa-ab02-25fae90644c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-8d9ebced-721f-4160-a6c8-33d08abf7429,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-2845ff2a-9778-4834-9478-dd23c6e5de92,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-99688e94-e10f-4654-b993-84ced45b86d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-c28f8afc-120d-4c22-ac6f-049986edd041,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-e371e92f-c0d3-4c5a-bc3a-2878c937afac,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-2cce68c3-1fe6-42ef-89d0-c3252e476c5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145453656-172.17.0.2-1598088549965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35301,DS-cf200232-8039-4b43-8f64-c3a1f8ada7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-a7371836-4b06-4c30-9c12-e12227c395d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-1da18193-4f5c-4f81-92ed-5f8d69fb8828,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-3c3c2267-9a90-4ae9-a609-158593573e58,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-ad8c4fa8-2212-4320-8179-16f82670eb88,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-9be89824-ee19-4226-9cd5-b97dc5bb3e94,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-59e21aed-1c18-4eba-9cd3-5e191a28f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-c9d7bce3-3670-4f2a-a989-869f1d45dfd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145453656-172.17.0.2-1598088549965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35301,DS-cf200232-8039-4b43-8f64-c3a1f8ada7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-a7371836-4b06-4c30-9c12-e12227c395d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-1da18193-4f5c-4f81-92ed-5f8d69fb8828,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-3c3c2267-9a90-4ae9-a609-158593573e58,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-ad8c4fa8-2212-4320-8179-16f82670eb88,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-9be89824-ee19-4226-9cd5-b97dc5bb3e94,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-59e21aed-1c18-4eba-9cd3-5e191a28f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-c9d7bce3-3670-4f2a-a989-869f1d45dfd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884692256-172.17.0.2-1598088902082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33362,DS-28e24906-a6e4-46fd-9289-4101f44f9d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-16496c3a-a33f-493b-9a60-7c8059d46f21,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-9f9f6439-96b9-4c0c-bd82-f7518fb3aa70,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-41f12bf5-19dc-440f-9b8a-bebe823b7514,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-669d753a-378a-4b61-842e-40a78a15ae58,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-f1345622-b4d8-46a7-b46f-f2da690136dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-bd6de4ca-356a-43e8-9bfb-f96e1e36a6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-f8ee8570-d666-4826-b88b-7c807a8f89f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884692256-172.17.0.2-1598088902082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33362,DS-28e24906-a6e4-46fd-9289-4101f44f9d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-16496c3a-a33f-493b-9a60-7c8059d46f21,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-9f9f6439-96b9-4c0c-bd82-f7518fb3aa70,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-41f12bf5-19dc-440f-9b8a-bebe823b7514,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-669d753a-378a-4b61-842e-40a78a15ae58,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-f1345622-b4d8-46a7-b46f-f2da690136dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-bd6de4ca-356a-43e8-9bfb-f96e1e36a6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-f8ee8570-d666-4826-b88b-7c807a8f89f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905692669-172.17.0.2-1598089415347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33533,DS-575fe51c-7212-4e15-b4af-3dcfbc4830d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-e760e6ec-58ab-4bde-9ea9-cdc302e5ef29,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-6c70ab43-2b92-4e9b-8f92-8994006a2bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-7bb5d374-5e47-4fde-bf44-20d312081275,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-f1b14a54-9996-4381-9ae9-58bd9e654804,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-253981c5-891c-4744-9a0a-b354d8ce413c,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-b57a4de9-52ea-4b9e-916d-66db4b01292c,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-fbbfedcc-6c27-46e4-8897-19840ee07e42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905692669-172.17.0.2-1598089415347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33533,DS-575fe51c-7212-4e15-b4af-3dcfbc4830d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-e760e6ec-58ab-4bde-9ea9-cdc302e5ef29,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-6c70ab43-2b92-4e9b-8f92-8994006a2bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-7bb5d374-5e47-4fde-bf44-20d312081275,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-f1b14a54-9996-4381-9ae9-58bd9e654804,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-253981c5-891c-4744-9a0a-b354d8ce413c,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-b57a4de9-52ea-4b9e-916d-66db4b01292c,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-fbbfedcc-6c27-46e4-8897-19840ee07e42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678488314-172.17.0.2-1598089447092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40783,DS-4fd43cde-f142-4c7d-a294-648b969c939d,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-1c146380-e1b4-4a67-a75b-8cd2bb406714,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-c7733d22-edbe-41a2-8185-1437352d5aca,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-261c92e2-eb46-4403-815a-866de7792442,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-43639ae7-b741-4887-a524-c7123c2861c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-fdbcd18d-cef8-4152-a17d-79956edb1722,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-171b6bff-7aaf-4c57-a965-58ea325d6b95,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-8d7fc291-4e50-4c69-bca7-d98551b541b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678488314-172.17.0.2-1598089447092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40783,DS-4fd43cde-f142-4c7d-a294-648b969c939d,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-1c146380-e1b4-4a67-a75b-8cd2bb406714,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-c7733d22-edbe-41a2-8185-1437352d5aca,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-261c92e2-eb46-4403-815a-866de7792442,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-43639ae7-b741-4887-a524-c7123c2861c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-fdbcd18d-cef8-4152-a17d-79956edb1722,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-171b6bff-7aaf-4c57-a965-58ea325d6b95,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-8d7fc291-4e50-4c69-bca7-d98551b541b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602680083-172.17.0.2-1598089482786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37437,DS-aaf5eaef-4552-4bb7-86cc-b4bbdbe5abdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-01197bed-8e50-41bc-ba21-2f54cd21d08a,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-4a172a59-e132-4c3f-b596-eea096d4ed13,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-ca8c25a4-3b4b-4ee7-9d9a-1cf79074a806,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-97f6f072-2d37-497c-a606-7bb4c5d5903b,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-b5e0492d-b097-43bc-9f9c-bb76c9da1de5,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-578f27c8-af60-47cf-87b4-e9710f062330,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-5d60dcef-328b-4821-8e8b-69fb3425c259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602680083-172.17.0.2-1598089482786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37437,DS-aaf5eaef-4552-4bb7-86cc-b4bbdbe5abdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-01197bed-8e50-41bc-ba21-2f54cd21d08a,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-4a172a59-e132-4c3f-b596-eea096d4ed13,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-ca8c25a4-3b4b-4ee7-9d9a-1cf79074a806,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-97f6f072-2d37-497c-a606-7bb4c5d5903b,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-b5e0492d-b097-43bc-9f9c-bb76c9da1de5,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-578f27c8-af60-47cf-87b4-e9710f062330,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-5d60dcef-328b-4821-8e8b-69fb3425c259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672745255-172.17.0.2-1598089630444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42958,DS-1c925a7a-5625-4c7e-ac8c-7bd8a1bb8c37,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-4467e276-fec1-42c5-ad0a-1a2a18b0f162,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-012d1329-4b7d-4643-8702-09ac68de408c,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-7827b784-b80c-4c05-a865-68345d112cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-ab5c1f04-209c-4590-8276-1f43b6be7957,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-2caf3e19-e2a4-4819-aa42-848659994aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-1bd9fbf7-de03-464a-91e7-50ef6b66651f,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-13a64d68-ff26-4bd4-a926-eccfa6d7bc53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672745255-172.17.0.2-1598089630444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42958,DS-1c925a7a-5625-4c7e-ac8c-7bd8a1bb8c37,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-4467e276-fec1-42c5-ad0a-1a2a18b0f162,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-012d1329-4b7d-4643-8702-09ac68de408c,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-7827b784-b80c-4c05-a865-68345d112cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-ab5c1f04-209c-4590-8276-1f43b6be7957,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-2caf3e19-e2a4-4819-aa42-848659994aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-1bd9fbf7-de03-464a-91e7-50ef6b66651f,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-13a64d68-ff26-4bd4-a926-eccfa6d7bc53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051741454-172.17.0.2-1598090825913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45579,DS-b2dda09b-0cca-4ace-aa80-c12084fa588a,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-6bb8b079-9e81-4b4c-902d-fbc330b94f96,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-facb100b-da49-4c3e-bb34-76661d00803b,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-c10274d1-d72b-4a7a-8508-6b3976c78a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-600a6356-fb2c-4bec-8b49-e6044880ed56,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-891545d1-ab37-461a-bbe0-085f0801b79f,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-c40ce7c9-7503-4273-8394-881037a6f655,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-63330a93-dfa9-4dde-9545-0567a7280051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051741454-172.17.0.2-1598090825913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45579,DS-b2dda09b-0cca-4ace-aa80-c12084fa588a,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-6bb8b079-9e81-4b4c-902d-fbc330b94f96,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-facb100b-da49-4c3e-bb34-76661d00803b,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-c10274d1-d72b-4a7a-8508-6b3976c78a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-600a6356-fb2c-4bec-8b49-e6044880ed56,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-891545d1-ab37-461a-bbe0-085f0801b79f,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-c40ce7c9-7503-4273-8394-881037a6f655,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-63330a93-dfa9-4dde-9545-0567a7280051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921028017-172.17.0.2-1598090898989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34692,DS-56077a18-8975-428e-bb0d-ee7d5f563445,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-1eaee08e-5691-4ad6-8d5a-f2e69f3179af,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-1b0b63c6-0a1d-4a59-9837-253efff3de80,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-4c7b54e0-4ce1-42a9-81fd-788b048c77c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-8550115c-d065-45ec-b90d-9f53c5caf672,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-93020d41-5328-4ad3-a960-814e30bd3146,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-caea9c47-d035-4470-ab7f-8bf4614f3130,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-a61eff27-4cd0-4849-bcbe-11a9ceeb1730,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921028017-172.17.0.2-1598090898989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34692,DS-56077a18-8975-428e-bb0d-ee7d5f563445,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-1eaee08e-5691-4ad6-8d5a-f2e69f3179af,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-1b0b63c6-0a1d-4a59-9837-253efff3de80,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-4c7b54e0-4ce1-42a9-81fd-788b048c77c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-8550115c-d065-45ec-b90d-9f53c5caf672,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-93020d41-5328-4ad3-a960-814e30bd3146,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-caea9c47-d035-4470-ab7f-8bf4614f3130,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-a61eff27-4cd0-4849-bcbe-11a9ceeb1730,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760179834-172.17.0.2-1598090936894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41325,DS-63aedd4e-68e7-425c-8119-8f0324ea69f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-540bd067-01cb-4e1b-bf34-f7f7d7a61384,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-33a04eb1-f719-4c75-a5e2-0e49b83a6c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-4337d859-f869-47dd-8fac-86c8ca2ae6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-b68fdb7c-8fdd-427f-9955-6365b44d29a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-37865763-dff0-4584-aa79-536f68e55e45,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-27ac2223-96fb-4845-a964-d260e0275ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-c97a0cfc-46c8-413c-b5a8-56f5b4d5e1e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760179834-172.17.0.2-1598090936894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41325,DS-63aedd4e-68e7-425c-8119-8f0324ea69f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-540bd067-01cb-4e1b-bf34-f7f7d7a61384,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-33a04eb1-f719-4c75-a5e2-0e49b83a6c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-4337d859-f869-47dd-8fac-86c8ca2ae6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-b68fdb7c-8fdd-427f-9955-6365b44d29a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-37865763-dff0-4584-aa79-536f68e55e45,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-27ac2223-96fb-4845-a964-d260e0275ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-c97a0cfc-46c8-413c-b5a8-56f5b4d5e1e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681766260-172.17.0.2-1598091167619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43823,DS-d370ab19-d47d-4d3f-9406-65ef4ee06c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-4c4e1444-b229-4d8c-8797-4802297e798d,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-b5d9ebb0-6a2f-44b2-9597-8f999b6318ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-01942628-291d-47e7-893c-6b81e09b49b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-5a8275cc-dc38-4e69-a0e2-4b95503f8d74,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-2108f07c-7af2-4296-ad63-bb5b7db159dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-5ce2eebf-5e5a-4f5b-9245-bf8f550bd09f,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-5d5014c2-fcf0-4bd3-94b6-ea99a6c3ebd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681766260-172.17.0.2-1598091167619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43823,DS-d370ab19-d47d-4d3f-9406-65ef4ee06c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-4c4e1444-b229-4d8c-8797-4802297e798d,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-b5d9ebb0-6a2f-44b2-9597-8f999b6318ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-01942628-291d-47e7-893c-6b81e09b49b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-5a8275cc-dc38-4e69-a0e2-4b95503f8d74,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-2108f07c-7af2-4296-ad63-bb5b7db159dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-5ce2eebf-5e5a-4f5b-9245-bf8f550bd09f,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-5d5014c2-fcf0-4bd3-94b6-ea99a6c3ebd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909594225-172.17.0.2-1598091287596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38698,DS-b1ac5695-40d1-425e-92eb-e061716ddd08,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-0e6acbd2-6c15-498e-804a-68a7424b8a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-22cb128a-aa5b-4ce2-8dd5-e198436fa721,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-1f0859de-4d67-4bc7-adf8-9b193d6591f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-18e406ee-a1f7-4963-ac9b-874556b91f47,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-18e0d004-734f-4c66-a13e-63d93f53092e,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-4076a10c-8962-404a-88eb-b993e857fc60,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-70966482-8da3-41e0-9814-2f05a8ee80e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909594225-172.17.0.2-1598091287596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38698,DS-b1ac5695-40d1-425e-92eb-e061716ddd08,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-0e6acbd2-6c15-498e-804a-68a7424b8a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-22cb128a-aa5b-4ce2-8dd5-e198436fa721,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-1f0859de-4d67-4bc7-adf8-9b193d6591f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-18e406ee-a1f7-4963-ac9b-874556b91f47,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-18e0d004-734f-4c66-a13e-63d93f53092e,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-4076a10c-8962-404a-88eb-b993e857fc60,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-70966482-8da3-41e0-9814-2f05a8ee80e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824950812-172.17.0.2-1598091606198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37993,DS-539ff77b-39e2-4828-ab55-e2b18267d551,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-38faaf48-540e-40e7-b8e6-ee1b1adb9040,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-e554fec0-9bb5-4286-82fb-7833597781a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-26ec339a-6a05-494d-9d4a-6f1758835b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-aa66d7f1-4a32-48dd-9c69-e57b63dd5f13,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-62817427-2164-49cd-91db-b4dd8195cd99,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-65db8b7b-cdba-4c96-a2a5-8f68a6c8b940,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-5d538849-cbd4-45bf-a55e-4347746c9e50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824950812-172.17.0.2-1598091606198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37993,DS-539ff77b-39e2-4828-ab55-e2b18267d551,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-38faaf48-540e-40e7-b8e6-ee1b1adb9040,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-e554fec0-9bb5-4286-82fb-7833597781a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-26ec339a-6a05-494d-9d4a-6f1758835b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-aa66d7f1-4a32-48dd-9c69-e57b63dd5f13,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-62817427-2164-49cd-91db-b4dd8195cd99,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-65db8b7b-cdba-4c96-a2a5-8f68a6c8b940,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-5d538849-cbd4-45bf-a55e-4347746c9e50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606928050-172.17.0.2-1598091643196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44478,DS-e6cc7d05-35c7-4128-b6b6-dd81fb2f1141,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-60261175-871d-4b02-95ff-695bbc6dee30,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-783e8c8a-a355-4e73-9d90-6a1b0baa98bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-93666bc7-19e5-439c-89e5-9b36f23716e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-f0d90ee2-59c1-44d8-8374-403588df2197,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-a9d016c7-66ae-4811-aee6-c114550a7f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-cc5ffc17-a054-4076-b617-b54f6d9977cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-4a23f7bc-242d-4f07-9735-73232e394952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606928050-172.17.0.2-1598091643196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44478,DS-e6cc7d05-35c7-4128-b6b6-dd81fb2f1141,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-60261175-871d-4b02-95ff-695bbc6dee30,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-783e8c8a-a355-4e73-9d90-6a1b0baa98bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-93666bc7-19e5-439c-89e5-9b36f23716e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-f0d90ee2-59c1-44d8-8374-403588df2197,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-a9d016c7-66ae-4811-aee6-c114550a7f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-cc5ffc17-a054-4076-b617-b54f6d9977cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-4a23f7bc-242d-4f07-9735-73232e394952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5630
