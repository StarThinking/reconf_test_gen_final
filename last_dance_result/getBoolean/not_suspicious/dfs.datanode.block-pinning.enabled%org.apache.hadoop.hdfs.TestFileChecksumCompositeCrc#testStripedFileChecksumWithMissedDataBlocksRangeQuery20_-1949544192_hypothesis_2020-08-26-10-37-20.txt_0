reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-387327066-172.17.0.13-1598438436859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40409,DS-6dd8036a-7920-47d8-80c7-3b90badda471,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-3403176e-98bf-4002-acbc-910bb4855610,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-93586ac8-32ad-4dc8-94c3-50fe2e1ad115,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-5bc6ae6a-065f-43c7-af24-734a2ff6f04a,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-824b70d2-07f1-4849-b843-22c19268eaae,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-aea22545-964b-4427-896c-d691687635bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-f84ae5a7-062a-499b-b876-f0f09d7f5601,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-26103437-bd4a-4384-b326-8545b2edb79e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-387327066-172.17.0.13-1598438436859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40409,DS-6dd8036a-7920-47d8-80c7-3b90badda471,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-3403176e-98bf-4002-acbc-910bb4855610,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-93586ac8-32ad-4dc8-94c3-50fe2e1ad115,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-5bc6ae6a-065f-43c7-af24-734a2ff6f04a,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-824b70d2-07f1-4849-b843-22c19268eaae,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-aea22545-964b-4427-896c-d691687635bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-f84ae5a7-062a-499b-b876-f0f09d7f5601,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-26103437-bd4a-4384-b326-8545b2edb79e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566422794-172.17.0.13-1598438595958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35506,DS-1cdb1954-4da2-45ef-b76a-8f333427336d,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-2ee7c833-bdbd-4ab3-a7dc-277df5f56642,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-e1191a51-6e6a-4969-8e9f-dff3e2a5bc66,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-301b428c-8145-4ee7-9bb4-35dd106915bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-0b44a4f4-a68e-40ba-a5f1-cc32d412be80,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-3f9846cd-3826-4c63-933d-7128d585db40,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-5bbc5423-712e-4906-964b-406ebf7ebc79,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-5b068174-8823-49b8-aa17-cd371e494813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566422794-172.17.0.13-1598438595958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35506,DS-1cdb1954-4da2-45ef-b76a-8f333427336d,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-2ee7c833-bdbd-4ab3-a7dc-277df5f56642,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-e1191a51-6e6a-4969-8e9f-dff3e2a5bc66,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-301b428c-8145-4ee7-9bb4-35dd106915bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-0b44a4f4-a68e-40ba-a5f1-cc32d412be80,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-3f9846cd-3826-4c63-933d-7128d585db40,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-5bbc5423-712e-4906-964b-406ebf7ebc79,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-5b068174-8823-49b8-aa17-cd371e494813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697154528-172.17.0.13-1598438666869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38193,DS-ba84ae19-e6bc-4dec-9952-83af8eb73c77,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-bfb4419b-b3ef-4da0-95a0-b77f462e2d93,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-7df260ae-0887-44dc-8b9a-85682bb43f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-18329e7b-0992-4d0f-95ba-74bc09083555,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-d5e1604c-d141-4a33-bde3-a2e3a8d736dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-8e55c086-3b16-4d3c-9047-cea38112c89b,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-a54df409-bcae-4c90-9fba-074895967485,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-54defe69-0617-4b99-bd3a-c87987f63821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697154528-172.17.0.13-1598438666869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38193,DS-ba84ae19-e6bc-4dec-9952-83af8eb73c77,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-bfb4419b-b3ef-4da0-95a0-b77f462e2d93,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-7df260ae-0887-44dc-8b9a-85682bb43f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-18329e7b-0992-4d0f-95ba-74bc09083555,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-d5e1604c-d141-4a33-bde3-a2e3a8d736dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-8e55c086-3b16-4d3c-9047-cea38112c89b,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-a54df409-bcae-4c90-9fba-074895967485,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-54defe69-0617-4b99-bd3a-c87987f63821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101673536-172.17.0.13-1598438823841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44647,DS-6ad68fdb-fd3f-423f-bd29-df812cc4b88c,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-38831880-ea4c-476a-b53b-ff5068e4c29d,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-ab41af33-7fe1-4e6b-b42c-af8392ca0c51,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-faee8f37-484c-4035-9944-6e5058a7360a,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-cee3a494-9af6-437e-a7cb-44e4579e1459,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-0c6377b8-6fda-4a9f-9c02-a9f3b84d299e,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-decd8159-cbb2-45b5-bd55-88c85fac78c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-5ca7d407-5e9e-40db-93eb-d2f01e279ed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101673536-172.17.0.13-1598438823841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44647,DS-6ad68fdb-fd3f-423f-bd29-df812cc4b88c,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-38831880-ea4c-476a-b53b-ff5068e4c29d,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-ab41af33-7fe1-4e6b-b42c-af8392ca0c51,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-faee8f37-484c-4035-9944-6e5058a7360a,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-cee3a494-9af6-437e-a7cb-44e4579e1459,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-0c6377b8-6fda-4a9f-9c02-a9f3b84d299e,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-decd8159-cbb2-45b5-bd55-88c85fac78c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-5ca7d407-5e9e-40db-93eb-d2f01e279ed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399277702-172.17.0.13-1598439055435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37408,DS-8c0ef7b5-9814-4acd-b4d4-3adf8139e8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-ec1673f2-6296-4ea2-a838-6e32a1c0670e,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-6d8f5e43-4884-45a4-92fb-e0ed4eda00ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-c7884e89-f14a-4443-b0b8-08e22c34ca8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-ea89dafd-6609-4726-ba70-17c509b58d60,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-4c509999-d1e1-4e12-a0e8-2aacd9df2737,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-74988953-d2a2-403d-9355-da32bef9ab13,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-2675efad-1bb2-40ca-8807-71cf1941a9a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399277702-172.17.0.13-1598439055435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37408,DS-8c0ef7b5-9814-4acd-b4d4-3adf8139e8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-ec1673f2-6296-4ea2-a838-6e32a1c0670e,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-6d8f5e43-4884-45a4-92fb-e0ed4eda00ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-c7884e89-f14a-4443-b0b8-08e22c34ca8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-ea89dafd-6609-4726-ba70-17c509b58d60,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-4c509999-d1e1-4e12-a0e8-2aacd9df2737,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-74988953-d2a2-403d-9355-da32bef9ab13,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-2675efad-1bb2-40ca-8807-71cf1941a9a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765127700-172.17.0.13-1598439638263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37351,DS-b38e088d-a898-4869-b4cf-f88d21e9d3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-4af4166f-11a8-4a98-b58d-5384f695f2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-149d6ad9-90a6-4954-a768-a9cb4a19c612,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-6aadd9ca-636d-4e4b-902c-743df599d48d,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-17ac6c60-ecdc-4042-b579-d53b77d1649f,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-5627170b-d8d2-48e0-8a8e-15a0d402cb08,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-29a9e63f-5c1b-4143-9e7e-f8706bf0abda,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-fa5888b1-88f9-4047-8a95-7f3fa3b4050e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765127700-172.17.0.13-1598439638263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37351,DS-b38e088d-a898-4869-b4cf-f88d21e9d3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-4af4166f-11a8-4a98-b58d-5384f695f2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-149d6ad9-90a6-4954-a768-a9cb4a19c612,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-6aadd9ca-636d-4e4b-902c-743df599d48d,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-17ac6c60-ecdc-4042-b579-d53b77d1649f,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-5627170b-d8d2-48e0-8a8e-15a0d402cb08,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-29a9e63f-5c1b-4143-9e7e-f8706bf0abda,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-fa5888b1-88f9-4047-8a95-7f3fa3b4050e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-60228056-172.17.0.13-1598439702032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34528,DS-eec5a677-ffbf-4bbf-9876-ada7a8bfb79c,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-221b475e-ffa3-47ee-9d0e-6ba5fea54d07,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-f15556f3-0ec0-4e32-8484-d154a9dd5754,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-a9a86394-ac04-4e66-9500-b6b60e63d4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-ab14c219-51c9-4acc-8c63-cb320657fc87,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-77041b33-8bdb-4b95-a306-9f969311c840,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-8464bf90-2b48-432a-8e69-0b8dd8cfc7be,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-1e9510dd-340a-4f05-bc9b-3f3a72176e15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-60228056-172.17.0.13-1598439702032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34528,DS-eec5a677-ffbf-4bbf-9876-ada7a8bfb79c,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-221b475e-ffa3-47ee-9d0e-6ba5fea54d07,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-f15556f3-0ec0-4e32-8484-d154a9dd5754,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-a9a86394-ac04-4e66-9500-b6b60e63d4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-ab14c219-51c9-4acc-8c63-cb320657fc87,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-77041b33-8bdb-4b95-a306-9f969311c840,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-8464bf90-2b48-432a-8e69-0b8dd8cfc7be,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-1e9510dd-340a-4f05-bc9b-3f3a72176e15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-758305896-172.17.0.13-1598440018705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39660,DS-38b858da-b464-4cb0-b20a-d6db20860cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-c78935ec-3ad4-495b-afa7-4abbc4f58205,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-40e9ede4-62b0-4367-9701-1a6f7f2ee382,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-0838da5c-d990-4371-ada0-80d384d20a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-a9b696e7-0bfc-4f94-91ea-4e59affc5d69,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-e394d3c3-8086-456b-8b95-28b313ffb0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-94fd2ccc-ef39-4a61-9efa-ba8673a18a60,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-fc658050-7b2a-4325-bfe0-61ba11b36535,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-758305896-172.17.0.13-1598440018705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39660,DS-38b858da-b464-4cb0-b20a-d6db20860cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-c78935ec-3ad4-495b-afa7-4abbc4f58205,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-40e9ede4-62b0-4367-9701-1a6f7f2ee382,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-0838da5c-d990-4371-ada0-80d384d20a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-a9b696e7-0bfc-4f94-91ea-4e59affc5d69,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-e394d3c3-8086-456b-8b95-28b313ffb0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-94fd2ccc-ef39-4a61-9efa-ba8673a18a60,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-fc658050-7b2a-4325-bfe0-61ba11b36535,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376317827-172.17.0.13-1598440545253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33773,DS-9c36d917-ee88-4443-bc12-3bc7922e791c,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-7fbfac6e-43d8-4686-81d4-7250238c9ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-89f204af-124a-4e69-a27c-085d8a08d97a,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-214b56c8-5fc4-4b29-ad5a-7bd580496872,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-8aee1696-eac6-4cf2-9809-1bb49ab37aed,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-984d3c05-fc82-4ef7-8f63-983b1dc99ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-80c97205-7650-44c2-8dbd-fa3537a0eb72,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-b476b847-88ee-4bb1-a801-3f3ca97c3045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376317827-172.17.0.13-1598440545253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33773,DS-9c36d917-ee88-4443-bc12-3bc7922e791c,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-7fbfac6e-43d8-4686-81d4-7250238c9ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-89f204af-124a-4e69-a27c-085d8a08d97a,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-214b56c8-5fc4-4b29-ad5a-7bd580496872,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-8aee1696-eac6-4cf2-9809-1bb49ab37aed,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-984d3c05-fc82-4ef7-8f63-983b1dc99ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-80c97205-7650-44c2-8dbd-fa3537a0eb72,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-b476b847-88ee-4bb1-a801-3f3ca97c3045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685753773-172.17.0.13-1598440618760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42956,DS-a169733f-72a6-47a0-a04d-0ec8b0875eee,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-a9e610fc-64a0-4819-aeaf-d4e0d7ce2be9,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-28fa8e7e-e398-4f96-84ef-32d8b921fb96,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-f5ba7803-8954-4187-8274-fff68e00aad5,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-10e11e5f-39df-45fb-a49c-bb332b125835,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-47994080-c5ce-42a7-98cf-137ba161327a,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-3c0fc867-962f-4196-9000-9618eb14935b,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-ab862414-2775-455c-af6d-aab25069d184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685753773-172.17.0.13-1598440618760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42956,DS-a169733f-72a6-47a0-a04d-0ec8b0875eee,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-a9e610fc-64a0-4819-aeaf-d4e0d7ce2be9,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-28fa8e7e-e398-4f96-84ef-32d8b921fb96,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-f5ba7803-8954-4187-8274-fff68e00aad5,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-10e11e5f-39df-45fb-a49c-bb332b125835,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-47994080-c5ce-42a7-98cf-137ba161327a,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-3c0fc867-962f-4196-9000-9618eb14935b,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-ab862414-2775-455c-af6d-aab25069d184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851478258-172.17.0.13-1598440883140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34643,DS-2a9e71d7-1b8b-4d69-a6f9-f88b3117ee2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-fc44c7fd-1f74-4f79-b6c4-4c9774b20a51,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-95cbcd88-ed05-48e3-932d-9af79e2ebf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-1c6e181b-5a70-40ce-9eef-35435b0356d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-d1b66d55-55da-404b-b23e-c72b575e20b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-4aa59e21-a329-4f0f-8360-531ae56cb28e,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-47c0e2fd-6ddc-4637-be13-658d7b0f951a,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-23c4f951-9547-4f6c-bec6-a0857a14d6da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851478258-172.17.0.13-1598440883140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34643,DS-2a9e71d7-1b8b-4d69-a6f9-f88b3117ee2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-fc44c7fd-1f74-4f79-b6c4-4c9774b20a51,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-95cbcd88-ed05-48e3-932d-9af79e2ebf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-1c6e181b-5a70-40ce-9eef-35435b0356d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-d1b66d55-55da-404b-b23e-c72b575e20b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-4aa59e21-a329-4f0f-8360-531ae56cb28e,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-47c0e2fd-6ddc-4637-be13-658d7b0f951a,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-23c4f951-9547-4f6c-bec6-a0857a14d6da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-522260725-172.17.0.13-1598441037961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41645,DS-c72a5739-e50d-4ba5-88a1-78640d33d225,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-8cf0d750-8fb2-42d6-9314-b161ea89d25c,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-51ae71f8-029d-420c-bac3-13f9c046d31d,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-2acfc177-fe81-49d6-a501-94ce0a7b747d,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-f0279037-f942-4339-bee2-78863d1ecd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-1483e709-0f38-4817-bf8a-7ed0d22c6f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-82545b1d-f3d9-48af-a561-e1f91ad11469,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-685a40af-0735-47c5-b3ef-4c88de6e274f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-522260725-172.17.0.13-1598441037961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41645,DS-c72a5739-e50d-4ba5-88a1-78640d33d225,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-8cf0d750-8fb2-42d6-9314-b161ea89d25c,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-51ae71f8-029d-420c-bac3-13f9c046d31d,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-2acfc177-fe81-49d6-a501-94ce0a7b747d,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-f0279037-f942-4339-bee2-78863d1ecd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-1483e709-0f38-4817-bf8a-7ed0d22c6f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-82545b1d-f3d9-48af-a561-e1f91ad11469,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-685a40af-0735-47c5-b3ef-4c88de6e274f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1853151890-172.17.0.13-1598442069428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37897,DS-b8762551-2160-424d-829d-9091ff7ae1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-2860bce4-11d6-41e0-b882-74e31f652228,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-bb40d4b1-189e-4fbf-9f47-46a0c2bd9021,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-0862cd30-5852-4c0e-bf1d-75ad1483feb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-4253445d-6eac-4067-99dc-bebcadc5b047,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-62829717-a48e-439e-941d-ac6a4ca2846e,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-45fcfa2f-3d4d-4f2b-a1dc-d43f5b8fcc67,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-53682a57-717c-42c5-ae7c-daf1bf5acc54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1853151890-172.17.0.13-1598442069428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37897,DS-b8762551-2160-424d-829d-9091ff7ae1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-2860bce4-11d6-41e0-b882-74e31f652228,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-bb40d4b1-189e-4fbf-9f47-46a0c2bd9021,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-0862cd30-5852-4c0e-bf1d-75ad1483feb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-4253445d-6eac-4067-99dc-bebcadc5b047,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-62829717-a48e-439e-941d-ac6a4ca2846e,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-45fcfa2f-3d4d-4f2b-a1dc-d43f5b8fcc67,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-53682a57-717c-42c5-ae7c-daf1bf5acc54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-292537892-172.17.0.13-1598442140768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43222,DS-b927be1c-6089-4f28-b8d1-82d027015b47,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-c8fec9ec-5427-454b-980e-37ca0ddbf71a,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-26e93722-3fe4-448a-9744-5c568c40eb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-236f2ada-2f5e-4e3f-a0c0-071245f097d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-bb0b6f74-15a6-4732-908a-017a9d5a9858,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-1fa7a05f-faa9-4a3b-9499-5df816148ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-c4069cf4-8301-4a45-a1ed-a71a56fd1cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-ad504a02-0c91-46aa-97d8-689490d2b81d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-292537892-172.17.0.13-1598442140768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43222,DS-b927be1c-6089-4f28-b8d1-82d027015b47,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-c8fec9ec-5427-454b-980e-37ca0ddbf71a,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-26e93722-3fe4-448a-9744-5c568c40eb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-236f2ada-2f5e-4e3f-a0c0-071245f097d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-bb0b6f74-15a6-4732-908a-017a9d5a9858,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-1fa7a05f-faa9-4a3b-9499-5df816148ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-c4069cf4-8301-4a45-a1ed-a71a56fd1cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-ad504a02-0c91-46aa-97d8-689490d2b81d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123288816-172.17.0.13-1598442180564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46325,DS-b048a409-fbcf-4ac3-ad14-2a4a2e8cd7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-a6d094c4-7b6c-4baf-8aa0-2101237709f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-3eaba36d-afc0-4ba3-a9a6-fb7c50bd58ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-6f9727d7-4612-4220-87bc-6b3dba0bf842,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-b8438fda-31e2-489c-b0d2-2d8a3e4f064f,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-1467b1b6-1aef-4a00-aed5-c05338a9767b,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-618b6873-5fdc-4e5b-a050-b23d0f3741d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-6733dfc1-624c-42a6-b714-7952acde6cd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123288816-172.17.0.13-1598442180564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46325,DS-b048a409-fbcf-4ac3-ad14-2a4a2e8cd7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-a6d094c4-7b6c-4baf-8aa0-2101237709f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-3eaba36d-afc0-4ba3-a9a6-fb7c50bd58ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-6f9727d7-4612-4220-87bc-6b3dba0bf842,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-b8438fda-31e2-489c-b0d2-2d8a3e4f064f,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-1467b1b6-1aef-4a00-aed5-c05338a9767b,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-618b6873-5fdc-4e5b-a050-b23d0f3741d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-6733dfc1-624c-42a6-b714-7952acde6cd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-310592736-172.17.0.13-1598442804829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34753,DS-7989d094-396c-41c0-8f8f-e96533ce5d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-6f7eaee1-a2b0-4070-b934-b3357664cbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-2fa454b2-b66d-4108-8909-7c24c07d1308,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-37928cdd-325a-45c5-b7a4-691ac13feaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-481d5e88-43fb-41c0-9598-f22cf1cefb92,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-d8875e32-a48c-4536-8724-1cc95e0cba21,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-d7661509-d8e3-4f99-999d-a63f2682a3de,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-24cf2acd-f40c-4c48-b2aa-a272da5b2ed5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-310592736-172.17.0.13-1598442804829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34753,DS-7989d094-396c-41c0-8f8f-e96533ce5d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-6f7eaee1-a2b0-4070-b934-b3357664cbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-2fa454b2-b66d-4108-8909-7c24c07d1308,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-37928cdd-325a-45c5-b7a4-691ac13feaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-481d5e88-43fb-41c0-9598-f22cf1cefb92,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-d8875e32-a48c-4536-8724-1cc95e0cba21,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-d7661509-d8e3-4f99-999d-a63f2682a3de,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-24cf2acd-f40c-4c48-b2aa-a272da5b2ed5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4671
