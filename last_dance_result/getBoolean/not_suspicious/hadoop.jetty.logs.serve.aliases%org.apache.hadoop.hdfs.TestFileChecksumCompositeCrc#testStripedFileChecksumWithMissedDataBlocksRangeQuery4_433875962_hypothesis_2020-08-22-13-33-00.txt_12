reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420164490-172.17.0.21-1598103990700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35771,DS-d32d75de-b32d-492e-a515-6a28efb2753b,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-a4983f9a-45f9-4872-a14d-8d7279506b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-e6dd0e74-839f-421d-9bcc-51cd574f1115,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-c002d39e-4a2c-433d-800b-7bcf11811cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-955d7fd6-3b53-4e48-9dc0-804f2675eebb,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-d76c3e97-7f3a-49e1-a149-9c0a1e789248,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-c8fe7e2c-3a68-4209-80e7-199f43b18535,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-ff3a7738-af56-412a-9ad8-12518d998571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420164490-172.17.0.21-1598103990700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35771,DS-d32d75de-b32d-492e-a515-6a28efb2753b,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-a4983f9a-45f9-4872-a14d-8d7279506b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-e6dd0e74-839f-421d-9bcc-51cd574f1115,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-c002d39e-4a2c-433d-800b-7bcf11811cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-955d7fd6-3b53-4e48-9dc0-804f2675eebb,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-d76c3e97-7f3a-49e1-a149-9c0a1e789248,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-c8fe7e2c-3a68-4209-80e7-199f43b18535,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-ff3a7738-af56-412a-9ad8-12518d998571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362557244-172.17.0.21-1598104277787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44604,DS-f19fe322-6697-4024-ad07-4a5b84bab110,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-8c03d602-f7c8-4f88-b8d9-dc0c470b224b,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-24276c0e-b5b0-4833-9e31-b459d9de3f00,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-53ec5fea-3cd3-449a-b460-84db0b4860b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-6a53de51-caf8-4682-920c-4b141819ba23,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-62b9e9c0-9a84-4a7a-a7d6-bdd357be7b35,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-4ed6a181-27c5-40d8-8d05-9c8167272baa,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-815d0929-ceb3-44c6-bb1b-7d7674534b28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362557244-172.17.0.21-1598104277787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44604,DS-f19fe322-6697-4024-ad07-4a5b84bab110,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-8c03d602-f7c8-4f88-b8d9-dc0c470b224b,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-24276c0e-b5b0-4833-9e31-b459d9de3f00,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-53ec5fea-3cd3-449a-b460-84db0b4860b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-6a53de51-caf8-4682-920c-4b141819ba23,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-62b9e9c0-9a84-4a7a-a7d6-bdd357be7b35,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-4ed6a181-27c5-40d8-8d05-9c8167272baa,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-815d0929-ceb3-44c6-bb1b-7d7674534b28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1893769064-172.17.0.21-1598104877757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39979,DS-e0ee029f-cef3-4363-b50c-5314a7cd6bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-b9dec381-c366-4cc5-826b-6ad10206d3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-d4017775-43da-4908-80ef-f61e05f9f3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-720f550a-2876-4b29-a046-bcfb05868563,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-acf9237d-9997-44ce-9a6b-4a70aa178ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-9b52a11e-d3bb-49a3-815e-cbde7571fceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-6bed2128-992e-4600-aad4-6172ce0f75fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-645f509a-292a-4321-993c-4f97d3e8d989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1893769064-172.17.0.21-1598104877757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39979,DS-e0ee029f-cef3-4363-b50c-5314a7cd6bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-b9dec381-c366-4cc5-826b-6ad10206d3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-d4017775-43da-4908-80ef-f61e05f9f3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-720f550a-2876-4b29-a046-bcfb05868563,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-acf9237d-9997-44ce-9a6b-4a70aa178ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-9b52a11e-d3bb-49a3-815e-cbde7571fceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-6bed2128-992e-4600-aad4-6172ce0f75fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-645f509a-292a-4321-993c-4f97d3e8d989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1932217316-172.17.0.21-1598105185407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42807,DS-f4796b31-11ca-4d1a-9570-708680733752,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-db756e1c-2d38-4ffb-a64a-5dae5464daeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-3d02238a-7b79-4e3c-80b2-9af5e2d26d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-8468d16c-6135-4643-b3e5-a5250d670bda,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-ce985834-3776-465d-b9ca-b6f39e14ab83,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-8464d9d9-c1f0-4f12-8ab7-3bface4be999,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-37810e14-7614-4c12-b1f6-30c5637c6a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-372eb3a1-c09a-4b5e-be3b-c63da6295a07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1932217316-172.17.0.21-1598105185407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42807,DS-f4796b31-11ca-4d1a-9570-708680733752,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-db756e1c-2d38-4ffb-a64a-5dae5464daeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-3d02238a-7b79-4e3c-80b2-9af5e2d26d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-8468d16c-6135-4643-b3e5-a5250d670bda,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-ce985834-3776-465d-b9ca-b6f39e14ab83,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-8464d9d9-c1f0-4f12-8ab7-3bface4be999,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-37810e14-7614-4c12-b1f6-30c5637c6a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-372eb3a1-c09a-4b5e-be3b-c63da6295a07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348776783-172.17.0.21-1598105647955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41040,DS-50fd1f66-0eed-478b-9e11-c4f03fc5db23,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-0dd6e6d8-1fc7-4cb9-a34f-a816146fa7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-bf9d1062-b93f-4b11-b67a-d0ae7af43678,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-24636e6d-2e8f-4df2-b75c-7c3cba3f26f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-d04d9208-768d-4118-bf4c-b054b107336a,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-d9f6854b-9954-4eb5-b6e7-8ca5b0824590,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-41271bfc-159f-442c-92eb-857af660dd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-4f7206a9-dab5-4d47-92ab-9494a6a5f3f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348776783-172.17.0.21-1598105647955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41040,DS-50fd1f66-0eed-478b-9e11-c4f03fc5db23,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-0dd6e6d8-1fc7-4cb9-a34f-a816146fa7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-bf9d1062-b93f-4b11-b67a-d0ae7af43678,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-24636e6d-2e8f-4df2-b75c-7c3cba3f26f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-d04d9208-768d-4118-bf4c-b054b107336a,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-d9f6854b-9954-4eb5-b6e7-8ca5b0824590,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-41271bfc-159f-442c-92eb-857af660dd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-4f7206a9-dab5-4d47-92ab-9494a6a5f3f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804328893-172.17.0.21-1598105965602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43091,DS-0110c983-6d94-4dee-b415-9fdc3a78d611,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-f02c3143-484f-4e86-a1db-c3de5a098906,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-878dcfbe-798d-4a69-8f97-1f6a6a495215,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-08c96e54-3e2f-4ea3-b703-1024ddd06fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-61d51a80-5574-4266-9438-774013773d63,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-6d95b369-0ec5-43ff-8313-2139c6304b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-8e7b1bf5-bd9c-4c15-8c34-52e7b4b2d48a,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-404a14b0-8694-4c19-8e82-0c5df65b137a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804328893-172.17.0.21-1598105965602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43091,DS-0110c983-6d94-4dee-b415-9fdc3a78d611,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-f02c3143-484f-4e86-a1db-c3de5a098906,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-878dcfbe-798d-4a69-8f97-1f6a6a495215,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-08c96e54-3e2f-4ea3-b703-1024ddd06fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-61d51a80-5574-4266-9438-774013773d63,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-6d95b369-0ec5-43ff-8313-2139c6304b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-8e7b1bf5-bd9c-4c15-8c34-52e7b4b2d48a,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-404a14b0-8694-4c19-8e82-0c5df65b137a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250023619-172.17.0.21-1598106348690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37239,DS-42117eea-d699-484a-a9e8-66c6e14240b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-f09356a9-8c0b-4fce-bc66-a2beff7d2eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-136751da-ddec-4cf2-8f57-a5eac2b75bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-9def4e5c-03e7-4abd-b016-88dc31870376,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-7e93a8e7-8a29-4328-85ae-aba22f2db085,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-4304ab0f-4cda-490a-b4da-b5674155a5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-986f681b-b34f-4abb-8d8d-1ca89fe28dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-03f37086-7153-4974-8969-4ebf22ad3c67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250023619-172.17.0.21-1598106348690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37239,DS-42117eea-d699-484a-a9e8-66c6e14240b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-f09356a9-8c0b-4fce-bc66-a2beff7d2eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-136751da-ddec-4cf2-8f57-a5eac2b75bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-9def4e5c-03e7-4abd-b016-88dc31870376,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-7e93a8e7-8a29-4328-85ae-aba22f2db085,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-4304ab0f-4cda-490a-b4da-b5674155a5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-986f681b-b34f-4abb-8d8d-1ca89fe28dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-03f37086-7153-4974-8969-4ebf22ad3c67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602282648-172.17.0.21-1598106716637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45827,DS-601dbc2a-10b4-4644-9f97-b34fbc95d6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-6baab535-42ea-4004-9e88-b1c5b95492cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-cca52a27-5a12-47d4-a533-fd0e3aca4e07,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-5d592612-9f5b-4787-8d34-1fc873fc0d03,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-f85d3a19-3e8f-47d6-924a-a9fad583af52,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-87cb34b7-e9b5-40c5-9135-214efda85280,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-8517e588-241c-4e63-869e-2d85f4426c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-b7855852-688e-408c-a320-793079ee64e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602282648-172.17.0.21-1598106716637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45827,DS-601dbc2a-10b4-4644-9f97-b34fbc95d6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-6baab535-42ea-4004-9e88-b1c5b95492cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-cca52a27-5a12-47d4-a533-fd0e3aca4e07,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-5d592612-9f5b-4787-8d34-1fc873fc0d03,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-f85d3a19-3e8f-47d6-924a-a9fad583af52,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-87cb34b7-e9b5-40c5-9135-214efda85280,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-8517e588-241c-4e63-869e-2d85f4426c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-b7855852-688e-408c-a320-793079ee64e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364398211-172.17.0.21-1598106778817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39294,DS-c5d78f72-c098-4bb7-9030-c319dcd47aba,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-89f047c6-d3ef-4909-9e58-4eb3559fddfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-28bf6dcf-5493-4fc3-8a75-f25accfc04f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-96fcb748-4b42-401f-8079-a969e5ceb60a,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-9888cf87-84bc-4218-aeaf-952c6fb9a3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-cadcca8b-a2ed-4162-bf6a-6a9993d74ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-41dad5bb-b158-426e-88b6-87ad1cd238bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-41214d15-c3d9-46e9-b8c3-1942de6a8477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364398211-172.17.0.21-1598106778817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39294,DS-c5d78f72-c098-4bb7-9030-c319dcd47aba,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-89f047c6-d3ef-4909-9e58-4eb3559fddfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-28bf6dcf-5493-4fc3-8a75-f25accfc04f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-96fcb748-4b42-401f-8079-a969e5ceb60a,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-9888cf87-84bc-4218-aeaf-952c6fb9a3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-cadcca8b-a2ed-4162-bf6a-6a9993d74ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-41dad5bb-b158-426e-88b6-87ad1cd238bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-41214d15-c3d9-46e9-b8c3-1942de6a8477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119246222-172.17.0.21-1598106809805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34902,DS-fdbbb70b-9beb-410d-93b1-47657d228de6,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-456b3e13-d5ba-4f10-9ee2-26a47f04abcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-3810dd6d-901b-4ac6-acbb-6944a386653b,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-bbbd78a7-9425-470f-8b01-fb4ee62fc80d,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-2b33f008-e938-46f9-8d5d-3ce965d357a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-db599231-bef2-4317-b181-50b9fd235c12,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-6f55d2ff-4e23-46cd-8753-d507e09e7efa,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-b9aaf187-4f72-42cc-9326-804a85a22c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119246222-172.17.0.21-1598106809805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34902,DS-fdbbb70b-9beb-410d-93b1-47657d228de6,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-456b3e13-d5ba-4f10-9ee2-26a47f04abcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-3810dd6d-901b-4ac6-acbb-6944a386653b,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-bbbd78a7-9425-470f-8b01-fb4ee62fc80d,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-2b33f008-e938-46f9-8d5d-3ce965d357a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-db599231-bef2-4317-b181-50b9fd235c12,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-6f55d2ff-4e23-46cd-8753-d507e09e7efa,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-b9aaf187-4f72-42cc-9326-804a85a22c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754178654-172.17.0.21-1598106841303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42765,DS-6438c744-4c70-4087-a99e-cbd1ba624441,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-3a8e362d-7d68-4420-a520-df7935ac1ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-bfd2febe-6bf1-4e2c-be34-3b014ff934f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-f68105c3-71c9-4df7-a2e2-c4714cc442ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-839cdcbb-4e9b-4fc7-82ad-c8a42b26a671,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-ac303041-e4d2-401e-ab66-d6eb1e1c7244,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-d5eb044b-d799-4999-a0e2-4affd5cedb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-e6dd4618-b4a3-468e-a582-174c76d52506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754178654-172.17.0.21-1598106841303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42765,DS-6438c744-4c70-4087-a99e-cbd1ba624441,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-3a8e362d-7d68-4420-a520-df7935ac1ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-bfd2febe-6bf1-4e2c-be34-3b014ff934f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-f68105c3-71c9-4df7-a2e2-c4714cc442ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-839cdcbb-4e9b-4fc7-82ad-c8a42b26a671,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-ac303041-e4d2-401e-ab66-d6eb1e1c7244,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-d5eb044b-d799-4999-a0e2-4affd5cedb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-e6dd4618-b4a3-468e-a582-174c76d52506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558743914-172.17.0.21-1598107071710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33368,DS-e9c9b774-3338-4688-a297-bff270a2a95e,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-6de672e2-f9e7-4848-8dab-36826b121384,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-17135144-bef5-4d59-b294-812268faf6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-f8889398-d8ff-478e-812c-b2de5c3bf826,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-d3be45ac-74fd-4327-aeae-6c1614153813,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-81fbb05e-4bf1-459c-8b07-880a851422c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-221afbf6-5f28-4a88-85f1-3981372d6d93,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-199456d1-3273-4abf-bb9d-84b32baaeb05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558743914-172.17.0.21-1598107071710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33368,DS-e9c9b774-3338-4688-a297-bff270a2a95e,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-6de672e2-f9e7-4848-8dab-36826b121384,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-17135144-bef5-4d59-b294-812268faf6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-f8889398-d8ff-478e-812c-b2de5c3bf826,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-d3be45ac-74fd-4327-aeae-6c1614153813,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-81fbb05e-4bf1-459c-8b07-880a851422c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-221afbf6-5f28-4a88-85f1-3981372d6d93,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-199456d1-3273-4abf-bb9d-84b32baaeb05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260181498-172.17.0.21-1598107618710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40067,DS-28f80aef-6411-4325-b157-625368228e40,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-1f9c912d-ff6c-4374-8c32-718cbe91cac8,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-4ef77192-2da9-4331-bec6-3e3474850a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-d457ab4a-d246-479b-8b7c-99d13018927c,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-246f7097-90c7-4c03-946c-80e7fb51e423,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-d8d60adb-b308-431d-a621-b1c68dc70830,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-ebfdb915-6ecc-40e7-9c6d-40b1e6d817e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-2a8ebad0-1805-4efa-a165-841affdbcf7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260181498-172.17.0.21-1598107618710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40067,DS-28f80aef-6411-4325-b157-625368228e40,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-1f9c912d-ff6c-4374-8c32-718cbe91cac8,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-4ef77192-2da9-4331-bec6-3e3474850a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-d457ab4a-d246-479b-8b7c-99d13018927c,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-246f7097-90c7-4c03-946c-80e7fb51e423,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-d8d60adb-b308-431d-a621-b1c68dc70830,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-ebfdb915-6ecc-40e7-9c6d-40b1e6d817e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-2a8ebad0-1805-4efa-a165-841affdbcf7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066470092-172.17.0.21-1598107684354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44636,DS-ec5e0dce-89a2-406e-8df1-1b751ac52405,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-61dbb1ab-e2a9-4ab7-b65e-53682b7d2f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-efe5e864-20f2-4bd8-88a6-36fdbcef2c26,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-b8deddfb-92db-42fd-8964-70f56a35e8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-b668f7f3-30b1-4152-9b14-87334baec6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-f023a1cf-c2d0-4445-ba10-284192df0f68,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-de0e9ea0-228e-43d7-b63c-a2c2a34e8068,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-d2cef790-5fcb-4f7b-9b81-3696115fce5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066470092-172.17.0.21-1598107684354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44636,DS-ec5e0dce-89a2-406e-8df1-1b751ac52405,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-61dbb1ab-e2a9-4ab7-b65e-53682b7d2f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-efe5e864-20f2-4bd8-88a6-36fdbcef2c26,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-b8deddfb-92db-42fd-8964-70f56a35e8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-b668f7f3-30b1-4152-9b14-87334baec6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-f023a1cf-c2d0-4445-ba10-284192df0f68,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-de0e9ea0-228e-43d7-b63c-a2c2a34e8068,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-d2cef790-5fcb-4f7b-9b81-3696115fce5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286845982-172.17.0.21-1598107885079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33589,DS-d031f5d2-58ea-42d0-86ab-e58f6cf1ecef,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-5a1faa4f-61c6-43f1-9d09-f867bbbbd840,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-1b5d5f06-a28d-4dde-a162-7e2e52314f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-1bb3f103-f505-4d26-8efb-f476e19d5109,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-8cf13f8b-6f41-433d-b678-fff0a48d8d35,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-bd555e7f-f75d-484b-9cda-6843c9872e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-54ac3838-6fe1-4324-b6b8-b2d16aa8d87f,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-e167944e-4f81-4212-99c6-e726e76450e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286845982-172.17.0.21-1598107885079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33589,DS-d031f5d2-58ea-42d0-86ab-e58f6cf1ecef,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-5a1faa4f-61c6-43f1-9d09-f867bbbbd840,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-1b5d5f06-a28d-4dde-a162-7e2e52314f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-1bb3f103-f505-4d26-8efb-f476e19d5109,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-8cf13f8b-6f41-433d-b678-fff0a48d8d35,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-bd555e7f-f75d-484b-9cda-6843c9872e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-54ac3838-6fe1-4324-b6b8-b2d16aa8d87f,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-e167944e-4f81-4212-99c6-e726e76450e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287224739-172.17.0.21-1598107954066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45243,DS-fbb64a7c-fd42-48f5-b205-6186a8c7e2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-33723be4-a31f-40c5-a78f-a1f67cc8e033,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-32da3d2b-0fab-4fca-9645-dfa3e8795dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-b1de4cb3-387e-4e42-b3a6-18f2c6045998,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-ad3164c6-98fb-4dda-af73-02e094a425cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-56a0c0bc-6b04-45ed-b345-6c09e168f748,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-16f4c333-cff0-45b0-8c34-03992cd11caf,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-8e0584e6-49a6-4b8d-baef-863447566358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287224739-172.17.0.21-1598107954066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45243,DS-fbb64a7c-fd42-48f5-b205-6186a8c7e2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-33723be4-a31f-40c5-a78f-a1f67cc8e033,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-32da3d2b-0fab-4fca-9645-dfa3e8795dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-b1de4cb3-387e-4e42-b3a6-18f2c6045998,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-ad3164c6-98fb-4dda-af73-02e094a425cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-56a0c0bc-6b04-45ed-b345-6c09e168f748,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-16f4c333-cff0-45b0-8c34-03992cd11caf,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-8e0584e6-49a6-4b8d-baef-863447566358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5089
