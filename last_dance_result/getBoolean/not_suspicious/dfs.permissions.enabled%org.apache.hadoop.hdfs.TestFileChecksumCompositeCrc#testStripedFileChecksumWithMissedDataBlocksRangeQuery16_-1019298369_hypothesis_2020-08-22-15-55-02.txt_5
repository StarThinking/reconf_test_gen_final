reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630846987-172.17.0.10-1598111938231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40818,DS-2dd13780-017b-49d5-99c1-7ba6fe506f73,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-774829a7-7d01-488a-a653-93e078a3262b,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-aad299db-be52-4032-b259-dd94247a399e,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-9d1c5bd4-e092-4055-a4b2-c847f819b74c,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-b512ce3c-a044-4e0a-9d6f-102d6d966c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-722a7b9c-4dcc-4c4a-bfb6-096c00ecb865,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-7f3f94c5-99b7-4c0a-94cb-5a960487d10d,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-2c29fdd0-93ae-429f-93ab-5416bd40d386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630846987-172.17.0.10-1598111938231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40818,DS-2dd13780-017b-49d5-99c1-7ba6fe506f73,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-774829a7-7d01-488a-a653-93e078a3262b,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-aad299db-be52-4032-b259-dd94247a399e,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-9d1c5bd4-e092-4055-a4b2-c847f819b74c,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-b512ce3c-a044-4e0a-9d6f-102d6d966c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-722a7b9c-4dcc-4c4a-bfb6-096c00ecb865,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-7f3f94c5-99b7-4c0a-94cb-5a960487d10d,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-2c29fdd0-93ae-429f-93ab-5416bd40d386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037432364-172.17.0.10-1598111975848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33888,DS-8a21e993-5cd5-4381-9720-d8c7147f6fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-84cc50a2-0eb4-4f66-84a3-9fbcd6755612,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-a19de86f-ad1a-4873-987c-65d0ac66adea,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-a8aaf0c0-396d-40ef-b2c1-a6e857c5e533,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-b4344518-9feb-4554-ada2-71996ba58f30,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-d7f89f19-0e17-4baf-acb8-5323ac3a0b55,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-94d58fbb-0e71-4233-b286-e767e3477c96,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-b44bd8b0-5b19-4c28-b3ab-65366135fe26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037432364-172.17.0.10-1598111975848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33888,DS-8a21e993-5cd5-4381-9720-d8c7147f6fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-84cc50a2-0eb4-4f66-84a3-9fbcd6755612,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-a19de86f-ad1a-4873-987c-65d0ac66adea,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-a8aaf0c0-396d-40ef-b2c1-a6e857c5e533,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-b4344518-9feb-4554-ada2-71996ba58f30,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-d7f89f19-0e17-4baf-acb8-5323ac3a0b55,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-94d58fbb-0e71-4233-b286-e767e3477c96,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-b44bd8b0-5b19-4c28-b3ab-65366135fe26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118695909-172.17.0.10-1598112129269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33633,DS-ab37afa3-eba4-47c5-9492-389bfdd9a19e,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-f82bc7b8-588e-482d-b862-0c506edb4c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-af72b046-009e-43be-81fa-34e9ba19ae12,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-a2007d04-ca71-4003-b740-4fe69dcb7047,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-1eb46dbd-7d3d-44bc-8ada-5c01f4e9015e,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-45352a26-bd9b-4399-80c0-1b9888d17112,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-ee8a75e2-b969-44cf-96db-61731904605d,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-2bb43860-5617-4fa9-a7b2-e7fe9302265d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118695909-172.17.0.10-1598112129269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33633,DS-ab37afa3-eba4-47c5-9492-389bfdd9a19e,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-f82bc7b8-588e-482d-b862-0c506edb4c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-af72b046-009e-43be-81fa-34e9ba19ae12,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-a2007d04-ca71-4003-b740-4fe69dcb7047,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-1eb46dbd-7d3d-44bc-8ada-5c01f4e9015e,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-45352a26-bd9b-4399-80c0-1b9888d17112,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-ee8a75e2-b969-44cf-96db-61731904605d,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-2bb43860-5617-4fa9-a7b2-e7fe9302265d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421009990-172.17.0.10-1598112336598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45563,DS-fbac2f8a-5ea0-48ed-b6af-00113107ab35,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-a0583e7c-5702-4565-b953-11f61e4e16af,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-a0dc0678-c0a4-49c0-93ec-5d8483b785d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-3f4f40ef-e165-4885-9ae8-f2c42dd1e90a,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-44314a34-f64b-48d3-84b1-610d18a06eca,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-1c8f15dd-0ae1-4a71-a371-bed0a7a3c791,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-1ae630e8-e396-491b-a16a-67ebcac1281a,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-17ea1938-d7cc-451d-80fb-276993bda66c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421009990-172.17.0.10-1598112336598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45563,DS-fbac2f8a-5ea0-48ed-b6af-00113107ab35,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-a0583e7c-5702-4565-b953-11f61e4e16af,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-a0dc0678-c0a4-49c0-93ec-5d8483b785d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-3f4f40ef-e165-4885-9ae8-f2c42dd1e90a,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-44314a34-f64b-48d3-84b1-610d18a06eca,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-1c8f15dd-0ae1-4a71-a371-bed0a7a3c791,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-1ae630e8-e396-491b-a16a-67ebcac1281a,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-17ea1938-d7cc-451d-80fb-276993bda66c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829015711-172.17.0.10-1598112747786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46681,DS-79dc2772-2db0-48f3-8692-06a319749e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-4643cb3d-801c-4ef4-b937-72fb74688a64,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-2e374747-7689-4abd-bc13-2d2df5d0c6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-d7108f6c-639c-4384-92b6-7cc0f8c869bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-ecc70f7d-c350-4c41-9c4b-6953a021a43d,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-4069e46f-ee1a-4de5-8af8-d55ac669367f,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-33cb85c0-58de-459d-aa26-901efc741d25,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-75e8191b-9eba-4a7a-b1c6-c6c52ac7cf8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829015711-172.17.0.10-1598112747786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46681,DS-79dc2772-2db0-48f3-8692-06a319749e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-4643cb3d-801c-4ef4-b937-72fb74688a64,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-2e374747-7689-4abd-bc13-2d2df5d0c6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-d7108f6c-639c-4384-92b6-7cc0f8c869bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-ecc70f7d-c350-4c41-9c4b-6953a021a43d,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-4069e46f-ee1a-4de5-8af8-d55ac669367f,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-33cb85c0-58de-459d-aa26-901efc741d25,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-75e8191b-9eba-4a7a-b1c6-c6c52ac7cf8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393209164-172.17.0.10-1598113516334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38634,DS-4d2ab74a-e3a6-4710-96c6-cc5f3bec1426,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-8f5de883-eabc-405a-94ef-d4dc588fa0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-1c82ccd3-4cd7-49b5-88de-65353add333b,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-910aa332-b357-49f1-8c80-70f60983c01b,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-6f7c5516-f31c-41dc-bc28-2dfe83e7d887,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-ed2ab292-d7f4-43b8-9a97-128bfe61f9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-df7a1432-6589-4da6-b677-8aa2418aa05b,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-959d7137-2e0b-4809-8f60-edaa699e0fac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393209164-172.17.0.10-1598113516334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38634,DS-4d2ab74a-e3a6-4710-96c6-cc5f3bec1426,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-8f5de883-eabc-405a-94ef-d4dc588fa0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-1c82ccd3-4cd7-49b5-88de-65353add333b,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-910aa332-b357-49f1-8c80-70f60983c01b,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-6f7c5516-f31c-41dc-bc28-2dfe83e7d887,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-ed2ab292-d7f4-43b8-9a97-128bfe61f9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-df7a1432-6589-4da6-b677-8aa2418aa05b,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-959d7137-2e0b-4809-8f60-edaa699e0fac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48826304-172.17.0.10-1598113969030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34809,DS-6d8abd7c-65f1-4ba5-9780-39b91c411202,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-bced9f91-ebea-4143-89e6-7d415161ebc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-be931fb5-3d30-4a0b-8f21-78eb5e1b55f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-c0b3c21f-4b07-4408-83f0-a7bf493eddb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-9e2125b0-9d8a-4a9a-bc10-c6e58232a12a,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-58fbf420-fca0-4c50-9a6a-f775e306e1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-c9bc6178-1d7c-4b9b-b17b-d42cccf60bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-76f722be-0626-4adc-b167-77eefa1d3910,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48826304-172.17.0.10-1598113969030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34809,DS-6d8abd7c-65f1-4ba5-9780-39b91c411202,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-bced9f91-ebea-4143-89e6-7d415161ebc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-be931fb5-3d30-4a0b-8f21-78eb5e1b55f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-c0b3c21f-4b07-4408-83f0-a7bf493eddb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-9e2125b0-9d8a-4a9a-bc10-c6e58232a12a,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-58fbf420-fca0-4c50-9a6a-f775e306e1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-c9bc6178-1d7c-4b9b-b17b-d42cccf60bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-76f722be-0626-4adc-b167-77eefa1d3910,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124133618-172.17.0.10-1598114343842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41299,DS-3704aeb2-a1d1-4160-b3ce-2ff1e3124f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-ed5b3c19-e072-4e0b-850f-026e589f7e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-d5369c4e-4f3a-4077-96a6-1322bbecbf62,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-c4105153-2a2e-463b-b170-5e50811c0cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-04e5f579-0923-4fd1-a700-90b13fc9021b,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-79f1b93a-c941-4fad-8034-1e79217b90a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-aad88cc5-400b-4114-af94-7d05ada1e390,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-0eaf710a-b7ce-4849-9a4a-7cf6fcc54953,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124133618-172.17.0.10-1598114343842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41299,DS-3704aeb2-a1d1-4160-b3ce-2ff1e3124f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-ed5b3c19-e072-4e0b-850f-026e589f7e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-d5369c4e-4f3a-4077-96a6-1322bbecbf62,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-c4105153-2a2e-463b-b170-5e50811c0cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-04e5f579-0923-4fd1-a700-90b13fc9021b,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-79f1b93a-c941-4fad-8034-1e79217b90a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-aad88cc5-400b-4114-af94-7d05ada1e390,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-0eaf710a-b7ce-4849-9a4a-7cf6fcc54953,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624556346-172.17.0.10-1598114442074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33397,DS-aec5eb66-bd59-4a0a-83b2-11dfaee2ce24,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-24164ed1-829e-4a2d-9f1c-e1be7ecd6161,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-940f6264-0c65-482a-9512-9bbc7d736360,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-7fb207ee-7edc-4b4e-a119-99ef5db4dc74,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-c9ecbc5e-02bd-492e-9cf8-51bd0c92eae3,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-cf4c7538-6b07-4af7-a179-bc3ee668cf73,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-68cefc72-1515-476a-80b7-01e5671d09d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-399b8f66-a24c-43a3-bdc9-e00f5b8a08da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624556346-172.17.0.10-1598114442074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33397,DS-aec5eb66-bd59-4a0a-83b2-11dfaee2ce24,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-24164ed1-829e-4a2d-9f1c-e1be7ecd6161,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-940f6264-0c65-482a-9512-9bbc7d736360,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-7fb207ee-7edc-4b4e-a119-99ef5db4dc74,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-c9ecbc5e-02bd-492e-9cf8-51bd0c92eae3,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-cf4c7538-6b07-4af7-a179-bc3ee668cf73,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-68cefc72-1515-476a-80b7-01e5671d09d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-399b8f66-a24c-43a3-bdc9-e00f5b8a08da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912667979-172.17.0.10-1598114810411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40760,DS-44746120-1ad1-4726-adf4-a347ef40f2db,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-c3bc2111-a0b6-4d9d-857f-725e83a61ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-b2cc3e47-499a-46e5-ae36-9ebb59736c70,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-f70332f6-6398-4a8c-bf88-b1bb4fcfdbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-ec34b918-6104-44e6-ba09-bc7556bf01c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-559298d7-305f-47a0-9e90-ecd74084bff7,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-99698962-a063-4a02-b851-8366c52c782f,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-ced3a8d2-02b8-4aed-a10b-c2cc11f374cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912667979-172.17.0.10-1598114810411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40760,DS-44746120-1ad1-4726-adf4-a347ef40f2db,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-c3bc2111-a0b6-4d9d-857f-725e83a61ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-b2cc3e47-499a-46e5-ae36-9ebb59736c70,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-f70332f6-6398-4a8c-bf88-b1bb4fcfdbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-ec34b918-6104-44e6-ba09-bc7556bf01c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-559298d7-305f-47a0-9e90-ecd74084bff7,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-99698962-a063-4a02-b851-8366c52c782f,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-ced3a8d2-02b8-4aed-a10b-c2cc11f374cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369109580-172.17.0.10-1598115151925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39511,DS-6faa8b87-6aac-4f72-89ea-f749475f7cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-1ed6f0fd-5386-49f1-9efa-f6c8581a0d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-19201b06-04c3-43da-83c9-5796176c5d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-6f34ab15-4f90-448f-966e-4ae14c053f38,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-00be564b-b79c-4a0e-80d4-534cfaf6cb28,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-11a17b95-8090-47db-a01d-8180bfed2201,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-da96adbc-6d39-4008-a862-34b252c64ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-2165968d-9eba-43f6-ae27-2b0086427fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369109580-172.17.0.10-1598115151925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39511,DS-6faa8b87-6aac-4f72-89ea-f749475f7cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-1ed6f0fd-5386-49f1-9efa-f6c8581a0d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-19201b06-04c3-43da-83c9-5796176c5d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-6f34ab15-4f90-448f-966e-4ae14c053f38,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-00be564b-b79c-4a0e-80d4-534cfaf6cb28,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-11a17b95-8090-47db-a01d-8180bfed2201,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-da96adbc-6d39-4008-a862-34b252c64ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-2165968d-9eba-43f6-ae27-2b0086427fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705726120-172.17.0.10-1598115774779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37118,DS-cbc08050-7315-4d06-bc3c-cdc982fb91b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-207c0152-bcaf-4136-a4e6-b442d62cf7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-3e3d560e-1b21-485f-8694-d708682b3b13,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-04ed6b09-dd0d-4f5f-9699-658474335a88,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-3b939baa-d59e-464a-a4e3-f302062adf20,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-98d53404-df60-4c23-bc5a-1a66911a7eee,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-0cc44f05-21de-4017-9d1e-f83921e09edb,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-b05d2b06-5cb0-4fc2-a6aa-23875e2e66b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705726120-172.17.0.10-1598115774779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37118,DS-cbc08050-7315-4d06-bc3c-cdc982fb91b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-207c0152-bcaf-4136-a4e6-b442d62cf7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-3e3d560e-1b21-485f-8694-d708682b3b13,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-04ed6b09-dd0d-4f5f-9699-658474335a88,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-3b939baa-d59e-464a-a4e3-f302062adf20,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-98d53404-df60-4c23-bc5a-1a66911a7eee,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-0cc44f05-21de-4017-9d1e-f83921e09edb,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-b05d2b06-5cb0-4fc2-a6aa-23875e2e66b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80768263-172.17.0.10-1598115883338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45457,DS-5ef5c94a-27d4-4507-b0cb-75d073e2bbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-bf7bdb6b-871a-4de0-8378-56209fdd807b,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-7263be4f-5e48-4a52-af55-3ec8e182c1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-e8f5a216-d0fd-4ad2-aa73-250527364fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-00c6467b-dd54-4919-a12a-22dca8856f49,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-e71e17df-1014-4b9c-a220-cf300233bda6,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-deed2b1b-b034-435c-baa6-fb685c1331db,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-d15185c1-b825-4f14-ad7d-55b3891f9316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80768263-172.17.0.10-1598115883338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45457,DS-5ef5c94a-27d4-4507-b0cb-75d073e2bbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-bf7bdb6b-871a-4de0-8378-56209fdd807b,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-7263be4f-5e48-4a52-af55-3ec8e182c1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-e8f5a216-d0fd-4ad2-aa73-250527364fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-00c6467b-dd54-4919-a12a-22dca8856f49,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-e71e17df-1014-4b9c-a220-cf300233bda6,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-deed2b1b-b034-435c-baa6-fb685c1331db,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-d15185c1-b825-4f14-ad7d-55b3891f9316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-576949734-172.17.0.10-1598116028046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42815,DS-4e5f587e-f5eb-4c52-a7c7-c4cb9b73498f,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-3642cbc2-1590-4498-b5e7-ba299bfdf15b,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-6766b99d-7ee5-4bce-8fe7-339d33cb5227,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-29880e0a-e178-47ab-a654-200f2effa8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-8cb48c3b-173f-484d-9adb-53783e110100,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-298f6885-15c0-4199-bcd0-2b65ea4f87c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-57d7220a-81db-40f6-9516-e67f38adf16a,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-23ea069b-f24e-4d73-aaa1-c2f8f7e8f8e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-576949734-172.17.0.10-1598116028046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42815,DS-4e5f587e-f5eb-4c52-a7c7-c4cb9b73498f,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-3642cbc2-1590-4498-b5e7-ba299bfdf15b,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-6766b99d-7ee5-4bce-8fe7-339d33cb5227,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-29880e0a-e178-47ab-a654-200f2effa8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-8cb48c3b-173f-484d-9adb-53783e110100,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-298f6885-15c0-4199-bcd0-2b65ea4f87c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-57d7220a-81db-40f6-9516-e67f38adf16a,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-23ea069b-f24e-4d73-aaa1-c2f8f7e8f8e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1629918053-172.17.0.10-1598116222233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43772,DS-0b9246ff-d877-49c8-8016-eed4a368e2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-0bb43416-68d7-47b8-828b-6b27b0ccbf53,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-818e1e0e-c810-4bad-a620-65fe8ec55b80,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-8f8d1e82-e099-4ebb-9c95-bf87227a00d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-ff41ce90-a962-44e3-b505-654749384113,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-ec86e35b-d66f-403d-b4b1-1988fee628e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-db6b2506-eb32-4e00-a04b-8d454d2abaab,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-bcba7d87-e937-438c-b7d8-feac4f4b1043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1629918053-172.17.0.10-1598116222233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43772,DS-0b9246ff-d877-49c8-8016-eed4a368e2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-0bb43416-68d7-47b8-828b-6b27b0ccbf53,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-818e1e0e-c810-4bad-a620-65fe8ec55b80,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-8f8d1e82-e099-4ebb-9c95-bf87227a00d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-ff41ce90-a962-44e3-b505-654749384113,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-ec86e35b-d66f-403d-b4b1-1988fee628e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-db6b2506-eb32-4e00-a04b-8d454d2abaab,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-bcba7d87-e937-438c-b7d8-feac4f4b1043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957389315-172.17.0.10-1598116324746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45511,DS-2c524463-ce91-4285-b84a-53613c500add,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-b44968f1-ba59-4ca6-ac29-8e5d75bdddcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-eb4e0bba-2701-4f87-bcc7-998791aa37c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-a3c0755b-bbc7-4112-b388-0b1d13e7a36a,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-9f908169-24d1-4c50-b7ea-b673f4813d21,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-66d342b3-5075-45b8-b7de-08dfc7af4bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-f3427736-1c4f-4345-84a2-397cd769c1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-09ddba48-0097-463e-b0be-e40b0ddf3196,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957389315-172.17.0.10-1598116324746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45511,DS-2c524463-ce91-4285-b84a-53613c500add,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-b44968f1-ba59-4ca6-ac29-8e5d75bdddcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-eb4e0bba-2701-4f87-bcc7-998791aa37c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-a3c0755b-bbc7-4112-b388-0b1d13e7a36a,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-9f908169-24d1-4c50-b7ea-b673f4813d21,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-66d342b3-5075-45b8-b7de-08dfc7af4bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-f3427736-1c4f-4345-84a2-397cd769c1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-09ddba48-0097-463e-b0be-e40b0ddf3196,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703713485-172.17.0.10-1598116359478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45801,DS-7242dad9-6126-44cb-a552-77e56c1bd4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-45b6266c-eb41-4190-877a-bab8489b33a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-4becdf5d-3f25-4b5e-b41a-586e2aae6c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-75f3bd03-2662-461a-a425-a115f4009ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-8041ac17-70d3-44df-94ff-6d43ba5fa143,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-5b7e9af6-0af1-46dc-9b06-6c185e679c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-05c4ed7b-00de-4803-a124-20813c66013a,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-3f8a21e0-a804-498b-95ce-d262ea4d1eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703713485-172.17.0.10-1598116359478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45801,DS-7242dad9-6126-44cb-a552-77e56c1bd4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-45b6266c-eb41-4190-877a-bab8489b33a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-4becdf5d-3f25-4b5e-b41a-586e2aae6c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-75f3bd03-2662-461a-a425-a115f4009ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-8041ac17-70d3-44df-94ff-6d43ba5fa143,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-5b7e9af6-0af1-46dc-9b06-6c185e679c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-05c4ed7b-00de-4803-a124-20813c66013a,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-3f8a21e0-a804-498b-95ce-d262ea4d1eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55055182-172.17.0.10-1598116609107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40810,DS-c422c41b-3a69-4a31-a276-146ba07464c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-bae2121e-f340-4376-8ab8-e224f9e73300,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-0cdd055a-81a6-4068-b9c2-793340f89502,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-b460a57a-73e5-4c8b-9e9f-d359216524b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-10acafad-e02a-4771-b531-98fc7757ada1,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-04677107-cebe-4a8b-9f95-b7ad8c77294d,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-91ed81e8-a922-4f93-8603-f1107a839831,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-393ee80e-b070-4ced-8cb6-1c60fd73a354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55055182-172.17.0.10-1598116609107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40810,DS-c422c41b-3a69-4a31-a276-146ba07464c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-bae2121e-f340-4376-8ab8-e224f9e73300,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-0cdd055a-81a6-4068-b9c2-793340f89502,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-b460a57a-73e5-4c8b-9e9f-d359216524b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-10acafad-e02a-4771-b531-98fc7757ada1,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-04677107-cebe-4a8b-9f95-b7ad8c77294d,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-91ed81e8-a922-4f93-8603-f1107a839831,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-393ee80e-b070-4ced-8cb6-1c60fd73a354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5225
