reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297918497-172.17.0.16-1598098012832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44223,DS-61523af4-6f63-49ad-8b0f-fb3585f9f5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-32c66063-dfb7-4e17-9725-168e2aeb1dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-737dbf76-e2cb-4b21-b533-464e24f4aef7,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-2a215585-5dab-4caf-9a0e-3aca2ec954bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-a8e2221c-da07-4523-bf3b-10bf2dd62372,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-4632eec9-d5bc-4fa3-a309-5e056640b7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-bf1973c3-fd4e-42d5-b637-8d91287c6edd,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-e38ba1d3-665d-48b6-afd0-08aef09489dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297918497-172.17.0.16-1598098012832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44223,DS-61523af4-6f63-49ad-8b0f-fb3585f9f5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-32c66063-dfb7-4e17-9725-168e2aeb1dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-737dbf76-e2cb-4b21-b533-464e24f4aef7,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-2a215585-5dab-4caf-9a0e-3aca2ec954bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-a8e2221c-da07-4523-bf3b-10bf2dd62372,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-4632eec9-d5bc-4fa3-a309-5e056640b7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-bf1973c3-fd4e-42d5-b637-8d91287c6edd,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-e38ba1d3-665d-48b6-afd0-08aef09489dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593757284-172.17.0.16-1598098159101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33068,DS-5ffa8a11-fc2c-4329-a8a9-60c7c56af0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-e2236d6f-602e-4504-98a2-41ef40e8817c,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-e6da2672-05dc-421f-8eac-064e7a3ef7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-d093b870-1cc7-4623-b073-48f9282553bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-606a969d-b6b0-4635-84d6-657faba04843,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-daac5a24-83d8-41f7-ab20-dc5f61784175,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-a5cf3925-a280-404a-8af9-47c586169daf,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-f97548b4-612c-41c8-b3d0-163eaa002e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593757284-172.17.0.16-1598098159101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33068,DS-5ffa8a11-fc2c-4329-a8a9-60c7c56af0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-e2236d6f-602e-4504-98a2-41ef40e8817c,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-e6da2672-05dc-421f-8eac-064e7a3ef7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-d093b870-1cc7-4623-b073-48f9282553bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-606a969d-b6b0-4635-84d6-657faba04843,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-daac5a24-83d8-41f7-ab20-dc5f61784175,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-a5cf3925-a280-404a-8af9-47c586169daf,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-f97548b4-612c-41c8-b3d0-163eaa002e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719569277-172.17.0.16-1598098229406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37587,DS-0c62fa0d-5472-4706-8d9e-a10cbd699819,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-8bb9a6dd-ddf3-4a34-8390-d6734e6d1545,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-84911eaa-b659-4934-a3fd-6ee34161dbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-f64b5c06-bd90-4a35-805e-c91c877d6a75,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-ea2f76cd-a011-4841-8315-ad6bd55eb973,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-278c2dc5-3d9f-469f-8526-200dcd429585,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-e0936cda-08a5-4444-945f-42c2ef86d150,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-d5cdb7c9-a684-4138-89b2-bd04e2678306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719569277-172.17.0.16-1598098229406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37587,DS-0c62fa0d-5472-4706-8d9e-a10cbd699819,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-8bb9a6dd-ddf3-4a34-8390-d6734e6d1545,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-84911eaa-b659-4934-a3fd-6ee34161dbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-f64b5c06-bd90-4a35-805e-c91c877d6a75,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-ea2f76cd-a011-4841-8315-ad6bd55eb973,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-278c2dc5-3d9f-469f-8526-200dcd429585,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-e0936cda-08a5-4444-945f-42c2ef86d150,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-d5cdb7c9-a684-4138-89b2-bd04e2678306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306184827-172.17.0.16-1598098559584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45750,DS-010456b1-aad4-422f-a957-9811bfba1a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-d6e564f6-befe-474d-9ad0-f218b01753a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-88c646e6-e835-4440-a7f2-9cf74e0d8ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-84b5d284-f8f3-4ece-95eb-863358c9bd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-b2ee2fd6-fdd1-4d7b-af12-c52550d0eb69,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-c273642d-7467-475a-94ce-a98665d510ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-76262b81-d1a1-4790-96d0-95decffb5b73,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-2e048b6b-d895-40b9-8b0e-5d882eeca427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306184827-172.17.0.16-1598098559584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45750,DS-010456b1-aad4-422f-a957-9811bfba1a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-d6e564f6-befe-474d-9ad0-f218b01753a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-88c646e6-e835-4440-a7f2-9cf74e0d8ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-84b5d284-f8f3-4ece-95eb-863358c9bd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-b2ee2fd6-fdd1-4d7b-af12-c52550d0eb69,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-c273642d-7467-475a-94ce-a98665d510ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-76262b81-d1a1-4790-96d0-95decffb5b73,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-2e048b6b-d895-40b9-8b0e-5d882eeca427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730347952-172.17.0.16-1598098627965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39862,DS-70e45334-4769-4d41-80bd-ecbef47095a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-9ea5b0da-24ea-447a-8f79-ddf1409835db,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-2006f95d-9dfb-4028-8890-343ad11e1638,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-56b60eae-566f-464b-97c3-4f0594295f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-a989050d-2089-4979-8bc2-2a38fbc06c22,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-18d21621-7f69-465b-a25b-a9487bda93f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-0c8adbbb-b95a-4485-baf7-1fb0f3bb46fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-3292332c-257f-4344-ae38-a9250f8ebc8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730347952-172.17.0.16-1598098627965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39862,DS-70e45334-4769-4d41-80bd-ecbef47095a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-9ea5b0da-24ea-447a-8f79-ddf1409835db,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-2006f95d-9dfb-4028-8890-343ad11e1638,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-56b60eae-566f-464b-97c3-4f0594295f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-a989050d-2089-4979-8bc2-2a38fbc06c22,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-18d21621-7f69-465b-a25b-a9487bda93f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-0c8adbbb-b95a-4485-baf7-1fb0f3bb46fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-3292332c-257f-4344-ae38-a9250f8ebc8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205500518-172.17.0.16-1598098663681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46778,DS-26e6bf54-b5a8-472f-89e7-839ace18ec9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-e2238880-16c7-4cf1-a036-c3eef4e14c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-7159e435-1402-4738-aa0b-f89e948092bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-4fbd1806-cc1e-4380-9932-f54de7082982,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-4c24647c-aa51-4431-a599-5aca79e8d3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-e0331aa4-1071-4f0c-af45-f3f112216e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-1bf431cf-2d04-4d76-92c6-5ac1bfdce70b,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-f5b9c9bf-2be1-41de-a79b-b03959815cb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205500518-172.17.0.16-1598098663681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46778,DS-26e6bf54-b5a8-472f-89e7-839ace18ec9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-e2238880-16c7-4cf1-a036-c3eef4e14c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-7159e435-1402-4738-aa0b-f89e948092bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-4fbd1806-cc1e-4380-9932-f54de7082982,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-4c24647c-aa51-4431-a599-5aca79e8d3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-e0331aa4-1071-4f0c-af45-f3f112216e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-1bf431cf-2d04-4d76-92c6-5ac1bfdce70b,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-f5b9c9bf-2be1-41de-a79b-b03959815cb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941840938-172.17.0.16-1598098946971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43605,DS-84054aab-76bc-45a2-845d-bd42dda04eae,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-924ea5f9-7670-4013-bca1-88f810ff7207,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-607e33fc-6554-4ee4-9ff5-a691b93428fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-ec14e55a-800d-4ca7-a8a6-62d117632332,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-272e6d22-ae82-487d-8f29-37e16d0d3554,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-f8383870-addf-4132-903c-4bd5f45ddb85,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-aa31e651-d522-43fd-ba24-9091ebe6282f,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-e4401563-4fd0-4ee1-9610-1a0968f7683e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941840938-172.17.0.16-1598098946971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43605,DS-84054aab-76bc-45a2-845d-bd42dda04eae,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-924ea5f9-7670-4013-bca1-88f810ff7207,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-607e33fc-6554-4ee4-9ff5-a691b93428fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-ec14e55a-800d-4ca7-a8a6-62d117632332,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-272e6d22-ae82-487d-8f29-37e16d0d3554,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-f8383870-addf-4132-903c-4bd5f45ddb85,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-aa31e651-d522-43fd-ba24-9091ebe6282f,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-e4401563-4fd0-4ee1-9610-1a0968f7683e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110355617-172.17.0.16-1598099427591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44664,DS-36bdc5cc-917b-476c-966e-4c469de2d028,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-fd356519-804f-4efb-b524-ee940bb027a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-583ea236-7cf5-4d16-a23d-02717bdc7e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-eab5ef30-a20b-4d0b-84c1-4034a40fce93,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-645995c4-08ec-4145-993e-d2c344f0df94,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-c6e3f94d-b7eb-4144-b0d5-10641208e7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-fb8ad005-6f6a-403f-9231-e415cac0cc34,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-c22cb2f4-839b-4acc-9df6-671b1b01edd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110355617-172.17.0.16-1598099427591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44664,DS-36bdc5cc-917b-476c-966e-4c469de2d028,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-fd356519-804f-4efb-b524-ee940bb027a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-583ea236-7cf5-4d16-a23d-02717bdc7e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-eab5ef30-a20b-4d0b-84c1-4034a40fce93,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-645995c4-08ec-4145-993e-d2c344f0df94,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-c6e3f94d-b7eb-4144-b0d5-10641208e7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-fb8ad005-6f6a-403f-9231-e415cac0cc34,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-c22cb2f4-839b-4acc-9df6-671b1b01edd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603361061-172.17.0.16-1598099459129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46328,DS-512bfe0c-6ad1-41f9-a359-15ca9c7dc5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-93c8aa17-74d8-4c21-a547-69b9e2e9dd15,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-9f5b395d-d6fc-4c08-a166-3b79c46cc508,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-b3b0ef2d-f400-4d25-9ca9-710ac24e0c78,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-2ae69e4e-0adc-4161-b294-733e5ec3bde1,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-884174ad-1ba1-4a26-a366-e81c080a3da7,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-bc54ccf2-5ed6-4af2-a423-d58c984dde1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-ffd92b7f-7ff5-4a75-9bb7-5ef80107c2c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603361061-172.17.0.16-1598099459129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46328,DS-512bfe0c-6ad1-41f9-a359-15ca9c7dc5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-93c8aa17-74d8-4c21-a547-69b9e2e9dd15,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-9f5b395d-d6fc-4c08-a166-3b79c46cc508,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-b3b0ef2d-f400-4d25-9ca9-710ac24e0c78,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-2ae69e4e-0adc-4161-b294-733e5ec3bde1,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-884174ad-1ba1-4a26-a366-e81c080a3da7,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-bc54ccf2-5ed6-4af2-a423-d58c984dde1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-ffd92b7f-7ff5-4a75-9bb7-5ef80107c2c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559076544-172.17.0.16-1598099966630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45498,DS-83417a1c-0660-4bfe-8ccc-edbe0c753978,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-68a83cde-77ef-4fa8-8bd3-45e8b5a3c36d,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-98982af4-e394-4dfc-bb00-d004927cbfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-6b60f544-bdb1-4ae7-9303-c2cb8d4b35d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-ca7eb512-b53b-47d0-8b25-858501b8bad5,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-cea631a4-606d-46cf-8605-d10a5bf0331e,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-cb57123b-ac28-4f5e-8997-fe5252049dac,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-19f1c03e-20db-4320-b599-13b311a313b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559076544-172.17.0.16-1598099966630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45498,DS-83417a1c-0660-4bfe-8ccc-edbe0c753978,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-68a83cde-77ef-4fa8-8bd3-45e8b5a3c36d,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-98982af4-e394-4dfc-bb00-d004927cbfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-6b60f544-bdb1-4ae7-9303-c2cb8d4b35d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-ca7eb512-b53b-47d0-8b25-858501b8bad5,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-cea631a4-606d-46cf-8605-d10a5bf0331e,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-cb57123b-ac28-4f5e-8997-fe5252049dac,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-19f1c03e-20db-4320-b599-13b311a313b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699602514-172.17.0.16-1598099997590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34437,DS-737c7015-7f31-4c36-a326-5ab099a1ae63,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-074fb047-e1ce-4357-97f4-8ea06a1a227a,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-8c8c3810-258e-401b-af3a-681bfb4f77ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-562860ad-62c6-4528-b0ec-700165f716fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-cac21ff4-f358-4e06-ac82-09fbe09decb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-aea74628-e76b-43aa-825b-dc29ef788c55,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-b671da58-1ce2-4f03-902c-5aba0bbb39df,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-8423322e-9c1f-4d76-ba90-a3a4aa60b514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699602514-172.17.0.16-1598099997590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34437,DS-737c7015-7f31-4c36-a326-5ab099a1ae63,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-074fb047-e1ce-4357-97f4-8ea06a1a227a,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-8c8c3810-258e-401b-af3a-681bfb4f77ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-562860ad-62c6-4528-b0ec-700165f716fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-cac21ff4-f358-4e06-ac82-09fbe09decb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-aea74628-e76b-43aa-825b-dc29ef788c55,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-b671da58-1ce2-4f03-902c-5aba0bbb39df,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-8423322e-9c1f-4d76-ba90-a3a4aa60b514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080040039-172.17.0.16-1598100028176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42296,DS-514aa85d-2dfc-43a6-af10-37fce0a49b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-b7289f4c-9a56-43b9-ba2c-ddca11d70f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-2bd07915-ebc0-464b-88b3-95e0f30ab670,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-396de2bc-127b-447b-866e-7dd2e0641ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-ef2bedcb-f158-45fc-baae-b68325684c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-a6e639b9-b3c7-48c1-8b90-cdc14197e6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-dd59f9fd-ce39-4e0e-91a2-34f68ce39066,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-9126335a-3ba8-4419-a3bc-04afbd6efeed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080040039-172.17.0.16-1598100028176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42296,DS-514aa85d-2dfc-43a6-af10-37fce0a49b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-b7289f4c-9a56-43b9-ba2c-ddca11d70f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-2bd07915-ebc0-464b-88b3-95e0f30ab670,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-396de2bc-127b-447b-866e-7dd2e0641ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-ef2bedcb-f158-45fc-baae-b68325684c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-a6e639b9-b3c7-48c1-8b90-cdc14197e6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-dd59f9fd-ce39-4e0e-91a2-34f68ce39066,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-9126335a-3ba8-4419-a3bc-04afbd6efeed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656182969-172.17.0.16-1598100196426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36431,DS-6995a800-3487-4090-adb4-75180c0ed968,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-18774a09-8de4-4fa0-bded-30f1f26a8259,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-9dc581a5-3762-4f74-b9c5-8a4dfcd7d39c,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-79906339-09ad-4dc6-a966-c3367ea4f6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-35502df2-55ae-41fe-ba9e-34169c3933b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-f0235779-de32-4062-aef2-98236ca3fcff,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-ae097691-3c0d-43e8-a736-76bab4865c70,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-69419df6-d978-41f3-92a4-8dbe0361bdfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656182969-172.17.0.16-1598100196426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36431,DS-6995a800-3487-4090-adb4-75180c0ed968,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-18774a09-8de4-4fa0-bded-30f1f26a8259,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-9dc581a5-3762-4f74-b9c5-8a4dfcd7d39c,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-79906339-09ad-4dc6-a966-c3367ea4f6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-35502df2-55ae-41fe-ba9e-34169c3933b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-f0235779-de32-4062-aef2-98236ca3fcff,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-ae097691-3c0d-43e8-a736-76bab4865c70,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-69419df6-d978-41f3-92a4-8dbe0361bdfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801945182-172.17.0.16-1598100347371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44498,DS-bd659d47-6446-44f7-9b66-7b175ba5b024,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-256e0ff6-f86b-4e89-af58-2bf995f6438f,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-e6928350-c703-4681-8c7d-7b18959989e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-8fb4cf77-4a80-4031-b1ed-d63f368e356c,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-957c5d47-92ce-418e-a5c9-1228d9ef247b,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-26d0713e-4670-4a70-b604-096e8102d011,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-f50ab9fe-9cdf-4595-a08a-d526d60a5827,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-6eb9257d-87d8-47cc-a537-de9a147cdf50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801945182-172.17.0.16-1598100347371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44498,DS-bd659d47-6446-44f7-9b66-7b175ba5b024,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-256e0ff6-f86b-4e89-af58-2bf995f6438f,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-e6928350-c703-4681-8c7d-7b18959989e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-8fb4cf77-4a80-4031-b1ed-d63f368e356c,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-957c5d47-92ce-418e-a5c9-1228d9ef247b,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-26d0713e-4670-4a70-b604-096e8102d011,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-f50ab9fe-9cdf-4595-a08a-d526d60a5827,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-6eb9257d-87d8-47cc-a537-de9a147cdf50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845831000-172.17.0.16-1598100444473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45565,DS-d2ff4505-6715-4866-a771-96e1f26128d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-d641dd90-1f01-49d1-972e-368a8844276a,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-03efd83f-177c-41f3-bb6e-7040cd117c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-e09114a2-4fe6-4136-b9d9-c4a7a21990e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-58933c77-88f8-40a9-ac45-a0bb3adff8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-7c39d7af-3f57-4b81-ae85-0e1cf11ce9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-a68a3cec-d53e-4228-94c1-d928e236be8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-050a42c2-b234-42b3-875e-ea0730ce9e71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845831000-172.17.0.16-1598100444473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45565,DS-d2ff4505-6715-4866-a771-96e1f26128d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-d641dd90-1f01-49d1-972e-368a8844276a,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-03efd83f-177c-41f3-bb6e-7040cd117c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-e09114a2-4fe6-4136-b9d9-c4a7a21990e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-58933c77-88f8-40a9-ac45-a0bb3adff8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-7c39d7af-3f57-4b81-ae85-0e1cf11ce9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-a68a3cec-d53e-4228-94c1-d928e236be8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-050a42c2-b234-42b3-875e-ea0730ce9e71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-521420616-172.17.0.16-1598100576022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33586,DS-2e9e8998-7b12-4e6f-8c78-cc709c7d59da,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-257c37c1-f209-4008-901e-466a0b7c1082,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-6f130a33-6cfb-4cb7-81a1-8358922a32f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-7306f4c8-8d21-45d1-a11a-3a8a69a45665,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-31b11c97-6bc0-4c81-8653-54325924ae1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-dbaf16fa-4fbb-412c-8a7e-47d3fdb19f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-e97ab489-621d-468c-8ab9-78bc6f809872,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-ac9340e1-c7b1-4cbb-9bad-419979142b2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-521420616-172.17.0.16-1598100576022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33586,DS-2e9e8998-7b12-4e6f-8c78-cc709c7d59da,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-257c37c1-f209-4008-901e-466a0b7c1082,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-6f130a33-6cfb-4cb7-81a1-8358922a32f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-7306f4c8-8d21-45d1-a11a-3a8a69a45665,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-31b11c97-6bc0-4c81-8653-54325924ae1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-dbaf16fa-4fbb-412c-8a7e-47d3fdb19f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-e97ab489-621d-468c-8ab9-78bc6f809872,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-ac9340e1-c7b1-4cbb-9bad-419979142b2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-38112399-172.17.0.16-1598100844926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41056,DS-838d26af-60cb-484a-a6d7-9e66e4e46cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-94c008cd-709f-4e7d-8b49-55926c8b3d26,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-3ee9c451-df6f-413e-82c2-855dd10d954a,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-a6cb681e-bfd6-47e2-ac18-b26e89da57b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-05be240f-f790-496e-bf1a-87ca9b27fcac,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-8b7962bf-c6ad-46a9-a883-4678270eb1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-cdf522b5-de37-402b-bea0-97b3429f8696,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-693ec45f-0cef-4258-ba75-3ce37abc3ca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-38112399-172.17.0.16-1598100844926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41056,DS-838d26af-60cb-484a-a6d7-9e66e4e46cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-94c008cd-709f-4e7d-8b49-55926c8b3d26,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-3ee9c451-df6f-413e-82c2-855dd10d954a,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-a6cb681e-bfd6-47e2-ac18-b26e89da57b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-05be240f-f790-496e-bf1a-87ca9b27fcac,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-8b7962bf-c6ad-46a9-a883-4678270eb1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-cdf522b5-de37-402b-bea0-97b3429f8696,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-693ec45f-0cef-4258-ba75-3ce37abc3ca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142529345-172.17.0.16-1598101631378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40911,DS-4406b260-4b43-4e11-87a9-512bf2c41a74,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-3a5952c9-b780-41ec-aff3-a11424a2f3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-9b378d7d-875d-4847-b9ff-e9d7d566219f,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-4dbe87c9-b094-4bce-ac89-0f0a3b785902,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-ee6de1ec-a2a1-4c6a-a274-5f3e578d86c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-9311d30a-d42f-4bfa-981b-5dd12f5fcc31,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-cf4be2aa-7cdb-4663-8569-6e7d8d6f6a31,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-9d15197e-a02c-463f-8e51-434639d17ef1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142529345-172.17.0.16-1598101631378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40911,DS-4406b260-4b43-4e11-87a9-512bf2c41a74,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-3a5952c9-b780-41ec-aff3-a11424a2f3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-9b378d7d-875d-4847-b9ff-e9d7d566219f,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-4dbe87c9-b094-4bce-ac89-0f0a3b785902,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-ee6de1ec-a2a1-4c6a-a274-5f3e578d86c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-9311d30a-d42f-4bfa-981b-5dd12f5fcc31,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-cf4be2aa-7cdb-4663-8569-6e7d8d6f6a31,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-9d15197e-a02c-463f-8e51-434639d17ef1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5288
