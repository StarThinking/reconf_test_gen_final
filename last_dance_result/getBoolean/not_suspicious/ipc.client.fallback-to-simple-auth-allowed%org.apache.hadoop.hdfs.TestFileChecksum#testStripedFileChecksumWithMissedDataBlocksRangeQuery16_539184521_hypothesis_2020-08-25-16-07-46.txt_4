reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-30589368-172.17.0.3-1598372473003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43068,DS-ebd4e8f2-0078-4faa-a650-ea97cfa5af7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-b43203aa-afdf-41b0-b085-c824bafb70de,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-bd7dd93f-6bf5-4086-b6c3-8297f3422c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-730ba812-13a6-4fc8-b03f-815d426a6c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-5b2ee530-c713-4488-b870-94e9b14cf7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-2245d644-d83a-4479-90b2-cf12b92e20d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-f5096fb9-a423-4d5b-96b4-615a9916f93c,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-a75db221-772f-4bbe-aeb2-5781665444bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-30589368-172.17.0.3-1598372473003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43068,DS-ebd4e8f2-0078-4faa-a650-ea97cfa5af7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-b43203aa-afdf-41b0-b085-c824bafb70de,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-bd7dd93f-6bf5-4086-b6c3-8297f3422c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-730ba812-13a6-4fc8-b03f-815d426a6c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-5b2ee530-c713-4488-b870-94e9b14cf7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-2245d644-d83a-4479-90b2-cf12b92e20d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-f5096fb9-a423-4d5b-96b4-615a9916f93c,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-a75db221-772f-4bbe-aeb2-5781665444bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680595333-172.17.0.3-1598372686658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41520,DS-e6dffea3-aab5-4cf5-9449-39a459dab63a,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-229687fa-04b7-4f23-b8e1-967750da92e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-ac5197ea-fcaa-41d8-94c3-70a62fa5e01d,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-f4c31474-bd4d-4c69-837d-5278cba5dd41,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-dfca8345-456f-4f32-a01a-3b21669c2d89,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-60e9a278-59c9-4938-a493-9fe6a2561fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-a214bee2-2d19-4364-9090-d0ee1eb7dc87,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-9aed3457-6eb6-4341-b5e6-4b02f5895076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680595333-172.17.0.3-1598372686658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41520,DS-e6dffea3-aab5-4cf5-9449-39a459dab63a,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-229687fa-04b7-4f23-b8e1-967750da92e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-ac5197ea-fcaa-41d8-94c3-70a62fa5e01d,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-f4c31474-bd4d-4c69-837d-5278cba5dd41,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-dfca8345-456f-4f32-a01a-3b21669c2d89,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-60e9a278-59c9-4938-a493-9fe6a2561fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-a214bee2-2d19-4364-9090-d0ee1eb7dc87,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-9aed3457-6eb6-4341-b5e6-4b02f5895076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781008091-172.17.0.3-1598372876411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40384,DS-0a3b9bf3-a9f0-41d3-bbed-61bdeac2b131,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-e47171c9-7e0c-4f7c-8482-c795b6d2309f,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-1a2a0af8-c194-466a-957c-2d6d15a1c633,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-67f52de1-6070-4554-a172-0ba8379935fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-4d1bed90-edd4-4b32-a35c-29379bcc8fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-3f0d0d6d-a2fe-499b-ab4a-ba8642b7e656,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-7f9321a9-5005-4d52-93be-fffbe8d09d41,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-b361b3c8-28f4-496d-a238-835478c2bd0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781008091-172.17.0.3-1598372876411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40384,DS-0a3b9bf3-a9f0-41d3-bbed-61bdeac2b131,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-e47171c9-7e0c-4f7c-8482-c795b6d2309f,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-1a2a0af8-c194-466a-957c-2d6d15a1c633,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-67f52de1-6070-4554-a172-0ba8379935fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-4d1bed90-edd4-4b32-a35c-29379bcc8fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-3f0d0d6d-a2fe-499b-ab4a-ba8642b7e656,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-7f9321a9-5005-4d52-93be-fffbe8d09d41,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-b361b3c8-28f4-496d-a238-835478c2bd0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864689514-172.17.0.3-1598373644742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45966,DS-21e7c8ff-bd79-4e6a-b420-77bccdca9840,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-b618ee04-83c0-4798-86f0-8a18fd517524,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-93e60c05-f231-46ed-bfae-795af1fc7e08,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-e864400e-c6ab-4960-a30b-ac451ce2403d,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-aaf42e7a-cf54-4661-bfc7-d830655acba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-6e0b562e-0574-4931-96b3-ca1bb7204a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-f32e0dd3-1b4b-4b43-bcb3-0e962e74a6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-ad789037-7231-430e-980f-2f40f622e741,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864689514-172.17.0.3-1598373644742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45966,DS-21e7c8ff-bd79-4e6a-b420-77bccdca9840,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-b618ee04-83c0-4798-86f0-8a18fd517524,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-93e60c05-f231-46ed-bfae-795af1fc7e08,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-e864400e-c6ab-4960-a30b-ac451ce2403d,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-aaf42e7a-cf54-4661-bfc7-d830655acba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-6e0b562e-0574-4931-96b3-ca1bb7204a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-f32e0dd3-1b4b-4b43-bcb3-0e962e74a6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-ad789037-7231-430e-980f-2f40f622e741,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265338495-172.17.0.3-1598373681878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35132,DS-a5978824-5c0f-4390-93f7-a20625936aae,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-38ee05d5-37b7-45fd-a763-546d6b45f1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-7f660e8e-8d13-4d83-8637-905ca914aa45,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-9d405157-82be-4c54-96e6-5da4e6e620b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-98171538-a415-4a43-8fc0-a7f1a57e939f,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-b2e62c5d-5c54-46b0-861e-63fcf15e77d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-4b7af91d-c608-48d1-af1c-8c5e2c5a9bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-2633c2fc-502d-40cf-af28-d1d246040047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265338495-172.17.0.3-1598373681878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35132,DS-a5978824-5c0f-4390-93f7-a20625936aae,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-38ee05d5-37b7-45fd-a763-546d6b45f1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-7f660e8e-8d13-4d83-8637-905ca914aa45,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-9d405157-82be-4c54-96e6-5da4e6e620b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-98171538-a415-4a43-8fc0-a7f1a57e939f,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-b2e62c5d-5c54-46b0-861e-63fcf15e77d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-4b7af91d-c608-48d1-af1c-8c5e2c5a9bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-2633c2fc-502d-40cf-af28-d1d246040047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469290122-172.17.0.3-1598374103792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42681,DS-8ec24677-2500-48e2-b7a0-ea7fcd2707e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-021f588b-4bb4-4987-be51-e5a19be38a81,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-cc64c58f-b77e-4b6d-89c7-8a9044df36c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-8e262c58-1095-49e7-8a0d-96c1af80c7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-ca2fc7e3-fb7c-49b8-b093-2e164dffa6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-c0690c93-5be6-47ec-9fee-fba60bf6398d,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-bbc8633e-c8d3-47ef-a328-efd373147ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-73c6fb46-1c04-402b-8458-9e7e3adf4aa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469290122-172.17.0.3-1598374103792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42681,DS-8ec24677-2500-48e2-b7a0-ea7fcd2707e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-021f588b-4bb4-4987-be51-e5a19be38a81,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-cc64c58f-b77e-4b6d-89c7-8a9044df36c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-8e262c58-1095-49e7-8a0d-96c1af80c7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-ca2fc7e3-fb7c-49b8-b093-2e164dffa6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-c0690c93-5be6-47ec-9fee-fba60bf6398d,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-bbc8633e-c8d3-47ef-a328-efd373147ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-73c6fb46-1c04-402b-8458-9e7e3adf4aa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-346769904-172.17.0.3-1598374144623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41235,DS-4a80e449-a8eb-4c65-b9e0-4dd570175763,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-92e9188d-6f4b-427f-9ede-a32aaac8d4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-00027f4e-6d09-4417-b92c-680d0dd76dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-b0562442-7097-4468-9458-979958b8601d,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-ae8e457c-d21b-422d-8c09-28441ca30dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-93217ef3-f07b-4a9a-8aca-18e0f115fd91,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-a61f78b6-7a6b-4375-86f3-d620bc3fbd37,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-2edc10f8-c060-4816-ba20-f0d9ecaaeda9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-346769904-172.17.0.3-1598374144623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41235,DS-4a80e449-a8eb-4c65-b9e0-4dd570175763,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-92e9188d-6f4b-427f-9ede-a32aaac8d4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-00027f4e-6d09-4417-b92c-680d0dd76dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-b0562442-7097-4468-9458-979958b8601d,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-ae8e457c-d21b-422d-8c09-28441ca30dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-93217ef3-f07b-4a9a-8aca-18e0f115fd91,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-a61f78b6-7a6b-4375-86f3-d620bc3fbd37,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-2edc10f8-c060-4816-ba20-f0d9ecaaeda9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817241393-172.17.0.3-1598374396097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41498,DS-c0605182-d38c-4f45-a513-cfd672b9c9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-7c1523a8-a0cb-4bcc-bfca-05d012879b20,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-7dc076e3-62d4-44af-bd3b-b144263465f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-8704381c-4d6f-49e8-abc0-b857bd42d95f,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-71054410-a478-4089-b7b9-42c0ac20bf10,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-7fa9d8e0-fbfd-47a3-8952-8ce10eb0cb91,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-faf89e9f-0acc-4910-9986-7ee5602ed8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-d61a7563-c52a-4dae-a3f0-ccf8f50024e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817241393-172.17.0.3-1598374396097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41498,DS-c0605182-d38c-4f45-a513-cfd672b9c9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-7c1523a8-a0cb-4bcc-bfca-05d012879b20,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-7dc076e3-62d4-44af-bd3b-b144263465f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-8704381c-4d6f-49e8-abc0-b857bd42d95f,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-71054410-a478-4089-b7b9-42c0ac20bf10,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-7fa9d8e0-fbfd-47a3-8952-8ce10eb0cb91,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-faf89e9f-0acc-4910-9986-7ee5602ed8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-d61a7563-c52a-4dae-a3f0-ccf8f50024e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1447576897-172.17.0.3-1598375153302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46818,DS-6c78b2b9-3de1-4c4f-9b61-db72800fe149,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-e387f95e-cbcb-438f-9e92-2c614b228653,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-042a9621-7f97-43a6-bcda-7af638ea18b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-9136385d-c849-4e0c-ad7d-5a72c72ec339,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-c083d683-d973-4bf6-ba21-18587f7dc130,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-1245f16f-9386-47d6-9a59-121b02e92ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-88751539-3227-4e42-87a3-d693f1225554,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-dcc544d0-7b91-4d75-b14a-b13f0eb215ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1447576897-172.17.0.3-1598375153302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46818,DS-6c78b2b9-3de1-4c4f-9b61-db72800fe149,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-e387f95e-cbcb-438f-9e92-2c614b228653,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-042a9621-7f97-43a6-bcda-7af638ea18b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-9136385d-c849-4e0c-ad7d-5a72c72ec339,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-c083d683-d973-4bf6-ba21-18587f7dc130,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-1245f16f-9386-47d6-9a59-121b02e92ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-88751539-3227-4e42-87a3-d693f1225554,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-dcc544d0-7b91-4d75-b14a-b13f0eb215ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641890801-172.17.0.3-1598375351227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39470,DS-3f3c2afa-9c78-48aa-9ec9-3b72442c336c,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-bf338f35-1627-4454-a28d-a9493de38342,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-ef92ce53-b8bf-46c0-b23a-15b18d1bf69d,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-23f73e5b-635a-42ea-a8bd-83c5a7effb75,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-99db5836-0f9d-4783-9a44-cd54afbbc425,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-dece1f35-0a01-46f8-8f09-15eb170214da,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-f9ccb34d-9313-4675-a7e8-d85fcaa22fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-580e50ab-e13a-464d-bd2a-11bceae1d655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-641890801-172.17.0.3-1598375351227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39470,DS-3f3c2afa-9c78-48aa-9ec9-3b72442c336c,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-bf338f35-1627-4454-a28d-a9493de38342,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-ef92ce53-b8bf-46c0-b23a-15b18d1bf69d,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-23f73e5b-635a-42ea-a8bd-83c5a7effb75,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-99db5836-0f9d-4783-9a44-cd54afbbc425,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-dece1f35-0a01-46f8-8f09-15eb170214da,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-f9ccb34d-9313-4675-a7e8-d85fcaa22fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-580e50ab-e13a-464d-bd2a-11bceae1d655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449824811-172.17.0.3-1598375424055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43040,DS-0173f5b9-ef7c-4482-a9f6-4f1a303d8da9,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-ebb6ac66-8e51-43b4-b2b0-e0beb9dec1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-802af99f-743f-4af5-81f0-32adcccade46,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-f1fd4f6e-5540-4cdd-93c1-6930e3f775fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-3b6e66e7-6014-4fee-8b79-ca377995c90c,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-956ca97e-db27-435e-8066-914574853a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-8e415ce2-f05c-4a1c-acd3-93c28dee3dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-63e8d044-67dd-4d48-8949-6afcc1378c50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449824811-172.17.0.3-1598375424055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43040,DS-0173f5b9-ef7c-4482-a9f6-4f1a303d8da9,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-ebb6ac66-8e51-43b4-b2b0-e0beb9dec1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-802af99f-743f-4af5-81f0-32adcccade46,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-f1fd4f6e-5540-4cdd-93c1-6930e3f775fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-3b6e66e7-6014-4fee-8b79-ca377995c90c,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-956ca97e-db27-435e-8066-914574853a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-8e415ce2-f05c-4a1c-acd3-93c28dee3dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-63e8d044-67dd-4d48-8949-6afcc1378c50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6398442-172.17.0.3-1598375464852:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41074,DS-8279efbe-985a-4bcb-85c7-a4ea56342e45,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-6ca671a9-7655-489c-931e-2c883e401e37,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-695a3e0c-34e8-4cc0-b7c9-8b91cfb95524,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-fbc315d1-c4f9-4423-8b87-7e370831d93f,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-1bfe73ef-8690-4764-878e-6645e8a27df0,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-020ba5e2-b145-462f-b198-ceb25117162e,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-29b93d42-2e3a-43b2-8875-3da3678a574a,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-3b007ea1-6167-4324-83c4-32406db87e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6398442-172.17.0.3-1598375464852:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41074,DS-8279efbe-985a-4bcb-85c7-a4ea56342e45,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-6ca671a9-7655-489c-931e-2c883e401e37,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-695a3e0c-34e8-4cc0-b7c9-8b91cfb95524,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-fbc315d1-c4f9-4423-8b87-7e370831d93f,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-1bfe73ef-8690-4764-878e-6645e8a27df0,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-020ba5e2-b145-462f-b198-ceb25117162e,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-29b93d42-2e3a-43b2-8875-3da3678a574a,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-3b007ea1-6167-4324-83c4-32406db87e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1533735457-172.17.0.3-1598375801701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44945,DS-d6de8ad4-ad3f-4ac8-aa62-946e31cdd451,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-adecb82a-840d-4cf3-a7ed-400ee5a99771,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-3ef18365-3dd9-44a4-98b4-b4c29e289b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-deb2262d-f258-44f8-a689-e9561264ecf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-9582319a-f5f3-4939-81e2-d15da55a323e,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-7a76da94-ad89-4ab0-89c6-b97b2322c949,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-2bd008e0-4364-461f-823a-736268e22851,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-212536ad-ea42-4a90-bfe9-1494d1f32df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1533735457-172.17.0.3-1598375801701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44945,DS-d6de8ad4-ad3f-4ac8-aa62-946e31cdd451,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-adecb82a-840d-4cf3-a7ed-400ee5a99771,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-3ef18365-3dd9-44a4-98b4-b4c29e289b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-deb2262d-f258-44f8-a689-e9561264ecf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-9582319a-f5f3-4939-81e2-d15da55a323e,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-7a76da94-ad89-4ab0-89c6-b97b2322c949,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-2bd008e0-4364-461f-823a-736268e22851,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-212536ad-ea42-4a90-bfe9-1494d1f32df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564122728-172.17.0.3-1598376124975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41932,DS-c8abdad2-562d-48e8-b1ff-af5e78d8f7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-5bc1b640-540a-463a-972f-06693f03c9da,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-e39e8801-d738-4247-b0e3-f756a425c3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-dd869cd5-99a8-4418-9bb1-230c6306156f,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-9388961f-ed6a-43e4-b11d-a9601610d9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-f6177fe9-cd2d-40bc-9eab-22b405f15079,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-8b6a055f-4b7c-4515-88d3-5927b03928b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-1b374c15-6b07-4858-93b3-374a574e7ad8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564122728-172.17.0.3-1598376124975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41932,DS-c8abdad2-562d-48e8-b1ff-af5e78d8f7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-5bc1b640-540a-463a-972f-06693f03c9da,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-e39e8801-d738-4247-b0e3-f756a425c3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-dd869cd5-99a8-4418-9bb1-230c6306156f,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-9388961f-ed6a-43e4-b11d-a9601610d9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-f6177fe9-cd2d-40bc-9eab-22b405f15079,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-8b6a055f-4b7c-4515-88d3-5927b03928b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-1b374c15-6b07-4858-93b3-374a574e7ad8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1893004138-172.17.0.3-1598376266670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44659,DS-97c23ca9-c0ed-4d71-90d7-5d63ee14c5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-55cf4b65-a636-45ed-9fae-d8c39f38a1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-60a5bfd8-e766-45ea-aa35-723a5d996474,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-57da471c-a933-423c-943c-75952f130908,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-4ee39a79-f000-44d5-9781-b41c9f79da90,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-25cd545f-bc4e-4e1e-b033-edf08d45e4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-ad9a0cd8-a2d5-4d1e-9678-98236616c8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-81ee428f-0e09-41a1-8cbf-5a295966f0bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1893004138-172.17.0.3-1598376266670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44659,DS-97c23ca9-c0ed-4d71-90d7-5d63ee14c5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-55cf4b65-a636-45ed-9fae-d8c39f38a1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-60a5bfd8-e766-45ea-aa35-723a5d996474,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-57da471c-a933-423c-943c-75952f130908,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-4ee39a79-f000-44d5-9781-b41c9f79da90,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-25cd545f-bc4e-4e1e-b033-edf08d45e4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-ad9a0cd8-a2d5-4d1e-9678-98236616c8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-81ee428f-0e09-41a1-8cbf-5a295966f0bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-355678795-172.17.0.3-1598376572654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38647,DS-9bf8a634-75fa-417e-b62b-f270887bd908,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-018065a8-d729-490d-9cec-3522582ba5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-c93ffbb4-553b-482a-b4f8-e3f2b74c53ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-78bdef2c-da6d-40f5-a95e-0cedef7a3d11,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-cffa1c02-93ac-4649-acf5-9525868dbb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-f9039fc3-4b8e-4228-bfe0-32ac0ecee24a,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-0441be00-0fc7-4aff-b79e-bfdb879dbb67,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-19a78148-3a66-4829-a443-86b580751b36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-355678795-172.17.0.3-1598376572654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38647,DS-9bf8a634-75fa-417e-b62b-f270887bd908,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-018065a8-d729-490d-9cec-3522582ba5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-c93ffbb4-553b-482a-b4f8-e3f2b74c53ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-78bdef2c-da6d-40f5-a95e-0cedef7a3d11,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-cffa1c02-93ac-4649-acf5-9525868dbb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-f9039fc3-4b8e-4228-bfe0-32ac0ecee24a,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-0441be00-0fc7-4aff-b79e-bfdb879dbb67,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-19a78148-3a66-4829-a443-86b580751b36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5447
