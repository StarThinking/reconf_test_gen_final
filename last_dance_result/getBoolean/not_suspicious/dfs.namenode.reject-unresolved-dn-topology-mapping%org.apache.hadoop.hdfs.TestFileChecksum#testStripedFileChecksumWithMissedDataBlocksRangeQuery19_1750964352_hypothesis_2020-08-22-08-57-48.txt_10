reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774908660-172.17.0.15-1598086871800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34827,DS-81be4bca-c181-44e8-84a7-52a19f0e157c,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-865a2891-2979-4402-ade8-478f94327b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-6e077e3d-5c90-4b47-ae49-d53b6fde832c,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-38196231-d756-4d0e-a1d3-632db830b2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-37484ab2-8cf7-4d38-89f2-ba23900f337a,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-d03a6ded-1907-4ce2-9ad6-4ada15dcbadf,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-40af7e66-876a-4bde-a7bb-f1bef5ae6977,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-3c3b07c6-4df0-46a1-9f0d-2b5f016cf62f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774908660-172.17.0.15-1598086871800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34827,DS-81be4bca-c181-44e8-84a7-52a19f0e157c,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-865a2891-2979-4402-ade8-478f94327b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-6e077e3d-5c90-4b47-ae49-d53b6fde832c,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-38196231-d756-4d0e-a1d3-632db830b2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-37484ab2-8cf7-4d38-89f2-ba23900f337a,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-d03a6ded-1907-4ce2-9ad6-4ada15dcbadf,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-40af7e66-876a-4bde-a7bb-f1bef5ae6977,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-3c3b07c6-4df0-46a1-9f0d-2b5f016cf62f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167457846-172.17.0.15-1598086909722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41029,DS-9a0b9d25-564b-43cc-88d7-e466d262bc40,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-e15498fc-9e3c-4fea-aaab-d5e7b04a4818,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-efc40269-b044-4e07-951a-85463d8735ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-ba68b6f0-c777-4230-be75-80f1fddc819e,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-5c82829c-ac14-4134-8db6-4be55247863e,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-7573281d-acc5-47c7-bc51-ff0f17795cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-21a40724-7f52-4cf9-b7e1-6b05b046887c,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-e07bbc94-4185-4c3b-84dd-e3e33c7a30ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167457846-172.17.0.15-1598086909722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41029,DS-9a0b9d25-564b-43cc-88d7-e466d262bc40,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-e15498fc-9e3c-4fea-aaab-d5e7b04a4818,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-efc40269-b044-4e07-951a-85463d8735ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-ba68b6f0-c777-4230-be75-80f1fddc819e,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-5c82829c-ac14-4134-8db6-4be55247863e,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-7573281d-acc5-47c7-bc51-ff0f17795cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-21a40724-7f52-4cf9-b7e1-6b05b046887c,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-e07bbc94-4185-4c3b-84dd-e3e33c7a30ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861728792-172.17.0.15-1598087507862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37767,DS-66e6acd8-8c34-4d3f-b36b-fd6e1a42ff44,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-f05c25f1-9aa5-4494-8062-59db781fc4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-62a9a9be-2b0b-4bd7-907e-87065de176d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-861e8e83-6c39-4be2-806a-729bb6a72354,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-9986c3bc-6a2a-47ce-9bff-f23e166413fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-9179cc81-2e87-4f08-b1b9-9a0c308588ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-57d155bc-f3ec-4183-8135-7d05d3914c81,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-2d0fe24f-c441-4a80-a0e2-653f6d602e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861728792-172.17.0.15-1598087507862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37767,DS-66e6acd8-8c34-4d3f-b36b-fd6e1a42ff44,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-f05c25f1-9aa5-4494-8062-59db781fc4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-62a9a9be-2b0b-4bd7-907e-87065de176d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-861e8e83-6c39-4be2-806a-729bb6a72354,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-9986c3bc-6a2a-47ce-9bff-f23e166413fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-9179cc81-2e87-4f08-b1b9-9a0c308588ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-57d155bc-f3ec-4183-8135-7d05d3914c81,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-2d0fe24f-c441-4a80-a0e2-653f6d602e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637997485-172.17.0.15-1598087629161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35780,DS-b429f678-64dd-4c21-bf57-282d3d9945bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-8e24d34b-c3c1-4e8e-b53b-1067ad5f4b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-11e024c5-2c4f-42e0-9f46-186965fcc0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-4feadf98-f9e9-4d74-9bcc-c04c5b276df5,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-732014fd-4529-4441-9d5d-e18bb5c16a62,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-907d1197-45d3-412b-95a6-c9ed0fcb9b06,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-3e0f5f54-f861-412a-9079-f212aa53ecc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-0edb05b4-9b0f-49b3-a026-a1d8141736fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637997485-172.17.0.15-1598087629161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35780,DS-b429f678-64dd-4c21-bf57-282d3d9945bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-8e24d34b-c3c1-4e8e-b53b-1067ad5f4b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-11e024c5-2c4f-42e0-9f46-186965fcc0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-4feadf98-f9e9-4d74-9bcc-c04c5b276df5,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-732014fd-4529-4441-9d5d-e18bb5c16a62,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-907d1197-45d3-412b-95a6-c9ed0fcb9b06,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-3e0f5f54-f861-412a-9079-f212aa53ecc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-0edb05b4-9b0f-49b3-a026-a1d8141736fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652279977-172.17.0.15-1598087704325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41989,DS-b105562b-fa5f-4d1e-a8ba-fee0a9839c31,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-a3f96db4-38c6-4a90-809b-03fd4d8f71a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-98ccdc09-bfd6-4bc6-82f5-e3967c042869,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-b86cc620-199c-48c6-a47b-885e7b3a19f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-65e93593-4083-4307-b6b5-d4ffbc8d8d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-ff1efc0b-381a-4db4-82fb-61f38e74c9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-46a0e5e4-be37-44a0-8afa-f4b0a77b8205,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-2a54c1db-a3dc-44f1-9dc8-2b8b20f637a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652279977-172.17.0.15-1598087704325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41989,DS-b105562b-fa5f-4d1e-a8ba-fee0a9839c31,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-a3f96db4-38c6-4a90-809b-03fd4d8f71a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-98ccdc09-bfd6-4bc6-82f5-e3967c042869,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-b86cc620-199c-48c6-a47b-885e7b3a19f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-65e93593-4083-4307-b6b5-d4ffbc8d8d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-ff1efc0b-381a-4db4-82fb-61f38e74c9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-46a0e5e4-be37-44a0-8afa-f4b0a77b8205,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-2a54c1db-a3dc-44f1-9dc8-2b8b20f637a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2064685544-172.17.0.15-1598087738135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41244,DS-039c2550-4843-4488-b61e-515a64ed7565,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-9f97fa6f-438f-4d3c-b658-f73676b33675,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-e7a0a764-dad3-4d9b-8272-7b511409f92b,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-6a780594-448e-4481-9ae9-44f05b3f78af,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-f9ea3d07-41f3-4ba4-9597-03f9c52bda4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-8b387e83-f413-4f66-a464-31f40e0ed022,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-b8f24160-b7b6-4503-9691-983b048df3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-3161d061-d6ed-4fda-a155-12c9af741d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2064685544-172.17.0.15-1598087738135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41244,DS-039c2550-4843-4488-b61e-515a64ed7565,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-9f97fa6f-438f-4d3c-b658-f73676b33675,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-e7a0a764-dad3-4d9b-8272-7b511409f92b,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-6a780594-448e-4481-9ae9-44f05b3f78af,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-f9ea3d07-41f3-4ba4-9597-03f9c52bda4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-8b387e83-f413-4f66-a464-31f40e0ed022,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-b8f24160-b7b6-4503-9691-983b048df3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-3161d061-d6ed-4fda-a155-12c9af741d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829143274-172.17.0.15-1598087821794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42784,DS-7f18ae9e-c192-43d6-9c07-60e76e92ea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-dd9f2d5a-f128-424b-8d01-711fe33e817b,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-0145d1e1-df5b-4c07-9714-f5614e2bad82,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-847463a4-b03f-4086-8971-43ea44b6ebf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-54846bdc-6304-4075-ac00-0f97ff299cec,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-bd78f876-b7a5-4974-b10c-2e907857a178,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-d5574acb-8cdf-446e-9dec-46def9251333,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-053a2b55-b8e6-4c61-9721-9e45dc3a9e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829143274-172.17.0.15-1598087821794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42784,DS-7f18ae9e-c192-43d6-9c07-60e76e92ea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-dd9f2d5a-f128-424b-8d01-711fe33e817b,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-0145d1e1-df5b-4c07-9714-f5614e2bad82,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-847463a4-b03f-4086-8971-43ea44b6ebf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-54846bdc-6304-4075-ac00-0f97ff299cec,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-bd78f876-b7a5-4974-b10c-2e907857a178,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-d5574acb-8cdf-446e-9dec-46def9251333,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-053a2b55-b8e6-4c61-9721-9e45dc3a9e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118793145-172.17.0.15-1598087897739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35493,DS-68cebd9b-ba06-45db-8f25-5abd8afa1e12,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-fd0052c2-0f67-4243-822e-8f8a72e9404d,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-bb93a7d4-a2c4-4deb-9d80-245715f70cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-71438baa-fcac-4a96-b391-a6a9d5b16b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-a4ade3ff-3984-4ea8-83e3-4cf8c3d518dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-800a9347-c7d7-4aed-94cd-6d4b56e960ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-f0644858-d1f1-4747-9970-3c21322cf0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-51c99089-fc75-445e-a2cf-56088dc90951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118793145-172.17.0.15-1598087897739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35493,DS-68cebd9b-ba06-45db-8f25-5abd8afa1e12,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-fd0052c2-0f67-4243-822e-8f8a72e9404d,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-bb93a7d4-a2c4-4deb-9d80-245715f70cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-71438baa-fcac-4a96-b391-a6a9d5b16b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-a4ade3ff-3984-4ea8-83e3-4cf8c3d518dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-800a9347-c7d7-4aed-94cd-6d4b56e960ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-f0644858-d1f1-4747-9970-3c21322cf0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-51c99089-fc75-445e-a2cf-56088dc90951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646156617-172.17.0.15-1598088010025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44863,DS-9c40e724-f00c-4727-9c36-f4a5467c4c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-6c3a9d6e-6069-4525-b9cc-13a4d31ef00f,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-d9d8651f-f3c8-4159-8e8b-77a6fbd20af9,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-3efd5603-96d8-4d43-be94-ae0050d9c2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-1d234f0a-8355-42ed-9635-b9c7eec6650c,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-9fbe63b6-b1c5-4871-a2ce-dbd6f80c74ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-62c4a979-c580-4a40-9770-79ffb8a89efe,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-ce783a1c-75c8-4e18-9036-c4808ad68d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646156617-172.17.0.15-1598088010025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44863,DS-9c40e724-f00c-4727-9c36-f4a5467c4c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-6c3a9d6e-6069-4525-b9cc-13a4d31ef00f,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-d9d8651f-f3c8-4159-8e8b-77a6fbd20af9,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-3efd5603-96d8-4d43-be94-ae0050d9c2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-1d234f0a-8355-42ed-9635-b9c7eec6650c,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-9fbe63b6-b1c5-4871-a2ce-dbd6f80c74ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-62c4a979-c580-4a40-9770-79ffb8a89efe,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-ce783a1c-75c8-4e18-9036-c4808ad68d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227978162-172.17.0.15-1598088262136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43835,DS-e1374227-e3d2-4bdf-b839-f87c1fb3e1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-b01e2407-f478-47fd-80cd-c5e0452261b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-7aa33604-04c5-47e1-b589-8bb6e5427264,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-61887d03-1192-4923-941f-56f70df30c97,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-c6831e04-0326-46bf-87ee-e59b6767875c,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-fbc3864f-a4dc-4dfb-a977-2417d1bdaa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-66a83907-a907-4e24-bafa-b48a45271ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-8e001cc4-706b-4613-bf4e-8b80ff474f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227978162-172.17.0.15-1598088262136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43835,DS-e1374227-e3d2-4bdf-b839-f87c1fb3e1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-b01e2407-f478-47fd-80cd-c5e0452261b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-7aa33604-04c5-47e1-b589-8bb6e5427264,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-61887d03-1192-4923-941f-56f70df30c97,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-c6831e04-0326-46bf-87ee-e59b6767875c,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-fbc3864f-a4dc-4dfb-a977-2417d1bdaa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-66a83907-a907-4e24-bafa-b48a45271ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-8e001cc4-706b-4613-bf4e-8b80ff474f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-207468818-172.17.0.15-1598089547988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34629,DS-db743caf-8e82-412c-8a35-4ab9bf1f6c54,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-1c34d56f-bc68-44c3-9179-f15ccd482d34,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-0efd5c3d-01de-495d-a7fd-73bc391279cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-8b0290cb-8fec-4476-8f3b-4f4cdee37623,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-a5e89d0a-5c9a-4044-baaf-b7cf51eda48a,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-5c108d9b-b946-4a74-adf1-a68f075b9a18,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-37727984-8f37-466e-944b-73807837d5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-26879881-09bb-4838-a0bb-da6c79715acf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-207468818-172.17.0.15-1598089547988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34629,DS-db743caf-8e82-412c-8a35-4ab9bf1f6c54,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-1c34d56f-bc68-44c3-9179-f15ccd482d34,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-0efd5c3d-01de-495d-a7fd-73bc391279cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-8b0290cb-8fec-4476-8f3b-4f4cdee37623,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-a5e89d0a-5c9a-4044-baaf-b7cf51eda48a,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-5c108d9b-b946-4a74-adf1-a68f075b9a18,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-37727984-8f37-466e-944b-73807837d5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-26879881-09bb-4838-a0bb-da6c79715acf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642372240-172.17.0.15-1598089793223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46523,DS-02a77916-41e3-446a-be82-150321083ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-904da431-02af-4165-b988-5f2cc74367d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-4e6189ec-414f-4b7c-8929-a48068d5a0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-986b0754-437a-45c1-8d66-e330c65462f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-a3be8ffc-cf0c-433f-855d-c549e2ca45df,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-69408635-d8f6-4b85-a803-cb0a5fc7d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-63903d4b-ab24-4acb-bb2f-c7e2ea8b9170,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-e43e8a9a-efe8-48e9-a1e1-791801bbe894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642372240-172.17.0.15-1598089793223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46523,DS-02a77916-41e3-446a-be82-150321083ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-904da431-02af-4165-b988-5f2cc74367d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-4e6189ec-414f-4b7c-8929-a48068d5a0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-986b0754-437a-45c1-8d66-e330c65462f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-a3be8ffc-cf0c-433f-855d-c549e2ca45df,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-69408635-d8f6-4b85-a803-cb0a5fc7d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-63903d4b-ab24-4acb-bb2f-c7e2ea8b9170,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-e43e8a9a-efe8-48e9-a1e1-791801bbe894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1666782222-172.17.0.15-1598090362555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36118,DS-59888004-1869-42f9-8f01-a5eef2b97330,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-729d0e5b-eea2-4046-807b-36a0f699807a,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-cc6668b3-934a-4a85-90a3-c829555a7982,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-da17117d-4d6a-426f-92dd-10dc17b197fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-e5d70d2e-f3a1-4256-8c85-0cb359d46aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-4cdac433-b781-4ec8-b48e-cbbacb3fa80c,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-c2ea7866-1495-4fb1-bfa7-67d69ee2f8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-b29767cd-8e59-4f82-9ab9-f63bc0cb5dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1666782222-172.17.0.15-1598090362555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36118,DS-59888004-1869-42f9-8f01-a5eef2b97330,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-729d0e5b-eea2-4046-807b-36a0f699807a,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-cc6668b3-934a-4a85-90a3-c829555a7982,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-da17117d-4d6a-426f-92dd-10dc17b197fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-e5d70d2e-f3a1-4256-8c85-0cb359d46aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-4cdac433-b781-4ec8-b48e-cbbacb3fa80c,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-c2ea7866-1495-4fb1-bfa7-67d69ee2f8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-b29767cd-8e59-4f82-9ab9-f63bc0cb5dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721500942-172.17.0.15-1598090712317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43262,DS-07884ac2-dba6-4bdb-8344-56c2085d6574,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-838c6c0c-a4b5-422b-8dae-d1f87307366f,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-193d6a9c-d04a-481d-9148-c3872fa0b811,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-3debcd1d-75e5-4ad0-81db-a1bc4b2d3cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-4c3d05e7-a037-4edd-ae3e-0330e791cd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-b2d23720-aca4-418b-a160-eeed19d497e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-108f0c7c-a10e-4be0-9219-7303eff8d7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-b78c639e-9c0e-4644-8f56-d2b5957a26c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721500942-172.17.0.15-1598090712317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43262,DS-07884ac2-dba6-4bdb-8344-56c2085d6574,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-838c6c0c-a4b5-422b-8dae-d1f87307366f,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-193d6a9c-d04a-481d-9148-c3872fa0b811,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-3debcd1d-75e5-4ad0-81db-a1bc4b2d3cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-4c3d05e7-a037-4edd-ae3e-0330e791cd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-b2d23720-aca4-418b-a160-eeed19d497e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-108f0c7c-a10e-4be0-9219-7303eff8d7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-b78c639e-9c0e-4644-8f56-d2b5957a26c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81193813-172.17.0.15-1598090792710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41310,DS-b38a3386-1937-45bf-9d41-588524563177,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-9b617df9-2da0-4c76-9112-0370c378545e,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-dc2cd96d-9057-4bd3-8687-13e58ad6cf22,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-9526ab92-a659-4b08-bbea-fa7be11cf77b,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-0ba5d6ee-5e40-4190-a1c8-9864485be047,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-b3993b8a-5f94-461b-b5da-4d16c4a96d96,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-b42a8d35-e4e0-4422-9b5b-56398e2ab609,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-898ffb05-462a-40d1-86d0-8fb109788864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81193813-172.17.0.15-1598090792710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41310,DS-b38a3386-1937-45bf-9d41-588524563177,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-9b617df9-2da0-4c76-9112-0370c378545e,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-dc2cd96d-9057-4bd3-8687-13e58ad6cf22,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-9526ab92-a659-4b08-bbea-fa7be11cf77b,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-0ba5d6ee-5e40-4190-a1c8-9864485be047,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-b3993b8a-5f94-461b-b5da-4d16c4a96d96,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-b42a8d35-e4e0-4422-9b5b-56398e2ab609,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-898ffb05-462a-40d1-86d0-8fb109788864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140580530-172.17.0.15-1598091372107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33654,DS-b7ff909a-de20-4e79-a579-18ef655a5960,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-4c13c1c0-dffc-4540-8aa5-7bd755efed73,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-3e7cc806-e7a0-47b3-8dc6-36722c0c4e17,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-2836bbc4-22ab-4c92-9ea2-6c30c42a6497,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-aa7e1f34-14f4-4747-9eac-81cf419bd4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-35bdeef0-491b-4d37-9e71-97d6cef50d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-1bd9c0b7-85d9-4404-ba89-c63f92b66b94,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-6f248e09-3511-4272-932d-b0d130157656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140580530-172.17.0.15-1598091372107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33654,DS-b7ff909a-de20-4e79-a579-18ef655a5960,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-4c13c1c0-dffc-4540-8aa5-7bd755efed73,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-3e7cc806-e7a0-47b3-8dc6-36722c0c4e17,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-2836bbc4-22ab-4c92-9ea2-6c30c42a6497,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-aa7e1f34-14f4-4747-9eac-81cf419bd4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-35bdeef0-491b-4d37-9e71-97d6cef50d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-1bd9c0b7-85d9-4404-ba89-c63f92b66b94,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-6f248e09-3511-4272-932d-b0d130157656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-882028733-172.17.0.15-1598091526353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33925,DS-293ce078-13c4-41dc-a05a-b685f26b2504,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-294e1090-687c-4b43-8886-330df09123af,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-de6bd4da-e4b4-4aae-85b7-2d5d7e8ee578,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-43b6a059-b162-43d0-87e8-8f6b4bad2f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-1de9fa58-5032-43cd-813e-4b54c5cddc34,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-cb2260be-d0a1-47d4-a7d3-e66bf04b963d,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-6df7a8ac-8fa3-4c73-92b5-f8ef993c0b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-6d0afd10-f8d2-49fc-8db9-6e553dbc5a9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-882028733-172.17.0.15-1598091526353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33925,DS-293ce078-13c4-41dc-a05a-b685f26b2504,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-294e1090-687c-4b43-8886-330df09123af,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-de6bd4da-e4b4-4aae-85b7-2d5d7e8ee578,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-43b6a059-b162-43d0-87e8-8f6b4bad2f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-1de9fa58-5032-43cd-813e-4b54c5cddc34,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-cb2260be-d0a1-47d4-a7d3-e66bf04b963d,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-6df7a8ac-8fa3-4c73-92b5-f8ef993c0b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-6d0afd10-f8d2-49fc-8db9-6e553dbc5a9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5525
