reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889886350-172.17.0.19-1598429883497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39060,DS-1512b172-50dc-4ab2-9312-b3de5019980a,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-1645d274-0842-4bd9-ae7e-2025f02990af,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-39828363-2670-4a40-9ffa-ab9e3b053b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-c32d05c2-f191-4516-b922-3f3e4015ebea,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-930305b5-0231-4719-a605-69d6f8637a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-aaf7b360-24a8-4091-8444-aa9c0f73788c,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-fbaa7fb5-31a4-4c4c-98e8-b533a294561b,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-de60a52c-9777-49f7-8a5a-aac9531bcdc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889886350-172.17.0.19-1598429883497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39060,DS-1512b172-50dc-4ab2-9312-b3de5019980a,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-1645d274-0842-4bd9-ae7e-2025f02990af,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-39828363-2670-4a40-9ffa-ab9e3b053b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-c32d05c2-f191-4516-b922-3f3e4015ebea,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-930305b5-0231-4719-a605-69d6f8637a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-aaf7b360-24a8-4091-8444-aa9c0f73788c,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-fbaa7fb5-31a4-4c4c-98e8-b533a294561b,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-de60a52c-9777-49f7-8a5a-aac9531bcdc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072082207-172.17.0.19-1598430219178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39485,DS-44fd477b-54ee-4ab3-b848-5d0872d32844,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-e6974bb6-169e-4705-83c0-3cd5b20f16f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-2b7c5ff1-a4c5-483f-b8fd-d80bbb8d1fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-04b525c0-2341-4817-ac92-d633d7a6a95b,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-12e6f7f1-c998-442c-9ef3-cde812e9678c,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-90af15f2-e5bd-4e22-acce-d36a409466d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-f42dcf93-d71a-49dc-b8b7-f04d261ae61a,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-dee5064a-333a-4a6e-bf74-e417ada3a13e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072082207-172.17.0.19-1598430219178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39485,DS-44fd477b-54ee-4ab3-b848-5d0872d32844,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-e6974bb6-169e-4705-83c0-3cd5b20f16f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-2b7c5ff1-a4c5-483f-b8fd-d80bbb8d1fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-04b525c0-2341-4817-ac92-d633d7a6a95b,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-12e6f7f1-c998-442c-9ef3-cde812e9678c,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-90af15f2-e5bd-4e22-acce-d36a409466d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-f42dcf93-d71a-49dc-b8b7-f04d261ae61a,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-dee5064a-333a-4a6e-bf74-e417ada3a13e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820305682-172.17.0.19-1598430684860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34177,DS-71d332bd-55dd-4c98-a5c2-de45a9c03dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-9d771cc3-7275-47f2-a88c-d5a79bb7ced7,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-608464cd-1fd8-4fcc-a78a-d8725404c81e,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-f07a6e5d-c739-4cfa-bff8-bf805156f27f,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-ac0605e5-8412-46f3-9e03-58cc2c59a463,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-61cc3753-080f-4408-8645-568b2b79b5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-6f44e4cc-9a77-4847-b3d7-c5fdd80d1928,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-3c0c0e09-0f7c-4ea4-94c1-1ac88cfb5f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820305682-172.17.0.19-1598430684860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34177,DS-71d332bd-55dd-4c98-a5c2-de45a9c03dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-9d771cc3-7275-47f2-a88c-d5a79bb7ced7,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-608464cd-1fd8-4fcc-a78a-d8725404c81e,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-f07a6e5d-c739-4cfa-bff8-bf805156f27f,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-ac0605e5-8412-46f3-9e03-58cc2c59a463,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-61cc3753-080f-4408-8645-568b2b79b5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-6f44e4cc-9a77-4847-b3d7-c5fdd80d1928,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-3c0c0e09-0f7c-4ea4-94c1-1ac88cfb5f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381947459-172.17.0.19-1598430763592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40904,DS-442bfc58-774a-4ab7-a2a9-1a9db5514574,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-72ca30fe-ac7a-4d17-a45a-be8c14f7e0af,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-e37fe5b0-8203-4a1c-a433-c07ac34ee740,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-b8b75dea-ed86-42c7-99c1-3430e8951029,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-82361ab3-474e-4ce3-b650-56a2240c4b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-1398b5cc-fc65-43b3-92d1-ed348b33cf92,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-8aad37b0-0b1f-442e-b9b0-ad45b1b9ee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-3a9e597b-f09b-48de-8cfe-cf973778093b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381947459-172.17.0.19-1598430763592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40904,DS-442bfc58-774a-4ab7-a2a9-1a9db5514574,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-72ca30fe-ac7a-4d17-a45a-be8c14f7e0af,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-e37fe5b0-8203-4a1c-a433-c07ac34ee740,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-b8b75dea-ed86-42c7-99c1-3430e8951029,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-82361ab3-474e-4ce3-b650-56a2240c4b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-1398b5cc-fc65-43b3-92d1-ed348b33cf92,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-8aad37b0-0b1f-442e-b9b0-ad45b1b9ee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-3a9e597b-f09b-48de-8cfe-cf973778093b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589692008-172.17.0.19-1598431212232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-71efd442-7520-471b-9bed-68bc2c638328,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-cc2d5c6d-a1e9-435b-aef3-95736548e82b,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-2b95f57c-a921-4d1d-9403-9d6d40e2caab,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-34fdf0c2-8339-45f8-9605-fb317db1944a,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-773f718e-18a0-4658-853a-e4d24a01e202,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-f7059d21-6169-4da8-942a-18cfe3753c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-ee660349-5c9a-4555-b9ba-7eb51916983c,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-797bd8e7-00fd-4cdb-9b57-5074c2e8c3f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589692008-172.17.0.19-1598431212232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-71efd442-7520-471b-9bed-68bc2c638328,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-cc2d5c6d-a1e9-435b-aef3-95736548e82b,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-2b95f57c-a921-4d1d-9403-9d6d40e2caab,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-34fdf0c2-8339-45f8-9605-fb317db1944a,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-773f718e-18a0-4658-853a-e4d24a01e202,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-f7059d21-6169-4da8-942a-18cfe3753c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-ee660349-5c9a-4555-b9ba-7eb51916983c,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-797bd8e7-00fd-4cdb-9b57-5074c2e8c3f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206558040-172.17.0.19-1598431452551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44353,DS-adff55c0-523f-4509-a9c6-e6d42bcdc274,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-27521ded-56a0-49ce-a674-0eef20856714,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-79155462-4a56-420c-8b82-d9d3599dc45d,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-c44f3b76-adbf-42df-aa99-c500eb37a791,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-7d048eb2-09e9-4c9a-9406-252566621a74,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-b8a8dfcd-39a0-49f7-a683-aa5f91f241ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-ba057864-6a96-4d88-b7b7-854d4bbcc64b,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-3282ecf2-cf6b-4ec9-b179-83670672161a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206558040-172.17.0.19-1598431452551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44353,DS-adff55c0-523f-4509-a9c6-e6d42bcdc274,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-27521ded-56a0-49ce-a674-0eef20856714,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-79155462-4a56-420c-8b82-d9d3599dc45d,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-c44f3b76-adbf-42df-aa99-c500eb37a791,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-7d048eb2-09e9-4c9a-9406-252566621a74,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-b8a8dfcd-39a0-49f7-a683-aa5f91f241ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-ba057864-6a96-4d88-b7b7-854d4bbcc64b,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-3282ecf2-cf6b-4ec9-b179-83670672161a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187079960-172.17.0.19-1598431873318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36572,DS-780c7bfb-e7e3-4fda-9c27-5235e6855fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-81002a95-9d5a-4cc2-8223-e99c45aa6fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-c327ccd5-5793-4ce2-9565-cab64d1f6602,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-1ea1a2f1-d7c3-43d3-b3f0-a8b56e31b650,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-0a4ea525-ba31-4c5d-ba48-077615660d69,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-d9025f05-94fe-441e-aa82-e1a52db97fba,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-ddfa6cf5-de7b-4127-b9e4-9f7b29a7e066,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-d40850e6-cb51-424f-affe-db8a03c57ed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187079960-172.17.0.19-1598431873318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36572,DS-780c7bfb-e7e3-4fda-9c27-5235e6855fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-81002a95-9d5a-4cc2-8223-e99c45aa6fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-c327ccd5-5793-4ce2-9565-cab64d1f6602,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-1ea1a2f1-d7c3-43d3-b3f0-a8b56e31b650,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-0a4ea525-ba31-4c5d-ba48-077615660d69,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-d9025f05-94fe-441e-aa82-e1a52db97fba,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-ddfa6cf5-de7b-4127-b9e4-9f7b29a7e066,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-d40850e6-cb51-424f-affe-db8a03c57ed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427878040-172.17.0.19-1598433773306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38018,DS-4c064144-266f-4c20-ab1b-ffb9577d378a,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-2b8b46de-41f3-4315-af0d-182b535a56d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-6213247b-693f-4c6f-8bc2-301eead9c0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-7ac5015d-0395-41cc-a1a0-d6c6fee3d60e,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-f8a8a606-76fc-4902-8362-9d4679209c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-dc5be34f-42f8-4103-ab5a-aba84689789c,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-8135a094-9e73-4344-8ebc-1993485f3aca,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-96a7aee0-dd39-42b5-98d6-752590a800d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427878040-172.17.0.19-1598433773306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38018,DS-4c064144-266f-4c20-ab1b-ffb9577d378a,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-2b8b46de-41f3-4315-af0d-182b535a56d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-6213247b-693f-4c6f-8bc2-301eead9c0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-7ac5015d-0395-41cc-a1a0-d6c6fee3d60e,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-f8a8a606-76fc-4902-8362-9d4679209c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-dc5be34f-42f8-4103-ab5a-aba84689789c,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-8135a094-9e73-4344-8ebc-1993485f3aca,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-96a7aee0-dd39-42b5-98d6-752590a800d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096462632-172.17.0.19-1598433842292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45088,DS-aba206e0-3805-4c8e-afae-3c13a91c5fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-0c78cd5d-652d-4b76-a9ff-dcf867c40cee,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-d5c007a9-c629-4b92-9aa9-646bf7b36516,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-db867234-ec83-4525-a4fe-4cabfed5ee67,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-d1eba413-8a30-4a54-9847-ed883904a772,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-c355e198-4613-444d-b47f-868920de7d75,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-0c6c0c1d-844d-4294-baed-025482288cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-1e01c1dd-36f8-49ee-8955-c4682a0e683e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096462632-172.17.0.19-1598433842292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45088,DS-aba206e0-3805-4c8e-afae-3c13a91c5fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-0c78cd5d-652d-4b76-a9ff-dcf867c40cee,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-d5c007a9-c629-4b92-9aa9-646bf7b36516,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-db867234-ec83-4525-a4fe-4cabfed5ee67,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-d1eba413-8a30-4a54-9847-ed883904a772,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-c355e198-4613-444d-b47f-868920de7d75,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-0c6c0c1d-844d-4294-baed-025482288cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-1e01c1dd-36f8-49ee-8955-c4682a0e683e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938990469-172.17.0.19-1598433913152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42366,DS-4a179dc9-0afa-4b47-abae-afd87eb25b10,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-21774cc5-3eaf-46af-a2e6-5ee97efc478f,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-977e8113-7776-47f8-bcfb-e69a7e5bfb57,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-ff1519ab-0bfe-4378-a8e5-adb69ae651a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-a32f8baf-d6d4-4048-8af5-d0189526aaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-df168d87-3aa2-42d6-b1ec-56286ca116e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-542409fc-8e6b-40b5-b628-9b2500855e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-971998f3-075c-4d15-9cc1-65fa02abdd2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938990469-172.17.0.19-1598433913152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42366,DS-4a179dc9-0afa-4b47-abae-afd87eb25b10,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-21774cc5-3eaf-46af-a2e6-5ee97efc478f,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-977e8113-7776-47f8-bcfb-e69a7e5bfb57,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-ff1519ab-0bfe-4378-a8e5-adb69ae651a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-a32f8baf-d6d4-4048-8af5-d0189526aaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-df168d87-3aa2-42d6-b1ec-56286ca116e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-542409fc-8e6b-40b5-b628-9b2500855e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-971998f3-075c-4d15-9cc1-65fa02abdd2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263482550-172.17.0.19-1598434285135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33572,DS-3392a372-8945-46d4-871a-a15caef59d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-d5cdc6f5-2b1c-4553-b553-08aff81e4b26,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-1cd7a486-4237-48f0-b961-20efba33fc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-72d84425-99ac-411b-b298-1ca01e12f80b,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-a2c145b2-66fd-4776-9a98-9903412b5a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-88ef5935-3014-4aa1-830f-19b4f8b70ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-accc7ac0-6d4f-4010-8fd8-a186fab1913d,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-a774d18b-34e3-4de5-9a33-3a04be561378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1263482550-172.17.0.19-1598434285135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33572,DS-3392a372-8945-46d4-871a-a15caef59d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-d5cdc6f5-2b1c-4553-b553-08aff81e4b26,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-1cd7a486-4237-48f0-b961-20efba33fc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-72d84425-99ac-411b-b298-1ca01e12f80b,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-a2c145b2-66fd-4776-9a98-9903412b5a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-88ef5935-3014-4aa1-830f-19b4f8b70ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-accc7ac0-6d4f-4010-8fd8-a186fab1913d,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-a774d18b-34e3-4de5-9a33-3a04be561378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5277
