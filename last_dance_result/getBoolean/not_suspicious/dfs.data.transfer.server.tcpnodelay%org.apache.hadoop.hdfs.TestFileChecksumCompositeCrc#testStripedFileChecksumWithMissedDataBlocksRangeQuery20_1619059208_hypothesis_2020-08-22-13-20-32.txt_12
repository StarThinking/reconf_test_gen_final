reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585493934-172.17.0.18-1598102628865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39545,DS-f8cd7a7f-07e8-4794-84d3-8da9910a62a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-15273402-f7c1-406d-a263-63b0ff2e9cce,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-695ecd44-ce5c-4ff4-bec2-351450cccda5,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-fb416179-91f8-41b7-a16b-847e573a3ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-8cde873a-b20f-4289-a274-189c828856d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-7e82a785-261d-425a-8918-e3b5d191fa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-650b169d-2935-4fc6-aaf4-9bbddaa1240a,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-64166930-b955-46fc-ae77-ac34fc9d0125,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585493934-172.17.0.18-1598102628865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39545,DS-f8cd7a7f-07e8-4794-84d3-8da9910a62a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-15273402-f7c1-406d-a263-63b0ff2e9cce,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-695ecd44-ce5c-4ff4-bec2-351450cccda5,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-fb416179-91f8-41b7-a16b-847e573a3ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-8cde873a-b20f-4289-a274-189c828856d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-7e82a785-261d-425a-8918-e3b5d191fa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-650b169d-2935-4fc6-aaf4-9bbddaa1240a,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-64166930-b955-46fc-ae77-ac34fc9d0125,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522592159-172.17.0.18-1598103006091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44003,DS-2225ffdc-fe1e-42f7-9215-432b5c535c06,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-213fae4b-e9d3-40fd-b2ca-eef85b63e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-6945c7ab-5460-4575-98c6-4871d65cc982,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-d78c24cc-3fb1-4a6c-8abe-104be7d445ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-f97b6f2f-0cee-4a60-9fb1-6fe5da8c7d89,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-74afe0f0-4a8f-4d83-9613-90ce16607655,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-032f1ff3-253c-43ba-ac24-21f8e5be11e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-a47fad26-8b16-4e56-affb-9825832655fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522592159-172.17.0.18-1598103006091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44003,DS-2225ffdc-fe1e-42f7-9215-432b5c535c06,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-213fae4b-e9d3-40fd-b2ca-eef85b63e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-6945c7ab-5460-4575-98c6-4871d65cc982,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-d78c24cc-3fb1-4a6c-8abe-104be7d445ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-f97b6f2f-0cee-4a60-9fb1-6fe5da8c7d89,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-74afe0f0-4a8f-4d83-9613-90ce16607655,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-032f1ff3-253c-43ba-ac24-21f8e5be11e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-a47fad26-8b16-4e56-affb-9825832655fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593500551-172.17.0.18-1598103635954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40666,DS-d9ed3cec-bfa7-40b8-9cbe-f03e674d00d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-1a8e4d3e-2cc1-466e-92f3-5cf295d0b9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-04fcf5d4-904d-479b-b4e1-ca1dca9fba10,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-39aa169d-301c-4aaa-b55d-2b804fb6280b,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-4da24485-14ce-4e66-b647-e6103caed02f,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-7d4e5d24-96ef-4710-b7d6-f1439f662b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-a61c206b-ef8b-4608-8efe-c52e9fd90457,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-ab7dd27a-07ce-4864-89d6-d4cb9c199e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593500551-172.17.0.18-1598103635954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40666,DS-d9ed3cec-bfa7-40b8-9cbe-f03e674d00d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-1a8e4d3e-2cc1-466e-92f3-5cf295d0b9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-04fcf5d4-904d-479b-b4e1-ca1dca9fba10,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-39aa169d-301c-4aaa-b55d-2b804fb6280b,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-4da24485-14ce-4e66-b647-e6103caed02f,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-7d4e5d24-96ef-4710-b7d6-f1439f662b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-a61c206b-ef8b-4608-8efe-c52e9fd90457,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-ab7dd27a-07ce-4864-89d6-d4cb9c199e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789612337-172.17.0.18-1598103711229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33984,DS-337853de-fb9e-4ad2-9e9c-e0fadc460385,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-cf6be0a5-70ef-4401-94e4-f0e7a8012afe,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-f21dd589-5f32-4ff6-9047-6020f09b0276,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-18757e15-7a24-4fb7-aaab-70528b06861e,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-3f65d732-bce8-4b21-b574-0fe5a9bd4565,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-75354733-25a7-499d-bf07-d62219c1eb98,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-f5005457-30fd-441c-ad21-0531b10c6bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-62ff2030-fdde-4da0-9a04-6fb68a69e4f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789612337-172.17.0.18-1598103711229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33984,DS-337853de-fb9e-4ad2-9e9c-e0fadc460385,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-cf6be0a5-70ef-4401-94e4-f0e7a8012afe,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-f21dd589-5f32-4ff6-9047-6020f09b0276,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-18757e15-7a24-4fb7-aaab-70528b06861e,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-3f65d732-bce8-4b21-b574-0fe5a9bd4565,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-75354733-25a7-499d-bf07-d62219c1eb98,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-f5005457-30fd-441c-ad21-0531b10c6bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-62ff2030-fdde-4da0-9a04-6fb68a69e4f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2045668950-172.17.0.18-1598103788105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35512,DS-49f17a87-b495-4e52-9b13-e5e72b731b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-4d730305-4e73-4905-bb55-078f81ef7dba,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-ff8772b0-6aac-470f-9e79-b1e1351f67c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-31218fc9-a240-4dd3-a612-8262c09d0083,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-aeba8af3-3448-4d16-b50e-19693ca17cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-8ecdc749-b126-48a7-9e23-8f223cbb36b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-8430e627-1cef-4bb2-9bbf-35ce34e37041,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-60605a1a-e102-47d0-9472-ac7dab4b5ebf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2045668950-172.17.0.18-1598103788105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35512,DS-49f17a87-b495-4e52-9b13-e5e72b731b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-4d730305-4e73-4905-bb55-078f81ef7dba,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-ff8772b0-6aac-470f-9e79-b1e1351f67c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-31218fc9-a240-4dd3-a612-8262c09d0083,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-aeba8af3-3448-4d16-b50e-19693ca17cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-8ecdc749-b126-48a7-9e23-8f223cbb36b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-8430e627-1cef-4bb2-9bbf-35ce34e37041,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-60605a1a-e102-47d0-9472-ac7dab4b5ebf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475833614-172.17.0.18-1598104017811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34417,DS-3b095bc3-78e4-4e25-b38d-8bb7da677c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-c7e2308f-a44a-4396-b8f8-c4352a7f22dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-3e58a84f-7ecf-40ac-be41-6397ab844b99,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-25175087-35f8-4874-86e2-40aafca443d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-c58b4f84-c0e8-43e0-9d95-c3cbf26561fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-8624d428-8261-42b8-a530-36a75513451e,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-0ad354b8-9a03-4444-b9c5-2586696ba4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-5ac5e3dd-ce29-4558-bb8e-f6fbfb2b9d7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475833614-172.17.0.18-1598104017811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34417,DS-3b095bc3-78e4-4e25-b38d-8bb7da677c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-c7e2308f-a44a-4396-b8f8-c4352a7f22dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-3e58a84f-7ecf-40ac-be41-6397ab844b99,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-25175087-35f8-4874-86e2-40aafca443d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-c58b4f84-c0e8-43e0-9d95-c3cbf26561fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-8624d428-8261-42b8-a530-36a75513451e,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-0ad354b8-9a03-4444-b9c5-2586696ba4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-5ac5e3dd-ce29-4558-bb8e-f6fbfb2b9d7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900532889-172.17.0.18-1598104391256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34052,DS-9c73e704-213c-461d-bd48-c9bd95e8197d,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-0e99b768-dd6f-45b9-98e7-9d81cd7a7bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-a9cc128a-0002-4fbe-b2f4-6b20d7c03330,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-caca642b-baf3-4603-be1d-be4880b17a00,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-41d23696-0a55-46c7-b550-e35a93f76f02,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-292aa601-93eb-40f3-a0d4-2e72b219a161,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-9b36c63e-6926-431c-bf55-a76919e38948,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-3ff60d4f-96b0-4cb8-b3c1-9d60898b374b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900532889-172.17.0.18-1598104391256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34052,DS-9c73e704-213c-461d-bd48-c9bd95e8197d,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-0e99b768-dd6f-45b9-98e7-9d81cd7a7bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-a9cc128a-0002-4fbe-b2f4-6b20d7c03330,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-caca642b-baf3-4603-be1d-be4880b17a00,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-41d23696-0a55-46c7-b550-e35a93f76f02,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-292aa601-93eb-40f3-a0d4-2e72b219a161,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-9b36c63e-6926-431c-bf55-a76919e38948,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-3ff60d4f-96b0-4cb8-b3c1-9d60898b374b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43893242-172.17.0.18-1598104467904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40788,DS-ecac5ae7-06f9-4135-b0b2-d7fb70e3a218,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-da08c66f-fff4-404e-a9b9-077e16e3d8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-6c93326f-def3-4e1e-8921-c41caf444318,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-8f4e9d4e-226b-44a2-8e28-3dc271e047d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-85f998ff-1c35-470b-b538-f8c58e496a48,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-3c034503-c1da-4cc8-bd32-6df471f49c52,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-51b8a473-15f0-4e6a-84d5-800be5a971f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-aaec5bb6-1d07-4939-af12-aac857f7af82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43893242-172.17.0.18-1598104467904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40788,DS-ecac5ae7-06f9-4135-b0b2-d7fb70e3a218,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-da08c66f-fff4-404e-a9b9-077e16e3d8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-6c93326f-def3-4e1e-8921-c41caf444318,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-8f4e9d4e-226b-44a2-8e28-3dc271e047d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-85f998ff-1c35-470b-b538-f8c58e496a48,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-3c034503-c1da-4cc8-bd32-6df471f49c52,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-51b8a473-15f0-4e6a-84d5-800be5a971f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-aaec5bb6-1d07-4939-af12-aac857f7af82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1560528931-172.17.0.18-1598104545333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-bdec86b8-806a-45b9-b2cf-836db1ca79e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-9d0d38c6-9c67-4c54-9cd3-1500bfe6c793,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-eb8ab3f0-9e68-4146-8b1e-5b571a972906,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-b853a42e-789f-4fc8-a358-676f82964b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-efc70b97-4e7c-416a-96a9-9d20d36a0e14,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-a886dc49-8b2b-4893-99b9-aa532dea251f,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-560dc96b-ae95-4669-a31c-dc4152c2c32a,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-4296f79d-e543-4768-9d48-9d4f4623b1eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1560528931-172.17.0.18-1598104545333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-bdec86b8-806a-45b9-b2cf-836db1ca79e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-9d0d38c6-9c67-4c54-9cd3-1500bfe6c793,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-eb8ab3f0-9e68-4146-8b1e-5b571a972906,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-b853a42e-789f-4fc8-a358-676f82964b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-efc70b97-4e7c-416a-96a9-9d20d36a0e14,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-a886dc49-8b2b-4893-99b9-aa532dea251f,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-560dc96b-ae95-4669-a31c-dc4152c2c32a,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-4296f79d-e543-4768-9d48-9d4f4623b1eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56581318-172.17.0.18-1598104665353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33131,DS-f4b2e87d-cf3e-4664-9dc4-45a3dfaa874a,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-0c170ba7-1a22-4928-bddd-7bf7053f67f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-776576c8-7807-4769-8e0c-d9eb7c7c9c42,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-8162d66a-8bca-4f32-9b02-e09ae2e7c7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-2e30a1ca-2911-463c-be3f-13ed1b13b5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-f18107fe-4a16-4914-b9fd-61565f067819,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-c7fa9bf1-6050-43e4-92a7-d36f8e49c1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-e4ac603e-fc04-45a1-a0f1-7c4c4ceb9431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56581318-172.17.0.18-1598104665353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33131,DS-f4b2e87d-cf3e-4664-9dc4-45a3dfaa874a,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-0c170ba7-1a22-4928-bddd-7bf7053f67f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-776576c8-7807-4769-8e0c-d9eb7c7c9c42,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-8162d66a-8bca-4f32-9b02-e09ae2e7c7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-2e30a1ca-2911-463c-be3f-13ed1b13b5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-f18107fe-4a16-4914-b9fd-61565f067819,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-c7fa9bf1-6050-43e4-92a7-d36f8e49c1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-e4ac603e-fc04-45a1-a0f1-7c4c4ceb9431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609819593-172.17.0.18-1598104947680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35401,DS-48a9e5bc-79f4-4389-8dad-c1f2699ec0df,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-0c4b5828-b2f4-45b6-b216-ae26dea8450c,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-89922da8-a1e6-4da4-9074-8cf8c4477085,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-0b93f87d-c6a4-40c0-bd5f-fe5c92781db9,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-eee2db75-e8c9-4f5e-95a3-63f5379b35ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-4f62578b-87bf-443e-a00d-9d68b502c544,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-e9431849-8da5-462f-bc12-e0d086a9e462,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-abc2b7d1-1fa8-4afe-bbaa-e5f1c2fa00d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609819593-172.17.0.18-1598104947680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35401,DS-48a9e5bc-79f4-4389-8dad-c1f2699ec0df,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-0c4b5828-b2f4-45b6-b216-ae26dea8450c,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-89922da8-a1e6-4da4-9074-8cf8c4477085,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-0b93f87d-c6a4-40c0-bd5f-fe5c92781db9,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-eee2db75-e8c9-4f5e-95a3-63f5379b35ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-4f62578b-87bf-443e-a00d-9d68b502c544,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-e9431849-8da5-462f-bc12-e0d086a9e462,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-abc2b7d1-1fa8-4afe-bbaa-e5f1c2fa00d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719893571-172.17.0.18-1598105246101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44732,DS-ef628b54-1ea2-4e98-b574-1ad007a76741,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-b0930315-ed47-4f3e-a5f7-98f2b0450373,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-f3413386-ea65-4b36-a2bf-19c75791eeda,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-a2e6c4f0-e538-4b98-87a9-6e9aa452b864,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-ef477d9d-7853-4ec0-9d58-78f6179876c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-04ab8161-02ff-4e5d-bb08-75dc1e5b3634,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-4bfba0f2-932e-4477-88b0-4d5fe0d0495b,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-1270ff4e-d59d-4462-b76a-1b80492a099d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719893571-172.17.0.18-1598105246101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44732,DS-ef628b54-1ea2-4e98-b574-1ad007a76741,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-b0930315-ed47-4f3e-a5f7-98f2b0450373,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-f3413386-ea65-4b36-a2bf-19c75791eeda,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-a2e6c4f0-e538-4b98-87a9-6e9aa452b864,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-ef477d9d-7853-4ec0-9d58-78f6179876c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-04ab8161-02ff-4e5d-bb08-75dc1e5b3634,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-4bfba0f2-932e-4477-88b0-4d5fe0d0495b,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-1270ff4e-d59d-4462-b76a-1b80492a099d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178972934-172.17.0.18-1598105393021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41965,DS-fcc1f571-f31f-4345-abda-246dbcad1855,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-b932138d-3dd9-4e4f-96bb-72e8c36c711b,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-540840a3-f2e8-4ff7-94af-694efd9827d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-cc37739e-cb0c-4dbd-a55f-2c739c34ce20,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-fc08f640-8ec4-4409-a7c2-69e60d5d4164,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-b5c047a6-e0dd-4632-9f55-af15f6dc5e46,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-d89f7f72-c0e2-4add-913f-1d8691c5a60d,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-bf09c0b5-73a2-4e44-b64d-2fbc0eea52ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178972934-172.17.0.18-1598105393021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41965,DS-fcc1f571-f31f-4345-abda-246dbcad1855,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-b932138d-3dd9-4e4f-96bb-72e8c36c711b,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-540840a3-f2e8-4ff7-94af-694efd9827d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-cc37739e-cb0c-4dbd-a55f-2c739c34ce20,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-fc08f640-8ec4-4409-a7c2-69e60d5d4164,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-b5c047a6-e0dd-4632-9f55-af15f6dc5e46,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-d89f7f72-c0e2-4add-913f-1d8691c5a60d,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-bf09c0b5-73a2-4e44-b64d-2fbc0eea52ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549580575-172.17.0.18-1598106111516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36304,DS-f4cfe2c3-6ead-452e-95ac-71c5c4aa86a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-3bbc686e-b6b1-459b-86d7-c8d38e024ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-45ff3975-0e8e-488a-bddd-06a009bf834d,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-c434fd6a-22f9-4672-9774-8833178b180b,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-f01466c9-a34c-46ba-b6d1-ea4ed8e035f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-4ef69d08-534a-4df9-81ae-3a75738890a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-04c86a5f-be1c-4406-83bf-e918459a2273,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-3d119dbd-0220-40a3-85ae-6ce487fc0439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549580575-172.17.0.18-1598106111516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36304,DS-f4cfe2c3-6ead-452e-95ac-71c5c4aa86a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-3bbc686e-b6b1-459b-86d7-c8d38e024ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-45ff3975-0e8e-488a-bddd-06a009bf834d,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-c434fd6a-22f9-4672-9774-8833178b180b,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-f01466c9-a34c-46ba-b6d1-ea4ed8e035f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-4ef69d08-534a-4df9-81ae-3a75738890a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-04c86a5f-be1c-4406-83bf-e918459a2273,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-3d119dbd-0220-40a3-85ae-6ce487fc0439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-884683388-172.17.0.18-1598106247535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-ad66aeca-5d2a-4eb1-a922-326665bb6562,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-a972b601-94ee-4559-8e03-d86c3c343baa,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-a21f68bb-dcdc-41a7-9fb4-e2a1a3bc699d,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-24ac92b3-022d-499c-8882-c8093ec870dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-19758444-feb3-47ed-a5dc-88bdd0b8a991,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-1413b36d-5167-4e7f-8cdc-172d2c811949,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-b1ad7e61-8eaa-4ef7-9a77-ef884ad2fd98,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-6eab213b-6edf-440d-b266-e85e747dd4d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-884683388-172.17.0.18-1598106247535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-ad66aeca-5d2a-4eb1-a922-326665bb6562,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-a972b601-94ee-4559-8e03-d86c3c343baa,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-a21f68bb-dcdc-41a7-9fb4-e2a1a3bc699d,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-24ac92b3-022d-499c-8882-c8093ec870dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-19758444-feb3-47ed-a5dc-88bdd0b8a991,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-1413b36d-5167-4e7f-8cdc-172d2c811949,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-b1ad7e61-8eaa-4ef7-9a77-ef884ad2fd98,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-6eab213b-6edf-440d-b266-e85e747dd4d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1392461059-172.17.0.18-1598106866812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37757,DS-2f61f556-13f7-4c4e-80e4-4bc34d333f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-286935d4-1c0c-4e97-b600-2b6af2aa382f,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-722097f2-1764-428c-a5b9-ab3bea7c8eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-46e6354f-e2c1-4424-948a-09bb7e936be7,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-4069a850-89bf-4abb-a34f-ee38ea29815e,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-207ed45d-3f3c-4e7c-94bf-67553feb5888,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-c778e734-67ff-4858-be01-cd367bf87f62,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-d3daba96-5dae-43b1-9208-70a47773c44c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1392461059-172.17.0.18-1598106866812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37757,DS-2f61f556-13f7-4c4e-80e4-4bc34d333f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-286935d4-1c0c-4e97-b600-2b6af2aa382f,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-722097f2-1764-428c-a5b9-ab3bea7c8eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-46e6354f-e2c1-4424-948a-09bb7e936be7,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-4069a850-89bf-4abb-a34f-ee38ea29815e,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-207ed45d-3f3c-4e7c-94bf-67553feb5888,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-c778e734-67ff-4858-be01-cd367bf87f62,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-d3daba96-5dae-43b1-9208-70a47773c44c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1150141836-172.17.0.18-1598106998090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33281,DS-ba7c64c1-0aa5-4cc6-b966-403713e7f10d,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-9a9a1020-9b68-418a-967b-35880f4d2427,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-d792c5f8-2d8d-4b7b-8e2e-e3c88dd16035,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-d1e004f0-1f19-46f3-b1c2-ea94266282cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-df4aa1fe-ad72-4641-b93b-ec3bfd27ff6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-1b466a81-960b-42d1-acaa-7d23845f2b26,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-b04cd38c-c1d2-4d00-9cdb-390a524c75f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-8cc7579d-1855-4f05-9132-f39d33fb8b97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1150141836-172.17.0.18-1598106998090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33281,DS-ba7c64c1-0aa5-4cc6-b966-403713e7f10d,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-9a9a1020-9b68-418a-967b-35880f4d2427,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-d792c5f8-2d8d-4b7b-8e2e-e3c88dd16035,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-d1e004f0-1f19-46f3-b1c2-ea94266282cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-df4aa1fe-ad72-4641-b93b-ec3bfd27ff6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-1b466a81-960b-42d1-acaa-7d23845f2b26,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-b04cd38c-c1d2-4d00-9cdb-390a524c75f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-8cc7579d-1855-4f05-9132-f39d33fb8b97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22994885-172.17.0.18-1598107498924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40549,DS-9dd474ca-bcb7-4e86-889b-d41a8738b35c,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-4213e6cf-ad38-47dc-a755-46b6494de229,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-5f1dad0b-b95c-4f5e-bb46-6e0b7a7b5811,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-fcdc81d5-90f0-46c8-8c02-82b753207fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-5d40936e-df2b-41b1-a442-7af5f6ec4b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-9df25253-e42c-4d6a-a924-59dc6d024497,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-06f563ff-168d-4a76-bc7a-b00192e06992,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-af2ab0be-58f1-46eb-8872-375b01837c13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22994885-172.17.0.18-1598107498924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40549,DS-9dd474ca-bcb7-4e86-889b-d41a8738b35c,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-4213e6cf-ad38-47dc-a755-46b6494de229,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-5f1dad0b-b95c-4f5e-bb46-6e0b7a7b5811,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-fcdc81d5-90f0-46c8-8c02-82b753207fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-5d40936e-df2b-41b1-a442-7af5f6ec4b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-9df25253-e42c-4d6a-a924-59dc6d024497,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-06f563ff-168d-4a76-bc7a-b00192e06992,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-af2ab0be-58f1-46eb-8872-375b01837c13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5501
