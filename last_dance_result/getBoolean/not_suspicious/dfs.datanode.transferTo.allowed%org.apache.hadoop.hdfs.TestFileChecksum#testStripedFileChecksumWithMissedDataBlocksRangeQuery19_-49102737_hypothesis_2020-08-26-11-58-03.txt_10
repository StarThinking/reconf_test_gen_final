reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129171776-172.17.0.14-1598443399765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35345,DS-c8801549-01e1-4042-adf7-5c5123652041,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-b8263e8e-eeba-4594-8b4d-b5f45f04a856,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-5dcfe9da-ec64-4995-ba5d-43626b8415ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-8286adc4-4d7f-4367-856b-793215d6e923,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-89218af7-6af9-46fd-a568-674c63bd7420,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-917c731c-b4eb-48fc-a7c3-60981e92dfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-b5bd4a7c-aae8-4697-9cbc-e0fedd3c0d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-cf5400ea-9a40-4abe-98bc-6d8a3de8af21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129171776-172.17.0.14-1598443399765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35345,DS-c8801549-01e1-4042-adf7-5c5123652041,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-b8263e8e-eeba-4594-8b4d-b5f45f04a856,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-5dcfe9da-ec64-4995-ba5d-43626b8415ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-8286adc4-4d7f-4367-856b-793215d6e923,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-89218af7-6af9-46fd-a568-674c63bd7420,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-917c731c-b4eb-48fc-a7c3-60981e92dfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-b5bd4a7c-aae8-4697-9cbc-e0fedd3c0d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-cf5400ea-9a40-4abe-98bc-6d8a3de8af21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117628155-172.17.0.14-1598443863655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37996,DS-4eb91f59-f904-4187-95a7-78397ad2d19e,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-3f8d650a-c29b-4503-8cf4-bb24f85e9a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-d0e80dff-cece-44e7-8da0-98237cffa077,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-fe971281-8cc0-4cd1-ab8f-6960674d4507,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-2c68347d-2e5f-4c62-be2b-7fd14dbf8755,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-686ab545-6066-42c4-be6b-12fa34a54ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-664cf960-4e76-4d63-9e18-32f501c2c13d,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-cc6e571f-4508-4fd2-a75f-5a70d13b41f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117628155-172.17.0.14-1598443863655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37996,DS-4eb91f59-f904-4187-95a7-78397ad2d19e,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-3f8d650a-c29b-4503-8cf4-bb24f85e9a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-d0e80dff-cece-44e7-8da0-98237cffa077,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-fe971281-8cc0-4cd1-ab8f-6960674d4507,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-2c68347d-2e5f-4c62-be2b-7fd14dbf8755,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-686ab545-6066-42c4-be6b-12fa34a54ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-664cf960-4e76-4d63-9e18-32f501c2c13d,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-cc6e571f-4508-4fd2-a75f-5a70d13b41f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066230066-172.17.0.14-1598443906866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42255,DS-323c2f54-e6ef-4367-8d1e-1af43a2fdfed,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-02f23a2a-3906-4527-8538-1e2888bce313,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-ffa043ce-85e0-44e5-b82a-4af9df9625ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-f39e3608-7ea1-43fe-8282-12cbcc784595,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-91887ddc-3659-45b6-b965-95df81e72b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-b647f440-5d48-494a-8644-3abd1e34bdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-8f514118-6c3a-4012-900d-bec4a0d1b998,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-b5edf20f-15b5-4695-b659-52f95f5f6517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066230066-172.17.0.14-1598443906866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42255,DS-323c2f54-e6ef-4367-8d1e-1af43a2fdfed,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-02f23a2a-3906-4527-8538-1e2888bce313,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-ffa043ce-85e0-44e5-b82a-4af9df9625ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-f39e3608-7ea1-43fe-8282-12cbcc784595,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-91887ddc-3659-45b6-b965-95df81e72b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-b647f440-5d48-494a-8644-3abd1e34bdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-8f514118-6c3a-4012-900d-bec4a0d1b998,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-b5edf20f-15b5-4695-b659-52f95f5f6517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608759743-172.17.0.14-1598444095015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34331,DS-38394709-42ed-479e-885d-0dfad5e84da4,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-bc958672-0954-4e9b-83b6-d8bfa807b93d,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-ada0b517-d483-4e14-ba80-7184a7208a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-974f274f-3361-4ac7-b0f4-a0fcb66bade8,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-d2933c87-2433-4c8d-a42a-b0bb93e029b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-9f27e122-ef47-4885-84a4-225a19935d61,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-eeefb642-39f5-43bd-b572-2efdb1627c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-d6f68402-d303-4b26-8b55-48ffe1b6493d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1608759743-172.17.0.14-1598444095015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34331,DS-38394709-42ed-479e-885d-0dfad5e84da4,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-bc958672-0954-4e9b-83b6-d8bfa807b93d,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-ada0b517-d483-4e14-ba80-7184a7208a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-974f274f-3361-4ac7-b0f4-a0fcb66bade8,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-d2933c87-2433-4c8d-a42a-b0bb93e029b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-9f27e122-ef47-4885-84a4-225a19935d61,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-eeefb642-39f5-43bd-b572-2efdb1627c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-d6f68402-d303-4b26-8b55-48ffe1b6493d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413738575-172.17.0.14-1598444321495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37918,DS-c7378215-f910-4e16-bde1-aefafc10a3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-d08d5b49-3477-46ec-9aab-65d09ae140de,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-b6eb4bda-ceab-4550-b80e-fd9f815d76b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-6d0f6e2c-db66-4845-91ee-79a4a7f46b62,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-b9e1ae41-fdc9-40ff-9f17-2e40d105a331,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-0b845d9d-847e-4da8-82cc-dad312ecc3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-4d5a97f5-466a-44d3-9912-244e918fae64,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-3e4dfdb2-d8b2-4580-a7d1-7427aa2a8efa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413738575-172.17.0.14-1598444321495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37918,DS-c7378215-f910-4e16-bde1-aefafc10a3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-d08d5b49-3477-46ec-9aab-65d09ae140de,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-b6eb4bda-ceab-4550-b80e-fd9f815d76b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-6d0f6e2c-db66-4845-91ee-79a4a7f46b62,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-b9e1ae41-fdc9-40ff-9f17-2e40d105a331,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-0b845d9d-847e-4da8-82cc-dad312ecc3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-4d5a97f5-466a-44d3-9912-244e918fae64,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-3e4dfdb2-d8b2-4580-a7d1-7427aa2a8efa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717297930-172.17.0.14-1598444733704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42594,DS-977d404b-6021-46a5-a569-23051d217701,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-874037c7-eacf-4a98-aae5-8406f0c9ca11,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-4f791c3d-b55b-4e7c-9172-1fa90cf10123,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-7344ca36-cd39-4046-8fd8-6971c87335c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-db6b39c2-4553-4805-abee-7070f727fba8,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-3aabdc1b-3af2-4325-bde5-ec5166d5d57e,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-5fa6a4d0-453b-43af-82fa-79f5f0c511d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-f3730290-a277-4fe2-8af6-56457a648656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717297930-172.17.0.14-1598444733704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42594,DS-977d404b-6021-46a5-a569-23051d217701,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-874037c7-eacf-4a98-aae5-8406f0c9ca11,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-4f791c3d-b55b-4e7c-9172-1fa90cf10123,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-7344ca36-cd39-4046-8fd8-6971c87335c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-db6b39c2-4553-4805-abee-7070f727fba8,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-3aabdc1b-3af2-4325-bde5-ec5166d5d57e,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-5fa6a4d0-453b-43af-82fa-79f5f0c511d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-f3730290-a277-4fe2-8af6-56457a648656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-346824198-172.17.0.14-1598445840593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43859,DS-e7faa132-409c-4a00-b973-a421e965b0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-9c5da893-3e16-4cbd-bfd1-47d27f5b1f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-67dda348-9152-4362-89c2-632eaadd81fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-8cfa7986-e6f8-405a-ba84-c49103750f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-0d25a600-3401-48e3-851c-8601cac1fb78,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-d62cade6-f793-4301-812b-8b7d9457ae63,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-50f27005-f47f-4914-a1eb-6bbd35569f35,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-cf3f1387-ae47-40d0-8461-23701b8dc334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-346824198-172.17.0.14-1598445840593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43859,DS-e7faa132-409c-4a00-b973-a421e965b0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-9c5da893-3e16-4cbd-bfd1-47d27f5b1f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-67dda348-9152-4362-89c2-632eaadd81fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-8cfa7986-e6f8-405a-ba84-c49103750f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-0d25a600-3401-48e3-851c-8601cac1fb78,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-d62cade6-f793-4301-812b-8b7d9457ae63,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-50f27005-f47f-4914-a1eb-6bbd35569f35,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-cf3f1387-ae47-40d0-8461-23701b8dc334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1141449509-172.17.0.14-1598446011037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46769,DS-da01a496-1e81-4ab7-bf73-ada96631e457,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-ef4159bd-710f-4d8e-8a85-1d91ed819e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-c1b03cd0-9c50-4668-b142-e49a48917a19,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-b9264bb4-ba8a-48a6-ab44-da7ed1deb04b,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-704fec76-0b38-4013-a153-2a74ba6e4fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-03b3b92c-0af1-4af0-a9f5-db372ec0ca41,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-d0ff3d79-1e50-47dc-a4a2-7ad3e224d027,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-7fdeb795-debe-4df0-a812-981a18a1e2d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1141449509-172.17.0.14-1598446011037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46769,DS-da01a496-1e81-4ab7-bf73-ada96631e457,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-ef4159bd-710f-4d8e-8a85-1d91ed819e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-c1b03cd0-9c50-4668-b142-e49a48917a19,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-b9264bb4-ba8a-48a6-ab44-da7ed1deb04b,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-704fec76-0b38-4013-a153-2a74ba6e4fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-03b3b92c-0af1-4af0-a9f5-db372ec0ca41,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-d0ff3d79-1e50-47dc-a4a2-7ad3e224d027,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-7fdeb795-debe-4df0-a812-981a18a1e2d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254213718-172.17.0.14-1598446037180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38343,DS-3184213a-c3d7-4ab3-aba0-2c37c37bd47b,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-0e7d9f55-48cc-4375-a8b7-0f59e0c6646c,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-baa7b2a6-a7ed-467c-85e8-6e449ae73758,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-a30ccf88-46e8-4965-af03-abd639db3adf,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-d89c9626-56b9-4012-9fff-8da8377ab009,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-a649d719-8ecf-4435-ab0d-8c13a01be99b,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-5197a6a3-7685-4ed9-a5fe-d62ef14eff75,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-7bd54066-68e1-4564-a0f4-04368a169fee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254213718-172.17.0.14-1598446037180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38343,DS-3184213a-c3d7-4ab3-aba0-2c37c37bd47b,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-0e7d9f55-48cc-4375-a8b7-0f59e0c6646c,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-baa7b2a6-a7ed-467c-85e8-6e449ae73758,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-a30ccf88-46e8-4965-af03-abd639db3adf,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-d89c9626-56b9-4012-9fff-8da8377ab009,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-a649d719-8ecf-4435-ab0d-8c13a01be99b,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-5197a6a3-7685-4ed9-a5fe-d62ef14eff75,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-7bd54066-68e1-4564-a0f4-04368a169fee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162937268-172.17.0.14-1598446111232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36652,DS-70ea97f7-1255-4892-96b4-0e5413df4a32,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-656c12c2-30df-460b-9ee8-3a44593f74cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-c041b754-501f-4d48-a8f9-dc6841930d78,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-a382c6a8-a022-40b7-884e-71e2e3211773,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-5e9d97aa-9ff7-4303-ae96-5bc3f6622007,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-f8c65a0b-f4fc-4f7b-9fa6-4545570468d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-c85621ea-e2c1-46c8-a8f3-fed01a318380,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-76fdf4a0-4421-4074-a672-45acf14269fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162937268-172.17.0.14-1598446111232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36652,DS-70ea97f7-1255-4892-96b4-0e5413df4a32,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-656c12c2-30df-460b-9ee8-3a44593f74cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-c041b754-501f-4d48-a8f9-dc6841930d78,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-a382c6a8-a022-40b7-884e-71e2e3211773,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-5e9d97aa-9ff7-4303-ae96-5bc3f6622007,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-f8c65a0b-f4fc-4f7b-9fa6-4545570468d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-c85621ea-e2c1-46c8-a8f3-fed01a318380,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-76fdf4a0-4421-4074-a672-45acf14269fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-992654301-172.17.0.14-1598446443994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41965,DS-699bf3bd-14b7-44cf-b151-c269f0e39ece,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-dc2bbaa4-bfd2-43a6-877a-a31dd1122e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-473523e6-7fbd-4918-b425-af3bb8820688,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-2a8c5884-4acd-4030-9ab6-c6f2b2a215fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-d0b76312-c5e7-4154-8ebb-a860a7daf054,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-9cd8eea2-2469-4d9e-99d5-e565f51b940b,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-14788c74-830f-4642-a296-6ee1b9cc6c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-491cca54-56b4-4b55-a3a3-353e5c9a9c12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-992654301-172.17.0.14-1598446443994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41965,DS-699bf3bd-14b7-44cf-b151-c269f0e39ece,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-dc2bbaa4-bfd2-43a6-877a-a31dd1122e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-473523e6-7fbd-4918-b425-af3bb8820688,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-2a8c5884-4acd-4030-9ab6-c6f2b2a215fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-d0b76312-c5e7-4154-8ebb-a860a7daf054,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-9cd8eea2-2469-4d9e-99d5-e565f51b940b,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-14788c74-830f-4642-a296-6ee1b9cc6c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-491cca54-56b4-4b55-a3a3-353e5c9a9c12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1363459290-172.17.0.14-1598446878478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40369,DS-4a572204-f9b2-41f6-93a4-35c2d99c68bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-c5988fec-24b5-4009-9d0e-7ac7764c2150,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-fb1f2c56-e7c8-4a67-832c-865dc6648090,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-3f18e0d4-b04e-49fb-9beb-c5ebf7a65add,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-d2bd2492-91c1-4187-befe-dfbbdaff733a,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-6dc0ee01-a07b-40da-9a9a-5c1f7726502e,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-d8b3a941-7462-4f6f-89b6-84acc0d84f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-8f7b04ae-0d66-449c-8baa-c8ec2e3bb776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1363459290-172.17.0.14-1598446878478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40369,DS-4a572204-f9b2-41f6-93a4-35c2d99c68bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-c5988fec-24b5-4009-9d0e-7ac7764c2150,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-fb1f2c56-e7c8-4a67-832c-865dc6648090,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-3f18e0d4-b04e-49fb-9beb-c5ebf7a65add,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-d2bd2492-91c1-4187-befe-dfbbdaff733a,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-6dc0ee01-a07b-40da-9a9a-5c1f7726502e,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-d8b3a941-7462-4f6f-89b6-84acc0d84f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-8f7b04ae-0d66-449c-8baa-c8ec2e3bb776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799940070-172.17.0.14-1598447013224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-939eb46b-2113-4fba-b62f-a286952457f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-a3247e3f-3679-4145-a371-999129870a98,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-a846256c-b37c-4d37-b5a0-1fef398a25b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-53b2322c-db37-484e-acc8-17227d162f60,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-ff1859eb-8ebf-4f23-bddb-7d0f24b40b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-64b69503-1602-4ab3-8d07-26f3daa0c008,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-0bc47612-0772-416c-99b3-c65066064258,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-6086cf1d-7ac6-4e46-b5b5-4356325295ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799940070-172.17.0.14-1598447013224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-939eb46b-2113-4fba-b62f-a286952457f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-a3247e3f-3679-4145-a371-999129870a98,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-a846256c-b37c-4d37-b5a0-1fef398a25b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-53b2322c-db37-484e-acc8-17227d162f60,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-ff1859eb-8ebf-4f23-bddb-7d0f24b40b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-64b69503-1602-4ab3-8d07-26f3daa0c008,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-0bc47612-0772-416c-99b3-c65066064258,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-6086cf1d-7ac6-4e46-b5b5-4356325295ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551479162-172.17.0.14-1598447139072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38120,DS-95daf13d-2c48-4143-a38c-96a84f37e070,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-e6273421-7bd8-433b-ad3a-800d2119a1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-aaee191d-6679-4134-a653-595bcf8a2532,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-ca111292-5869-4b14-ad23-bc99fb6687c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-4cb66bed-20e5-402a-83ca-4b8bafb10e34,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-150c6268-389d-4236-bb9a-4809ca8eaa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-9147a793-9247-4ab8-a311-34af28af5351,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-5f6a9f16-df15-4f7d-b73f-88065caf23e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551479162-172.17.0.14-1598447139072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38120,DS-95daf13d-2c48-4143-a38c-96a84f37e070,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-e6273421-7bd8-433b-ad3a-800d2119a1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-aaee191d-6679-4134-a653-595bcf8a2532,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-ca111292-5869-4b14-ad23-bc99fb6687c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-4cb66bed-20e5-402a-83ca-4b8bafb10e34,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-150c6268-389d-4236-bb9a-4809ca8eaa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-9147a793-9247-4ab8-a311-34af28af5351,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-5f6a9f16-df15-4f7d-b73f-88065caf23e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082916909-172.17.0.14-1598447196250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34127,DS-b651fdcf-f57b-40f5-a786-cd2f59237e41,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-28873e7a-45fa-4483-b8dd-fdf947caa9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-b028af38-146e-4a46-885e-c1d0fbeea17d,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-f3d9098d-2e45-4e91-a6a0-583639bc5aba,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-bfc43661-1a3b-4da9-9359-89659e46d09b,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-f14e8386-567e-4bec-b519-b6458bc5be8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-be0b4b02-ade4-4a90-84e0-e3a7c049daf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-b43a1587-bf68-44e8-8f87-a70d8b84c394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082916909-172.17.0.14-1598447196250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34127,DS-b651fdcf-f57b-40f5-a786-cd2f59237e41,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-28873e7a-45fa-4483-b8dd-fdf947caa9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-b028af38-146e-4a46-885e-c1d0fbeea17d,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-f3d9098d-2e45-4e91-a6a0-583639bc5aba,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-bfc43661-1a3b-4da9-9359-89659e46d09b,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-f14e8386-567e-4bec-b519-b6458bc5be8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-be0b4b02-ade4-4a90-84e0-e3a7c049daf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-b43a1587-bf68-44e8-8f87-a70d8b84c394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422122914-172.17.0.14-1598447360627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46883,DS-0a03e117-083d-43d4-bfe8-b007ba8f63dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-32110635-5aec-4142-8fbc-5ce72c0faa71,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-c8218ecd-593e-47c1-ae71-7edd62691dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-e2880a89-7e3b-402e-ae4b-4138d268568e,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-849263cc-07fc-48bd-9fed-038b115c2e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-8ed5322f-ba55-4448-837f-fd3908166b78,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-0eed0ab2-1ce9-4a48-b709-02f5d3f09ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-bb503b84-0a40-4c4e-9df9-af8e116cbf97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422122914-172.17.0.14-1598447360627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46883,DS-0a03e117-083d-43d4-bfe8-b007ba8f63dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-32110635-5aec-4142-8fbc-5ce72c0faa71,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-c8218ecd-593e-47c1-ae71-7edd62691dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-e2880a89-7e3b-402e-ae4b-4138d268568e,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-849263cc-07fc-48bd-9fed-038b115c2e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-8ed5322f-ba55-4448-837f-fd3908166b78,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-0eed0ab2-1ce9-4a48-b709-02f5d3f09ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-bb503b84-0a40-4c4e-9df9-af8e116cbf97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798105128-172.17.0.14-1598447575832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40208,DS-6b1d7d80-dfe8-423b-8e41-e9780fd045aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-7bbe0be5-fffe-42e6-8107-4f97fce2075b,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-ec8f5f08-245b-4c9a-9a87-7cffcc3cc5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-c51309a0-a0ed-4c82-9e2f-d0eae6adccbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-fc790b3b-7456-4bea-8a42-edb5ff0e046a,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-f8a1d98b-c816-4345-ba28-7bd5151bb7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-fdb4d697-2762-4598-ac9a-4e4b9f6180a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-f55124f9-92e6-4146-9ea2-b69ab9ad05ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798105128-172.17.0.14-1598447575832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40208,DS-6b1d7d80-dfe8-423b-8e41-e9780fd045aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-7bbe0be5-fffe-42e6-8107-4f97fce2075b,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-ec8f5f08-245b-4c9a-9a87-7cffcc3cc5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-c51309a0-a0ed-4c82-9e2f-d0eae6adccbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-fc790b3b-7456-4bea-8a42-edb5ff0e046a,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-f8a1d98b-c816-4345-ba28-7bd5151bb7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-fdb4d697-2762-4598-ac9a-4e4b9f6180a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-f55124f9-92e6-4146-9ea2-b69ab9ad05ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044771762-172.17.0.14-1598447670832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-707ea208-212a-4733-ab56-2252effd23ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-ab4573d6-b260-4275-8f88-8ee358dd12a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-b6bbac4f-d7a3-4757-8159-030dd4c7a662,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-10a72ac6-be3e-40d9-a282-5dc6eab59912,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-e0bdd208-c7bd-4479-b25e-310dff5bebcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-0200dbd7-699f-474b-a0e5-0ecb20805ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-c460ae8f-4394-4030-ac8b-3ed6c4c26a89,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-58ccdc5d-ab3c-4583-b6fb-f1e024d5c2e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044771762-172.17.0.14-1598447670832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-707ea208-212a-4733-ab56-2252effd23ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-ab4573d6-b260-4275-8f88-8ee358dd12a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-b6bbac4f-d7a3-4757-8159-030dd4c7a662,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-10a72ac6-be3e-40d9-a282-5dc6eab59912,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-e0bdd208-c7bd-4479-b25e-310dff5bebcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-0200dbd7-699f-474b-a0e5-0ecb20805ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-c460ae8f-4394-4030-ac8b-3ed6c4c26a89,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-58ccdc5d-ab3c-4583-b6fb-f1e024d5c2e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307973433-172.17.0.14-1598447694560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41273,DS-8b1eb9cc-f1d2-4522-82d2-2e11f969140c,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-bf5fd90f-a8e2-4e84-bd0b-516bb954f26b,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-fb4b654a-8f1a-40d1-8869-9098f694819c,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-0ed18ef9-8117-4d49-857c-d47926749d23,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-6eadf2aa-4ceb-4921-81bf-23f07c951ade,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-407d27b1-a8b9-40cc-9ac6-11d34b45ef0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-0dca4b3f-049c-43d3-95e6-c92e2b9fecf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-32498e72-de2f-4bc3-b459-fb80cbcf3fd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307973433-172.17.0.14-1598447694560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41273,DS-8b1eb9cc-f1d2-4522-82d2-2e11f969140c,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-bf5fd90f-a8e2-4e84-bd0b-516bb954f26b,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-fb4b654a-8f1a-40d1-8869-9098f694819c,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-0ed18ef9-8117-4d49-857c-d47926749d23,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-6eadf2aa-4ceb-4921-81bf-23f07c951ade,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-407d27b1-a8b9-40cc-9ac6-11d34b45ef0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-0dca4b3f-049c-43d3-95e6-c92e2b9fecf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-32498e72-de2f-4bc3-b459-fb80cbcf3fd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377425316-172.17.0.14-1598447722600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38719,DS-4072dbba-994c-47eb-8465-bd5a055cabf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-de108c0f-0ac2-4da2-8e51-293c170236ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-5ad81419-a5cd-4a46-ac41-50dea1baec3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-4cdb27c3-56fb-4750-9d90-64061eb6f1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-3fb94923-43aa-43ed-90f3-2fa4f6cc65a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-b87ad425-6466-4865-9446-c7cc805e6d65,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-98dc1174-a20b-4c53-810d-9289278c7eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-df5d5df8-b1fd-40a9-b625-94c8077fd260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377425316-172.17.0.14-1598447722600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38719,DS-4072dbba-994c-47eb-8465-bd5a055cabf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-de108c0f-0ac2-4da2-8e51-293c170236ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-5ad81419-a5cd-4a46-ac41-50dea1baec3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-4cdb27c3-56fb-4750-9d90-64061eb6f1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-3fb94923-43aa-43ed-90f3-2fa4f6cc65a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-b87ad425-6466-4865-9446-c7cc805e6d65,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-98dc1174-a20b-4c53-810d-9289278c7eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-df5d5df8-b1fd-40a9-b625-94c8077fd260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 4714
