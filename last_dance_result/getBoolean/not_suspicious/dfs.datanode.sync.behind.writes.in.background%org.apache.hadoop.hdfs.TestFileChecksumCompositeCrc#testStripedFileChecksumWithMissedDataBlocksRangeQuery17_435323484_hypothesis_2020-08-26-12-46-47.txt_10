reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483393185-172.17.0.6-1598446366020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42166,DS-11345cf4-7f16-45ef-a9a5-b9b531f014d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-366c22c5-9e21-47de-85e1-52d7400b95e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-ae8317be-3247-4535-b480-657745efbdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-d075dffd-39f0-46aa-91c6-238d16f95796,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-c5061843-3205-42d4-b073-4d6ccf9718f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-6f87d6c5-963d-4966-93fe-819c265688b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-94abfb1a-3a44-436e-a4d8-80e36e23fe15,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-5735d9bd-5873-4873-a4af-fdddf080bc6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483393185-172.17.0.6-1598446366020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42166,DS-11345cf4-7f16-45ef-a9a5-b9b531f014d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-366c22c5-9e21-47de-85e1-52d7400b95e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-ae8317be-3247-4535-b480-657745efbdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-d075dffd-39f0-46aa-91c6-238d16f95796,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-c5061843-3205-42d4-b073-4d6ccf9718f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-6f87d6c5-963d-4966-93fe-819c265688b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-94abfb1a-3a44-436e-a4d8-80e36e23fe15,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-5735d9bd-5873-4873-a4af-fdddf080bc6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571650768-172.17.0.6-1598446696842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34282,DS-0180a45d-bff7-4260-9f72-5825bafb8852,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-7c5a75c3-26f4-454b-aa29-ea01c887ac23,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-266b8a75-1177-48b0-8050-38da42e1cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-f5f897dd-e7be-4d33-bfc5-d6fd92ec3035,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-09494867-1588-4254-b9dd-7458a2c96dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-843712f3-3b35-4aa8-9a4d-125e3e799133,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-86811abb-5791-42cc-84ac-6f77db30d4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-64e92a89-ff55-4c59-9d4e-620adb80bbeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571650768-172.17.0.6-1598446696842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34282,DS-0180a45d-bff7-4260-9f72-5825bafb8852,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-7c5a75c3-26f4-454b-aa29-ea01c887ac23,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-266b8a75-1177-48b0-8050-38da42e1cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-f5f897dd-e7be-4d33-bfc5-d6fd92ec3035,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-09494867-1588-4254-b9dd-7458a2c96dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-843712f3-3b35-4aa8-9a4d-125e3e799133,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-86811abb-5791-42cc-84ac-6f77db30d4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-64e92a89-ff55-4c59-9d4e-620adb80bbeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738317726-172.17.0.6-1598446906759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43084,DS-fad5f772-9817-4778-822f-6cf49b1f0d62,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-7cd5a3c5-e803-4618-9cd3-8bd4e3fe0420,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-cd66d5f2-792d-403f-9221-7671622fa0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-1c7f37cf-c7ac-4f94-b3b5-f6926b0df444,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-97136a6e-b809-40cc-8619-cdd48a325370,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-dbb20e7e-fa5b-4126-8575-6c76b6748060,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-806c7ef8-745b-4204-a022-9df7cea4d793,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-83dca15d-2671-4c63-88dd-f8f72d64a5d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738317726-172.17.0.6-1598446906759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43084,DS-fad5f772-9817-4778-822f-6cf49b1f0d62,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-7cd5a3c5-e803-4618-9cd3-8bd4e3fe0420,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-cd66d5f2-792d-403f-9221-7671622fa0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-1c7f37cf-c7ac-4f94-b3b5-f6926b0df444,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-97136a6e-b809-40cc-8619-cdd48a325370,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-dbb20e7e-fa5b-4126-8575-6c76b6748060,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-806c7ef8-745b-4204-a022-9df7cea4d793,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-83dca15d-2671-4c63-88dd-f8f72d64a5d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-896300340-172.17.0.6-1598446937326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41780,DS-c1ca14c5-6495-4998-8e0d-176dda6c04e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-47cbf0bf-8b42-4038-8253-8d27fdf648bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-2f7233f5-756d-4be4-bfb3-51d52f4ee276,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-181b05f7-ea39-446c-aed3-68e1ad2e0005,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-536d462d-a67a-4831-880d-69fa4db283b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-43c552d0-8c48-41d4-a3ae-b946b3250997,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-a832d1f3-692a-4956-adc8-f4193d09623f,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-7c5e77bb-e875-45c1-8d6f-22c2d7a10462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-896300340-172.17.0.6-1598446937326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41780,DS-c1ca14c5-6495-4998-8e0d-176dda6c04e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-47cbf0bf-8b42-4038-8253-8d27fdf648bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-2f7233f5-756d-4be4-bfb3-51d52f4ee276,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-181b05f7-ea39-446c-aed3-68e1ad2e0005,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-536d462d-a67a-4831-880d-69fa4db283b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-43c552d0-8c48-41d4-a3ae-b946b3250997,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-a832d1f3-692a-4956-adc8-f4193d09623f,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-7c5e77bb-e875-45c1-8d6f-22c2d7a10462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-523934585-172.17.0.6-1598447015637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43767,DS-ac8723c9-a220-4b33-bbad-a55eb2e653fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-0ad8aa4f-69a2-411c-a626-b8e00c019d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-02974fb2-28f4-49ba-8814-d7b6506165b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-e2e4f597-540c-4938-8f7a-aac3182d5eea,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-f7b8d087-0f80-4264-96f5-8c9e82cdd642,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-d876745e-b034-4bad-a288-76416cf5953c,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-aad6e40a-7b13-4950-8968-68d104608e71,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-7f92b250-fed7-458b-9175-51548e4724ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-523934585-172.17.0.6-1598447015637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43767,DS-ac8723c9-a220-4b33-bbad-a55eb2e653fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-0ad8aa4f-69a2-411c-a626-b8e00c019d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-02974fb2-28f4-49ba-8814-d7b6506165b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-e2e4f597-540c-4938-8f7a-aac3182d5eea,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-f7b8d087-0f80-4264-96f5-8c9e82cdd642,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-d876745e-b034-4bad-a288-76416cf5953c,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-aad6e40a-7b13-4950-8968-68d104608e71,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-7f92b250-fed7-458b-9175-51548e4724ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668262170-172.17.0.6-1598447560996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33899,DS-40885350-d50d-4695-aa39-4f76795ac9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-482ad437-16a8-4804-99b9-3bbd2cbf0647,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-3eaa8eaf-5ffc-4efb-983e-3657ebc653e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-e88135d5-62de-4c77-ac1f-2ac519f5ca73,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-812a6133-222a-4fe8-b25f-1a7e42ab5935,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-b362afc9-668f-405e-9c3d-1c613fd2abe8,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-2adca658-6fd4-426d-92d7-9293c5853fac,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-7a468492-918d-4ae0-a72c-2711eaaaf71d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668262170-172.17.0.6-1598447560996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33899,DS-40885350-d50d-4695-aa39-4f76795ac9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-482ad437-16a8-4804-99b9-3bbd2cbf0647,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-3eaa8eaf-5ffc-4efb-983e-3657ebc653e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-e88135d5-62de-4c77-ac1f-2ac519f5ca73,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-812a6133-222a-4fe8-b25f-1a7e42ab5935,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-b362afc9-668f-405e-9c3d-1c613fd2abe8,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-2adca658-6fd4-426d-92d7-9293c5853fac,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-7a468492-918d-4ae0-a72c-2711eaaaf71d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708105367-172.17.0.6-1598447677251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38466,DS-9eb7f2fa-9561-40cd-9d10-bff5f3903b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-4fcd6de3-6d0b-42a1-9951-a815666493c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-f6282c52-ebea-41ec-9631-ab302c7b706e,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-12d3d99b-6730-4d0d-91b8-c6e345afdbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-a89c0b2c-7f45-4129-b21b-8ec3f84e325c,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-60778ea8-e5a9-488e-85d2-8a3b40283efc,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-1f8bad20-c84b-43d6-a01f-b694ab9d36a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-43e8f339-3218-4309-a4b3-93556dc4128e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1708105367-172.17.0.6-1598447677251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38466,DS-9eb7f2fa-9561-40cd-9d10-bff5f3903b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-4fcd6de3-6d0b-42a1-9951-a815666493c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-f6282c52-ebea-41ec-9631-ab302c7b706e,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-12d3d99b-6730-4d0d-91b8-c6e345afdbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-a89c0b2c-7f45-4129-b21b-8ec3f84e325c,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-60778ea8-e5a9-488e-85d2-8a3b40283efc,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-1f8bad20-c84b-43d6-a01f-b694ab9d36a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-43e8f339-3218-4309-a4b3-93556dc4128e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-509503609-172.17.0.6-1598447786462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40965,DS-169e8d6a-f068-4c12-89e6-05efc4060865,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-88187fb4-8395-47b1-89fe-113aad0f6a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-a94eeabb-5269-424e-8ab8-dec7224725bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-3bb3fb88-1238-450d-9562-c56011279e11,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-0650f1fb-0045-4e74-83f2-2d9cea1b806e,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-10299c84-1fbb-47a4-ab28-38630563a723,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-54bdc9d2-239a-489c-a60d-2593120ef588,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-84696392-b1b3-4a6c-81cd-dfbc3f1b7c67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-509503609-172.17.0.6-1598447786462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40965,DS-169e8d6a-f068-4c12-89e6-05efc4060865,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-88187fb4-8395-47b1-89fe-113aad0f6a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-a94eeabb-5269-424e-8ab8-dec7224725bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-3bb3fb88-1238-450d-9562-c56011279e11,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-0650f1fb-0045-4e74-83f2-2d9cea1b806e,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-10299c84-1fbb-47a4-ab28-38630563a723,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-54bdc9d2-239a-489c-a60d-2593120ef588,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-84696392-b1b3-4a6c-81cd-dfbc3f1b7c67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788830042-172.17.0.6-1598448101654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-9bcee5de-6df6-44b7-907c-f6dba7e26e46,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-65742904-ea44-4b48-9c8e-7145d39cc2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-0df55f19-4ab8-46b8-8c7d-aef247830cec,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-99cdda35-197f-44e4-885b-a5edc0b745cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-641ad338-bf06-4ac5-9222-40b1d2721a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-2a42e6b1-fd21-4dd4-bb78-11fc1874a39b,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-79721c2c-2351-43c6-9bae-051178f1eeec,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-bca6b2aa-717f-42bb-8a36-0b80ac1a149e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788830042-172.17.0.6-1598448101654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-9bcee5de-6df6-44b7-907c-f6dba7e26e46,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-65742904-ea44-4b48-9c8e-7145d39cc2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-0df55f19-4ab8-46b8-8c7d-aef247830cec,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-99cdda35-197f-44e4-885b-a5edc0b745cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-641ad338-bf06-4ac5-9222-40b1d2721a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-2a42e6b1-fd21-4dd4-bb78-11fc1874a39b,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-79721c2c-2351-43c6-9bae-051178f1eeec,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-bca6b2aa-717f-42bb-8a36-0b80ac1a149e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063600588-172.17.0.6-1598448313830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38982,DS-8dfdc079-211b-46d6-94ea-e7ae9d590700,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-15cdfe97-e81e-4ea1-9d29-d89fb3d999e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-1acf2c04-0c25-4dc7-b3ba-83c10a63edf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-8082a63b-abe6-4067-9133-f9c59f0512c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-76f68b21-1b54-417a-b8b7-00211a12eb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-0f8b2c48-8fc9-435e-81cf-07665ce8ed21,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-0b8f1dbb-48e1-49f8-88b2-de468c31438a,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-3ab6df2d-3adb-460d-bd3e-d039decd74d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063600588-172.17.0.6-1598448313830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38982,DS-8dfdc079-211b-46d6-94ea-e7ae9d590700,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-15cdfe97-e81e-4ea1-9d29-d89fb3d999e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-1acf2c04-0c25-4dc7-b3ba-83c10a63edf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-8082a63b-abe6-4067-9133-f9c59f0512c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-76f68b21-1b54-417a-b8b7-00211a12eb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-0f8b2c48-8fc9-435e-81cf-07665ce8ed21,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-0b8f1dbb-48e1-49f8-88b2-de468c31438a,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-3ab6df2d-3adb-460d-bd3e-d039decd74d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1381432247-172.17.0.6-1598448620853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33495,DS-aace0532-9a5f-49f2-be8c-6ee783eb61ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-1038e865-a5bd-445f-93b7-3e2d1942dd10,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-5cccc9fb-1fea-464c-94fb-6a62169ffd31,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-b9551025-754c-4186-9a88-191ff7be6556,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-8de824e4-eabe-4406-9ccc-6d646e81690b,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-d32d0888-bd64-4b56-b242-6354f59ee8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-dd396341-c274-4d2a-a052-ff7ed7429b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-7c6cde75-9d45-4638-8241-e12f0fc23f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1381432247-172.17.0.6-1598448620853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33495,DS-aace0532-9a5f-49f2-be8c-6ee783eb61ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-1038e865-a5bd-445f-93b7-3e2d1942dd10,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-5cccc9fb-1fea-464c-94fb-6a62169ffd31,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-b9551025-754c-4186-9a88-191ff7be6556,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-8de824e4-eabe-4406-9ccc-6d646e81690b,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-d32d0888-bd64-4b56-b242-6354f59ee8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-dd396341-c274-4d2a-a052-ff7ed7429b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-7c6cde75-9d45-4638-8241-e12f0fc23f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-659517544-172.17.0.6-1598449040654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45376,DS-4a3aff66-2fa1-4621-a9a5-dcd49f45b2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-6cb28f73-4581-4dbe-bc55-4661a2e0cf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-45b4e567-9914-4a6e-8497-d35d828874d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-8d748f36-17c3-4f62-8a20-13586cc8afd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-f73ead01-7ce1-498e-8234-86ae5b876257,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-f23d08c3-4850-4433-aed2-d122e24389cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-e070cd3b-a6b9-45d0-b849-edefa3603a52,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-b4a34718-4efa-43f1-8ddb-0d974aae3061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-659517544-172.17.0.6-1598449040654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45376,DS-4a3aff66-2fa1-4621-a9a5-dcd49f45b2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-6cb28f73-4581-4dbe-bc55-4661a2e0cf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-45b4e567-9914-4a6e-8497-d35d828874d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-8d748f36-17c3-4f62-8a20-13586cc8afd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-f73ead01-7ce1-498e-8234-86ae5b876257,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-f23d08c3-4850-4433-aed2-d122e24389cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-e070cd3b-a6b9-45d0-b849-edefa3603a52,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-b4a34718-4efa-43f1-8ddb-0d974aae3061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817197345-172.17.0.6-1598449154018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35139,DS-9a448195-01fc-4256-925e-cf716999df26,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-b034f9fb-5a94-4fc0-942f-cf2831f6e56c,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-1809f83b-4e0b-44fb-948d-b179b135a69c,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-74e4693c-8de7-4fe6-a240-c84f50bf763c,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-4126ecbf-6c3a-447d-b97f-37c8f4a6f759,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-37a986a3-cee0-4ab7-8b7a-4e13ded3a4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-b6c8520e-b9b2-4959-8c8d-ce49a67b11e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-c4b1e09c-115a-4c87-81d0-b86397e1087a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817197345-172.17.0.6-1598449154018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35139,DS-9a448195-01fc-4256-925e-cf716999df26,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-b034f9fb-5a94-4fc0-942f-cf2831f6e56c,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-1809f83b-4e0b-44fb-948d-b179b135a69c,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-74e4693c-8de7-4fe6-a240-c84f50bf763c,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-4126ecbf-6c3a-447d-b97f-37c8f4a6f759,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-37a986a3-cee0-4ab7-8b7a-4e13ded3a4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-b6c8520e-b9b2-4959-8c8d-ce49a67b11e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-c4b1e09c-115a-4c87-81d0-b86397e1087a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1653688628-172.17.0.6-1598449851167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39512,DS-028d1024-6849-42c8-a778-23deb8415f66,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-41da4264-317c-4ba6-838b-a45d410388a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-986eec3d-04e4-4671-9199-3bcc18661f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-bd62a920-3fb0-4744-9827-18c871d0b68f,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-8b6ef684-ec71-4026-a2a0-3819dfb7719b,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-f1b64d20-e0cf-44ff-9d83-e4683cb832b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-4a29fbd1-000f-4ac9-a5a4-f6a80de26e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-c71b6d61-5a22-4f5d-bfad-a0d7b673c41f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1653688628-172.17.0.6-1598449851167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39512,DS-028d1024-6849-42c8-a778-23deb8415f66,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-41da4264-317c-4ba6-838b-a45d410388a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-986eec3d-04e4-4671-9199-3bcc18661f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-bd62a920-3fb0-4744-9827-18c871d0b68f,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-8b6ef684-ec71-4026-a2a0-3819dfb7719b,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-f1b64d20-e0cf-44ff-9d83-e4683cb832b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-4a29fbd1-000f-4ac9-a5a4-f6a80de26e69,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-c71b6d61-5a22-4f5d-bfad-a0d7b673c41f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638530196-172.17.0.6-1598450191579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41724,DS-a1039334-3d91-45d0-a114-728e97a291b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-08f07c74-47cc-40eb-bd8d-a50b125523ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-9188423e-d9d0-4dcf-b912-840669e013d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-0feedc1a-9cea-4a12-8a1d-a1718c64567d,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-9a91c86c-60af-4828-94ad-82f5f9df9a19,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-9b4889e2-0a15-4123-9816-4f00e4ad4bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-aa1469c7-38f0-41ee-b711-436f8c250a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-054b97db-af2a-48ff-91db-57a870263034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638530196-172.17.0.6-1598450191579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41724,DS-a1039334-3d91-45d0-a114-728e97a291b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-08f07c74-47cc-40eb-bd8d-a50b125523ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-9188423e-d9d0-4dcf-b912-840669e013d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-0feedc1a-9cea-4a12-8a1d-a1718c64567d,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-9a91c86c-60af-4828-94ad-82f5f9df9a19,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-9b4889e2-0a15-4123-9816-4f00e4ad4bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-aa1469c7-38f0-41ee-b711-436f8c250a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-054b97db-af2a-48ff-91db-57a870263034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409041433-172.17.0.6-1598450726278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39238,DS-569d4386-9cfe-42dc-b775-92f8d9af0249,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-7dbbccc0-95cf-45f0-b118-e972caa00e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-69628e3a-d971-4310-b3c8-904effc936d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-4301f8c4-0c4e-45bd-8e1a-3cbf8a4ae379,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-8def8546-ce37-4ccc-a22c-353a08861a45,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-a27cbbbb-4c5e-43cb-b298-807c70182854,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-517ee782-771d-41cb-bb02-dea229bc33ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-0e50ddf4-36c2-4125-a2cf-8677ac1d30b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409041433-172.17.0.6-1598450726278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39238,DS-569d4386-9cfe-42dc-b775-92f8d9af0249,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-7dbbccc0-95cf-45f0-b118-e972caa00e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-69628e3a-d971-4310-b3c8-904effc936d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-4301f8c4-0c4e-45bd-8e1a-3cbf8a4ae379,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-8def8546-ce37-4ccc-a22c-353a08861a45,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-a27cbbbb-4c5e-43cb-b298-807c70182854,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-517ee782-771d-41cb-bb02-dea229bc33ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-0e50ddf4-36c2-4125-a2cf-8677ac1d30b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806080739-172.17.0.6-1598450951858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32930,DS-66fd61f0-c6a5-4a7b-b511-111f10065b03,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-fea03447-6e85-4858-b131-fc042936679a,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-0cb5a8ce-979c-4450-b81b-176f28260d37,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-9cd76fd5-0389-4d36-b6d8-7ef2180924f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-8672e41d-11c7-4b41-b72a-fdcb9ffc2557,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-7b555409-a4b6-4dda-bba8-2fb0b5d0452c,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-06b030c0-113a-4850-982b-60073e2da4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-0fc8cf5c-9ec9-4072-9c20-ef6e5f0cc54f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806080739-172.17.0.6-1598450951858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32930,DS-66fd61f0-c6a5-4a7b-b511-111f10065b03,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-fea03447-6e85-4858-b131-fc042936679a,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-0cb5a8ce-979c-4450-b81b-176f28260d37,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-9cd76fd5-0389-4d36-b6d8-7ef2180924f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-8672e41d-11c7-4b41-b72a-fdcb9ffc2557,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-7b555409-a4b6-4dda-bba8-2fb0b5d0452c,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-06b030c0-113a-4850-982b-60073e2da4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-0fc8cf5c-9ec9-4072-9c20-ef6e5f0cc54f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 4994
