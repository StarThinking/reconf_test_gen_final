reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669801270-172.17.0.12-1598188267588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37010,DS-811617ea-5113-4421-9d19-73035bd091b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-d0c19ceb-ad8d-48c6-8ffc-d255244fb7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-5709f015-de41-4941-b9d1-92dc4a0b8cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-0d487c07-99a8-4ec2-96e9-7a232b79cbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-57f01e2f-ba30-49bb-b40d-c09bc7106c84,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-9316ce03-5963-4e24-97e3-39f56353b845,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-db7102e1-fb28-4537-822a-fd0473450c07,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-2ee9a274-4b1c-455a-8615-2de843ee31a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669801270-172.17.0.12-1598188267588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37010,DS-811617ea-5113-4421-9d19-73035bd091b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-d0c19ceb-ad8d-48c6-8ffc-d255244fb7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-5709f015-de41-4941-b9d1-92dc4a0b8cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-0d487c07-99a8-4ec2-96e9-7a232b79cbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-57f01e2f-ba30-49bb-b40d-c09bc7106c84,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-9316ce03-5963-4e24-97e3-39f56353b845,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-db7102e1-fb28-4537-822a-fd0473450c07,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-2ee9a274-4b1c-455a-8615-2de843ee31a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735012881-172.17.0.12-1598188646886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36210,DS-17aed106-06d7-42a0-97d7-a01190afbf53,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-388d04c5-e4d8-49d2-8234-175147474688,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-fbb3ff44-f1c1-44ee-8793-36a7aed80056,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-fbb36d32-579f-43d9-aa71-50e40031681e,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-5dc0e306-6642-46c2-ab6f-6ed6024e61c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-60ad4516-6b40-47a0-a3e5-3b79ce6649da,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-73d1ba20-c87d-4a21-8906-9a87d163bb65,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-4ab2f970-55ef-4287-8a82-a1ca3870c67c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735012881-172.17.0.12-1598188646886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36210,DS-17aed106-06d7-42a0-97d7-a01190afbf53,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-388d04c5-e4d8-49d2-8234-175147474688,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-fbb3ff44-f1c1-44ee-8793-36a7aed80056,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-fbb36d32-579f-43d9-aa71-50e40031681e,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-5dc0e306-6642-46c2-ab6f-6ed6024e61c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-60ad4516-6b40-47a0-a3e5-3b79ce6649da,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-73d1ba20-c87d-4a21-8906-9a87d163bb65,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-4ab2f970-55ef-4287-8a82-a1ca3870c67c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579353403-172.17.0.12-1598188983317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42206,DS-a0c93544-8736-4e25-a67f-bc291167617e,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-4e47fd41-10e2-42d2-806a-c381d160c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-51e103dd-a609-4544-9c0f-de10ec7accc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-1aaabfb0-d2d8-482b-be5c-c946bf84cf77,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-57739234-02fb-4bb2-afdc-d9afd965881e,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-08a06941-6917-4cd0-bb3b-9f56fc06f100,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-a63b5c48-04ba-4d90-ba1a-9fcd88d49b63,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-464ccb45-c3b5-4b33-89e7-0b9e9108ecac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579353403-172.17.0.12-1598188983317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42206,DS-a0c93544-8736-4e25-a67f-bc291167617e,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-4e47fd41-10e2-42d2-806a-c381d160c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-51e103dd-a609-4544-9c0f-de10ec7accc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-1aaabfb0-d2d8-482b-be5c-c946bf84cf77,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-57739234-02fb-4bb2-afdc-d9afd965881e,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-08a06941-6917-4cd0-bb3b-9f56fc06f100,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-a63b5c48-04ba-4d90-ba1a-9fcd88d49b63,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-464ccb45-c3b5-4b33-89e7-0b9e9108ecac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988871636-172.17.0.12-1598189040098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38580,DS-62bcf66e-c50d-4254-889e-1517442eeb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-6b5055c0-58f3-451b-a9f7-0b4c817eb61a,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-2df1da4b-3025-43b9-b452-a06ce4d2bf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-ce7f4459-618a-4065-a721-e0f2fd5bfab4,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-273e18a1-cc65-48f9-afd1-791b08cc9584,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-760329f4-992c-4e96-8979-741fcc8a5c19,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-50e4ef0f-93fe-46c2-878b-bd9f1ff6b949,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-a94eaf7b-40e8-449a-83b9-9fdde54e16f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988871636-172.17.0.12-1598189040098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38580,DS-62bcf66e-c50d-4254-889e-1517442eeb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-6b5055c0-58f3-451b-a9f7-0b4c817eb61a,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-2df1da4b-3025-43b9-b452-a06ce4d2bf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-ce7f4459-618a-4065-a721-e0f2fd5bfab4,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-273e18a1-cc65-48f9-afd1-791b08cc9584,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-760329f4-992c-4e96-8979-741fcc8a5c19,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-50e4ef0f-93fe-46c2-878b-bd9f1ff6b949,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-a94eaf7b-40e8-449a-83b9-9fdde54e16f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241824311-172.17.0.12-1598189139372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38592,DS-4082525a-3c0a-4701-b708-404def89fa54,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-c954547b-f2dd-4f28-afab-7ab82b4d46a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-34858d4c-7088-4509-adf9-2f843c09b7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-431442ec-0fad-4514-b48a-ebab11e9e0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-7dc19a73-0304-4bc9-9b08-ccac1ba5562f,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-bc880f66-a053-4f2d-adda-f9246c03d19e,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-1650c85d-43aa-4e25-981f-9accdfc5649d,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-ea395d21-0938-4d04-8fdf-c66109ff3b35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241824311-172.17.0.12-1598189139372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38592,DS-4082525a-3c0a-4701-b708-404def89fa54,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-c954547b-f2dd-4f28-afab-7ab82b4d46a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-34858d4c-7088-4509-adf9-2f843c09b7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-431442ec-0fad-4514-b48a-ebab11e9e0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-7dc19a73-0304-4bc9-9b08-ccac1ba5562f,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-bc880f66-a053-4f2d-adda-f9246c03d19e,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-1650c85d-43aa-4e25-981f-9accdfc5649d,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-ea395d21-0938-4d04-8fdf-c66109ff3b35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319696683-172.17.0.12-1598189367280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45242,DS-157b7929-fe8b-454d-ab28-efc418197726,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-786331ae-b64f-4f8b-b49f-0b094487c744,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-f59b33c4-4068-41f9-a858-a37e61105ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-d0950ad4-51d5-4f07-8f86-b87b8f78b1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-d5af7470-1d98-4ae1-8aa6-ad8f68537cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-deb38e68-cabb-44f2-b313-f940ef6c73e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-966eccc0-3484-4185-896e-fa65aa72406c,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-fbdd60d2-9140-419b-b7d8-ae208edd8d99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319696683-172.17.0.12-1598189367280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45242,DS-157b7929-fe8b-454d-ab28-efc418197726,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-786331ae-b64f-4f8b-b49f-0b094487c744,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-f59b33c4-4068-41f9-a858-a37e61105ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-d0950ad4-51d5-4f07-8f86-b87b8f78b1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-d5af7470-1d98-4ae1-8aa6-ad8f68537cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-deb38e68-cabb-44f2-b313-f940ef6c73e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-966eccc0-3484-4185-896e-fa65aa72406c,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-fbdd60d2-9140-419b-b7d8-ae208edd8d99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247703971-172.17.0.12-1598189509101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39252,DS-e61c2779-cf33-4155-b924-6b9fc0721ece,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-96c9cf64-7106-4a4c-a5ab-e02d966bcb97,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-c58d9f7c-b0d0-4aff-8e2c-79295c0ecbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-0c599e81-4657-4029-8e79-f0d9eebfc26c,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-a8a5afd7-1183-43de-b488-c0484615ce34,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-aa88b1d8-67c1-4268-af50-eaeb43a33266,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-5501eb4f-4702-445b-988f-d913bf151363,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-0def867a-c8b3-47b3-9f3f-1c762adedce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247703971-172.17.0.12-1598189509101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39252,DS-e61c2779-cf33-4155-b924-6b9fc0721ece,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-96c9cf64-7106-4a4c-a5ab-e02d966bcb97,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-c58d9f7c-b0d0-4aff-8e2c-79295c0ecbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-0c599e81-4657-4029-8e79-f0d9eebfc26c,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-a8a5afd7-1183-43de-b488-c0484615ce34,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-aa88b1d8-67c1-4268-af50-eaeb43a33266,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-5501eb4f-4702-445b-988f-d913bf151363,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-0def867a-c8b3-47b3-9f3f-1c762adedce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91680333-172.17.0.12-1598189557609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45459,DS-9112d617-509d-435a-be77-1a716fb69c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-68f4452e-0f16-432e-a60b-0f59566cf3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-031a641c-dd32-4b52-8c68-cfe02682ad50,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-2483b7a7-6208-450a-82db-83febf05f411,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-325bbb91-5f3b-437a-80c0-fcb4fe7af705,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-6653265b-0f1e-47ee-a597-c9edbc65cffe,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-43d76bc5-3324-420f-b7c0-33615f994180,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-4376fe50-f8bb-49fb-b41b-e9606ee8ddfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91680333-172.17.0.12-1598189557609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45459,DS-9112d617-509d-435a-be77-1a716fb69c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-68f4452e-0f16-432e-a60b-0f59566cf3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-031a641c-dd32-4b52-8c68-cfe02682ad50,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-2483b7a7-6208-450a-82db-83febf05f411,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-325bbb91-5f3b-437a-80c0-fcb4fe7af705,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-6653265b-0f1e-47ee-a597-c9edbc65cffe,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-43d76bc5-3324-420f-b7c0-33615f994180,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-4376fe50-f8bb-49fb-b41b-e9606ee8ddfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608370369-172.17.0.12-1598190017368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34126,DS-c7797abc-d8ad-41d3-8dd1-7ca6901d5b84,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-2a61c898-510c-47ae-bdf4-87ea7948c1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-11e40a39-70de-4ea1-a1e7-8dcd8e60a058,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-62d2e12c-b7b5-4e9e-bc8e-9ce00debcd50,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-db89443d-cfec-4498-935c-0f1b8e3ee2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-01bf3ef1-a015-4157-9192-0f8ee2bedaca,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-ce57d921-0c83-44cc-b7c6-7b70370fdc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-b9aefc98-d6dc-49ba-8599-78517ed1e2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608370369-172.17.0.12-1598190017368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34126,DS-c7797abc-d8ad-41d3-8dd1-7ca6901d5b84,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-2a61c898-510c-47ae-bdf4-87ea7948c1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-11e40a39-70de-4ea1-a1e7-8dcd8e60a058,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-62d2e12c-b7b5-4e9e-bc8e-9ce00debcd50,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-db89443d-cfec-4498-935c-0f1b8e3ee2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-01bf3ef1-a015-4157-9192-0f8ee2bedaca,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-ce57d921-0c83-44cc-b7c6-7b70370fdc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-b9aefc98-d6dc-49ba-8599-78517ed1e2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029472064-172.17.0.12-1598190629978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46618,DS-4933ee4e-1f4b-473c-b55a-f5db2819c9de,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-5620a8ba-4d07-4cb5-9618-cc089a54c82c,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-422bc46b-517b-4f2f-b296-3af5090b464e,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-de67f466-4635-44f6-9697-eb9247c1bbff,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-09bfb07c-fb0b-4ab9-b5ab-7fd4eee597d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-ab46a1ba-1ec7-4f18-b7cc-1c861209b284,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-f394f633-2492-443e-bb66-6b2ada1ccf9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-b0a0c74f-998b-4d20-840c-1e4da9e8c608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029472064-172.17.0.12-1598190629978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46618,DS-4933ee4e-1f4b-473c-b55a-f5db2819c9de,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-5620a8ba-4d07-4cb5-9618-cc089a54c82c,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-422bc46b-517b-4f2f-b296-3af5090b464e,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-de67f466-4635-44f6-9697-eb9247c1bbff,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-09bfb07c-fb0b-4ab9-b5ab-7fd4eee597d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-ab46a1ba-1ec7-4f18-b7cc-1c861209b284,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-f394f633-2492-443e-bb66-6b2ada1ccf9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-b0a0c74f-998b-4d20-840c-1e4da9e8c608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107385625-172.17.0.12-1598190721025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41013,DS-79499bce-e02f-4578-930a-88f03dc4535f,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-2597c63b-8a16-410a-aa89-19295fadf900,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-75d5cedb-272d-43b5-a275-d7ece9cec8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-e7d6b82b-2fb8-445a-969b-92e78c1fceab,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-4671a11d-de79-4e90-b9b9-e72c0465a9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-94f683fa-44b2-4829-b6e2-4402d404201b,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-4ac91eec-c19c-46eb-96fc-ed2642b88a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-b1a9d3b1-814c-46ac-b7b3-0dac91fcbbc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107385625-172.17.0.12-1598190721025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41013,DS-79499bce-e02f-4578-930a-88f03dc4535f,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-2597c63b-8a16-410a-aa89-19295fadf900,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-75d5cedb-272d-43b5-a275-d7ece9cec8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-e7d6b82b-2fb8-445a-969b-92e78c1fceab,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-4671a11d-de79-4e90-b9b9-e72c0465a9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-94f683fa-44b2-4829-b6e2-4402d404201b,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-4ac91eec-c19c-46eb-96fc-ed2642b88a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-b1a9d3b1-814c-46ac-b7b3-0dac91fcbbc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846121894-172.17.0.12-1598190890985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43755,DS-f8414c9e-48ca-4647-97ab-703284261e48,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-fbe9f477-9092-4e47-945f-7f06887172ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-eb465c34-30e8-46a8-9bf9-066666f9ca9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-3c8c37ed-904c-4134-ac90-1e133da2f006,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-cdb66eed-2a7a-4659-82d2-a744448a9d52,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-bb48cb62-1512-4964-a2dc-5c0698b60acd,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-5bab37d9-8c21-453e-bde4-72ee2733aeba,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-e1f3802e-14c6-4929-9315-26be2c76fe4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846121894-172.17.0.12-1598190890985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43755,DS-f8414c9e-48ca-4647-97ab-703284261e48,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-fbe9f477-9092-4e47-945f-7f06887172ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-eb465c34-30e8-46a8-9bf9-066666f9ca9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-3c8c37ed-904c-4134-ac90-1e133da2f006,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-cdb66eed-2a7a-4659-82d2-a744448a9d52,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-bb48cb62-1512-4964-a2dc-5c0698b60acd,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-5bab37d9-8c21-453e-bde4-72ee2733aeba,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-e1f3802e-14c6-4929-9315-26be2c76fe4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648621278-172.17.0.12-1598191520748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36103,DS-92e767e5-95d5-4062-9d98-0b3a751e40a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-85985408-b6e6-423a-acd8-6e83100cca8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-1a8a06d2-70f4-4d80-9f2e-79949dd8f389,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-5ad603e4-b14a-4f81-8b9a-fcc43d046c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-c403596f-ecfc-4df0-831f-d5c729f91343,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-6566c9cd-d98b-45e7-a748-54241ba62d02,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-0a9413c8-85bc-4968-b7b8-1e9e69ed5e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-6511ec63-8300-4ed7-93fa-853639cc951d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648621278-172.17.0.12-1598191520748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36103,DS-92e767e5-95d5-4062-9d98-0b3a751e40a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-85985408-b6e6-423a-acd8-6e83100cca8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-1a8a06d2-70f4-4d80-9f2e-79949dd8f389,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-5ad603e4-b14a-4f81-8b9a-fcc43d046c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-c403596f-ecfc-4df0-831f-d5c729f91343,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-6566c9cd-d98b-45e7-a748-54241ba62d02,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-0a9413c8-85bc-4968-b7b8-1e9e69ed5e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-6511ec63-8300-4ed7-93fa-853639cc951d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865629665-172.17.0.12-1598191799226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41089,DS-d08b9c1f-82eb-496d-bee4-18826f59794c,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-0f6fdaf7-2d03-4b91-9a8a-e4e6d62658bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-1e12617e-3239-4831-a182-21847fa15f42,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-75a5be5c-998d-4cfa-bde3-5880e6605be6,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-05b05f46-2362-45a1-be8e-e84193db7105,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-4df436e5-9676-4ccb-80ac-613cdff161b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-11c8ea18-15d9-4eff-9303-0a304f980b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-61e6cb9d-8d4a-4e73-b111-379dbd8745b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865629665-172.17.0.12-1598191799226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41089,DS-d08b9c1f-82eb-496d-bee4-18826f59794c,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-0f6fdaf7-2d03-4b91-9a8a-e4e6d62658bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-1e12617e-3239-4831-a182-21847fa15f42,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-75a5be5c-998d-4cfa-bde3-5880e6605be6,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-05b05f46-2362-45a1-be8e-e84193db7105,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-4df436e5-9676-4ccb-80ac-613cdff161b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-11c8ea18-15d9-4eff-9303-0a304f980b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-61e6cb9d-8d4a-4e73-b111-379dbd8745b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606941551-172.17.0.12-1598192318265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35637,DS-a3b2426a-d6b3-4331-9a0c-6eb7982ff582,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-cf7c8602-e740-4735-bb45-a3038311e93b,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-1010f5c1-3b0a-45f8-b2f2-2b53ea895cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-2ec37e7e-aa4a-45b8-ace9-5ff0119f26cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-82cbff75-91de-4d37-9a5a-2d3fc6c9d193,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-fb06b70a-9f92-47d1-9b43-819ce1fd5ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-636ac8ce-3217-4e4e-b69f-c8a92bdb08c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-f5ef88aa-fa44-4be3-a4c3-a238bea7eb6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606941551-172.17.0.12-1598192318265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35637,DS-a3b2426a-d6b3-4331-9a0c-6eb7982ff582,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-cf7c8602-e740-4735-bb45-a3038311e93b,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-1010f5c1-3b0a-45f8-b2f2-2b53ea895cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-2ec37e7e-aa4a-45b8-ace9-5ff0119f26cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-82cbff75-91de-4d37-9a5a-2d3fc6c9d193,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-fb06b70a-9f92-47d1-9b43-819ce1fd5ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-636ac8ce-3217-4e4e-b69f-c8a92bdb08c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-f5ef88aa-fa44-4be3-a4c3-a238bea7eb6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374996815-172.17.0.12-1598192454133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46380,DS-212f00e7-ce4d-482d-9205-33e94825add6,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-73a3b059-6c98-4556-a2dc-2d3b9d58a837,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-aff4f8a7-82c2-41e1-979a-169ac5251f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-fe2f709f-a27f-46df-8410-85d798b4302c,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-78653e70-d72d-40d7-a7e0-f3961bcf24ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-aaa09354-3273-4315-98be-0dc7369817f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-2af91ab9-31af-48ae-b80a-ce02a8894e63,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-f4a06da1-ba07-470a-b4ce-138e475e5fe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374996815-172.17.0.12-1598192454133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46380,DS-212f00e7-ce4d-482d-9205-33e94825add6,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-73a3b059-6c98-4556-a2dc-2d3b9d58a837,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-aff4f8a7-82c2-41e1-979a-169ac5251f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-fe2f709f-a27f-46df-8410-85d798b4302c,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-78653e70-d72d-40d7-a7e0-f3961bcf24ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-aaa09354-3273-4315-98be-0dc7369817f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-2af91ab9-31af-48ae-b80a-ce02a8894e63,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-f4a06da1-ba07-470a-b4ce-138e475e5fe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862091471-172.17.0.12-1598192666554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39666,DS-f2652dc3-82df-4081-81b0-849c77e70080,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-f2a0e9b2-016f-4dbe-a19f-69d70994b50f,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-b61161fb-5f37-4f07-a6a6-e3622a110a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-3913daee-b050-461a-8ad0-249e2e7872f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-dda8ace9-ef26-4c67-85ea-b9f915df3f71,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-92497e4d-1ecc-446a-b610-ae89120c5be9,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-ee25626d-2c4f-40e0-875f-e292ec2a2806,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-e05c9f8f-7c60-4970-bc2d-49eec01d7a34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862091471-172.17.0.12-1598192666554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39666,DS-f2652dc3-82df-4081-81b0-849c77e70080,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-f2a0e9b2-016f-4dbe-a19f-69d70994b50f,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-b61161fb-5f37-4f07-a6a6-e3622a110a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-3913daee-b050-461a-8ad0-249e2e7872f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-dda8ace9-ef26-4c67-85ea-b9f915df3f71,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-92497e4d-1ecc-446a-b610-ae89120c5be9,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-ee25626d-2c4f-40e0-875f-e292ec2a2806,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-e05c9f8f-7c60-4970-bc2d-49eec01d7a34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-468629545-172.17.0.12-1598193792895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37409,DS-ab3fd69d-c25d-4c8b-a3fc-4179d3a76a23,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-babe189e-0679-427c-a074-0c1ac42175f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-c2dd3542-4ab3-4a10-bfa8-63d5952b3473,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-acb45ad3-8f68-4486-aa42-fdf5f74c3392,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-d1614e1a-6dba-4066-8b2b-b9488da9fe92,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-230c67a4-6f98-47cf-afea-f1c56aeb51a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-95cfbf55-1a6d-4e5c-a1d1-aed9a6c602ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-abe0b544-7706-4db7-8abd-95478e6e90cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-468629545-172.17.0.12-1598193792895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37409,DS-ab3fd69d-c25d-4c8b-a3fc-4179d3a76a23,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-babe189e-0679-427c-a074-0c1ac42175f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-c2dd3542-4ab3-4a10-bfa8-63d5952b3473,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-acb45ad3-8f68-4486-aa42-fdf5f74c3392,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-d1614e1a-6dba-4066-8b2b-b9488da9fe92,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-230c67a4-6f98-47cf-afea-f1c56aeb51a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-95cfbf55-1a6d-4e5c-a1d1-aed9a6c602ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-abe0b544-7706-4db7-8abd-95478e6e90cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101504820-172.17.0.12-1598194103053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36747,DS-ae3ca0fb-0161-4db0-9d58-e3fcc5ce7f54,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-7261dcca-0d07-4e9d-8454-635d91b8592a,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-d6c92dc1-3bc4-4e73-9e4f-49f05f77af8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-3b6c236b-08b7-4f80-b57e-b699c2ac409a,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-4613a66e-beed-4fae-b6e4-bedd1b0b9ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-4f0127c0-cf53-4e25-bf9a-59aba48559c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-45a6ee75-14f1-4884-afe7-fa71b132c63b,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-9b993cf9-3090-4d81-a9e8-20b7cce2c592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101504820-172.17.0.12-1598194103053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36747,DS-ae3ca0fb-0161-4db0-9d58-e3fcc5ce7f54,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-7261dcca-0d07-4e9d-8454-635d91b8592a,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-d6c92dc1-3bc4-4e73-9e4f-49f05f77af8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-3b6c236b-08b7-4f80-b57e-b699c2ac409a,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-4613a66e-beed-4fae-b6e4-bedd1b0b9ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-4f0127c0-cf53-4e25-bf9a-59aba48559c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-45a6ee75-14f1-4884-afe7-fa71b132c63b,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-9b993cf9-3090-4d81-a9e8-20b7cce2c592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 6447
