reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528010569-172.17.0.20-1598381699337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36352,DS-ec0de407-4f93-4b32-8deb-c8cfc1399db2,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-de243804-a30c-4f7d-97ba-7319f746a41f,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-224a0a3e-eebc-4144-8b73-dc17fed5dfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-fc8ab571-3afa-4ed4-8ea8-4a0b99a77151,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-dc799372-4781-4b01-802f-002e5a12ddd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-c054e250-70ef-42ba-90eb-53f09aff0d02,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-df3d9ea8-6be1-41b4-a213-15ea27b955da,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-2ab3992c-c70f-4e74-9b84-1498d0939bd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528010569-172.17.0.20-1598381699337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36352,DS-ec0de407-4f93-4b32-8deb-c8cfc1399db2,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-de243804-a30c-4f7d-97ba-7319f746a41f,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-224a0a3e-eebc-4144-8b73-dc17fed5dfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-fc8ab571-3afa-4ed4-8ea8-4a0b99a77151,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-dc799372-4781-4b01-802f-002e5a12ddd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-c054e250-70ef-42ba-90eb-53f09aff0d02,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-df3d9ea8-6be1-41b4-a213-15ea27b955da,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-2ab3992c-c70f-4e74-9b84-1498d0939bd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846083380-172.17.0.20-1598381918984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40132,DS-24105c3e-7204-433f-815d-86fc13bd825c,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-05c291c1-ef1c-4fc8-9875-07443cd9be9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-9ca7a60e-e41d-4e03-a78a-01d0b0ed8899,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-89435c57-755e-4ba8-adea-a08ce206020c,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-3694e50f-0310-49f0-80c7-88c74eadddc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-a3c38a19-9dbd-4336-ab3c-bb7ee9e67dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-7a374bbd-dc04-48d6-8181-bb63be91bcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-3792850f-efff-4969-bca5-d837d740fa8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846083380-172.17.0.20-1598381918984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40132,DS-24105c3e-7204-433f-815d-86fc13bd825c,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-05c291c1-ef1c-4fc8-9875-07443cd9be9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-9ca7a60e-e41d-4e03-a78a-01d0b0ed8899,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-89435c57-755e-4ba8-adea-a08ce206020c,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-3694e50f-0310-49f0-80c7-88c74eadddc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-a3c38a19-9dbd-4336-ab3c-bb7ee9e67dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-7a374bbd-dc04-48d6-8181-bb63be91bcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-3792850f-efff-4969-bca5-d837d740fa8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1622935412-172.17.0.20-1598382158310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41608,DS-8a3b8339-8860-43c1-9ac8-9f3ad7a9d57f,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-0585c588-7572-44fe-bcb9-1eef55345d83,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-68a7311d-edb3-4bda-9c47-7903a8cbb500,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-08e37226-f20e-4bf0-91f3-0d3ecfeec100,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-21ed1ee3-3f20-49fa-9ddd-5c4989d210c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-f2f0dad5-08ac-425a-b35f-73adb5d50842,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-1b278f99-276f-41bc-bfb3-a9778b18d13d,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-ca7e6ab0-9b95-47a7-9fb1-e471328f5e85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1622935412-172.17.0.20-1598382158310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41608,DS-8a3b8339-8860-43c1-9ac8-9f3ad7a9d57f,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-0585c588-7572-44fe-bcb9-1eef55345d83,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-68a7311d-edb3-4bda-9c47-7903a8cbb500,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-08e37226-f20e-4bf0-91f3-0d3ecfeec100,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-21ed1ee3-3f20-49fa-9ddd-5c4989d210c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-f2f0dad5-08ac-425a-b35f-73adb5d50842,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-1b278f99-276f-41bc-bfb3-a9778b18d13d,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-ca7e6ab0-9b95-47a7-9fb1-e471328f5e85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047671249-172.17.0.20-1598382567513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40240,DS-a3d811c2-5ba9-4b22-a4db-6145610d6a86,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-ae0f8ce0-3e2b-47e3-9924-0e0683127e64,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-6c4cb9d3-716b-4912-ad81-811148b3fc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-90d1d950-b95a-4dbd-9aaa-aa7d66dea341,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-07d368c9-56dc-4073-8796-3db6e596bff6,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-479bdf7f-d4cb-483b-9b05-b56fc72ec19c,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-8f7255df-1816-4440-9d17-a92f34222032,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-c3eccfd6-7b96-46c5-b85f-fa4c5af312ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047671249-172.17.0.20-1598382567513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40240,DS-a3d811c2-5ba9-4b22-a4db-6145610d6a86,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-ae0f8ce0-3e2b-47e3-9924-0e0683127e64,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-6c4cb9d3-716b-4912-ad81-811148b3fc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-90d1d950-b95a-4dbd-9aaa-aa7d66dea341,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-07d368c9-56dc-4073-8796-3db6e596bff6,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-479bdf7f-d4cb-483b-9b05-b56fc72ec19c,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-8f7255df-1816-4440-9d17-a92f34222032,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-c3eccfd6-7b96-46c5-b85f-fa4c5af312ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574626101-172.17.0.20-1598382963499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37263,DS-241054e8-316e-4cca-83fe-2c15da591f60,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-2a001d4d-6c20-4f41-a161-f1b01aab5212,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-9cbd866c-d774-4ef0-a20f-3f17f949142e,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-5a4332b6-9c50-4a87-b9fd-1932067e7290,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-4ae86f16-6d98-4545-ba5e-d1e7580103fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-d731580e-6179-4a49-bf1f-ae94dfb93294,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-0f3b128a-37d5-4648-8b9c-4a7dd2c92034,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-b6970c0e-133b-4343-bc93-47d64ab1424a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574626101-172.17.0.20-1598382963499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37263,DS-241054e8-316e-4cca-83fe-2c15da591f60,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-2a001d4d-6c20-4f41-a161-f1b01aab5212,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-9cbd866c-d774-4ef0-a20f-3f17f949142e,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-5a4332b6-9c50-4a87-b9fd-1932067e7290,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-4ae86f16-6d98-4545-ba5e-d1e7580103fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-d731580e-6179-4a49-bf1f-ae94dfb93294,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-0f3b128a-37d5-4648-8b9c-4a7dd2c92034,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-b6970c0e-133b-4343-bc93-47d64ab1424a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453261635-172.17.0.20-1598383241073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43123,DS-bd7bb992-bd70-4d99-8fac-868d42dc8fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-3e0afbf0-0746-4468-a14d-f892b7032410,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-8583fd49-3026-4c67-92cf-2bc728aa8382,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-3d656466-9e85-4182-9a9f-f3205b5c7e21,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-f3e2978d-14b3-4672-9511-a51685260345,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-3f7ffc4e-e0ab-4d3d-9a37-056f6dc7a49c,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-b4569b47-0e7d-4fd7-8909-d01375d276c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-6d64c76e-4e27-4f48-b9d2-08444e8619a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453261635-172.17.0.20-1598383241073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43123,DS-bd7bb992-bd70-4d99-8fac-868d42dc8fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-3e0afbf0-0746-4468-a14d-f892b7032410,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-8583fd49-3026-4c67-92cf-2bc728aa8382,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-3d656466-9e85-4182-9a9f-f3205b5c7e21,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-f3e2978d-14b3-4672-9511-a51685260345,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-3f7ffc4e-e0ab-4d3d-9a37-056f6dc7a49c,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-b4569b47-0e7d-4fd7-8909-d01375d276c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-6d64c76e-4e27-4f48-b9d2-08444e8619a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615446665-172.17.0.20-1598383316137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42239,DS-df2f1a29-4113-4576-a6f8-c343dc6e3659,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-38c7d690-71d2-4f37-b460-5777d6b42cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-0b24b7c4-11ac-4a58-bcca-2d6f5da9c73d,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-2022f0cb-ae21-4e5c-b2a2-6742d2437fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-2a008b21-7dca-46fc-b579-20f9ca3fd528,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-d6e70cf0-98ae-4829-9ec1-e3cfc3bcca67,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-c51b98d9-993b-41fc-bf65-3f3f701ac42a,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-332ea42a-6960-4d5b-862a-cd762597de9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615446665-172.17.0.20-1598383316137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42239,DS-df2f1a29-4113-4576-a6f8-c343dc6e3659,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-38c7d690-71d2-4f37-b460-5777d6b42cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-0b24b7c4-11ac-4a58-bcca-2d6f5da9c73d,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-2022f0cb-ae21-4e5c-b2a2-6742d2437fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-2a008b21-7dca-46fc-b579-20f9ca3fd528,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-d6e70cf0-98ae-4829-9ec1-e3cfc3bcca67,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-c51b98d9-993b-41fc-bf65-3f3f701ac42a,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-332ea42a-6960-4d5b-862a-cd762597de9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-688505301-172.17.0.20-1598383381087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43399,DS-b4ec973b-fe29-4783-8b3d-7d3ad72a10da,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-57dbbd6e-dd2d-4c82-a13e-7a9e292465e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-d60ac3a6-548f-49a0-8771-b4263a63368e,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-e030fadf-972f-4b81-950b-ef0a70864d29,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-a17db9d1-9232-4da1-b503-bf540af4f4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-d963d20c-dcd4-4ebe-8e94-caf4a568fb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-fc360b96-3a67-43ef-8248-d1df405a86c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-2305926d-9ff6-4f4b-9d87-426180004fdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-688505301-172.17.0.20-1598383381087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43399,DS-b4ec973b-fe29-4783-8b3d-7d3ad72a10da,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-57dbbd6e-dd2d-4c82-a13e-7a9e292465e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-d60ac3a6-548f-49a0-8771-b4263a63368e,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-e030fadf-972f-4b81-950b-ef0a70864d29,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-a17db9d1-9232-4da1-b503-bf540af4f4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-d963d20c-dcd4-4ebe-8e94-caf4a568fb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-fc360b96-3a67-43ef-8248-d1df405a86c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-2305926d-9ff6-4f4b-9d87-426180004fdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-755702010-172.17.0.20-1598383491310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46233,DS-9fb06b2d-60c8-4caf-9539-a00f1061946d,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-90ada0b5-c0a7-436c-98cf-0e73dadf884e,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-827f32f2-24f5-4f63-b67f-c7c253cf07de,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-ca5d1752-6e55-4866-ae76-6741c00e9170,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-db090580-e84e-473d-b2a3-acd868a29ace,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-fec051dc-1784-42c2-9325-fa1a03f7e100,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-edec5b20-67bd-40f3-9cf6-0e1432d84d81,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-af9fdfc8-e600-4706-89aa-ef28dc90bc87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-755702010-172.17.0.20-1598383491310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46233,DS-9fb06b2d-60c8-4caf-9539-a00f1061946d,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-90ada0b5-c0a7-436c-98cf-0e73dadf884e,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-827f32f2-24f5-4f63-b67f-c7c253cf07de,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-ca5d1752-6e55-4866-ae76-6741c00e9170,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-db090580-e84e-473d-b2a3-acd868a29ace,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-fec051dc-1784-42c2-9325-fa1a03f7e100,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-edec5b20-67bd-40f3-9cf6-0e1432d84d81,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-af9fdfc8-e600-4706-89aa-ef28dc90bc87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-579549190-172.17.0.20-1598383710642:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36600,DS-01c8903b-b13c-4607-8804-f5d71967ba4d,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-2300b998-3364-477c-9163-73f1a437cc73,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-391d3721-da50-4a6b-a402-a19360d3c36c,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-e2c7c396-3ab3-4f0a-ade5-67ed83e3f56a,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-a8c7085d-fdf8-4f50-9beb-d4db72b082ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-98bea19a-9d92-4ab1-a7ba-cdc0e2dc0604,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-f7ee76bf-a1cd-47ef-a180-6d62485cb855,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-23ecfdf4-cb6a-4abe-9c2a-c6dac87dbbc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-579549190-172.17.0.20-1598383710642:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36600,DS-01c8903b-b13c-4607-8804-f5d71967ba4d,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-2300b998-3364-477c-9163-73f1a437cc73,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-391d3721-da50-4a6b-a402-a19360d3c36c,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-e2c7c396-3ab3-4f0a-ade5-67ed83e3f56a,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-a8c7085d-fdf8-4f50-9beb-d4db72b082ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-98bea19a-9d92-4ab1-a7ba-cdc0e2dc0604,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-f7ee76bf-a1cd-47ef-a180-6d62485cb855,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-23ecfdf4-cb6a-4abe-9c2a-c6dac87dbbc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172219731-172.17.0.20-1598383746356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43569,DS-bc621f5f-4ece-4858-8a69-4497782ef08f,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-224791b4-50d1-4fad-a756-719d20fe7703,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-4e556cdb-cf11-4b50-a5d0-cb4ef8db40e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-4cbc99fc-ef93-4c1c-9123-10a2c77466e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-72d43422-ee38-4e73-b19e-19e0043c4939,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-3fec11e0-31a9-474b-9df0-992d04d59068,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-72988610-bec5-4ac9-8386-c59a8a2c2be3,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-5fbce63d-67e7-44c7-8a15-9c6a3802cf4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172219731-172.17.0.20-1598383746356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43569,DS-bc621f5f-4ece-4858-8a69-4497782ef08f,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-224791b4-50d1-4fad-a756-719d20fe7703,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-4e556cdb-cf11-4b50-a5d0-cb4ef8db40e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-4cbc99fc-ef93-4c1c-9123-10a2c77466e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-72d43422-ee38-4e73-b19e-19e0043c4939,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-3fec11e0-31a9-474b-9df0-992d04d59068,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-72988610-bec5-4ac9-8386-c59a8a2c2be3,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-5fbce63d-67e7-44c7-8a15-9c6a3802cf4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841690812-172.17.0.20-1598384338731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46187,DS-9ba75b40-da19-4564-86fe-20e10607f899,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-8cd7abad-5f56-40ca-9895-d92d2928da99,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-afd0fb6c-9959-4d49-8b40-3e683a0541fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-7e774cbd-a7eb-407d-8b9b-6a3d03daa835,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-0dfa2acc-3a04-4504-9bcf-2473eafd42fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-068f5103-693d-49bf-a15c-68ef8d208121,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-3228316c-aa1e-443c-b114-e45457706ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-10ccacd6-1fcf-4a44-9ba2-1f8afc4c7362,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841690812-172.17.0.20-1598384338731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46187,DS-9ba75b40-da19-4564-86fe-20e10607f899,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-8cd7abad-5f56-40ca-9895-d92d2928da99,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-afd0fb6c-9959-4d49-8b40-3e683a0541fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-7e774cbd-a7eb-407d-8b9b-6a3d03daa835,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-0dfa2acc-3a04-4504-9bcf-2473eafd42fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-068f5103-693d-49bf-a15c-68ef8d208121,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-3228316c-aa1e-443c-b114-e45457706ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-10ccacd6-1fcf-4a44-9ba2-1f8afc4c7362,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1555828514-172.17.0.20-1598384733478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45467,DS-e99c3cc3-bbd7-492e-80cf-02aa71e8fc29,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-9eecc83e-7817-4363-a1fa-81d3e3c351a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-2fc829eb-addb-4ade-ad1a-8790800b5ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-090d215c-dd39-409e-b12b-67d0a3c9eba9,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-ada24275-1d7e-4df3-8030-7d0431cf9732,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-7ea80647-ec9a-47e8-a523-95a5851e4d70,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-1f0294dc-93b1-4803-b229-173e56e5ef3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-876b1e97-1667-4a45-b785-5f8f9c18bee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1555828514-172.17.0.20-1598384733478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45467,DS-e99c3cc3-bbd7-492e-80cf-02aa71e8fc29,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-9eecc83e-7817-4363-a1fa-81d3e3c351a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-2fc829eb-addb-4ade-ad1a-8790800b5ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-090d215c-dd39-409e-b12b-67d0a3c9eba9,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-ada24275-1d7e-4df3-8030-7d0431cf9732,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-7ea80647-ec9a-47e8-a523-95a5851e4d70,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-1f0294dc-93b1-4803-b229-173e56e5ef3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-876b1e97-1667-4a45-b785-5f8f9c18bee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1200779513-172.17.0.20-1598385306901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40187,DS-ef942a56-cd54-4788-977e-0987e391a801,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-5e232aa1-483a-427f-9024-08bb83a6da6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-a21e1104-a345-404e-ad46-e526ad7b9f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-079a33e1-4177-4c82-828b-5983975c8c65,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-2e9aaadb-ad59-4035-b61c-07867cf855e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-e7dc30ba-73ac-468f-bba1-c5c44814ec57,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-fcc7e892-7da2-4ac1-9bea-838447c4e243,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-68fb2abb-66b2-459a-a7d9-6f04781fc089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1200779513-172.17.0.20-1598385306901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40187,DS-ef942a56-cd54-4788-977e-0987e391a801,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-5e232aa1-483a-427f-9024-08bb83a6da6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-a21e1104-a345-404e-ad46-e526ad7b9f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-079a33e1-4177-4c82-828b-5983975c8c65,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-2e9aaadb-ad59-4035-b61c-07867cf855e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-e7dc30ba-73ac-468f-bba1-c5c44814ec57,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-fcc7e892-7da2-4ac1-9bea-838447c4e243,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-68fb2abb-66b2-459a-a7d9-6f04781fc089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-319992369-172.17.0.20-1598385448413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44440,DS-ee292672-87fd-4981-aa1a-0ba369b6778a,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-97132d82-a295-4ad2-b824-c8e10f6c02ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-85e0c9b0-980a-404e-ba32-e4722ff8a1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-7479bd4e-2f71-4858-9208-b4acfbe44afe,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-c632de5f-6762-4b1a-856b-5e9bd9074d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-49bbefa3-9ff8-4393-a981-fa4228abedfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-d603bf09-30c7-439e-a01e-91eff30f0a64,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-fdc3933f-7c84-4f24-a42c-69dbdb48aa30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-319992369-172.17.0.20-1598385448413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44440,DS-ee292672-87fd-4981-aa1a-0ba369b6778a,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-97132d82-a295-4ad2-b824-c8e10f6c02ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-85e0c9b0-980a-404e-ba32-e4722ff8a1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-7479bd4e-2f71-4858-9208-b4acfbe44afe,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-c632de5f-6762-4b1a-856b-5e9bd9074d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-49bbefa3-9ff8-4393-a981-fa4228abedfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-d603bf09-30c7-439e-a01e-91eff30f0a64,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-fdc3933f-7c84-4f24-a42c-69dbdb48aa30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073272534-172.17.0.20-1598385543014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46315,DS-d82a8384-76ce-4ccf-b4de-aa0ab51987ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-53b0bffe-9dee-4ab7-8719-5e1925cc4c37,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-33818177-260c-4dca-b8cb-cfd8e23b08ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-903db4d6-2634-4484-a4b0-d8bab1242008,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-faaa0196-b7be-4d2a-bcf7-0d1ec7d5039a,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-71dfedaa-684b-4b6b-b4f8-2cfb003cc9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-47965193-70d3-425e-aeb8-0fb9a6effb72,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-7b3ed6b8-7cd6-46fb-94c9-e483f494dfa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073272534-172.17.0.20-1598385543014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46315,DS-d82a8384-76ce-4ccf-b4de-aa0ab51987ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-53b0bffe-9dee-4ab7-8719-5e1925cc4c37,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-33818177-260c-4dca-b8cb-cfd8e23b08ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-903db4d6-2634-4484-a4b0-d8bab1242008,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-faaa0196-b7be-4d2a-bcf7-0d1ec7d5039a,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-71dfedaa-684b-4b6b-b4f8-2cfb003cc9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-47965193-70d3-425e-aeb8-0fb9a6effb72,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-7b3ed6b8-7cd6-46fb-94c9-e483f494dfa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926780516-172.17.0.20-1598385921913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40446,DS-2147cef5-66eb-4ff8-baa3-c6b7e607fe79,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-744ac933-d549-413c-a3ed-b976a82a9646,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-2c1fa282-7304-4e8c-abe5-1e28cbc8c11e,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-9afeb341-1fef-4a19-8595-603f3a19ec83,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-f73b113b-b8ef-4f61-97e3-bfdb7dc30b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-fd21e5dc-9f17-4985-865a-e72bae2b4b59,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-32300efe-cd31-473e-a569-470359b74fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-3045c77c-aae3-4d7e-836e-6ed98337c945,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926780516-172.17.0.20-1598385921913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40446,DS-2147cef5-66eb-4ff8-baa3-c6b7e607fe79,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-744ac933-d549-413c-a3ed-b976a82a9646,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-2c1fa282-7304-4e8c-abe5-1e28cbc8c11e,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-9afeb341-1fef-4a19-8595-603f3a19ec83,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-f73b113b-b8ef-4f61-97e3-bfdb7dc30b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-fd21e5dc-9f17-4985-865a-e72bae2b4b59,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-32300efe-cd31-473e-a569-470359b74fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-3045c77c-aae3-4d7e-836e-6ed98337c945,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5154
