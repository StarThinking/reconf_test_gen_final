reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-652187873-172.17.0.16-1598165989575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35132,DS-97b3b9e9-4a80-443b-929a-d06477567463,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-3af90ebc-2900-4907-8a91-294c77ff4a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-ad7c5bdd-c9f3-4692-8ad5-b5948df6ace2,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-f1d8e752-4cf1-4cf6-9d13-4ccfb4a54961,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-9b503e40-18e1-4d30-8b63-dfad192457de,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-75525bf6-6aab-4665-b7d9-c92c8df989ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-e3247c99-e36b-4f8d-a08d-86b6bda6faaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-e42946e7-cbf5-4322-8957-3abffd919edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-652187873-172.17.0.16-1598165989575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35132,DS-97b3b9e9-4a80-443b-929a-d06477567463,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-3af90ebc-2900-4907-8a91-294c77ff4a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-ad7c5bdd-c9f3-4692-8ad5-b5948df6ace2,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-f1d8e752-4cf1-4cf6-9d13-4ccfb4a54961,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-9b503e40-18e1-4d30-8b63-dfad192457de,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-75525bf6-6aab-4665-b7d9-c92c8df989ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-e3247c99-e36b-4f8d-a08d-86b6bda6faaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-e42946e7-cbf5-4322-8957-3abffd919edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019802051-172.17.0.16-1598166356019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37673,DS-8ef68a35-208d-48d4-8c56-d123ca74b532,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-df8ad8c4-a0c9-49e2-ab2b-53a1effb21d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-72d46ca4-e00b-495c-b4c9-3e2751f86bce,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-efdb7932-5483-401f-a582-7c4e7281c026,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-35218fd5-58bf-4d19-850d-17f3b392585b,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-caf008a8-63d7-43ef-9db1-1b8d3a053114,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-aa200c9e-2022-4856-985f-6e6d8b441ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-af25c340-daa5-4471-a87a-a88ba370ed66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019802051-172.17.0.16-1598166356019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37673,DS-8ef68a35-208d-48d4-8c56-d123ca74b532,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-df8ad8c4-a0c9-49e2-ab2b-53a1effb21d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-72d46ca4-e00b-495c-b4c9-3e2751f86bce,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-efdb7932-5483-401f-a582-7c4e7281c026,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-35218fd5-58bf-4d19-850d-17f3b392585b,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-caf008a8-63d7-43ef-9db1-1b8d3a053114,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-aa200c9e-2022-4856-985f-6e6d8b441ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-af25c340-daa5-4471-a87a-a88ba370ed66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915430462-172.17.0.16-1598166679719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35139,DS-b9ace3b2-276d-4687-969f-6ead7c307972,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-e773aee5-e601-4b25-b53f-af882df00532,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-de35ae75-b572-43e4-beca-5e024324afe2,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-e13bf250-03b4-4a28-86f8-f5aee1fa2231,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-e148b4b7-e48a-44af-8dec-4ab5a1bafd33,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-f9d553aa-9edf-4ec4-8468-225c97851705,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-0aae3ef4-34b9-4c61-8d5d-4c8a954273b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-bbb07945-2a28-4c39-a3f1-ea5f01c70d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915430462-172.17.0.16-1598166679719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35139,DS-b9ace3b2-276d-4687-969f-6ead7c307972,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-e773aee5-e601-4b25-b53f-af882df00532,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-de35ae75-b572-43e4-beca-5e024324afe2,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-e13bf250-03b4-4a28-86f8-f5aee1fa2231,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-e148b4b7-e48a-44af-8dec-4ab5a1bafd33,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-f9d553aa-9edf-4ec4-8468-225c97851705,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-0aae3ef4-34b9-4c61-8d5d-4c8a954273b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-bbb07945-2a28-4c39-a3f1-ea5f01c70d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378796378-172.17.0.16-1598166908700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36441,DS-cefeeaa6-1263-4bf4-ac51-8e919831f79c,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-99d26350-c6b5-4c41-8e3c-ed93715a73cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-2e68b4aa-4cec-49bf-b54f-16ad7f636f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-d76ce0d5-863c-47b4-8da9-97c24b32f7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-8e5ad422-ba58-471f-86a0-1238a440dfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-6343dbb6-b919-4c95-b677-257d3f5b5d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-aa407d9e-595d-4181-a8f7-dd309c7b4966,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-4062428e-2794-40a9-b9b0-080de17e6622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378796378-172.17.0.16-1598166908700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36441,DS-cefeeaa6-1263-4bf4-ac51-8e919831f79c,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-99d26350-c6b5-4c41-8e3c-ed93715a73cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-2e68b4aa-4cec-49bf-b54f-16ad7f636f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-d76ce0d5-863c-47b4-8da9-97c24b32f7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-8e5ad422-ba58-471f-86a0-1238a440dfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-6343dbb6-b919-4c95-b677-257d3f5b5d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-aa407d9e-595d-4181-a8f7-dd309c7b4966,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-4062428e-2794-40a9-b9b0-080de17e6622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544990428-172.17.0.16-1598167176285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44871,DS-c34c6f3a-2f4c-47c1-8afe-a141cebb318d,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-b0cefdbc-39e7-4db4-97ad-762ab5b87e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-1bea0830-059a-4a88-9e92-a165b846dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-765e041f-830d-4346-88d1-decccdac6247,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-b539e392-ecbe-466d-afb7-2805d7967414,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-88b88758-aedb-469d-831e-8864b37be045,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-99589d4f-7a4f-4a60-86ad-9168ca8c3278,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-375422b5-dd02-417d-96ae-bc70902a32ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544990428-172.17.0.16-1598167176285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44871,DS-c34c6f3a-2f4c-47c1-8afe-a141cebb318d,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-b0cefdbc-39e7-4db4-97ad-762ab5b87e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-1bea0830-059a-4a88-9e92-a165b846dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-765e041f-830d-4346-88d1-decccdac6247,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-b539e392-ecbe-466d-afb7-2805d7967414,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-88b88758-aedb-469d-831e-8864b37be045,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-99589d4f-7a4f-4a60-86ad-9168ca8c3278,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-375422b5-dd02-417d-96ae-bc70902a32ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914691882-172.17.0.16-1598167291263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44731,DS-553ac148-fb76-4632-bcb4-5f8dd6687d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-38471a53-38e2-4a32-a6cc-26deca1649b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-16cc5afe-4fb5-4014-b0e7-a960504a63b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-433097f8-2c2f-4cae-be3e-5fa825b164d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-35760656-5499-4566-82bf-b080b41f8489,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-0d2cd996-ae40-451b-bdf1-e945abddb6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-0a080156-af99-48c1-8be6-b0001f2afc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-2806e66d-58fb-42f9-bc60-c5232ede588c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914691882-172.17.0.16-1598167291263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44731,DS-553ac148-fb76-4632-bcb4-5f8dd6687d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-38471a53-38e2-4a32-a6cc-26deca1649b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-16cc5afe-4fb5-4014-b0e7-a960504a63b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-433097f8-2c2f-4cae-be3e-5fa825b164d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-35760656-5499-4566-82bf-b080b41f8489,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-0d2cd996-ae40-451b-bdf1-e945abddb6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-0a080156-af99-48c1-8be6-b0001f2afc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-2806e66d-58fb-42f9-bc60-c5232ede588c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706256942-172.17.0.16-1598167326540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37058,DS-80369bfa-e046-43ce-a57f-b8d715ebc745,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-b6378698-b9ce-4c03-9c03-1dde06a9d977,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-f418be60-573e-4bc0-946f-03c1d6729c79,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-8f1907c4-07d2-4de2-a7e0-e0108c3b3cea,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-0e11de0f-5134-4410-a797-761160b3462b,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-0c11746c-e183-4454-b427-edbccd32c595,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-b405ee33-b9ef-4ddb-9394-8c35ae16c891,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-b3bd0584-4eea-42ad-b867-6b32a42d986e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706256942-172.17.0.16-1598167326540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37058,DS-80369bfa-e046-43ce-a57f-b8d715ebc745,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-b6378698-b9ce-4c03-9c03-1dde06a9d977,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-f418be60-573e-4bc0-946f-03c1d6729c79,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-8f1907c4-07d2-4de2-a7e0-e0108c3b3cea,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-0e11de0f-5134-4410-a797-761160b3462b,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-0c11746c-e183-4454-b427-edbccd32c595,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-b405ee33-b9ef-4ddb-9394-8c35ae16c891,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-b3bd0584-4eea-42ad-b867-6b32a42d986e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2001305360-172.17.0.16-1598167704108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37003,DS-b266dda8-2a4e-40cc-848d-c022182ce89f,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-3abc1a5a-4874-49c8-9f28-7e43f2433b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-07e019ff-9129-4854-a9c3-062cbf73ecd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-3852aefb-856f-4b1d-a371-a6e1a09a8e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-fb39c767-a3f5-4d86-a50c-a030fc60dd38,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-90f9c88a-fe14-4750-88a0-a5e9ac330d09,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-9ac4dcd6-5db7-4128-a92c-dfce66f14879,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-24e9cd7a-587e-4993-a4a4-ca918444fe44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2001305360-172.17.0.16-1598167704108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37003,DS-b266dda8-2a4e-40cc-848d-c022182ce89f,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-3abc1a5a-4874-49c8-9f28-7e43f2433b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-07e019ff-9129-4854-a9c3-062cbf73ecd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-3852aefb-856f-4b1d-a371-a6e1a09a8e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-fb39c767-a3f5-4d86-a50c-a030fc60dd38,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-90f9c88a-fe14-4750-88a0-a5e9ac330d09,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-9ac4dcd6-5db7-4128-a92c-dfce66f14879,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-24e9cd7a-587e-4993-a4a4-ca918444fe44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180763390-172.17.0.16-1598168769606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33859,DS-47ca3ae5-7163-4db5-91c8-76eb0349cac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-eda0e14e-2529-4ca0-ba6f-9f3a51c5fee2,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-7748b203-1d73-4659-b0b7-03faf0a98e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-767ff752-5b9d-4da0-babd-767e1bff156a,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-05ec20e9-99bc-4135-bfce-188030519685,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-fbb5a168-3b12-4158-b6b0-adb6528497c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-856923d5-2f79-4edd-9e9a-4cb8db1229a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-12e2bda1-4517-4a0a-9e40-6d3692eccf03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180763390-172.17.0.16-1598168769606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33859,DS-47ca3ae5-7163-4db5-91c8-76eb0349cac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-eda0e14e-2529-4ca0-ba6f-9f3a51c5fee2,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-7748b203-1d73-4659-b0b7-03faf0a98e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-767ff752-5b9d-4da0-babd-767e1bff156a,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-05ec20e9-99bc-4135-bfce-188030519685,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-fbb5a168-3b12-4158-b6b0-adb6528497c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-856923d5-2f79-4edd-9e9a-4cb8db1229a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-12e2bda1-4517-4a0a-9e40-6d3692eccf03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180380926-172.17.0.16-1598168807435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36724,DS-be16e57c-5daf-4f3a-bcf9-6be06ddcca97,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-225411c8-5663-412c-ac15-6d6df30115b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-d63e815a-c549-42c6-9a71-354fe6492ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-7e2fa3d4-e733-49dd-aa6e-06f51a07efae,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-20417dc0-5a4c-4a5f-9429-2606e6c3c344,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-0913c34e-61f2-486e-8f17-5b2edb743a14,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-6c5f640e-b098-4f6b-9b8e-d2e8b4c5bfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-9128e42e-ee24-4c98-b062-0d36b04abd50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180380926-172.17.0.16-1598168807435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36724,DS-be16e57c-5daf-4f3a-bcf9-6be06ddcca97,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-225411c8-5663-412c-ac15-6d6df30115b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-d63e815a-c549-42c6-9a71-354fe6492ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-7e2fa3d4-e733-49dd-aa6e-06f51a07efae,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-20417dc0-5a4c-4a5f-9429-2606e6c3c344,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-0913c34e-61f2-486e-8f17-5b2edb743a14,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-6c5f640e-b098-4f6b-9b8e-d2e8b4c5bfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-9128e42e-ee24-4c98-b062-0d36b04abd50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210496306-172.17.0.16-1598168877367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44783,DS-dc77e7b3-708d-4348-9486-4a37485bb3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-60f0be76-9b73-48d8-80d4-aa44aad8dcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-aae9f20f-2297-4c3d-925d-c89aedd73859,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-98f8cc7b-f0e4-417a-9d98-32031230641c,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-bcf6b002-9046-46c7-ae68-e035665f6b13,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-805555f3-51cf-4a3b-b2ad-a508ad2f1a29,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-dc0aa555-aed4-4c11-b250-842f14e563e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-853979b5-9af8-4175-be15-9d71ab4077e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210496306-172.17.0.16-1598168877367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44783,DS-dc77e7b3-708d-4348-9486-4a37485bb3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-60f0be76-9b73-48d8-80d4-aa44aad8dcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-aae9f20f-2297-4c3d-925d-c89aedd73859,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-98f8cc7b-f0e4-417a-9d98-32031230641c,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-bcf6b002-9046-46c7-ae68-e035665f6b13,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-805555f3-51cf-4a3b-b2ad-a508ad2f1a29,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-dc0aa555-aed4-4c11-b250-842f14e563e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-853979b5-9af8-4175-be15-9d71ab4077e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631164007-172.17.0.16-1598169066135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44299,DS-4b3fd11d-daf6-43a8-bc8f-5f8c2c8f539e,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-e2b3ca52-7e9f-45be-97ce-ad4381990396,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-45f14787-6161-472c-bca9-02b9af7a5839,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-9c7840e8-9373-46da-be52-a3112b5a9d56,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-3c6a6b79-98ec-49a9-a5cf-8965dfd7307d,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-12303dd3-9b29-434b-a79a-612d1e1b17ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-41b0fea9-96da-4e4c-b1a7-376ca3b39893,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-1585c803-b3a8-428d-91eb-03e4f6433d85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631164007-172.17.0.16-1598169066135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44299,DS-4b3fd11d-daf6-43a8-bc8f-5f8c2c8f539e,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-e2b3ca52-7e9f-45be-97ce-ad4381990396,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-45f14787-6161-472c-bca9-02b9af7a5839,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-9c7840e8-9373-46da-be52-a3112b5a9d56,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-3c6a6b79-98ec-49a9-a5cf-8965dfd7307d,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-12303dd3-9b29-434b-a79a-612d1e1b17ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-41b0fea9-96da-4e4c-b1a7-376ca3b39893,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-1585c803-b3a8-428d-91eb-03e4f6433d85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972707013-172.17.0.16-1598169170784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34133,DS-a4a7fd14-4849-4ef9-b140-7158f8654cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-006997e4-bfb6-433d-bbb3-9abd74b8be0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-ff1755e8-a225-43a4-a387-50c831820aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-bdc6bad0-919f-44ac-860c-c36a238591f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-50f6a8ae-ddfb-47ac-b1fc-0d6eea61f85e,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-f1d9f73e-8189-4a52-9820-63074d6ddc83,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-9f5ffa2c-01f8-4d3c-893b-81d536617b86,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-ec20fcb0-4363-43bc-8e52-9b62fe48b9b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972707013-172.17.0.16-1598169170784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34133,DS-a4a7fd14-4849-4ef9-b140-7158f8654cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-006997e4-bfb6-433d-bbb3-9abd74b8be0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-ff1755e8-a225-43a4-a387-50c831820aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-bdc6bad0-919f-44ac-860c-c36a238591f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-50f6a8ae-ddfb-47ac-b1fc-0d6eea61f85e,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-f1d9f73e-8189-4a52-9820-63074d6ddc83,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-9f5ffa2c-01f8-4d3c-893b-81d536617b86,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-ec20fcb0-4363-43bc-8e52-9b62fe48b9b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999351489-172.17.0.16-1598169313105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46253,DS-ae0fe97e-a6ff-4ee1-bd87-631349ff1673,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-5703b57d-d0c0-4f8b-aee7-fd62c2429cec,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-b9262e89-1310-4ce6-8db5-94c3f79af736,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-e072e019-0107-4953-8018-2a7e197b8a16,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-50b93478-946e-4c08-9ddf-96d9f5464de9,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-bfa94582-6841-4823-95bd-2585a6d054c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-ea8b8b6c-a160-4b1d-8930-5d203979cd58,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-79199e3c-584a-461f-9e04-ecbf87324190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999351489-172.17.0.16-1598169313105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46253,DS-ae0fe97e-a6ff-4ee1-bd87-631349ff1673,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-5703b57d-d0c0-4f8b-aee7-fd62c2429cec,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-b9262e89-1310-4ce6-8db5-94c3f79af736,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-e072e019-0107-4953-8018-2a7e197b8a16,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-50b93478-946e-4c08-9ddf-96d9f5464de9,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-bfa94582-6841-4823-95bd-2585a6d054c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-ea8b8b6c-a160-4b1d-8930-5d203979cd58,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-79199e3c-584a-461f-9e04-ecbf87324190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034452533-172.17.0.16-1598169698238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46571,DS-bd392f99-148d-48f7-afde-13633dd08800,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-e2e5cb70-ef34-4b38-93ca-6664431cba90,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-c2aa351a-9192-4b9f-acf1-eefa44d49812,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-567bdc23-7a97-462a-880c-5120c10c609c,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-54ba8ef0-47af-47a4-bee4-7d85063203ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-b7d894de-798c-4f3e-87c8-808d35290e62,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-d302ac91-d0c4-4861-9b62-af71e3d8c898,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-e8bc75cc-2bda-4eb7-bdee-6e4c9d6c6154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034452533-172.17.0.16-1598169698238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46571,DS-bd392f99-148d-48f7-afde-13633dd08800,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-e2e5cb70-ef34-4b38-93ca-6664431cba90,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-c2aa351a-9192-4b9f-acf1-eefa44d49812,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-567bdc23-7a97-462a-880c-5120c10c609c,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-54ba8ef0-47af-47a4-bee4-7d85063203ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-b7d894de-798c-4f3e-87c8-808d35290e62,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-d302ac91-d0c4-4861-9b62-af71e3d8c898,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-e8bc75cc-2bda-4eb7-bdee-6e4c9d6c6154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663499271-172.17.0.16-1598170227299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45308,DS-1b306e56-b847-485d-b4c0-32191060fa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-463f2a02-cf2e-4c68-8f49-653095ee789b,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-e8cec210-eb91-42d9-89b2-317cb8c156f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-a664ec44-889b-4112-8554-8c5fe8cb7f96,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-9eb968f0-a172-413b-b33f-692201ac1c42,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-f40c2585-aab2-4f6b-90e1-ed1a6949d99b,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-aec9a77c-86da-4f8b-9fbd-00f7e0f6442b,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-b06ebc03-8839-4b40-931b-6af9be8646f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663499271-172.17.0.16-1598170227299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45308,DS-1b306e56-b847-485d-b4c0-32191060fa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-463f2a02-cf2e-4c68-8f49-653095ee789b,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-e8cec210-eb91-42d9-89b2-317cb8c156f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-a664ec44-889b-4112-8554-8c5fe8cb7f96,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-9eb968f0-a172-413b-b33f-692201ac1c42,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-f40c2585-aab2-4f6b-90e1-ed1a6949d99b,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-aec9a77c-86da-4f8b-9fbd-00f7e0f6442b,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-b06ebc03-8839-4b40-931b-6af9be8646f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229940438-172.17.0.16-1598170688896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40331,DS-07d49929-0e1b-4db9-866b-1d94774c50c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-9f870781-b0c0-48cd-82f1-360e58763940,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-8e51b1dd-eac6-4960-953d-6883323860a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-b7bc3728-c91b-4c8f-834f-3ae78aac7cca,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-c7847c37-5a92-4d45-ab40-0b421ffb01da,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-19071ecf-d889-4682-915f-1ba40c3a0568,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-7a0ee0ef-5eab-4027-8af1-1eb27e7973d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-f12314ee-c674-476e-bf4b-a8c54637b665,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229940438-172.17.0.16-1598170688896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40331,DS-07d49929-0e1b-4db9-866b-1d94774c50c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-9f870781-b0c0-48cd-82f1-360e58763940,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-8e51b1dd-eac6-4960-953d-6883323860a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-b7bc3728-c91b-4c8f-834f-3ae78aac7cca,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-c7847c37-5a92-4d45-ab40-0b421ffb01da,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-19071ecf-d889-4682-915f-1ba40c3a0568,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-7a0ee0ef-5eab-4027-8af1-1eb27e7973d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-f12314ee-c674-476e-bf4b-a8c54637b665,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133412235-172.17.0.16-1598171049490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-c7e9502f-c678-4424-a2a2-c4afaa2062ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-80afa756-91be-455e-b640-817d3c6b47f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-88dec521-71bb-44c6-917e-375dc3d57e63,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-a9c213cd-62f6-4f98-81bb-619cad522543,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-850f7225-8b9c-49b5-9fbe-1abc02226316,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-c72f26dc-62d9-440d-a24c-17d5397f45e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-6a4002e5-7d73-4732-aceb-42e583c8ac25,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-4e7460ab-6525-4bd8-9c42-c89b3c57c345,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133412235-172.17.0.16-1598171049490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-c7e9502f-c678-4424-a2a2-c4afaa2062ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-80afa756-91be-455e-b640-817d3c6b47f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-88dec521-71bb-44c6-917e-375dc3d57e63,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-a9c213cd-62f6-4f98-81bb-619cad522543,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-850f7225-8b9c-49b5-9fbe-1abc02226316,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-c72f26dc-62d9-440d-a24c-17d5397f45e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-6a4002e5-7d73-4732-aceb-42e583c8ac25,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-4e7460ab-6525-4bd8-9c42-c89b3c57c345,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911834306-172.17.0.16-1598171126687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42383,DS-3bd44504-5724-48c7-a010-b3ade324d800,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-e1b7b7ab-62cc-4cd5-bd40-d9858bca6bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-73f510fe-b26d-4046-b8ad-7385d930440d,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-b8e1163c-f998-4950-94f4-b7612936ad95,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-c40163c3-a79e-4d15-ab57-e424bfda0d07,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-6a74d689-7a87-4541-817f-ab7bf0632ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-9b0f868f-ae22-4351-83ab-b0e41b7f77db,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-4bff6607-12e0-44a3-a052-c1cb8329d34f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911834306-172.17.0.16-1598171126687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42383,DS-3bd44504-5724-48c7-a010-b3ade324d800,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-e1b7b7ab-62cc-4cd5-bd40-d9858bca6bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-73f510fe-b26d-4046-b8ad-7385d930440d,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-b8e1163c-f998-4950-94f4-b7612936ad95,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-c40163c3-a79e-4d15-ab57-e424bfda0d07,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-6a74d689-7a87-4541-817f-ab7bf0632ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-9b0f868f-ae22-4351-83ab-b0e41b7f77db,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-4bff6607-12e0-44a3-a052-c1cb8329d34f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5521
