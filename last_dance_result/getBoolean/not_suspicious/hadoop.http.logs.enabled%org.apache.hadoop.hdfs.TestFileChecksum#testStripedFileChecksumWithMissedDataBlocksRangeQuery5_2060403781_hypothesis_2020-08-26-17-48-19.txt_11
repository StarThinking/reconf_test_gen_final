reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086000383-172.17.0.3-1598464118158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44728,DS-ba622f46-5f04-4c83-9120-1e556ccc3192,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-137c7210-9738-4946-b30e-3f94096b076d,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-d607dc3b-0b0a-4939-bceb-9476ac4f78fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-d2eda4bd-7fe8-41d4-a81c-ac135c0c6f07,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-a315ff10-affe-43d8-be1a-3df8729d8536,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-124889dc-2a49-4047-9da1-84f837b18ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-7181ffbf-9112-487f-ace6-eb8dc7bbe94c,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-3e3a6a57-db5a-4ac3-8fc5-e9bf1e7fa39f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086000383-172.17.0.3-1598464118158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44728,DS-ba622f46-5f04-4c83-9120-1e556ccc3192,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-137c7210-9738-4946-b30e-3f94096b076d,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-d607dc3b-0b0a-4939-bceb-9476ac4f78fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-d2eda4bd-7fe8-41d4-a81c-ac135c0c6f07,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-a315ff10-affe-43d8-be1a-3df8729d8536,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-124889dc-2a49-4047-9da1-84f837b18ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-7181ffbf-9112-487f-ace6-eb8dc7bbe94c,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-3e3a6a57-db5a-4ac3-8fc5-e9bf1e7fa39f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980361836-172.17.0.3-1598465647552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33956,DS-21571aa2-e9b8-4d4f-9c6a-3a6545031cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-f41f9d44-ad48-42b9-961e-6eff10cc8f78,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-2604a62b-c6c4-4706-93c5-c3267a8d8574,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-6a95408c-f45c-4ae2-a3d1-d0ef7cbc3185,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-725dfd05-3d0f-4765-a6ac-8cce97d515e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-fe681e0c-9a13-46b0-8cef-a9dd3fbc1bac,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-72beaee7-58a6-449c-940c-eeb4af602161,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-2ff38af9-cb25-420c-93fe-cf71262329a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980361836-172.17.0.3-1598465647552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33956,DS-21571aa2-e9b8-4d4f-9c6a-3a6545031cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-f41f9d44-ad48-42b9-961e-6eff10cc8f78,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-2604a62b-c6c4-4706-93c5-c3267a8d8574,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-6a95408c-f45c-4ae2-a3d1-d0ef7cbc3185,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-725dfd05-3d0f-4765-a6ac-8cce97d515e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-fe681e0c-9a13-46b0-8cef-a9dd3fbc1bac,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-72beaee7-58a6-449c-940c-eeb4af602161,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-2ff38af9-cb25-420c-93fe-cf71262329a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921918971-172.17.0.3-1598465776635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34381,DS-ff619988-0072-4d40-886b-0c6e85b3262c,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-ab8e5e94-2a44-47e7-9ce8-1c724d100893,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-77235ccc-93b8-40f2-b042-0df8007296a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-2dabca44-743f-47b0-b403-b789c2004cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-c2f2fb9f-43b5-43f1-b638-1966232ae0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-57726a3e-9bb0-4f5d-aa8d-81c547201b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-bc108bde-ea03-43e9-90f7-e3261a32b4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-dd9cec6e-088a-4335-a64c-d8e5e7cafbf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921918971-172.17.0.3-1598465776635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34381,DS-ff619988-0072-4d40-886b-0c6e85b3262c,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-ab8e5e94-2a44-47e7-9ce8-1c724d100893,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-77235ccc-93b8-40f2-b042-0df8007296a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-2dabca44-743f-47b0-b403-b789c2004cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-c2f2fb9f-43b5-43f1-b638-1966232ae0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-57726a3e-9bb0-4f5d-aa8d-81c547201b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-bc108bde-ea03-43e9-90f7-e3261a32b4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-dd9cec6e-088a-4335-a64c-d8e5e7cafbf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060431521-172.17.0.3-1598466386985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36588,DS-a6250094-b3a2-49d7-b16e-823439672965,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-2b0c805f-d376-4557-9e5a-f2b36d5059d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-b1d377ae-8a13-47fb-8022-b19b97d7181a,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-b3bcefbc-3c45-43ed-a710-7665569b57fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-ac130986-424f-4962-972c-0b4b25a942a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-0037640f-e333-491a-a422-08c5e85ef0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-206f5b5c-3ee6-4f72-b2c2-506200f5df46,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-94d11f29-f933-4716-86ca-324741972d2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060431521-172.17.0.3-1598466386985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36588,DS-a6250094-b3a2-49d7-b16e-823439672965,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-2b0c805f-d376-4557-9e5a-f2b36d5059d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-b1d377ae-8a13-47fb-8022-b19b97d7181a,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-b3bcefbc-3c45-43ed-a710-7665569b57fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-ac130986-424f-4962-972c-0b4b25a942a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-0037640f-e333-491a-a422-08c5e85ef0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-206f5b5c-3ee6-4f72-b2c2-506200f5df46,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-94d11f29-f933-4716-86ca-324741972d2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651433622-172.17.0.3-1598466516985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37969,DS-6fb39580-8cdf-48c5-8eb3-383f8565722a,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-6bb0050f-15e5-42a8-8fbe-7ad62a91e1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-80c4a8af-3752-4cdb-9e74-b239a890c0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-53653fa1-226c-4b38-b1f0-88fea6ca4c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-c2b1bbac-7ad0-4ad1-8a58-5b9bafa5e75d,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-7fde5559-fc95-4f72-b15d-dffb84665591,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-6751a057-38b8-475b-99d5-a93b9d968227,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-99504106-48a3-4354-a0e0-818eb08c23ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651433622-172.17.0.3-1598466516985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37969,DS-6fb39580-8cdf-48c5-8eb3-383f8565722a,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-6bb0050f-15e5-42a8-8fbe-7ad62a91e1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-80c4a8af-3752-4cdb-9e74-b239a890c0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-53653fa1-226c-4b38-b1f0-88fea6ca4c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-c2b1bbac-7ad0-4ad1-8a58-5b9bafa5e75d,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-7fde5559-fc95-4f72-b15d-dffb84665591,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-6751a057-38b8-475b-99d5-a93b9d968227,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-99504106-48a3-4354-a0e0-818eb08c23ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422262724-172.17.0.3-1598466718590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40628,DS-5fd65d1b-177e-4573-acfe-71a8a332de6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-f58ef079-4084-4735-8827-89a33ee3dd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-5eef62fa-a363-44df-b393-f2cbf6f28d42,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-cafeb4c3-84ab-4a09-8342-42f13c51f074,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-6aa3a7f2-5ac8-4d37-9da7-75f7306efcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-3be496b3-fadf-441b-8ef3-00579d3b43ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-07d7f06d-216d-4b74-b2c6-988d97595da5,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-2f2a698c-a072-459e-bae1-7e427966c26d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422262724-172.17.0.3-1598466718590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40628,DS-5fd65d1b-177e-4573-acfe-71a8a332de6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-f58ef079-4084-4735-8827-89a33ee3dd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-5eef62fa-a363-44df-b393-f2cbf6f28d42,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-cafeb4c3-84ab-4a09-8342-42f13c51f074,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-6aa3a7f2-5ac8-4d37-9da7-75f7306efcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-3be496b3-fadf-441b-8ef3-00579d3b43ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-07d7f06d-216d-4b74-b2c6-988d97595da5,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-2f2a698c-a072-459e-bae1-7e427966c26d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841747267-172.17.0.3-1598466946001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43450,DS-0ab02a58-de16-4f40-abb1-5e87c8510531,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-adaabaf3-f150-467d-9c09-f086a3162732,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-9c5b96ea-bc7b-44e4-abb5-6f79becf1329,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-467602c7-c21c-466d-9b21-4d0632df2a36,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-493a95c2-a515-43e3-9534-77aaf3d0653f,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-a34e9b74-348f-405f-8021-b6cf119e45b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-564bda6b-fafe-4e9c-8f03-3fce28e96277,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-2e905c76-43a9-48fc-9aaa-6091433dad0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841747267-172.17.0.3-1598466946001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43450,DS-0ab02a58-de16-4f40-abb1-5e87c8510531,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-adaabaf3-f150-467d-9c09-f086a3162732,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-9c5b96ea-bc7b-44e4-abb5-6f79becf1329,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-467602c7-c21c-466d-9b21-4d0632df2a36,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-493a95c2-a515-43e3-9534-77aaf3d0653f,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-a34e9b74-348f-405f-8021-b6cf119e45b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-564bda6b-fafe-4e9c-8f03-3fce28e96277,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-2e905c76-43a9-48fc-9aaa-6091433dad0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069591591-172.17.0.3-1598467241165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35872,DS-4c2d02d8-4ee6-4648-b2bd-40c7b2125ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-c107a7b6-eab4-452b-a6cc-d83a38e0b0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-591a4412-455b-443b-8d20-192a0e3a370c,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-486af5ab-88eb-4011-b39d-2cde38f6e044,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-1ee82b28-c355-41f9-8d39-c226996c6319,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-8eed95e3-d5bb-41db-abd7-c49c998f803d,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-71d2e783-8138-4441-99c2-1634c400d686,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-d47fa1c2-079c-4149-b05e-2741b7d4d034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069591591-172.17.0.3-1598467241165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35872,DS-4c2d02d8-4ee6-4648-b2bd-40c7b2125ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-c107a7b6-eab4-452b-a6cc-d83a38e0b0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-591a4412-455b-443b-8d20-192a0e3a370c,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-486af5ab-88eb-4011-b39d-2cde38f6e044,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-1ee82b28-c355-41f9-8d39-c226996c6319,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-8eed95e3-d5bb-41db-abd7-c49c998f803d,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-71d2e783-8138-4441-99c2-1634c400d686,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-d47fa1c2-079c-4149-b05e-2741b7d4d034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384113173-172.17.0.3-1598467321046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-faa2d6b3-8a47-4dd0-9eef-ad04d060fc29,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-8bf65a60-d0f2-462a-94e4-38a67b9bbe90,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-5509b7e5-fd3e-4ad1-b977-f519e05bdc38,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-62948bc4-7aa3-457f-8f25-29cd9b57ec3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-048860a8-eac6-4b8f-93bc-dea5361cfd74,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-73af3a48-0aa4-4faa-ae8b-e1c3e92fd68d,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-c3714fbf-7678-4698-aa6c-a3fca5e0dfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-12829f74-c14c-4a66-9c29-a29c6fae338b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384113173-172.17.0.3-1598467321046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-faa2d6b3-8a47-4dd0-9eef-ad04d060fc29,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-8bf65a60-d0f2-462a-94e4-38a67b9bbe90,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-5509b7e5-fd3e-4ad1-b977-f519e05bdc38,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-62948bc4-7aa3-457f-8f25-29cd9b57ec3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-048860a8-eac6-4b8f-93bc-dea5361cfd74,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-73af3a48-0aa4-4faa-ae8b-e1c3e92fd68d,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-c3714fbf-7678-4698-aa6c-a3fca5e0dfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-12829f74-c14c-4a66-9c29-a29c6fae338b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186505695-172.17.0.3-1598467384625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39676,DS-cf57248e-d282-4566-9815-da224cf18a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-ba3b130b-fc44-48a5-99a9-7ac75a6a2700,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-c8237596-fb3e-4654-8eda-11e794b5ac01,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-6917f462-2f97-4c2c-b2ed-dd0848b331d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-cc759f74-5272-4f1b-ae5a-d869c9cff3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-ffe4ba0b-0d88-4d0b-93c9-e30bf31f2cef,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-0dd3e349-1617-49d5-87ff-5169cd190e14,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-7793d4c2-7a86-4bdb-acf5-cd536a14702f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186505695-172.17.0.3-1598467384625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39676,DS-cf57248e-d282-4566-9815-da224cf18a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-ba3b130b-fc44-48a5-99a9-7ac75a6a2700,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-c8237596-fb3e-4654-8eda-11e794b5ac01,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-6917f462-2f97-4c2c-b2ed-dd0848b331d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-cc759f74-5272-4f1b-ae5a-d869c9cff3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-ffe4ba0b-0d88-4d0b-93c9-e30bf31f2cef,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-0dd3e349-1617-49d5-87ff-5169cd190e14,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-7793d4c2-7a86-4bdb-acf5-cd536a14702f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1018447152-172.17.0.3-1598467558481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43286,DS-c97fd4d3-724e-43de-87b3-e90fecdbbb00,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-c251cf35-f757-49be-9f64-41075d52583b,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-d8c75eb1-6e85-4261-ab63-2514409ce851,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-8285f6af-e4a1-433c-accd-ac936ffa6eef,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-ed797c42-0339-47ee-90ba-16038fddd467,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-425978cf-318f-40db-b55a-5881c7f65883,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-43907039-8b0e-4cfa-bc22-7993bd23f4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-c4d2c24a-053c-477e-81b6-0c0670ce21a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1018447152-172.17.0.3-1598467558481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43286,DS-c97fd4d3-724e-43de-87b3-e90fecdbbb00,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-c251cf35-f757-49be-9f64-41075d52583b,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-d8c75eb1-6e85-4261-ab63-2514409ce851,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-8285f6af-e4a1-433c-accd-ac936ffa6eef,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-ed797c42-0339-47ee-90ba-16038fddd467,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-425978cf-318f-40db-b55a-5881c7f65883,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-43907039-8b0e-4cfa-bc22-7993bd23f4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-c4d2c24a-053c-477e-81b6-0c0670ce21a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933006728-172.17.0.3-1598467590346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35218,DS-24b0324b-152a-469d-ab24-bf217e14597e,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-59b880ae-6831-4afb-8a97-c5008f2118d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-06d04826-8347-4c87-8ab9-9691510f4e00,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-18c036c0-b722-4044-b088-cdb0b756c06d,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-f94e47dd-21d0-4892-903e-242b920a40ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-67e6cc24-add1-4a76-b2f1-c0b63f923ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-3e801d84-2362-442c-96ce-02ede38361ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-52430805-8ade-4113-94b1-5dc51d5df0d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933006728-172.17.0.3-1598467590346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35218,DS-24b0324b-152a-469d-ab24-bf217e14597e,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-59b880ae-6831-4afb-8a97-c5008f2118d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-06d04826-8347-4c87-8ab9-9691510f4e00,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-18c036c0-b722-4044-b088-cdb0b756c06d,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-f94e47dd-21d0-4892-903e-242b920a40ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-67e6cc24-add1-4a76-b2f1-c0b63f923ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-3e801d84-2362-442c-96ce-02ede38361ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-52430805-8ade-4113-94b1-5dc51d5df0d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222075420-172.17.0.3-1598467779816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45414,DS-224b7d2d-fcd6-4931-a89b-18092a2369ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-ee95d3b5-2382-4715-8fcd-b0a25f9aaa70,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-d8f5fdcb-992f-421c-ab2e-bb195eae833b,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-e7927241-3a62-4e72-bbd2-f940e608137f,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-1449582b-cdc0-4235-8c2a-7d4789184b54,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-bb80ca2b-5890-4bfe-ab09-6ec810c7b2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-cfa4919b-41f6-4ea1-a35f-231b550923f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-e648b1d4-52c5-4399-9a95-3f43120cd205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222075420-172.17.0.3-1598467779816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45414,DS-224b7d2d-fcd6-4931-a89b-18092a2369ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-ee95d3b5-2382-4715-8fcd-b0a25f9aaa70,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-d8f5fdcb-992f-421c-ab2e-bb195eae833b,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-e7927241-3a62-4e72-bbd2-f940e608137f,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-1449582b-cdc0-4235-8c2a-7d4789184b54,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-bb80ca2b-5890-4bfe-ab09-6ec810c7b2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-cfa4919b-41f6-4ea1-a35f-231b550923f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-e648b1d4-52c5-4399-9a95-3f43120cd205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865218398-172.17.0.3-1598467795568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46086,DS-35042866-c33d-4efd-88ae-3e9428988143,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-1e06d1e7-07e6-4e8b-a0c4-46a0bfff447c,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-fb8cd9be-64ba-4e23-9191-70b45cdeb4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-8c848fa5-e6cf-4aea-b5a1-d114fbd0078a,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-b304620b-eba4-48c7-9f74-10900864cc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-4f661ed7-6fcb-44a4-b407-fdeed39de9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-cbd947d0-14af-451e-8187-d41ba596ef71,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-5fca5ed8-26e9-4b27-b87c-7ceac64d0932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865218398-172.17.0.3-1598467795568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46086,DS-35042866-c33d-4efd-88ae-3e9428988143,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-1e06d1e7-07e6-4e8b-a0c4-46a0bfff447c,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-fb8cd9be-64ba-4e23-9191-70b45cdeb4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-8c848fa5-e6cf-4aea-b5a1-d114fbd0078a,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-b304620b-eba4-48c7-9f74-10900864cc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-4f661ed7-6fcb-44a4-b407-fdeed39de9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-cbd947d0-14af-451e-8187-d41ba596ef71,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-5fca5ed8-26e9-4b27-b87c-7ceac64d0932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 3704
