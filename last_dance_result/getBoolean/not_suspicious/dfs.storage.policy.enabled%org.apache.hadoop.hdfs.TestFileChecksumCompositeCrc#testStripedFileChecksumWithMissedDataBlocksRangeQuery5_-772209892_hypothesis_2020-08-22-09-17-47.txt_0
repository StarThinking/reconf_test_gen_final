reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496435983-172.17.0.2-1598088630820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35798,DS-5dc7e2eb-e25f-4696-8eea-979ff27bb382,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-8d6a13f2-6d07-4cf6-9535-6acc0d760ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-37bfc5a0-c21e-49ad-bb10-92dacaa79f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-a7a43ab3-bed5-4342-ae83-ec41296fc1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-1c2bace3-7c6a-4ad7-a0bb-87b804460e78,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-09d0e80e-3b05-4e56-a34f-27777ea1f44f,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-1bd64732-141b-4336-87ed-111d8976be7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-1742f333-ab6f-4215-a65e-a49c2d2ee579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496435983-172.17.0.2-1598088630820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35798,DS-5dc7e2eb-e25f-4696-8eea-979ff27bb382,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-8d6a13f2-6d07-4cf6-9535-6acc0d760ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-37bfc5a0-c21e-49ad-bb10-92dacaa79f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-a7a43ab3-bed5-4342-ae83-ec41296fc1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-1c2bace3-7c6a-4ad7-a0bb-87b804460e78,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-09d0e80e-3b05-4e56-a34f-27777ea1f44f,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-1bd64732-141b-4336-87ed-111d8976be7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-1742f333-ab6f-4215-a65e-a49c2d2ee579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469389537-172.17.0.2-1598088737562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44074,DS-eb495618-bccd-42a6-9729-c36c3bd64d51,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-fb332667-a1a9-4489-a0d5-2a1b6fb47831,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-5e1e026b-332c-48e9-b0db-7a3528f751c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-387fbf35-94a2-4e94-b35e-a71370efc3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-ef231016-2363-43f7-a4dd-2c5d2b7a58b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-5028802d-50d6-4962-b72c-9e6321961da9,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-edecd4ae-35ed-4dd2-830b-632a636bb441,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-fa8c6677-7782-4ee8-983f-21bdf12e351e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469389537-172.17.0.2-1598088737562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44074,DS-eb495618-bccd-42a6-9729-c36c3bd64d51,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-fb332667-a1a9-4489-a0d5-2a1b6fb47831,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-5e1e026b-332c-48e9-b0db-7a3528f751c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-387fbf35-94a2-4e94-b35e-a71370efc3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-ef231016-2363-43f7-a4dd-2c5d2b7a58b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-5028802d-50d6-4962-b72c-9e6321961da9,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-edecd4ae-35ed-4dd2-830b-632a636bb441,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-fa8c6677-7782-4ee8-983f-21bdf12e351e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177801601-172.17.0.2-1598088892928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34909,DS-b375f5b4-b764-48d1-b9a5-b5d3f203ea7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-eb063f5b-056b-47b1-b36b-d345798a5204,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-d161e420-e0ca-4c9f-bda8-9525b5b6e50b,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-b4e6e656-793b-4d63-ac82-1d2f79d9dfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-10532da5-07f8-409d-a907-6aeb45a06c54,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-1c073017-2c70-404f-ba9f-57eaf3812101,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-5fba004f-3fef-4751-a1df-3838577e2788,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-32d958c4-cd5b-4cef-a320-be19cf58796f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177801601-172.17.0.2-1598088892928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34909,DS-b375f5b4-b764-48d1-b9a5-b5d3f203ea7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-eb063f5b-056b-47b1-b36b-d345798a5204,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-d161e420-e0ca-4c9f-bda8-9525b5b6e50b,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-b4e6e656-793b-4d63-ac82-1d2f79d9dfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-10532da5-07f8-409d-a907-6aeb45a06c54,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-1c073017-2c70-404f-ba9f-57eaf3812101,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-5fba004f-3fef-4751-a1df-3838577e2788,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-32d958c4-cd5b-4cef-a320-be19cf58796f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323604866-172.17.0.2-1598089346378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36247,DS-f2d8dbe3-158d-4b48-87f4-0b1175cd28b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-33c350c5-b237-4c7c-bea2-a3b86af66337,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-09466af3-55b4-4cb2-a964-ee04ed9f7b63,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-0b90f4c4-6871-4c37-8bc5-98b0c26b93dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-b793a11b-20b1-4521-ba3d-fab231162d68,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-048fa643-e75d-4c49-97fe-48d76915a4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-9dd8c7e1-589e-49b4-b63b-4d10110f7ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-a8e5df07-d0d2-45b9-8b1b-00c834b1aa0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323604866-172.17.0.2-1598089346378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36247,DS-f2d8dbe3-158d-4b48-87f4-0b1175cd28b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-33c350c5-b237-4c7c-bea2-a3b86af66337,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-09466af3-55b4-4cb2-a964-ee04ed9f7b63,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-0b90f4c4-6871-4c37-8bc5-98b0c26b93dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-b793a11b-20b1-4521-ba3d-fab231162d68,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-048fa643-e75d-4c49-97fe-48d76915a4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-9dd8c7e1-589e-49b4-b63b-4d10110f7ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-a8e5df07-d0d2-45b9-8b1b-00c834b1aa0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341283892-172.17.0.2-1598089806546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39460,DS-0ffbdb43-d4ed-4c52-bbd4-f6b53985db96,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-f54b716c-960f-44b4-8bb9-6ee94a6240ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-2a406b6c-89bc-41a7-8437-f85dec7aa6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-68ed46c7-df16-4dd0-8c57-2acbb637ff39,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-7a8885fc-8e8b-4b99-a7ac-b8f6af722dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-f4494684-1391-4f10-a6fd-b37fc9792ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-3e484db3-5e62-4b97-9103-c51f87488b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-9cd7839a-1d62-45b4-b03a-7a35e31c0a98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341283892-172.17.0.2-1598089806546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39460,DS-0ffbdb43-d4ed-4c52-bbd4-f6b53985db96,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-f54b716c-960f-44b4-8bb9-6ee94a6240ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-2a406b6c-89bc-41a7-8437-f85dec7aa6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-68ed46c7-df16-4dd0-8c57-2acbb637ff39,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-7a8885fc-8e8b-4b99-a7ac-b8f6af722dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-f4494684-1391-4f10-a6fd-b37fc9792ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-3e484db3-5e62-4b97-9103-c51f87488b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-9cd7839a-1d62-45b4-b03a-7a35e31c0a98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455391666-172.17.0.2-1598090049419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45341,DS-c9379ba0-1dff-4516-ad1b-faf4e6c7ddb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-52dfc433-c365-45f1-8eca-2bba454130da,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-12b851fa-2e7f-4c06-b9ff-a4a0e70add78,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-f90574a6-b54f-4927-9b6b-7cec1c08d2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-b9b29e23-63c6-443f-880c-e85d685db533,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-2425b5a8-6767-4412-b364-5b7998705ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-547f9781-9232-4cac-a566-98b754f206ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-4ad48512-b2b0-4b95-bdf2-57b113a4c74c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455391666-172.17.0.2-1598090049419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45341,DS-c9379ba0-1dff-4516-ad1b-faf4e6c7ddb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-52dfc433-c365-45f1-8eca-2bba454130da,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-12b851fa-2e7f-4c06-b9ff-a4a0e70add78,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-f90574a6-b54f-4927-9b6b-7cec1c08d2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-b9b29e23-63c6-443f-880c-e85d685db533,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-2425b5a8-6767-4412-b364-5b7998705ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-547f9781-9232-4cac-a566-98b754f206ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-4ad48512-b2b0-4b95-bdf2-57b113a4c74c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320071343-172.17.0.2-1598090225071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43603,DS-4996444a-6730-4fa2-93c8-0d6c858f0702,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-1b43c00d-42cf-4e74-8add-c1d792428a18,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-7daabf03-2524-4c1f-82c7-54fcfba5509b,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-b8ac2990-fa51-4e40-829e-b9a3e1643acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-373a9409-0c0f-4f9d-96f1-6037cd90cecc,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-27a829fb-a03c-4382-aa34-8ebc7a9dbb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-0ca7949b-091b-4c86-ac8d-d1392807af47,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-dbd8c5d4-fa72-470f-9092-dbf5d96fb350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320071343-172.17.0.2-1598090225071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43603,DS-4996444a-6730-4fa2-93c8-0d6c858f0702,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-1b43c00d-42cf-4e74-8add-c1d792428a18,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-7daabf03-2524-4c1f-82c7-54fcfba5509b,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-b8ac2990-fa51-4e40-829e-b9a3e1643acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-373a9409-0c0f-4f9d-96f1-6037cd90cecc,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-27a829fb-a03c-4382-aa34-8ebc7a9dbb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-0ca7949b-091b-4c86-ac8d-d1392807af47,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-dbd8c5d4-fa72-470f-9092-dbf5d96fb350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404515442-172.17.0.2-1598090268446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39802,DS-52ca56a3-cc6f-4daf-b252-6dd631aaffa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-6f1d5d8e-ed31-424c-834b-111a0b2a5255,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-d974ab20-d78d-42f2-a9c1-d0363e5d8159,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-d2b9bfa2-6cb0-4b31-a05e-dbf39f771ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-ff0f56e5-7621-4254-851c-73b33fda7dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-2936bb70-5c7a-4b3e-95cc-347ab793d907,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-88e9a2ed-a853-4fb8-a091-8df0aed5968d,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-bc707937-fb06-42d1-ade3-6ecb55a3e176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404515442-172.17.0.2-1598090268446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39802,DS-52ca56a3-cc6f-4daf-b252-6dd631aaffa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-6f1d5d8e-ed31-424c-834b-111a0b2a5255,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-d974ab20-d78d-42f2-a9c1-d0363e5d8159,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-d2b9bfa2-6cb0-4b31-a05e-dbf39f771ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-ff0f56e5-7621-4254-851c-73b33fda7dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-2936bb70-5c7a-4b3e-95cc-347ab793d907,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-88e9a2ed-a853-4fb8-a091-8df0aed5968d,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-bc707937-fb06-42d1-ade3-6ecb55a3e176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435687642-172.17.0.2-1598090747953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36574,DS-87af0e2f-3ce5-4003-a9f1-f818c08ae115,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-4071fc75-dc4c-4caa-9b85-e0b4ff14a0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-9c0a1481-2418-4701-bfe1-a7a793cce79e,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-8e0cf45f-79cf-45f1-b66f-aa5bcf8636e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-27d14b92-29ce-4f3a-84f6-1b74f8fad7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-f5342392-ca14-4414-855c-6227e0532aed,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-3ae891b1-c4e3-4fe3-8cc0-d356b9411e88,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-008173f6-d9e0-4e7a-ae11-434564435236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435687642-172.17.0.2-1598090747953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36574,DS-87af0e2f-3ce5-4003-a9f1-f818c08ae115,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-4071fc75-dc4c-4caa-9b85-e0b4ff14a0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-9c0a1481-2418-4701-bfe1-a7a793cce79e,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-8e0cf45f-79cf-45f1-b66f-aa5bcf8636e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-27d14b92-29ce-4f3a-84f6-1b74f8fad7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-f5342392-ca14-4414-855c-6227e0532aed,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-3ae891b1-c4e3-4fe3-8cc0-d356b9411e88,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-008173f6-d9e0-4e7a-ae11-434564435236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319922164-172.17.0.2-1598091755934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33023,DS-8e63dbdc-5812-4ec8-8d4b-aee26e7b4127,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-65240e3d-b542-4e66-8aa2-59ed02ad0ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-085057c6-f526-48d3-956a-ef328272cbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-8cd72719-2190-4f38-a1c2-254b336be7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-a21e63e8-dc2f-460a-8fd4-9935e646a6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-03cf3d41-e2a9-4d7d-999d-1eac7b172d67,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-c3238194-6ae8-4de8-9ea9-363808ed5e29,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-6dae2650-9d97-499c-9d08-dd817638c67b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319922164-172.17.0.2-1598091755934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33023,DS-8e63dbdc-5812-4ec8-8d4b-aee26e7b4127,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-65240e3d-b542-4e66-8aa2-59ed02ad0ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-085057c6-f526-48d3-956a-ef328272cbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-8cd72719-2190-4f38-a1c2-254b336be7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-a21e63e8-dc2f-460a-8fd4-9935e646a6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-03cf3d41-e2a9-4d7d-999d-1eac7b172d67,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-c3238194-6ae8-4de8-9ea9-363808ed5e29,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-6dae2650-9d97-499c-9d08-dd817638c67b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221106804-172.17.0.2-1598092404512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39761,DS-31522c3f-9039-4c20-ba41-53d51194912f,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-3f47475a-bc9e-4451-ad5f-814cd0ea30e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-9708cf40-8430-4fda-9c03-b8d621bdf532,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-5f2029fa-620b-49ee-ac1c-9f79ddda569d,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-a3ca6bdc-9222-43cc-ba7f-9bff7396493c,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-16e0eef5-2fd2-4ebc-b89f-823ef5cfdd41,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-9f1cab12-e1e2-48cd-8608-26818ea1fd29,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-f95215ec-8f03-41e2-a298-cdfb3e586614,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221106804-172.17.0.2-1598092404512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39761,DS-31522c3f-9039-4c20-ba41-53d51194912f,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-3f47475a-bc9e-4451-ad5f-814cd0ea30e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-9708cf40-8430-4fda-9c03-b8d621bdf532,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-5f2029fa-620b-49ee-ac1c-9f79ddda569d,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-a3ca6bdc-9222-43cc-ba7f-9bff7396493c,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-16e0eef5-2fd2-4ebc-b89f-823ef5cfdd41,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-9f1cab12-e1e2-48cd-8608-26818ea1fd29,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-f95215ec-8f03-41e2-a298-cdfb3e586614,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839536123-172.17.0.2-1598093014290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34960,DS-23ba4b41-8569-4b08-8f48-3fe49adb691e,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-cb26740d-f6c3-4d80-bef0-9c18b31c5869,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-d702c3fb-9871-472e-a7d4-4424cd9a2104,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-193849ec-d207-41f6-8ad6-09b395d5db7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-950d5c08-55e1-4bc5-8dab-99c7c8a7126b,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-16c0bb12-2985-4bbd-a55e-cbe9b685f7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-ff5b2e1a-0378-49af-b1be-faeda0b1da3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-77297246-4879-4946-8d77-9b96df34d674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839536123-172.17.0.2-1598093014290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34960,DS-23ba4b41-8569-4b08-8f48-3fe49adb691e,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-cb26740d-f6c3-4d80-bef0-9c18b31c5869,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-d702c3fb-9871-472e-a7d4-4424cd9a2104,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-193849ec-d207-41f6-8ad6-09b395d5db7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-950d5c08-55e1-4bc5-8dab-99c7c8a7126b,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-16c0bb12-2985-4bbd-a55e-cbe9b685f7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-ff5b2e1a-0378-49af-b1be-faeda0b1da3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-77297246-4879-4946-8d77-9b96df34d674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546400984-172.17.0.2-1598093302295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34303,DS-4bc05f9a-3bdf-488c-b1c8-797e74938d48,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-8d9eb2b7-207e-4ab5-bd9f-b128c6c51523,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-d5cbef14-8690-4c2d-9cc0-22c3d7476faa,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-2ecc8602-f908-4b60-ba65-65f3dd86b83f,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-e571f224-ed59-4af7-9af1-b4c5d4230d03,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-b2f1dfae-c598-43f0-b110-4be18a48c5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-3330fb56-34f0-4238-b431-d2185e756362,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-bf5ac57f-6953-4af8-b499-d469ca726aea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546400984-172.17.0.2-1598093302295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34303,DS-4bc05f9a-3bdf-488c-b1c8-797e74938d48,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-8d9eb2b7-207e-4ab5-bd9f-b128c6c51523,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-d5cbef14-8690-4c2d-9cc0-22c3d7476faa,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-2ecc8602-f908-4b60-ba65-65f3dd86b83f,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-e571f224-ed59-4af7-9af1-b4c5d4230d03,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-b2f1dfae-c598-43f0-b110-4be18a48c5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-3330fb56-34f0-4238-b431-d2185e756362,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-bf5ac57f-6953-4af8-b499-d469ca726aea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5658
