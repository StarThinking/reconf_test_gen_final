reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356993034-172.17.0.16-1598157446200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40171,DS-0aa6dde4-e73d-4a52-abf9-ad5127640930,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-6488220c-613c-4f50-b7a6-9a3c991d94c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-f65c57ca-61c5-4304-a738-6e0e75fc1454,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-7eb4e86c-0558-4fed-ae25-85cc27f7117e,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-b2610359-1f93-446b-ac93-c53f38467785,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-cecaf113-146d-4a6b-9985-366bf8a520fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-a1492093-cde7-421a-b161-21e6f1a9b023,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-074e4072-be75-472f-b2e7-41628b94c139,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356993034-172.17.0.16-1598157446200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40171,DS-0aa6dde4-e73d-4a52-abf9-ad5127640930,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-6488220c-613c-4f50-b7a6-9a3c991d94c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-f65c57ca-61c5-4304-a738-6e0e75fc1454,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-7eb4e86c-0558-4fed-ae25-85cc27f7117e,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-b2610359-1f93-446b-ac93-c53f38467785,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-cecaf113-146d-4a6b-9985-366bf8a520fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-a1492093-cde7-421a-b161-21e6f1a9b023,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-074e4072-be75-472f-b2e7-41628b94c139,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391197657-172.17.0.16-1598158259594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42077,DS-d8298b27-82b0-4f84-ae68-a8d451b408a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-9acb40a4-5b57-4410-9d1e-218df8ac79dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-e81e5a12-6c6e-4295-bb9f-e1c902fdff05,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-f0a1f659-9ee4-45e1-86d5-68fc60c06cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-c3c825a2-f322-4d15-9d53-035b81fefa51,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-99746748-fc6a-41d0-970f-94f15d0d4f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-51f322e0-2684-4b98-90c6-278f1b4c2c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-8ff49954-54ab-4343-940a-9a3c60249d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391197657-172.17.0.16-1598158259594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42077,DS-d8298b27-82b0-4f84-ae68-a8d451b408a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-9acb40a4-5b57-4410-9d1e-218df8ac79dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-e81e5a12-6c6e-4295-bb9f-e1c902fdff05,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-f0a1f659-9ee4-45e1-86d5-68fc60c06cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-c3c825a2-f322-4d15-9d53-035b81fefa51,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-99746748-fc6a-41d0-970f-94f15d0d4f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-51f322e0-2684-4b98-90c6-278f1b4c2c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-8ff49954-54ab-4343-940a-9a3c60249d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892088612-172.17.0.16-1598158536476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45357,DS-66c27ff8-76bf-4912-8d5f-5df2c88f5871,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-a6d8b2e9-3157-46c8-803b-a4aeb546dca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-c76df5e4-1504-44fb-bebd-900ff81d0cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-9d93311a-7534-483d-9da8-e41d32ce7240,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-60a454b3-b4da-4e1c-81ea-ada37bdaff6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-5db6dc09-2e6b-49cd-ac8d-7330574870b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-69294aa7-9a7b-4db1-ba80-c59f302ea99f,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-a62c53a0-a8d4-4410-9d97-3627834f306b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892088612-172.17.0.16-1598158536476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45357,DS-66c27ff8-76bf-4912-8d5f-5df2c88f5871,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-a6d8b2e9-3157-46c8-803b-a4aeb546dca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-c76df5e4-1504-44fb-bebd-900ff81d0cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-9d93311a-7534-483d-9da8-e41d32ce7240,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-60a454b3-b4da-4e1c-81ea-ada37bdaff6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-5db6dc09-2e6b-49cd-ac8d-7330574870b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-69294aa7-9a7b-4db1-ba80-c59f302ea99f,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-a62c53a0-a8d4-4410-9d97-3627834f306b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554248964-172.17.0.16-1598158918957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34112,DS-c8ab690b-cfb7-45bc-aeb9-46350026ff9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-e7b6c2fe-3260-49a6-a6a4-1e1a1ddd2ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-5decd826-8713-411e-ae3c-e584aa4b38c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-f5310a66-e8bb-40f9-82cb-514c47beb6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-7e515d55-2582-4274-aeeb-ccb840a9e5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-9f5ef972-dace-4ee2-b5a3-1dce13a08465,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-9fc42f1a-dee6-4134-9141-b07891f82c35,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-120ee5d9-0833-474b-b263-b5cc4ae74c13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554248964-172.17.0.16-1598158918957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34112,DS-c8ab690b-cfb7-45bc-aeb9-46350026ff9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-e7b6c2fe-3260-49a6-a6a4-1e1a1ddd2ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-5decd826-8713-411e-ae3c-e584aa4b38c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-f5310a66-e8bb-40f9-82cb-514c47beb6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-7e515d55-2582-4274-aeeb-ccb840a9e5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-9f5ef972-dace-4ee2-b5a3-1dce13a08465,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-9fc42f1a-dee6-4134-9141-b07891f82c35,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-120ee5d9-0833-474b-b263-b5cc4ae74c13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559743196-172.17.0.16-1598159054589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38815,DS-e0db9d22-c305-4c6c-ab9d-eaa3b9a9f06c,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-c759a438-9992-4dc0-987b-01fcad4fb993,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-8a21a5ae-5532-4751-b445-41d17355e50b,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-53389a08-6906-4b8c-8a30-c8bd6fa90f68,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-1d64f7f9-c2d2-440f-8704-2f18d313c1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-388b90a6-8ebb-458a-997c-e630b1409dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-d6f20fa5-345b-4bc9-8be0-3092a6a0441d,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-0fe1681f-8576-4cf4-9ad8-3a2a53e2c922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559743196-172.17.0.16-1598159054589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38815,DS-e0db9d22-c305-4c6c-ab9d-eaa3b9a9f06c,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-c759a438-9992-4dc0-987b-01fcad4fb993,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-8a21a5ae-5532-4751-b445-41d17355e50b,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-53389a08-6906-4b8c-8a30-c8bd6fa90f68,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-1d64f7f9-c2d2-440f-8704-2f18d313c1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-388b90a6-8ebb-458a-997c-e630b1409dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-d6f20fa5-345b-4bc9-8be0-3092a6a0441d,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-0fe1681f-8576-4cf4-9ad8-3a2a53e2c922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535238084-172.17.0.16-1598159084009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34259,DS-2b8bc9f5-c3c7-426a-877c-e40de00d9c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-c2bad90e-5809-4978-894a-e93f8d42108d,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-4a6c29a5-3bf7-47cb-a965-446dce3d4575,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-6b781e80-94cf-4258-b372-1dad8c549c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-2a27e664-06a3-4b17-8a76-373337278af4,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-2acea9f7-a26a-479d-8793-4312e2d6188d,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-7315185a-89fe-4c33-9ba4-97865590fd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-39185c3c-d1bc-4859-93aa-06aed12e0385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535238084-172.17.0.16-1598159084009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34259,DS-2b8bc9f5-c3c7-426a-877c-e40de00d9c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-c2bad90e-5809-4978-894a-e93f8d42108d,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-4a6c29a5-3bf7-47cb-a965-446dce3d4575,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-6b781e80-94cf-4258-b372-1dad8c549c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-2a27e664-06a3-4b17-8a76-373337278af4,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-2acea9f7-a26a-479d-8793-4312e2d6188d,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-7315185a-89fe-4c33-9ba4-97865590fd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-39185c3c-d1bc-4859-93aa-06aed12e0385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628807297-172.17.0.16-1598159500169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43130,DS-d3dcee98-a6a0-42a9-add4-ac4983d1aab1,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-ac2cef4a-cbed-4a18-b0d4-afb31d2fc9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-df9a6826-e182-408e-a983-e8e257e374ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-a1b50e3d-cfdb-42b3-9930-46a151413936,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-975a4096-c81e-4ac9-bbf4-a400d40ea0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-a0409ae2-53e5-47ed-ac63-bdbb23e7902e,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-8f8d883a-e60e-4b44-8d4c-8d65b7e98a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-91996a45-a204-443e-a0d3-aaaaffec8fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628807297-172.17.0.16-1598159500169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43130,DS-d3dcee98-a6a0-42a9-add4-ac4983d1aab1,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-ac2cef4a-cbed-4a18-b0d4-afb31d2fc9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-df9a6826-e182-408e-a983-e8e257e374ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-a1b50e3d-cfdb-42b3-9930-46a151413936,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-975a4096-c81e-4ac9-bbf4-a400d40ea0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-a0409ae2-53e5-47ed-ac63-bdbb23e7902e,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-8f8d883a-e60e-4b44-8d4c-8d65b7e98a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-91996a45-a204-443e-a0d3-aaaaffec8fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-660708402-172.17.0.16-1598159727377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42483,DS-dfce136c-77d2-48d2-aa4b-c3fcd20a6260,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-02d05eb5-66d2-4208-9a20-e27d8f604cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-f634b1bb-b754-4880-afbb-ec62bcfdd123,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-36ba1a73-b32f-4b4c-b1a7-0dcb6dcb5320,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-1f31f10f-7fbc-4096-b842-3df5ff214c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-d040212e-df07-4868-873e-58bc43da7c40,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-e011fbc9-601e-40d9-8df6-4401b70c5ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-672360f6-47c7-4433-b854-ba9217d1d554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-660708402-172.17.0.16-1598159727377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42483,DS-dfce136c-77d2-48d2-aa4b-c3fcd20a6260,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-02d05eb5-66d2-4208-9a20-e27d8f604cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-f634b1bb-b754-4880-afbb-ec62bcfdd123,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-36ba1a73-b32f-4b4c-b1a7-0dcb6dcb5320,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-1f31f10f-7fbc-4096-b842-3df5ff214c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-d040212e-df07-4868-873e-58bc43da7c40,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-e011fbc9-601e-40d9-8df6-4401b70c5ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-672360f6-47c7-4433-b854-ba9217d1d554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228709504-172.17.0.16-1598159972545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35081,DS-f8256155-b4d1-44a8-b8c1-979388945275,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-f07848b4-faf8-49b1-9079-6cec9af7dbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-6b0c45a7-3f8a-40c9-8043-75162918c6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-253de164-dfa4-4340-b8f7-97798a873f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-2bc72d6d-f511-431e-9a15-0977e3d9068f,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-30b81d95-c031-40fb-abe0-7d66fe98ce7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-331ac330-dae6-43c3-87ee-4cf135f7fbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-585cdad6-2377-4082-8186-81a92dc3b8f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228709504-172.17.0.16-1598159972545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35081,DS-f8256155-b4d1-44a8-b8c1-979388945275,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-f07848b4-faf8-49b1-9079-6cec9af7dbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-6b0c45a7-3f8a-40c9-8043-75162918c6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-253de164-dfa4-4340-b8f7-97798a873f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-2bc72d6d-f511-431e-9a15-0977e3d9068f,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-30b81d95-c031-40fb-abe0-7d66fe98ce7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-331ac330-dae6-43c3-87ee-4cf135f7fbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-585cdad6-2377-4082-8186-81a92dc3b8f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464527815-172.17.0.16-1598160154353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42395,DS-3c5a2c93-a50e-44cc-9d80-f43ab3ec952c,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-483f80e3-f536-459d-ad0a-a545c38e9292,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-e7674ae1-2725-4048-926d-349911667720,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-b60c7c74-98fa-41b7-b1f4-06d9bb08e156,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-e77ae3ea-acd9-453d-89d0-3c705f782317,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-0bd5b5a7-12cd-4e9f-bebd-e8ed09e9a442,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-85c74930-0588-4247-94ef-a1ec1c9fcef1,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-5023a627-5f4a-4b47-a002-878d5553a513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464527815-172.17.0.16-1598160154353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42395,DS-3c5a2c93-a50e-44cc-9d80-f43ab3ec952c,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-483f80e3-f536-459d-ad0a-a545c38e9292,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-e7674ae1-2725-4048-926d-349911667720,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-b60c7c74-98fa-41b7-b1f4-06d9bb08e156,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-e77ae3ea-acd9-453d-89d0-3c705f782317,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-0bd5b5a7-12cd-4e9f-bebd-e8ed09e9a442,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-85c74930-0588-4247-94ef-a1ec1c9fcef1,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-5023a627-5f4a-4b47-a002-878d5553a513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1947668170-172.17.0.16-1598160736961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39734,DS-f869e519-f65b-4e0c-bf78-2d79be164be2,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-4f0036c4-9618-4e0c-98c2-fd92a090eead,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-02785376-7e5c-451f-a2ff-a82ebce3250f,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-21f812f0-5886-4833-a8ca-8503be07ee07,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-18c6f693-149d-41d2-919f-348762855374,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-a34737bb-d3c8-429e-bea1-1348d6ba67d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-a5e2c30a-f418-4cfe-a81a-92b75c530312,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-a2b0f755-3e30-447e-95d1-000df2640c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1947668170-172.17.0.16-1598160736961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39734,DS-f869e519-f65b-4e0c-bf78-2d79be164be2,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-4f0036c4-9618-4e0c-98c2-fd92a090eead,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-02785376-7e5c-451f-a2ff-a82ebce3250f,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-21f812f0-5886-4833-a8ca-8503be07ee07,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-18c6f693-149d-41d2-919f-348762855374,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-a34737bb-d3c8-429e-bea1-1348d6ba67d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-a5e2c30a-f418-4cfe-a81a-92b75c530312,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-a2b0f755-3e30-447e-95d1-000df2640c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107756883-172.17.0.16-1598161729684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35025,DS-1685e499-95b1-46bb-a6b6-69453417d222,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-97fc502d-01ac-403f-b7a4-c0bb64b2b1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-84a6d59e-5fab-49b3-ab8b-e250dd650337,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-31ff274c-c3b8-432d-9b09-09863b523ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-6e99b4d5-01fa-4800-9276-2bcae6b3316a,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-0487b13a-2499-4518-89e5-8179dc7bb8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-f8aa1cca-490f-490e-8fd0-a20f15c7e865,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-1160fa62-44c0-4a1c-82ad-ce0b8179a672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107756883-172.17.0.16-1598161729684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35025,DS-1685e499-95b1-46bb-a6b6-69453417d222,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-97fc502d-01ac-403f-b7a4-c0bb64b2b1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-84a6d59e-5fab-49b3-ab8b-e250dd650337,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-31ff274c-c3b8-432d-9b09-09863b523ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-6e99b4d5-01fa-4800-9276-2bcae6b3316a,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-0487b13a-2499-4518-89e5-8179dc7bb8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-f8aa1cca-490f-490e-8fd0-a20f15c7e865,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-1160fa62-44c0-4a1c-82ad-ce0b8179a672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635919037-172.17.0.16-1598161941586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40252,DS-0f5ac0c4-46e5-460d-8374-472731d278ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-f96753f4-319c-4365-bfcc-2f22869fc835,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-c424fb5d-05f0-4974-8236-73cbdde2ebcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-844b4c70-debe-4111-923a-4aa553cde2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-2c004c8c-9d05-457c-9472-57613fb3fa37,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-336f68c5-fa51-432e-ab50-11504b91627b,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-b8ac198f-c921-4a81-b80b-5c20549d4dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-fb89f9d4-1e79-4f0e-8ad5-4cb099c3307b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635919037-172.17.0.16-1598161941586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40252,DS-0f5ac0c4-46e5-460d-8374-472731d278ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-f96753f4-319c-4365-bfcc-2f22869fc835,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-c424fb5d-05f0-4974-8236-73cbdde2ebcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-844b4c70-debe-4111-923a-4aa553cde2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-2c004c8c-9d05-457c-9472-57613fb3fa37,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-336f68c5-fa51-432e-ab50-11504b91627b,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-b8ac198f-c921-4a81-b80b-5c20549d4dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-fb89f9d4-1e79-4f0e-8ad5-4cb099c3307b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254008058-172.17.0.16-1598162133200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38766,DS-559d471d-46d2-424b-a6d3-e79f3b826613,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-038780e3-8e46-4abc-b94f-d4045cd83ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-d1e7b77d-985a-4777-a67f-e7b5ec06af53,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-e023d2e8-135d-4b27-9e85-39dd921ffb65,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-a5f81de7-6477-4351-ae78-83406374fbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-6a44206d-0ac5-4417-a7cd-32e52e62569a,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-85dc34d1-39b6-497f-8202-7b8bf9fcfb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-4e37b285-130d-49be-a9cb-fe4d8af38286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254008058-172.17.0.16-1598162133200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38766,DS-559d471d-46d2-424b-a6d3-e79f3b826613,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-038780e3-8e46-4abc-b94f-d4045cd83ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-d1e7b77d-985a-4777-a67f-e7b5ec06af53,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-e023d2e8-135d-4b27-9e85-39dd921ffb65,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-a5f81de7-6477-4351-ae78-83406374fbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-6a44206d-0ac5-4417-a7cd-32e52e62569a,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-85dc34d1-39b6-497f-8202-7b8bf9fcfb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-4e37b285-130d-49be-a9cb-fe4d8af38286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097528138-172.17.0.16-1598162345894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39321,DS-7e59cf01-83d6-48b1-bbdb-77484802c835,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-db57884c-9641-491f-9b71-af74dece9c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-cf2f7a3e-edbb-47fe-b6ed-8ba33a50b147,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-0ad945e3-69d4-49c6-b012-12c66c441eba,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-46089fc2-50fb-45e7-a1f5-e72077e21699,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-b60bef95-e4f2-4f0b-a749-6874403c0d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-d6e85213-826c-4d50-b6ea-74247b4adab9,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-120ccb39-bbe7-4c45-b612-168d898b9f62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097528138-172.17.0.16-1598162345894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39321,DS-7e59cf01-83d6-48b1-bbdb-77484802c835,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-db57884c-9641-491f-9b71-af74dece9c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-cf2f7a3e-edbb-47fe-b6ed-8ba33a50b147,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-0ad945e3-69d4-49c6-b012-12c66c441eba,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-46089fc2-50fb-45e7-a1f5-e72077e21699,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-b60bef95-e4f2-4f0b-a749-6874403c0d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-d6e85213-826c-4d50-b6ea-74247b4adab9,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-120ccb39-bbe7-4c45-b612-168d898b9f62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203203518-172.17.0.16-1598162461920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45706,DS-7eee1687-306e-4558-925c-83eb53495e18,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-b3480f39-0524-441b-a4d8-b9c8544b5986,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-964a2e8e-d306-4ba3-b3bd-84c201a6953d,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-df5e7b5d-9f5e-43c6-8c58-193809441006,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-4eeb56a9-178c-4cbf-85ec-a6e9b69684c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-0974e3c8-d394-4953-9b24-8534859cff9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-e050bd02-7363-4426-b4bb-b5c81af42b17,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-c5caf1a5-6448-425f-8ddc-3ab26e319ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203203518-172.17.0.16-1598162461920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45706,DS-7eee1687-306e-4558-925c-83eb53495e18,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-b3480f39-0524-441b-a4d8-b9c8544b5986,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-964a2e8e-d306-4ba3-b3bd-84c201a6953d,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-df5e7b5d-9f5e-43c6-8c58-193809441006,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-4eeb56a9-178c-4cbf-85ec-a6e9b69684c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-0974e3c8-d394-4953-9b24-8534859cff9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-e050bd02-7363-4426-b4bb-b5c81af42b17,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-c5caf1a5-6448-425f-8ddc-3ab26e319ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5205
