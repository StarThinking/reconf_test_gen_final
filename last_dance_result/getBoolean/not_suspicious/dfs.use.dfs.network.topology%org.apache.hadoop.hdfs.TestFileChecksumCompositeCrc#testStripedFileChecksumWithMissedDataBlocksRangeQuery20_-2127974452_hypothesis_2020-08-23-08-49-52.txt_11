reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177771960-172.17.0.15-1598174004854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38287,DS-6a7270ff-547e-4df8-b504-ebc5e0ac552c,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-a1fefd60-5fb4-4df1-8b0b-17ad74fb0cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-d76b0515-b2ea-493c-9536-2e543a9860c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-6dc49f67-4707-4f80-9a72-b58bd16a2657,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-2355786c-1643-4d01-83a4-10f198c22d50,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-6ad9b322-5b49-4ebf-b847-2f2dc20a0890,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-c31d8c8e-3a57-4aac-95b1-c7e9c131c2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-d8a8fe6b-1255-42bc-8fc3-cb150c3d7cbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177771960-172.17.0.15-1598174004854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38287,DS-6a7270ff-547e-4df8-b504-ebc5e0ac552c,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-a1fefd60-5fb4-4df1-8b0b-17ad74fb0cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-d76b0515-b2ea-493c-9536-2e543a9860c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-6dc49f67-4707-4f80-9a72-b58bd16a2657,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-2355786c-1643-4d01-83a4-10f198c22d50,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-6ad9b322-5b49-4ebf-b847-2f2dc20a0890,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-c31d8c8e-3a57-4aac-95b1-c7e9c131c2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-d8a8fe6b-1255-42bc-8fc3-cb150c3d7cbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409874770-172.17.0.15-1598174102683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39500,DS-ee0c9aea-9e34-4fb0-9189-bb4d45881235,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-9803f131-67a9-44f7-83dd-e780b9fb08c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-8e9d65f9-50ca-4cf6-bd88-08f0fb3dbb05,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-bcae30ad-0821-4e20-a870-f978d18b36c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-335f9e43-216d-4798-be09-36e9a2e014b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-f579da7e-4a54-40d8-a38d-1c22f5d785a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-378c176e-bdb4-42e9-932a-a24c5bc95d14,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-3d537e14-bb38-48e0-bd85-fdbd7d92a8de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409874770-172.17.0.15-1598174102683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39500,DS-ee0c9aea-9e34-4fb0-9189-bb4d45881235,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-9803f131-67a9-44f7-83dd-e780b9fb08c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-8e9d65f9-50ca-4cf6-bd88-08f0fb3dbb05,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-bcae30ad-0821-4e20-a870-f978d18b36c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-335f9e43-216d-4798-be09-36e9a2e014b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-f579da7e-4a54-40d8-a38d-1c22f5d785a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-378c176e-bdb4-42e9-932a-a24c5bc95d14,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-3d537e14-bb38-48e0-bd85-fdbd7d92a8de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382004688-172.17.0.15-1598174184843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42711,DS-69672c9e-da79-4f9e-8001-35a0b910726f,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-bb8171ed-63b8-4d1d-950a-62fe9169a995,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-580775df-c6c0-4cba-b9e0-77ec0d526675,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-52892f4f-ed03-4b32-a6bb-88e2a0064b99,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-0596e216-4895-440a-9978-71c973de4bff,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-d6f28cbc-1517-421e-8a47-d9cb07fa987a,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-cbe11dd1-ad68-439c-bebd-4156c2435d74,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-2ad3654f-5ba6-4bee-9977-18668b633f08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382004688-172.17.0.15-1598174184843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42711,DS-69672c9e-da79-4f9e-8001-35a0b910726f,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-bb8171ed-63b8-4d1d-950a-62fe9169a995,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-580775df-c6c0-4cba-b9e0-77ec0d526675,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-52892f4f-ed03-4b32-a6bb-88e2a0064b99,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-0596e216-4895-440a-9978-71c973de4bff,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-d6f28cbc-1517-421e-8a47-d9cb07fa987a,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-cbe11dd1-ad68-439c-bebd-4156c2435d74,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-2ad3654f-5ba6-4bee-9977-18668b633f08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008629891-172.17.0.15-1598174527985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45528,DS-9a8c73c2-1dc4-4118-badc-52f3c92875a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-0cd27080-f45b-4c1f-b69b-aa0af13d1e81,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-75923279-1060-4bba-99cc-b3c24cfc4dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-496484e3-88e8-45f1-954d-45438f8f7773,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-4a29317e-fbf6-4cb0-bc96-196ffb676b51,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-edb52d81-ba6f-4709-b4c7-219e222ba3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-5811fb6b-d659-4543-95f6-e0ae0f48c948,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-0d723964-abe5-4e87-bdd7-3b96255b88fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008629891-172.17.0.15-1598174527985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45528,DS-9a8c73c2-1dc4-4118-badc-52f3c92875a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-0cd27080-f45b-4c1f-b69b-aa0af13d1e81,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-75923279-1060-4bba-99cc-b3c24cfc4dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-496484e3-88e8-45f1-954d-45438f8f7773,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-4a29317e-fbf6-4cb0-bc96-196ffb676b51,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-edb52d81-ba6f-4709-b4c7-219e222ba3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-5811fb6b-d659-4543-95f6-e0ae0f48c948,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-0d723964-abe5-4e87-bdd7-3b96255b88fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736632252-172.17.0.15-1598174656571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39444,DS-189d041c-fdb8-44d6-bfd5-8b8d84803c06,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-1c6efb86-f704-413a-be57-477ecf23c56a,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-9c84d1f5-c745-4084-9fd9-00f2fac100bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-276d0200-6e22-4d89-a9d9-1366b415badb,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-93a083c9-1c4b-4e2a-917d-e37151ecd3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-3fc55d90-d1c8-477b-b397-741a5107604b,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-0838a95c-6968-445d-a8f0-4349dbca758f,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-74e07b94-e06d-471f-98cb-306c06c19772,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736632252-172.17.0.15-1598174656571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39444,DS-189d041c-fdb8-44d6-bfd5-8b8d84803c06,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-1c6efb86-f704-413a-be57-477ecf23c56a,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-9c84d1f5-c745-4084-9fd9-00f2fac100bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-276d0200-6e22-4d89-a9d9-1366b415badb,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-93a083c9-1c4b-4e2a-917d-e37151ecd3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-3fc55d90-d1c8-477b-b397-741a5107604b,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-0838a95c-6968-445d-a8f0-4349dbca758f,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-74e07b94-e06d-471f-98cb-306c06c19772,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508064848-172.17.0.15-1598174738724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36283,DS-db7b90f6-0db7-4612-baaa-47491991e79a,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-feacda99-09fd-4d16-8506-5b46cdf3b6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-d8b1549f-4d35-4b93-a32f-e5c99e0804a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-e2172196-3567-41a9-bc2e-4beacf3ff205,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-4bbc2a5c-1fc3-4eee-8e0b-1f302b7c6e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-fb921960-9cce-4678-801b-a42adcd5aa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-168a8674-4bb4-41d3-b4bb-144afac20259,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-db074813-9844-467d-bfb1-f0ce28ce01e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508064848-172.17.0.15-1598174738724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36283,DS-db7b90f6-0db7-4612-baaa-47491991e79a,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-feacda99-09fd-4d16-8506-5b46cdf3b6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-d8b1549f-4d35-4b93-a32f-e5c99e0804a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-e2172196-3567-41a9-bc2e-4beacf3ff205,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-4bbc2a5c-1fc3-4eee-8e0b-1f302b7c6e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-fb921960-9cce-4678-801b-a42adcd5aa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-168a8674-4bb4-41d3-b4bb-144afac20259,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-db074813-9844-467d-bfb1-f0ce28ce01e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910562457-172.17.0.15-1598174877203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34545,DS-112f10f6-abcd-4943-be9a-03dc28a2fd06,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-fcef345e-ee69-4986-84a9-6c6e5c9d9caa,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-d9517426-278a-439c-b2fd-c0bc36ac15a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-b09c3c1f-2c99-4ad1-8b23-83d840c5162f,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-9400e8e9-5c4c-4458-b5b0-8653526f5977,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-fa1ef541-6c79-4406-950b-7316c9a7a567,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-b81a8ec2-a32a-495a-8b15-f36b954b1075,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-6d692352-dd68-4f02-b60d-e972bff1daa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910562457-172.17.0.15-1598174877203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34545,DS-112f10f6-abcd-4943-be9a-03dc28a2fd06,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-fcef345e-ee69-4986-84a9-6c6e5c9d9caa,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-d9517426-278a-439c-b2fd-c0bc36ac15a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-b09c3c1f-2c99-4ad1-8b23-83d840c5162f,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-9400e8e9-5c4c-4458-b5b0-8653526f5977,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-fa1ef541-6c79-4406-950b-7316c9a7a567,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-b81a8ec2-a32a-495a-8b15-f36b954b1075,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-6d692352-dd68-4f02-b60d-e972bff1daa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975309613-172.17.0.15-1598175229892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34967,DS-62f77fcc-5fc2-45d6-b44f-b7cd41138c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-d1f7f0ab-07d3-4146-85cb-f23cf0af3200,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-b2d9129a-9838-4785-9c26-546b9b2e63f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-f82cd6f6-6f0a-44d4-a55d-d9e7cec05145,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-5e40522f-15b8-4bab-b458-4fd9737073a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-0720470b-8196-4c6c-bcf9-c871264a7623,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-879e6f18-f3fb-4e7c-a509-ca6bffd663ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-480972a2-6a30-427a-9679-dd1ddfd0871b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975309613-172.17.0.15-1598175229892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34967,DS-62f77fcc-5fc2-45d6-b44f-b7cd41138c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-d1f7f0ab-07d3-4146-85cb-f23cf0af3200,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-b2d9129a-9838-4785-9c26-546b9b2e63f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-f82cd6f6-6f0a-44d4-a55d-d9e7cec05145,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-5e40522f-15b8-4bab-b458-4fd9737073a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-0720470b-8196-4c6c-bcf9-c871264a7623,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-879e6f18-f3fb-4e7c-a509-ca6bffd663ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-480972a2-6a30-427a-9679-dd1ddfd0871b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862358668-172.17.0.15-1598175563955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36073,DS-891a34d9-fba5-4466-a59a-44b25837375e,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-1f313e33-7797-4a34-a735-790ae6c1cb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-143f9199-08cd-4858-9893-3fc266d5ee41,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-abc23cec-fd4d-4630-89ae-647862e97733,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-e4d72574-8224-4215-97a4-79a5bb9bd290,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-532e2e7d-ed11-4e36-a364-9189792b2e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-4c3fb269-1709-49fe-8606-18b4c05849be,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-cee0cf4e-f839-4ae6-a491-be41bc2ecd9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862358668-172.17.0.15-1598175563955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36073,DS-891a34d9-fba5-4466-a59a-44b25837375e,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-1f313e33-7797-4a34-a735-790ae6c1cb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-143f9199-08cd-4858-9893-3fc266d5ee41,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-abc23cec-fd4d-4630-89ae-647862e97733,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-e4d72574-8224-4215-97a4-79a5bb9bd290,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-532e2e7d-ed11-4e36-a364-9189792b2e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-4c3fb269-1709-49fe-8606-18b4c05849be,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-cee0cf4e-f839-4ae6-a491-be41bc2ecd9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1998328663-172.17.0.15-1598176242846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33493,DS-c165e124-8cae-4349-b82a-f38962ff1029,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-7cdacaa1-6ccd-4b25-9985-0e3673f7c17d,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-b9810411-4484-4db0-a75c-ae46f10eb22f,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-dea48b9d-f195-4a14-b53c-8c999be371c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-dc03faa0-94d2-4e42-bda2-b16d3bbef269,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-f985c72b-d68f-476e-bb2d-bb96dd005362,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-9503c8a8-053b-4255-9217-a4379506aade,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-c4271b65-f669-422d-82ac-c52eacf0389c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1998328663-172.17.0.15-1598176242846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33493,DS-c165e124-8cae-4349-b82a-f38962ff1029,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-7cdacaa1-6ccd-4b25-9985-0e3673f7c17d,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-b9810411-4484-4db0-a75c-ae46f10eb22f,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-dea48b9d-f195-4a14-b53c-8c999be371c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-dc03faa0-94d2-4e42-bda2-b16d3bbef269,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-f985c72b-d68f-476e-bb2d-bb96dd005362,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-9503c8a8-053b-4255-9217-a4379506aade,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-c4271b65-f669-422d-82ac-c52eacf0389c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983688065-172.17.0.15-1598176370008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42510,DS-18030eac-e13d-4078-af4e-e51cbc4da589,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-9b5507f7-ce74-4768-90a4-721d9086d277,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-7861b0d4-3183-4656-bd2a-4721391146cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-5317f00b-aec7-4f56-a607-0658c1b1d9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-2df3a222-9e3f-457d-a6f2-55467a2996a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-7622e755-817e-455f-b8ae-46ce7bad803c,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-54978a65-3856-418f-938e-1a6312e1e947,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-9255d807-b911-4598-a75e-fff769767cca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983688065-172.17.0.15-1598176370008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42510,DS-18030eac-e13d-4078-af4e-e51cbc4da589,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-9b5507f7-ce74-4768-90a4-721d9086d277,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-7861b0d4-3183-4656-bd2a-4721391146cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-5317f00b-aec7-4f56-a607-0658c1b1d9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-2df3a222-9e3f-457d-a6f2-55467a2996a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-7622e755-817e-455f-b8ae-46ce7bad803c,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-54978a65-3856-418f-938e-1a6312e1e947,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-9255d807-b911-4598-a75e-fff769767cca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141573456-172.17.0.15-1598177081000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40430,DS-a521b61c-68d4-44ab-9924-b7e7c27a0136,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-ceef66d6-df44-4d87-ab5c-13db1dc1df9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-e60e057f-1629-445f-9315-fe160d0fa98a,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-2df6bcfa-d331-4ee9-95e7-30b7a0ad3713,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-d0bc9ec1-36dd-48ca-a98a-58a65c47f0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-d361c9db-e08a-4276-920e-efb00dd3b311,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-6bfe4054-6be7-4d25-8ca3-c9cdc0432ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-d35c541e-6579-42c6-8e1c-c12f949454cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141573456-172.17.0.15-1598177081000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40430,DS-a521b61c-68d4-44ab-9924-b7e7c27a0136,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-ceef66d6-df44-4d87-ab5c-13db1dc1df9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-e60e057f-1629-445f-9315-fe160d0fa98a,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-2df6bcfa-d331-4ee9-95e7-30b7a0ad3713,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-d0bc9ec1-36dd-48ca-a98a-58a65c47f0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-d361c9db-e08a-4276-920e-efb00dd3b311,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-6bfe4054-6be7-4d25-8ca3-c9cdc0432ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-d35c541e-6579-42c6-8e1c-c12f949454cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677624665-172.17.0.15-1598177238232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34295,DS-05afefb9-e731-4e62-92e7-61cefa84043e,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-60782853-b13f-4e6c-a4a9-a23c62f2e370,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-4a477898-6441-4543-8c87-902c6adbc369,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-9fe1b6fb-889c-48d7-9257-b30e3c1cabcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-0e95bb0c-06d3-4f34-b770-fdee810f9a89,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-bf7a4db9-9690-4245-b351-717519567474,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-e52cd52a-6af4-4e6d-a9f7-009cd38f51c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-9c2cd133-dbc7-40e8-a294-e4f1c9339d5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677624665-172.17.0.15-1598177238232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34295,DS-05afefb9-e731-4e62-92e7-61cefa84043e,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-60782853-b13f-4e6c-a4a9-a23c62f2e370,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-4a477898-6441-4543-8c87-902c6adbc369,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-9fe1b6fb-889c-48d7-9257-b30e3c1cabcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-0e95bb0c-06d3-4f34-b770-fdee810f9a89,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-bf7a4db9-9690-4245-b351-717519567474,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-e52cd52a-6af4-4e6d-a9f7-009cd38f51c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-9c2cd133-dbc7-40e8-a294-e4f1c9339d5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761391018-172.17.0.15-1598177283803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37799,DS-8601f2ab-0c00-4b72-b281-5f550462885f,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-15f75ae9-5316-4d0a-8fe8-315e1552f407,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-8ad879de-e62a-45cc-b8c0-672f3d2b3e03,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-ccf2a091-91b3-404e-853c-c5634f16f841,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-00d65814-4c69-4d41-b5a9-907d97d64991,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-be81cb25-f268-4b8b-bee5-854b7441debd,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-093b2f1f-b8eb-4d07-b720-af2421b213cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-d690a470-069f-402e-a010-ee3d4c392238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761391018-172.17.0.15-1598177283803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37799,DS-8601f2ab-0c00-4b72-b281-5f550462885f,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-15f75ae9-5316-4d0a-8fe8-315e1552f407,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-8ad879de-e62a-45cc-b8c0-672f3d2b3e03,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-ccf2a091-91b3-404e-853c-c5634f16f841,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-00d65814-4c69-4d41-b5a9-907d97d64991,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-be81cb25-f268-4b8b-bee5-854b7441debd,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-093b2f1f-b8eb-4d07-b720-af2421b213cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-d690a470-069f-402e-a010-ee3d4c392238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6382
