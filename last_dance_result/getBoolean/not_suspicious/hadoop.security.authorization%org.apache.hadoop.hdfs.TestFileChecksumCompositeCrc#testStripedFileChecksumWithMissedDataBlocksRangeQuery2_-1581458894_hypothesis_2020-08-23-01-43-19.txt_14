reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935075838-172.17.0.13-1598147045705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43300,DS-7307e1b0-dfae-4188-b13d-13f6f8bed9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-10f8cb35-72c0-4d8c-b1ab-241d5b09b957,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-0b5fc8d5-1846-42d4-9c37-495f2f4556da,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-ece50d11-3966-444f-86a6-c95e6525729d,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-628bce64-3745-4fc9-81e2-6fc42f11ef89,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-dd223d5c-6514-491d-9214-6893c2e60c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-a6843853-8cf3-4a79-bfa7-56f8de7f9c68,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-946afece-a928-4d92-97f2-dca9aee38df2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935075838-172.17.0.13-1598147045705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43300,DS-7307e1b0-dfae-4188-b13d-13f6f8bed9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-10f8cb35-72c0-4d8c-b1ab-241d5b09b957,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-0b5fc8d5-1846-42d4-9c37-495f2f4556da,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-ece50d11-3966-444f-86a6-c95e6525729d,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-628bce64-3745-4fc9-81e2-6fc42f11ef89,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-dd223d5c-6514-491d-9214-6893c2e60c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-a6843853-8cf3-4a79-bfa7-56f8de7f9c68,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-946afece-a928-4d92-97f2-dca9aee38df2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618950232-172.17.0.13-1598147080160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33627,DS-15976b86-360d-4d43-a759-d0a83c92b72c,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-2365b4dd-76d1-4291-b5e6-b5ad2c95d332,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-629b9433-904e-4a3f-b08c-29f28d7555c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-c9a9f5d2-9eab-45b3-853b-2a26980bfea0,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-119cf7f7-b420-4564-a199-996bf9ecae11,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-7c4b507e-fa2b-4f10-ac1a-a877ab04ff6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-511ea8c7-436a-4960-a6ab-cc708d4398e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-c6d2d6cc-cf3a-4b6c-81c8-c6edae3c9ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618950232-172.17.0.13-1598147080160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33627,DS-15976b86-360d-4d43-a759-d0a83c92b72c,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-2365b4dd-76d1-4291-b5e6-b5ad2c95d332,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-629b9433-904e-4a3f-b08c-29f28d7555c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-c9a9f5d2-9eab-45b3-853b-2a26980bfea0,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-119cf7f7-b420-4564-a199-996bf9ecae11,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-7c4b507e-fa2b-4f10-ac1a-a877ab04ff6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-511ea8c7-436a-4960-a6ab-cc708d4398e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-c6d2d6cc-cf3a-4b6c-81c8-c6edae3c9ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925225914-172.17.0.13-1598147573483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35967,DS-b97ffeb2-7caa-4e50-b7f6-cb144091f704,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-37f72a3e-ff39-45a8-b006-fca3d2fd4037,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-672a3abe-0fd8-492e-a1bf-5c63f89a2786,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-1e8e259e-90b5-4d25-bc2c-af7b27b670f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-fbee2df9-49d6-4298-be83-e74b4bd9aa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-43adf605-afa9-4369-b46b-f6cf91879c65,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-7d2abb39-6b9c-4fbb-8eb7-84c10f124135,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-27c90a05-3471-421d-99ed-d4347c753619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925225914-172.17.0.13-1598147573483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35967,DS-b97ffeb2-7caa-4e50-b7f6-cb144091f704,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-37f72a3e-ff39-45a8-b006-fca3d2fd4037,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-672a3abe-0fd8-492e-a1bf-5c63f89a2786,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-1e8e259e-90b5-4d25-bc2c-af7b27b670f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-fbee2df9-49d6-4298-be83-e74b4bd9aa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-43adf605-afa9-4369-b46b-f6cf91879c65,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-7d2abb39-6b9c-4fbb-8eb7-84c10f124135,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-27c90a05-3471-421d-99ed-d4347c753619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801129376-172.17.0.13-1598147721164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33986,DS-7b0760a7-4fa7-459c-b871-302060877cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-79e1aef4-46f3-42c3-a955-77ac717a20c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-d272aa31-f81f-4437-9df4-48dbca0e76a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-aa86cb00-d26f-4379-aaf5-a01ae417f201,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-deb41e75-7347-4706-a21e-07c4c25f943b,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-381fd02d-e02d-4e7b-a45e-6ecdea5284b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-71674d03-85ca-404c-99b0-bfc208721662,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-6dfe2e97-0a18-4c21-973a-20ebaafba1e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801129376-172.17.0.13-1598147721164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33986,DS-7b0760a7-4fa7-459c-b871-302060877cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-79e1aef4-46f3-42c3-a955-77ac717a20c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-d272aa31-f81f-4437-9df4-48dbca0e76a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-aa86cb00-d26f-4379-aaf5-a01ae417f201,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-deb41e75-7347-4706-a21e-07c4c25f943b,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-381fd02d-e02d-4e7b-a45e-6ecdea5284b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-71674d03-85ca-404c-99b0-bfc208721662,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-6dfe2e97-0a18-4c21-973a-20ebaafba1e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675493931-172.17.0.13-1598147757731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42781,DS-c417b106-36d9-44b9-8b73-13db7671906d,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-38cb338a-df36-465b-931e-0d9925316273,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-206fbced-b0aa-4abe-8990-eb4339def839,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-eba7308b-70cf-4354-8ac6-4632fabbc67a,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-5b1472db-5c95-4fd1-bcd0-5d57a292c1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-fdd1714e-7df6-4404-bd64-80ac6234e7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-e2b8cd5d-197e-492e-a9fa-4058bccb3384,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-e3d364b5-b95f-40dc-af07-6ebcb8f697c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675493931-172.17.0.13-1598147757731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42781,DS-c417b106-36d9-44b9-8b73-13db7671906d,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-38cb338a-df36-465b-931e-0d9925316273,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-206fbced-b0aa-4abe-8990-eb4339def839,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-eba7308b-70cf-4354-8ac6-4632fabbc67a,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-5b1472db-5c95-4fd1-bcd0-5d57a292c1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-fdd1714e-7df6-4404-bd64-80ac6234e7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-e2b8cd5d-197e-492e-a9fa-4058bccb3384,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-e3d364b5-b95f-40dc-af07-6ebcb8f697c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482036391-172.17.0.13-1598147958312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33841,DS-ea22a1ea-aeac-4aaf-9bf3-b4aebf33638f,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-bd58b6a9-2e74-4a5c-aeca-2ffbdab5aeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-b1f1e9a5-44ad-4b03-b2dd-265bbe6c6eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-dea47f83-a386-43da-9b09-5ac1e4755975,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-355f397e-66ed-4872-9be6-39c4aea8af41,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-56f9f63a-829f-4395-ad73-c49477d2115a,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-c5ae27f6-12c3-4221-9c6b-5cbabfff55fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-cc167c77-f0dc-40bf-ac5c-65c967ecd850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482036391-172.17.0.13-1598147958312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33841,DS-ea22a1ea-aeac-4aaf-9bf3-b4aebf33638f,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-bd58b6a9-2e74-4a5c-aeca-2ffbdab5aeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-b1f1e9a5-44ad-4b03-b2dd-265bbe6c6eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-dea47f83-a386-43da-9b09-5ac1e4755975,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-355f397e-66ed-4872-9be6-39c4aea8af41,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-56f9f63a-829f-4395-ad73-c49477d2115a,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-c5ae27f6-12c3-4221-9c6b-5cbabfff55fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-cc167c77-f0dc-40bf-ac5c-65c967ecd850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178457685-172.17.0.13-1598148039203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45273,DS-45f4f8e1-0111-4396-9687-8bd12f2f3502,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-a24dc5b8-d3e2-4999-bb51-badbb586644f,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-a6ed014f-e84e-444a-a23d-9d3e0e8bd192,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-11869027-2050-42c3-8690-607ea8f0717e,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-5b79b69f-f9cd-4a6e-a378-027ab2a3d3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-eb321dc6-a885-4cbb-9b69-86069dded7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-d8b5718e-c95a-46e1-95bc-2539c13425f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-7a61397d-521e-4cde-a655-d3a8c9dd9e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178457685-172.17.0.13-1598148039203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45273,DS-45f4f8e1-0111-4396-9687-8bd12f2f3502,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-a24dc5b8-d3e2-4999-bb51-badbb586644f,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-a6ed014f-e84e-444a-a23d-9d3e0e8bd192,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-11869027-2050-42c3-8690-607ea8f0717e,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-5b79b69f-f9cd-4a6e-a378-027ab2a3d3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-eb321dc6-a885-4cbb-9b69-86069dded7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-d8b5718e-c95a-46e1-95bc-2539c13425f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-7a61397d-521e-4cde-a655-d3a8c9dd9e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937137726-172.17.0.13-1598148587304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-b7bbaaf3-3b25-40ea-9d5e-ad535dbf9fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-a02b01cb-5760-42e4-b3f6-597dd64c9be4,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-ca15c297-b01f-4ae2-ad9a-2a8cc3295f25,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-e4179044-a969-424c-a13f-c48c56b1b3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-51b8eb24-115b-4d71-9e36-2f4e4bb071c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-3cd6c44d-cad3-4e8b-8d95-37f8eacd696e,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-683d6305-af1e-4592-8daa-5481b35dbea8,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-eeefd9be-5ccb-4ece-80da-ce359206211f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937137726-172.17.0.13-1598148587304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-b7bbaaf3-3b25-40ea-9d5e-ad535dbf9fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-a02b01cb-5760-42e4-b3f6-597dd64c9be4,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-ca15c297-b01f-4ae2-ad9a-2a8cc3295f25,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-e4179044-a969-424c-a13f-c48c56b1b3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-51b8eb24-115b-4d71-9e36-2f4e4bb071c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-3cd6c44d-cad3-4e8b-8d95-37f8eacd696e,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-683d6305-af1e-4592-8daa-5481b35dbea8,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-eeefd9be-5ccb-4ece-80da-ce359206211f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382742384-172.17.0.13-1598149305465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33537,DS-7afb0488-5056-47bc-a913-a9dd7e73e326,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-d9625572-a320-4c82-860e-687c1022e867,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-ede88b5d-bec0-47d5-8051-504b544deda8,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-8a005a05-9cf5-421b-8093-6526b48c02ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-d81ff92c-6860-4cd2-a658-28b735400443,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-c0c90c6b-d2d2-437e-bef5-ec278694461e,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-fbb3fed0-bee5-4f0d-8bcd-6c4c125d3acb,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-4665768b-fcfd-40b6-9b76-a817669088fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382742384-172.17.0.13-1598149305465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33537,DS-7afb0488-5056-47bc-a913-a9dd7e73e326,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-d9625572-a320-4c82-860e-687c1022e867,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-ede88b5d-bec0-47d5-8051-504b544deda8,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-8a005a05-9cf5-421b-8093-6526b48c02ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-d81ff92c-6860-4cd2-a658-28b735400443,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-c0c90c6b-d2d2-437e-bef5-ec278694461e,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-fbb3fed0-bee5-4f0d-8bcd-6c4c125d3acb,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-4665768b-fcfd-40b6-9b76-a817669088fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691394733-172.17.0.13-1598149381362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40421,DS-fefa979d-3e5e-486f-9584-ac1e46d97cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-55ddad93-35c4-4ffb-80c7-a2838c9b8fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-09ecde6b-f385-4750-aeb1-376702e059f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-3683bd72-9589-4703-8460-93f1ffc048bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-c17b0d0e-34aa-4b80-910e-d767adecb4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-830590ad-b65b-40b7-9ca4-604f8ca4f779,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-f3b48cda-8f20-4b80-a3b1-7b5de999c759,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-b910ea1f-4a46-45b1-b0e6-5104583535b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691394733-172.17.0.13-1598149381362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40421,DS-fefa979d-3e5e-486f-9584-ac1e46d97cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-55ddad93-35c4-4ffb-80c7-a2838c9b8fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-09ecde6b-f385-4750-aeb1-376702e059f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-3683bd72-9589-4703-8460-93f1ffc048bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-c17b0d0e-34aa-4b80-910e-d767adecb4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-830590ad-b65b-40b7-9ca4-604f8ca4f779,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-f3b48cda-8f20-4b80-a3b1-7b5de999c759,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-b910ea1f-4a46-45b1-b0e6-5104583535b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695593392-172.17.0.13-1598149455534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44701,DS-913ee7f2-9193-4015-895b-000bc3e0910b,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-5f65c810-ef08-494d-bd8d-bf150319e936,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-5e386e96-67c7-452a-9c14-d88c0e9d9f93,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-9f0b824a-a6d1-4b88-ae4e-ee0e84f2baa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-6adf9078-95b3-49fb-a9b1-76e60d898a94,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-81b88945-f6e9-444c-bb08-7743fe1b3956,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-d1c3dace-6e07-4a28-8abd-bce2883d333f,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-ac010a0e-ad83-4718-b67b-09e5d196ec10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695593392-172.17.0.13-1598149455534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44701,DS-913ee7f2-9193-4015-895b-000bc3e0910b,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-5f65c810-ef08-494d-bd8d-bf150319e936,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-5e386e96-67c7-452a-9c14-d88c0e9d9f93,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-9f0b824a-a6d1-4b88-ae4e-ee0e84f2baa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-6adf9078-95b3-49fb-a9b1-76e60d898a94,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-81b88945-f6e9-444c-bb08-7743fe1b3956,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-d1c3dace-6e07-4a28-8abd-bce2883d333f,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-ac010a0e-ad83-4718-b67b-09e5d196ec10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984653794-172.17.0.13-1598149674949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38669,DS-ee131cc1-1908-4ecc-b5fb-b474769d33ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-ac45068d-b8af-441c-930c-662d9f80b3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-467547cc-d168-4d6c-845b-05278ce5185b,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-bf871672-75b5-43a1-8892-d65de4544f70,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-d224a0be-461c-42dc-8971-37ee4fdd8e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-3f315e01-d76b-4979-903a-3e01c11495ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-d94012f8-7fd8-404a-80fb-6cdb16063a31,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-b5232d35-a73c-4a0f-b551-a5c0dace9c06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984653794-172.17.0.13-1598149674949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38669,DS-ee131cc1-1908-4ecc-b5fb-b474769d33ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-ac45068d-b8af-441c-930c-662d9f80b3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-467547cc-d168-4d6c-845b-05278ce5185b,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-bf871672-75b5-43a1-8892-d65de4544f70,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-d224a0be-461c-42dc-8971-37ee4fdd8e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-3f315e01-d76b-4979-903a-3e01c11495ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-d94012f8-7fd8-404a-80fb-6cdb16063a31,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-b5232d35-a73c-4a0f-b551-a5c0dace9c06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72004461-172.17.0.13-1598149788666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41820,DS-b6f6c0f3-e381-42a4-9de5-7179896ad130,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-7df378d0-17e1-45f8-bc9a-d2e5b2d19ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-3c5a03f9-3cc5-4201-ab24-00810c9ed649,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-f0f8cf51-c209-47a2-93ff-a6623d638d64,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-16f67e86-8beb-45d3-a08e-8221561191f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-a6baa74e-7bfd-4a1d-8706-f6b8c6e12594,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-c343ba33-fe4d-45e8-8e60-9c1b7769dc71,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-214ea79b-76e1-4986-b795-523424d9a133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72004461-172.17.0.13-1598149788666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41820,DS-b6f6c0f3-e381-42a4-9de5-7179896ad130,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-7df378d0-17e1-45f8-bc9a-d2e5b2d19ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-3c5a03f9-3cc5-4201-ab24-00810c9ed649,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-f0f8cf51-c209-47a2-93ff-a6623d638d64,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-16f67e86-8beb-45d3-a08e-8221561191f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-a6baa74e-7bfd-4a1d-8706-f6b8c6e12594,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-c343ba33-fe4d-45e8-8e60-9c1b7769dc71,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-214ea79b-76e1-4986-b795-523424d9a133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-33757604-172.17.0.13-1598149918112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35758,DS-5e887b58-194b-4183-a9de-7906de94b7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-131438a4-45ef-4996-8505-cdd5db245147,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-24561358-b1d0-40b9-ad18-bdb62cc3a458,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-c396acfa-1e86-4cc2-bcd1-62e714ad5215,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-abde203c-4b7c-4809-95ec-47cf070d55f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-badb1af4-1df3-40a0-98dc-121475a647f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-5dd33450-c4d5-47ab-96ed-4c7feb05a8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-fbafa5e1-a9fb-4b8a-9fe4-8ed7c6fca57b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-33757604-172.17.0.13-1598149918112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35758,DS-5e887b58-194b-4183-a9de-7906de94b7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-131438a4-45ef-4996-8505-cdd5db245147,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-24561358-b1d0-40b9-ad18-bdb62cc3a458,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-c396acfa-1e86-4cc2-bcd1-62e714ad5215,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-abde203c-4b7c-4809-95ec-47cf070d55f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-badb1af4-1df3-40a0-98dc-121475a647f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-5dd33450-c4d5-47ab-96ed-4c7feb05a8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-fbafa5e1-a9fb-4b8a-9fe4-8ed7c6fca57b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777796731-172.17.0.13-1598150315723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41766,DS-7cc18f99-04f6-4cc5-8ee2-17fa96d26c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-3a1311b7-2e79-4edb-b87d-ffd785755d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-704cda6d-e19d-48a4-b92e-1f5ddb10d478,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-3211f4fa-7f5e-4e29-b204-e6c4d077c476,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-53de0e49-61d1-4451-a685-d04573476537,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-6a6ba353-5f8c-41ae-b1a6-d0059ea73185,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-e734e414-4c7f-442e-a2b1-e2b3d0aa01cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-b73b3065-42e6-48b0-a6e6-8ad649e8ab75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777796731-172.17.0.13-1598150315723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41766,DS-7cc18f99-04f6-4cc5-8ee2-17fa96d26c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-3a1311b7-2e79-4edb-b87d-ffd785755d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-704cda6d-e19d-48a4-b92e-1f5ddb10d478,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-3211f4fa-7f5e-4e29-b204-e6c4d077c476,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-53de0e49-61d1-4451-a685-d04573476537,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-6a6ba353-5f8c-41ae-b1a6-d0059ea73185,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-e734e414-4c7f-442e-a2b1-e2b3d0aa01cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-b73b3065-42e6-48b0-a6e6-8ad649e8ab75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342340308-172.17.0.13-1598150558115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-83875c40-d00f-4b57-95b2-c086f7818528,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-26288514-52e8-41ed-a44d-48e6061a88cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-efb31b63-0c5e-475e-9966-c0a889b35c05,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-7d6f90a5-dd23-4afd-9aa4-0bd6313311c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-e77d8047-2888-479b-a970-43984638691f,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-f65584f8-a469-4081-8353-6d991a339568,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-b9f0b497-ee99-4613-830d-f9dd4e56c8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-6496b522-b29d-413e-b96c-f520d47da41e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342340308-172.17.0.13-1598150558115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-83875c40-d00f-4b57-95b2-c086f7818528,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-26288514-52e8-41ed-a44d-48e6061a88cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-efb31b63-0c5e-475e-9966-c0a889b35c05,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-7d6f90a5-dd23-4afd-9aa4-0bd6313311c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-e77d8047-2888-479b-a970-43984638691f,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-f65584f8-a469-4081-8353-6d991a339568,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-b9f0b497-ee99-4613-830d-f9dd4e56c8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-6496b522-b29d-413e-b96c-f520d47da41e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939927993-172.17.0.13-1598150771343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45759,DS-bc1b53d0-ec93-4da7-ba6b-c96940d5d9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-a2ca69b3-de5b-45a2-a0b8-eb1b3fe56708,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-f06ee760-53b8-47c9-b9d0-ac03ee19272f,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-146f34d3-c7cf-47fd-ae85-89235fecc51a,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-73f37250-d636-487e-bdf6-bb75f593e24d,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-6de04649-ab63-4787-b0bb-2825ac046a62,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-5b089e01-90dd-4922-b630-47e53168839d,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-858be82c-da8a-4cac-b232-1769db4ce3af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939927993-172.17.0.13-1598150771343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45759,DS-bc1b53d0-ec93-4da7-ba6b-c96940d5d9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-a2ca69b3-de5b-45a2-a0b8-eb1b3fe56708,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-f06ee760-53b8-47c9-b9d0-ac03ee19272f,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-146f34d3-c7cf-47fd-ae85-89235fecc51a,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-73f37250-d636-487e-bdf6-bb75f593e24d,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-6de04649-ab63-4787-b0bb-2825ac046a62,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-5b089e01-90dd-4922-b630-47e53168839d,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-858be82c-da8a-4cac-b232-1769db4ce3af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522499726-172.17.0.13-1598151080405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38383,DS-249923f8-38dd-40a8-81d3-03e195607398,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-a873fe0e-fc8d-4d47-a3aa-c5264f959d91,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-552791a3-9034-4b56-a4f4-0319c7478429,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-eed96d9e-1632-4b1e-a01a-3e534cf41ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-996b2ac1-af5e-4a4f-a78a-44d74cfdce80,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-aec2704d-f06e-47fa-8d92-64440abc2edb,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-7d87bd51-6e9b-4cdd-acd8-e1b86ae1d826,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-2f4b35f6-79d6-4caf-9846-e15663baff0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522499726-172.17.0.13-1598151080405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38383,DS-249923f8-38dd-40a8-81d3-03e195607398,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-a873fe0e-fc8d-4d47-a3aa-c5264f959d91,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-552791a3-9034-4b56-a4f4-0319c7478429,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-eed96d9e-1632-4b1e-a01a-3e534cf41ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-996b2ac1-af5e-4a4f-a78a-44d74cfdce80,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-aec2704d-f06e-47fa-8d92-64440abc2edb,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-7d87bd51-6e9b-4cdd-acd8-e1b86ae1d826,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-2f4b35f6-79d6-4caf-9846-e15663baff0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230306077-172.17.0.13-1598151498661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34832,DS-97144571-2421-4aec-9df1-fe0ab210dea1,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-9da67e4a-d75d-4a04-96bc-e91f5c065a09,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-5f07e411-f257-4fbc-bd03-55871f84569a,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-63ad1ec4-2d22-49a9-9672-8f39ae4e48ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-fa880b4e-634b-4a11-a1aa-9a2d955b4b40,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-ad7f7a05-aede-43a0-bfa5-a0221fbdba3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-0495a188-2899-4a0e-9b47-766e2eaf13bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-1a3c2882-8622-4ad7-9e44-63390ad73759,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230306077-172.17.0.13-1598151498661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34832,DS-97144571-2421-4aec-9df1-fe0ab210dea1,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-9da67e4a-d75d-4a04-96bc-e91f5c065a09,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-5f07e411-f257-4fbc-bd03-55871f84569a,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-63ad1ec4-2d22-49a9-9672-8f39ae4e48ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-fa880b4e-634b-4a11-a1aa-9a2d955b4b40,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-ad7f7a05-aede-43a0-bfa5-a0221fbdba3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-0495a188-2899-4a0e-9b47-766e2eaf13bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-1a3c2882-8622-4ad7-9e44-63390ad73759,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855250465-172.17.0.13-1598152009535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37158,DS-b6cb1c2f-ba7a-4e7d-a62c-c57cc88b4ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-9f9b97de-0505-4992-bf7f-83eed8efef97,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-00c5be38-6cbc-46ff-ba41-edfa09fcaa74,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-07d76c6b-30ed-496c-99c8-cc1b9b18c39e,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-b2faa786-56ff-4107-9d49-065bd240d04f,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-743b830c-b4bc-41f8-a0a2-798087a21d49,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-c69d9dcf-565a-4287-aedf-cccde5042c12,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-2f54a859-ca55-47d9-a22a-f7300085d69e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855250465-172.17.0.13-1598152009535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37158,DS-b6cb1c2f-ba7a-4e7d-a62c-c57cc88b4ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-9f9b97de-0505-4992-bf7f-83eed8efef97,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-00c5be38-6cbc-46ff-ba41-edfa09fcaa74,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-07d76c6b-30ed-496c-99c8-cc1b9b18c39e,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-b2faa786-56ff-4107-9d49-065bd240d04f,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-743b830c-b4bc-41f8-a0a2-798087a21d49,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-c69d9dcf-565a-4287-aedf-cccde5042c12,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-2f54a859-ca55-47d9-a22a-f7300085d69e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988235375-172.17.0.13-1598152210242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39965,DS-4d5cb144-58e2-4a84-9e9b-0a819fe54055,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-167f7bfa-f407-434a-a92a-18af80a55639,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-dbfa7c6a-a4f6-4067-a0c1-757dbaa8c143,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-d940b888-6be7-445b-afbb-346f28fe22e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-78133716-11f7-43b0-adc5-62646a2b2e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-a4996bed-77a6-49a3-91ce-6e7733e96cab,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-3dfaaac9-f277-49b1-9526-27b543be4e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-302fc045-ada0-4c59-a30e-05a347096979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988235375-172.17.0.13-1598152210242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39965,DS-4d5cb144-58e2-4a84-9e9b-0a819fe54055,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-167f7bfa-f407-434a-a92a-18af80a55639,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-dbfa7c6a-a4f6-4067-a0c1-757dbaa8c143,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-d940b888-6be7-445b-afbb-346f28fe22e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-78133716-11f7-43b0-adc5-62646a2b2e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-a4996bed-77a6-49a3-91ce-6e7733e96cab,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-3dfaaac9-f277-49b1-9526-27b543be4e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-302fc045-ada0-4c59-a30e-05a347096979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5623
