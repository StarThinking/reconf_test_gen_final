reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-644966633-172.17.0.12-1598395258428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37089,DS-1c2841c4-7f70-426e-ba1a-9230b79a25ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-af0eabb1-5dad-4ab5-87b8-8ba1ea9c3a92,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-03bace83-b66e-4e36-b65b-92e34755093b,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-ef46a5dd-d787-4246-a790-12d44128fa4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-18079528-3c2b-4888-aef8-b7e935602b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-2b3f770e-9e58-42b8-aec6-b618ad245811,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-6afd961a-9ecf-4764-ba7e-8f05e5705167,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-197629b1-cbae-468e-9b71-e4e2d923fb31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-644966633-172.17.0.12-1598395258428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37089,DS-1c2841c4-7f70-426e-ba1a-9230b79a25ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-af0eabb1-5dad-4ab5-87b8-8ba1ea9c3a92,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-03bace83-b66e-4e36-b65b-92e34755093b,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-ef46a5dd-d787-4246-a790-12d44128fa4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-18079528-3c2b-4888-aef8-b7e935602b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-2b3f770e-9e58-42b8-aec6-b618ad245811,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-6afd961a-9ecf-4764-ba7e-8f05e5705167,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-197629b1-cbae-468e-9b71-e4e2d923fb31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954379548-172.17.0.12-1598395328693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33370,DS-24c0c0f3-3f11-4ff9-9738-8eaac6472cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-6afdc831-a524-4b78-89cc-7735f3fcb584,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-bee665dc-c7ce-4146-9938-0f9f88de9eab,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-ea6b8e10-3dc2-4fb5-bf1c-09252dc0dc76,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-6d4c1138-dcb0-49ad-a29c-0855b2b400d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-8b2e1f4e-9525-4178-979e-321e355d4182,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-24f9ba24-9a90-4b92-bcdc-65c4891b2927,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-b2bfec83-55d2-46c9-b596-617382a4fdbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954379548-172.17.0.12-1598395328693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33370,DS-24c0c0f3-3f11-4ff9-9738-8eaac6472cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-6afdc831-a524-4b78-89cc-7735f3fcb584,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-bee665dc-c7ce-4146-9938-0f9f88de9eab,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-ea6b8e10-3dc2-4fb5-bf1c-09252dc0dc76,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-6d4c1138-dcb0-49ad-a29c-0855b2b400d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-8b2e1f4e-9525-4178-979e-321e355d4182,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-24f9ba24-9a90-4b92-bcdc-65c4891b2927,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-b2bfec83-55d2-46c9-b596-617382a4fdbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594733913-172.17.0.12-1598395754451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44990,DS-30ef0f73-682b-49b0-b0e2-de4e2243dd26,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-a40ed855-cec9-4028-965a-25b41d9a606c,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-387c81e4-aa73-45fd-b431-31ca9ba40676,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-edbe1bc4-7e5b-4f43-ad0f-5d04b2eef5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-a04c35bc-1457-4264-b793-3bd8954043c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-40ae9e8c-246f-4f21-9915-fc4bc33d4e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-9e706321-7809-44ff-9cb3-f34831f92f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-15a0c484-10ac-42ed-ac45-ba9571d8031d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594733913-172.17.0.12-1598395754451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44990,DS-30ef0f73-682b-49b0-b0e2-de4e2243dd26,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-a40ed855-cec9-4028-965a-25b41d9a606c,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-387c81e4-aa73-45fd-b431-31ca9ba40676,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-edbe1bc4-7e5b-4f43-ad0f-5d04b2eef5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-a04c35bc-1457-4264-b793-3bd8954043c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-40ae9e8c-246f-4f21-9915-fc4bc33d4e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-9e706321-7809-44ff-9cb3-f34831f92f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-15a0c484-10ac-42ed-ac45-ba9571d8031d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034735911-172.17.0.12-1598396240605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35546,DS-b87d2e57-4c28-4425-8e96-3c90fb7bc0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-8018ae7b-94d9-4e2e-a375-1e9d2564cc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-6dd39bf2-fc22-47fa-bb01-447d0454a7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-283f0faf-8d04-4695-9e5b-0c2b65c14151,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-7a19c9bd-806a-4621-9041-4244d9d087bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-a1470a07-caca-4fc8-b48e-9bb744c70e88,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-1cb655b6-6f6c-44e6-8ca1-5a93f6c1ea50,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-2b4bd4f9-36b4-4382-9553-3088c4e5fec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034735911-172.17.0.12-1598396240605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35546,DS-b87d2e57-4c28-4425-8e96-3c90fb7bc0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-8018ae7b-94d9-4e2e-a375-1e9d2564cc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-6dd39bf2-fc22-47fa-bb01-447d0454a7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-283f0faf-8d04-4695-9e5b-0c2b65c14151,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-7a19c9bd-806a-4621-9041-4244d9d087bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-a1470a07-caca-4fc8-b48e-9bb744c70e88,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-1cb655b6-6f6c-44e6-8ca1-5a93f6c1ea50,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-2b4bd4f9-36b4-4382-9553-3088c4e5fec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429995988-172.17.0.12-1598396665208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42350,DS-181e0d99-d410-4f3e-9ff6-38e66353f98b,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-0824644b-ebe9-4564-814d-8541017d7197,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-3d77c379-b687-4a52-a1f9-2395f85e504b,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-0d725b00-2a53-40fd-b0ce-c755c5d853bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-e4eeb6fd-7241-4971-b715-e9d18bbb7a82,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-0faec37b-76ba-417e-8621-1d74b652e247,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-a2c0963c-53ef-480b-afc0-2ec286ffc08b,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-6d19a3af-f084-4529-9905-9b4b8fec373f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429995988-172.17.0.12-1598396665208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42350,DS-181e0d99-d410-4f3e-9ff6-38e66353f98b,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-0824644b-ebe9-4564-814d-8541017d7197,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-3d77c379-b687-4a52-a1f9-2395f85e504b,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-0d725b00-2a53-40fd-b0ce-c755c5d853bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-e4eeb6fd-7241-4971-b715-e9d18bbb7a82,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-0faec37b-76ba-417e-8621-1d74b652e247,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-a2c0963c-53ef-480b-afc0-2ec286ffc08b,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-6d19a3af-f084-4529-9905-9b4b8fec373f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-462061904-172.17.0.12-1598396731622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34187,DS-0e841411-3024-41a7-9b2c-d175fc1c8731,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-675efbd2-1204-4487-a917-9b94b8d6ba95,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-8b6103fe-ea45-4528-84a4-0f0bb5a914c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-fca0d7a0-1e41-409a-b434-212390152adf,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-b61011de-1143-4682-b1e3-fdeebb102806,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-91cf86e9-2dd9-4c6d-8d2a-5c223dbbce1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-99ae4a2c-288d-4761-ad6b-171d4b8e6cff,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-acf9489e-3e68-476e-827d-93b26944f84a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-462061904-172.17.0.12-1598396731622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34187,DS-0e841411-3024-41a7-9b2c-d175fc1c8731,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-675efbd2-1204-4487-a917-9b94b8d6ba95,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-8b6103fe-ea45-4528-84a4-0f0bb5a914c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-fca0d7a0-1e41-409a-b434-212390152adf,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-b61011de-1143-4682-b1e3-fdeebb102806,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-91cf86e9-2dd9-4c6d-8d2a-5c223dbbce1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-99ae4a2c-288d-4761-ad6b-171d4b8e6cff,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-acf9489e-3e68-476e-827d-93b26944f84a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602005495-172.17.0.12-1598397581610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38315,DS-1f215540-feb7-41b2-a27f-2f2071f83db3,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-df3fcfc0-6c21-4dca-9653-233b1dcc23ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-b578a00f-26cc-4058-a468-f9c22d324b32,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-05eabe02-901e-4112-8f46-68ea16fe1a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-f4af1336-5dda-4077-ba7e-d8d4e467b3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-c5565259-c838-444d-8282-6e32098269f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-f57f835a-c3aa-4e80-9a18-f89cc534a9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-3e5bdf07-2b2c-46d1-8716-c412d2eb3685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602005495-172.17.0.12-1598397581610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38315,DS-1f215540-feb7-41b2-a27f-2f2071f83db3,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-df3fcfc0-6c21-4dca-9653-233b1dcc23ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-b578a00f-26cc-4058-a468-f9c22d324b32,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-05eabe02-901e-4112-8f46-68ea16fe1a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-f4af1336-5dda-4077-ba7e-d8d4e467b3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-c5565259-c838-444d-8282-6e32098269f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-f57f835a-c3aa-4e80-9a18-f89cc534a9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-3e5bdf07-2b2c-46d1-8716-c412d2eb3685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278165751-172.17.0.12-1598398038776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38818,DS-3741f840-8762-47fa-b947-4814255ccf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-393f5924-aaac-4c59-bcf7-7a0bad86e24b,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-4597f227-3938-4652-a893-867f39911f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-1d3efd1a-6e99-4d3e-9125-453599a857e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-4c25241b-e452-4e38-a84b-433ac996e34a,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-74887a23-e6b8-417c-8927-e8bfc1c29b54,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-a6e7e7d5-6293-4b28-8f97-f9e3ef74f897,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-d070c887-a9f4-4895-a1de-4487c3f0b6ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278165751-172.17.0.12-1598398038776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38818,DS-3741f840-8762-47fa-b947-4814255ccf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-393f5924-aaac-4c59-bcf7-7a0bad86e24b,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-4597f227-3938-4652-a893-867f39911f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-1d3efd1a-6e99-4d3e-9125-453599a857e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-4c25241b-e452-4e38-a84b-433ac996e34a,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-74887a23-e6b8-417c-8927-e8bfc1c29b54,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-a6e7e7d5-6293-4b28-8f97-f9e3ef74f897,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-d070c887-a9f4-4895-a1de-4487c3f0b6ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176175822-172.17.0.12-1598398129144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44147,DS-8adcab8b-3dfa-46cf-a262-b2847ff2b522,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-7b866e69-7f7d-42ed-8c17-c2c4d99bb06a,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-eb36dfac-1337-4905-b802-72a9efc11d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-50a83fe0-44d2-4d5b-90e1-33cf2ad2c62e,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-045924c6-807b-4fcb-a881-2c9c6e7588e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-06bdc22f-653e-43da-a309-0984f25e4247,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-aab076af-ae8e-48c5-bf78-d27a6247c6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-2b5de937-c967-448f-b166-6f94e00640f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176175822-172.17.0.12-1598398129144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44147,DS-8adcab8b-3dfa-46cf-a262-b2847ff2b522,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-7b866e69-7f7d-42ed-8c17-c2c4d99bb06a,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-eb36dfac-1337-4905-b802-72a9efc11d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-50a83fe0-44d2-4d5b-90e1-33cf2ad2c62e,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-045924c6-807b-4fcb-a881-2c9c6e7588e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-06bdc22f-653e-43da-a309-0984f25e4247,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-aab076af-ae8e-48c5-bf78-d27a6247c6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-2b5de937-c967-448f-b166-6f94e00640f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006913353-172.17.0.12-1598398806078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-471e6c03-e5f4-4291-a89b-7de8147a6174,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-c4af11e8-4aa5-4d28-9e91-9a64e18dfee0,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-42d767b0-e0fb-4d40-807d-7c6304d5b4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-9d9a01bc-6e54-4b7e-b196-c339719d6a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-ff9a3a2c-e3a6-4e39-bf39-310abcf47f99,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-c72570d0-7093-42c1-9090-68ad5ce093b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-144b9ca9-e3d3-4565-9a15-8007544dd034,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-5704089c-714a-46cf-b493-50f776d805f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006913353-172.17.0.12-1598398806078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-471e6c03-e5f4-4291-a89b-7de8147a6174,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-c4af11e8-4aa5-4d28-9e91-9a64e18dfee0,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-42d767b0-e0fb-4d40-807d-7c6304d5b4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-9d9a01bc-6e54-4b7e-b196-c339719d6a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-ff9a3a2c-e3a6-4e39-bf39-310abcf47f99,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-c72570d0-7093-42c1-9090-68ad5ce093b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-144b9ca9-e3d3-4565-9a15-8007544dd034,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-5704089c-714a-46cf-b493-50f776d805f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131251750-172.17.0.12-1598399084336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41883,DS-97b73f95-4432-4ea6-8849-c8cda80dc6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-a1484456-f7a3-434a-9e1f-d05f05fa0095,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-18f54f26-5c41-4bef-9bc5-54d8b724e89f,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-0b6a3c9b-5469-4060-a1e7-e0ccf4a98af5,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-90206f0d-a50c-4593-adba-36fbbaa646f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-07a0bb4b-13b2-4b61-9b0c-6edc2182c492,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-830c4f81-ca79-4e87-80cd-48cc030aa635,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-c8459b01-a0c7-4419-8197-65af9769d1dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131251750-172.17.0.12-1598399084336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41883,DS-97b73f95-4432-4ea6-8849-c8cda80dc6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-a1484456-f7a3-434a-9e1f-d05f05fa0095,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-18f54f26-5c41-4bef-9bc5-54d8b724e89f,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-0b6a3c9b-5469-4060-a1e7-e0ccf4a98af5,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-90206f0d-a50c-4593-adba-36fbbaa646f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-07a0bb4b-13b2-4b61-9b0c-6edc2182c492,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-830c4f81-ca79-4e87-80cd-48cc030aa635,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-c8459b01-a0c7-4419-8197-65af9769d1dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127450181-172.17.0.12-1598399479376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33388,DS-b48f4eeb-e2af-4336-8baa-e1fdf899ec5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-887e0007-79b8-4758-bef3-2f647d742179,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-ba4c3ef2-dc32-478a-911f-07faa4d0ffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-26886a4e-2353-44f0-b3f9-b825b7c489c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-469fbd4c-2769-4274-ac00-16d461425a86,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-b04543c2-dc39-4a2e-8dcd-3fe0809941c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-e66fd6f1-8aa4-4c00-8370-105e1a16c1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-3a05f779-c573-467d-8306-2570750b9f62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127450181-172.17.0.12-1598399479376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33388,DS-b48f4eeb-e2af-4336-8baa-e1fdf899ec5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-887e0007-79b8-4758-bef3-2f647d742179,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-ba4c3ef2-dc32-478a-911f-07faa4d0ffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-26886a4e-2353-44f0-b3f9-b825b7c489c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-469fbd4c-2769-4274-ac00-16d461425a86,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-b04543c2-dc39-4a2e-8dcd-3fe0809941c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-e66fd6f1-8aa4-4c00-8370-105e1a16c1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-3a05f779-c573-467d-8306-2570750b9f62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051778914-172.17.0.12-1598399513610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35577,DS-d3217d0b-bb06-4a14-929d-c0fca74b6771,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-53cc8c39-91ea-4781-a4de-39eef72e9634,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-80a0fda6-fc51-4085-8592-ffb5874b5b25,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-859f94a7-f048-4fe0-abca-92b30b3a01e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-5f5cd3b3-4f54-47ae-bfe7-19e1eb860e82,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-6895f49c-2531-47c3-91c8-e87a2ce5d057,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-fcf0e868-9671-49a7-b3a5-00dff887a856,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-52b312d6-689a-4c28-a7bc-3a071bd22d30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051778914-172.17.0.12-1598399513610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35577,DS-d3217d0b-bb06-4a14-929d-c0fca74b6771,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-53cc8c39-91ea-4781-a4de-39eef72e9634,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-80a0fda6-fc51-4085-8592-ffb5874b5b25,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-859f94a7-f048-4fe0-abca-92b30b3a01e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-5f5cd3b3-4f54-47ae-bfe7-19e1eb860e82,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-6895f49c-2531-47c3-91c8-e87a2ce5d057,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-fcf0e868-9671-49a7-b3a5-00dff887a856,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-52b312d6-689a-4c28-a7bc-3a071bd22d30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926119089-172.17.0.12-1598399589264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33354,DS-1a8fd8f6-1a5e-4a84-83a1-3416aad90355,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-f99c06cc-edaf-43fa-a2ad-525dd317a671,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-73745c9d-c158-4309-a8f0-c7e079ccca88,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-e0f305a9-a894-4f84-95ae-879f8b441819,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-61869871-26a5-4279-a8bc-e1cac2875ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-bc628a67-b9c4-429c-8158-a4bbc97b0333,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-bf962b9c-c563-4e49-a9c3-0c276bdd9466,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-940eba6c-78d9-4b46-8ffc-0a66c73c7523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926119089-172.17.0.12-1598399589264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33354,DS-1a8fd8f6-1a5e-4a84-83a1-3416aad90355,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-f99c06cc-edaf-43fa-a2ad-525dd317a671,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-73745c9d-c158-4309-a8f0-c7e079ccca88,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-e0f305a9-a894-4f84-95ae-879f8b441819,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-61869871-26a5-4279-a8bc-e1cac2875ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-bc628a67-b9c4-429c-8158-a4bbc97b0333,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-bf962b9c-c563-4e49-a9c3-0c276bdd9466,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-940eba6c-78d9-4b46-8ffc-0a66c73c7523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-552578853-172.17.0.12-1598399622382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37926,DS-2b08bf79-8e09-4ced-a571-f40e9d2a3694,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-a4f5835c-233c-4092-bf8b-9b081f22ab41,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-8400aac3-ef7f-4c27-9940-066b06aefd81,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-40a619c5-45c7-470d-8950-54921d547252,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-73fc361f-1dab-4be6-9f31-fa9f33e2433b,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-a023daca-a67b-456e-bd7b-878afc5f12d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-784f705a-ec48-4969-9ae3-8be3b8988759,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-7e843e45-4204-4cf4-a66f-26e0c9dc9f09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-552578853-172.17.0.12-1598399622382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37926,DS-2b08bf79-8e09-4ced-a571-f40e9d2a3694,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-a4f5835c-233c-4092-bf8b-9b081f22ab41,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-8400aac3-ef7f-4c27-9940-066b06aefd81,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-40a619c5-45c7-470d-8950-54921d547252,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-73fc361f-1dab-4be6-9f31-fa9f33e2433b,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-a023daca-a67b-456e-bd7b-878afc5f12d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-784f705a-ec48-4969-9ae3-8be3b8988759,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-7e843e45-4204-4cf4-a66f-26e0c9dc9f09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5011
