reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700204037-172.17.0.14-1598340461099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43272,DS-5a279d13-50b1-4120-a3c1-f6a1e6ec8d35,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-51f87468-40e9-4494-aaa7-7607af53aa94,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-c956aae3-b0ee-4385-88e0-dd5925361230,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-e02df628-5136-4087-97ca-4f617ca764a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-1013dd73-7ebb-49fd-aa25-82de4e46f658,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-665d8410-a301-4150-9729-64fb425fb986,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-7089de67-ed52-4c4f-8efc-abaf1fc62cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-42fb3d02-eccb-4f31-8762-c985616faf8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700204037-172.17.0.14-1598340461099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43272,DS-5a279d13-50b1-4120-a3c1-f6a1e6ec8d35,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-51f87468-40e9-4494-aaa7-7607af53aa94,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-c956aae3-b0ee-4385-88e0-dd5925361230,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-e02df628-5136-4087-97ca-4f617ca764a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-1013dd73-7ebb-49fd-aa25-82de4e46f658,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-665d8410-a301-4150-9729-64fb425fb986,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-7089de67-ed52-4c4f-8efc-abaf1fc62cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-42fb3d02-eccb-4f31-8762-c985616faf8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068014439-172.17.0.14-1598340708230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33093,DS-7e4f4e84-2d5d-433e-8ae7-6cc46e4a9442,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-4907a088-2346-468a-9e7d-037bb7118b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-b40ca5d9-2501-4bc9-9334-c53350a70c87,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-afb1696e-b7d8-4074-8b29-7254483df268,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-571061c8-f2c1-4ad3-b77f-c17afdda074a,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-11c33119-3ad7-431e-8b24-ec2d718a89ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-0cf8a4b6-ea13-43b1-bc86-77c6144e43ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-bb3742e7-9967-49a2-8c79-c796bf5f308f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068014439-172.17.0.14-1598340708230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33093,DS-7e4f4e84-2d5d-433e-8ae7-6cc46e4a9442,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-4907a088-2346-468a-9e7d-037bb7118b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-b40ca5d9-2501-4bc9-9334-c53350a70c87,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-afb1696e-b7d8-4074-8b29-7254483df268,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-571061c8-f2c1-4ad3-b77f-c17afdda074a,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-11c33119-3ad7-431e-8b24-ec2d718a89ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-0cf8a4b6-ea13-43b1-bc86-77c6144e43ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-bb3742e7-9967-49a2-8c79-c796bf5f308f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1666917970-172.17.0.14-1598341222766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34527,DS-2db80be5-45a9-4dd5-a740-db4f60f3d1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-51d32bb7-3d58-45da-8e1a-c1beb4278b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-a66533cd-d338-456c-b44d-6d4c1c21b4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-e6f3b9f5-cbbb-49ad-9596-83bb07d4461f,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-3a324524-8c99-4ff2-a5b3-eeab14274128,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-2ce5b4b8-e084-43b2-ad58-1cde8b5338f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-d2d99491-7f63-49ac-aac5-819a5db88bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-22430b61-e4ec-495b-a63a-ad9d074dba28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1666917970-172.17.0.14-1598341222766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34527,DS-2db80be5-45a9-4dd5-a740-db4f60f3d1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-51d32bb7-3d58-45da-8e1a-c1beb4278b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-a66533cd-d338-456c-b44d-6d4c1c21b4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-e6f3b9f5-cbbb-49ad-9596-83bb07d4461f,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-3a324524-8c99-4ff2-a5b3-eeab14274128,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-2ce5b4b8-e084-43b2-ad58-1cde8b5338f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-d2d99491-7f63-49ac-aac5-819a5db88bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-22430b61-e4ec-495b-a63a-ad9d074dba28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707420613-172.17.0.14-1598341372675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41568,DS-442fd2df-01af-4c75-8775-de39ca52b380,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-70f650ac-f364-4f3d-8d69-4170a7618b99,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-98954ada-a7f0-4746-ba67-277a24b62d26,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-407ff1bd-32e2-4d6f-af24-cd8d253f8dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-036835b5-e3d7-4916-a7e5-975d9853a004,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-2e8a5c8f-780e-4668-bdca-ab4ff05091be,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-6de672d9-b310-4232-82a5-812443d78ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-f3a2c172-86db-4fd7-a43d-f69dd055e5fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707420613-172.17.0.14-1598341372675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41568,DS-442fd2df-01af-4c75-8775-de39ca52b380,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-70f650ac-f364-4f3d-8d69-4170a7618b99,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-98954ada-a7f0-4746-ba67-277a24b62d26,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-407ff1bd-32e2-4d6f-af24-cd8d253f8dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-036835b5-e3d7-4916-a7e5-975d9853a004,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-2e8a5c8f-780e-4668-bdca-ab4ff05091be,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-6de672d9-b310-4232-82a5-812443d78ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-f3a2c172-86db-4fd7-a43d-f69dd055e5fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706131376-172.17.0.14-1598341480826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44111,DS-d1c75277-9381-417c-927e-4a5e41671b49,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-f1591b69-5a73-44d2-a613-70586e11eeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-ecad32b3-35c3-4294-8cf4-bfd1c1f87b41,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-46ae0df8-6d4a-4904-bd8c-63f5d35f225d,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-3433176b-83c7-445b-8d62-05cff26af866,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-c194d4b4-cb2f-4b8e-a773-3ad3b68fac5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-8b0e6fcb-fccc-43f2-bb12-11f6b4fb07ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-ba6095e0-80d5-4665-b94d-53031a481537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706131376-172.17.0.14-1598341480826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44111,DS-d1c75277-9381-417c-927e-4a5e41671b49,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-f1591b69-5a73-44d2-a613-70586e11eeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-ecad32b3-35c3-4294-8cf4-bfd1c1f87b41,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-46ae0df8-6d4a-4904-bd8c-63f5d35f225d,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-3433176b-83c7-445b-8d62-05cff26af866,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-c194d4b4-cb2f-4b8e-a773-3ad3b68fac5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-8b0e6fcb-fccc-43f2-bb12-11f6b4fb07ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-ba6095e0-80d5-4665-b94d-53031a481537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231377997-172.17.0.14-1598341706179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43950,DS-54f13ead-3aae-47c0-b507-5e1d48158b56,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-c4c0e2f6-a9b6-41bd-bd4b-c28f85c9fabb,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-9f723750-230e-4891-a6b9-1240238be349,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-1eaf06d5-2f0e-4840-9f7f-09dd5d92e974,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-436bbc17-9ba7-44f0-98fa-f34b388927eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-6d30b706-f492-4eab-9be1-53d4914d1820,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-2757de09-25c7-440e-b08d-2a2c2a8ff9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-0ce90e4a-93a0-459d-8b7f-c517774ea9a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231377997-172.17.0.14-1598341706179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43950,DS-54f13ead-3aae-47c0-b507-5e1d48158b56,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-c4c0e2f6-a9b6-41bd-bd4b-c28f85c9fabb,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-9f723750-230e-4891-a6b9-1240238be349,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-1eaf06d5-2f0e-4840-9f7f-09dd5d92e974,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-436bbc17-9ba7-44f0-98fa-f34b388927eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-6d30b706-f492-4eab-9be1-53d4914d1820,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-2757de09-25c7-440e-b08d-2a2c2a8ff9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-0ce90e4a-93a0-459d-8b7f-c517774ea9a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248922710-172.17.0.14-1598341839983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35556,DS-e2f7c7b1-2a16-41b8-b653-a149128fa2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-50b68c25-5c37-4453-89d7-9e792b40fbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-82c24e32-a3ff-4143-b8aa-62b1fee9d1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-59f7710b-cd3b-4c53-9a9b-ef873487db5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-667e6331-f61c-4408-a017-012b0f8a1600,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-81b0893c-1338-470b-8428-a87927440382,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-0e1b1766-b224-45c5-98f0-7e3dd702699b,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-a71a0739-e1b0-43e6-94ff-aa16a5fd546f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248922710-172.17.0.14-1598341839983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35556,DS-e2f7c7b1-2a16-41b8-b653-a149128fa2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-50b68c25-5c37-4453-89d7-9e792b40fbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-82c24e32-a3ff-4143-b8aa-62b1fee9d1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-59f7710b-cd3b-4c53-9a9b-ef873487db5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-667e6331-f61c-4408-a017-012b0f8a1600,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-81b0893c-1338-470b-8428-a87927440382,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-0e1b1766-b224-45c5-98f0-7e3dd702699b,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-a71a0739-e1b0-43e6-94ff-aa16a5fd546f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927180181-172.17.0.14-1598341873012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35817,DS-c12d52b6-7f81-450f-abf0-56eab0b068ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-5aec9b7b-f768-4de3-ad20-5538f603275e,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-d3109197-4ddb-4edf-b0d0-5d2bd73eccce,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-c4008dbc-9248-4981-bfc7-993465077562,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-993dfb3b-3afb-467c-b0f3-14b4bc340f80,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-1bed4622-17d8-47d3-b831-8d15bca85d82,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-ae469cd4-e92a-443f-91bd-d45c147013ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-4bfd5f43-b6c8-4faf-8b1f-c2e1dc632e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927180181-172.17.0.14-1598341873012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35817,DS-c12d52b6-7f81-450f-abf0-56eab0b068ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-5aec9b7b-f768-4de3-ad20-5538f603275e,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-d3109197-4ddb-4edf-b0d0-5d2bd73eccce,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-c4008dbc-9248-4981-bfc7-993465077562,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-993dfb3b-3afb-467c-b0f3-14b4bc340f80,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-1bed4622-17d8-47d3-b831-8d15bca85d82,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-ae469cd4-e92a-443f-91bd-d45c147013ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-4bfd5f43-b6c8-4faf-8b1f-c2e1dc632e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304194285-172.17.0.14-1598341900733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-3c7e6724-a68f-43cc-ba43-bfe6e4119f13,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-d1b31a46-c13a-46ec-8892-3c3f62a49d87,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-6b7d4803-4662-4a08-86c4-8d164090ed78,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-eddd9de7-ec02-45b6-8a76-3f83b13e4970,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-ea84850f-2293-4641-b0bb-ad005f5ef57f,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-3c4ce360-bafc-4c0d-8548-ec487667bcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-dfcc31dc-d852-46e9-9e30-2a5ba9d5b0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-881272de-633a-4647-aaf5-46f13dc93839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304194285-172.17.0.14-1598341900733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-3c7e6724-a68f-43cc-ba43-bfe6e4119f13,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-d1b31a46-c13a-46ec-8892-3c3f62a49d87,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-6b7d4803-4662-4a08-86c4-8d164090ed78,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-eddd9de7-ec02-45b6-8a76-3f83b13e4970,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-ea84850f-2293-4641-b0bb-ad005f5ef57f,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-3c4ce360-bafc-4c0d-8548-ec487667bcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-dfcc31dc-d852-46e9-9e30-2a5ba9d5b0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-881272de-633a-4647-aaf5-46f13dc93839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961749929-172.17.0.14-1598342083782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44323,DS-37619ae5-325c-4295-8cdf-362f13edd35b,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-5eec7532-fcb5-49ac-b952-959cfe78303e,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-7713a481-c584-4426-9db8-5ec2d5267a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-7b35c453-d2e9-40a8-bfc0-42dd6b8ae7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-3ee8d8d9-1d64-421c-8c39-82647d508530,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-2d099c8d-6b12-4322-b7a4-6f894768d29d,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-e885f870-ad06-4195-b380-bdb4fb53bfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-2dde5359-641a-421e-b0af-5aaa593d36cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961749929-172.17.0.14-1598342083782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44323,DS-37619ae5-325c-4295-8cdf-362f13edd35b,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-5eec7532-fcb5-49ac-b952-959cfe78303e,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-7713a481-c584-4426-9db8-5ec2d5267a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-7b35c453-d2e9-40a8-bfc0-42dd6b8ae7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-3ee8d8d9-1d64-421c-8c39-82647d508530,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-2d099c8d-6b12-4322-b7a4-6f894768d29d,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-e885f870-ad06-4195-b380-bdb4fb53bfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-2dde5359-641a-421e-b0af-5aaa593d36cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153634635-172.17.0.14-1598342141399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45874,DS-2d04314e-8c78-4c3b-a6ed-aedf1dba7045,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-d05f3cc4-7792-483e-b222-31e45fd6d778,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-87770c79-fbd4-4d76-9cc3-08c396472d25,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-00e1d625-4220-4369-b55d-4c39ba385df6,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-4833e4c0-e70e-4960-8109-0b8421ad0e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-1efb9deb-ebfa-4e55-9437-44d4dee98f61,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-0a684e89-4569-4ba4-a074-f41f10dc47ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-0b62b56e-0d24-4f65-ac5f-ed58e8f192af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153634635-172.17.0.14-1598342141399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45874,DS-2d04314e-8c78-4c3b-a6ed-aedf1dba7045,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-d05f3cc4-7792-483e-b222-31e45fd6d778,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-87770c79-fbd4-4d76-9cc3-08c396472d25,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-00e1d625-4220-4369-b55d-4c39ba385df6,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-4833e4c0-e70e-4960-8109-0b8421ad0e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-1efb9deb-ebfa-4e55-9437-44d4dee98f61,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-0a684e89-4569-4ba4-a074-f41f10dc47ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-0b62b56e-0d24-4f65-ac5f-ed58e8f192af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175222818-172.17.0.14-1598342315949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36062,DS-dd5cdfb7-0fd1-49f3-8936-7d22f1553833,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-95183315-47e5-451f-9639-b6d18a8f4cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-d97a0afc-5eb8-42c4-89eb-ac597e792493,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-a2cf292d-3f74-4715-9f7a-af2c27ffd0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-687db894-8f19-4c8b-8d29-918123fa3a26,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-257d0337-e559-4973-a790-ad90d9508ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-9b7b9909-f491-4b4d-8459-5e55fa094971,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-08d1d2b9-fddd-4d68-9472-48c131005674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175222818-172.17.0.14-1598342315949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36062,DS-dd5cdfb7-0fd1-49f3-8936-7d22f1553833,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-95183315-47e5-451f-9639-b6d18a8f4cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-d97a0afc-5eb8-42c4-89eb-ac597e792493,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-a2cf292d-3f74-4715-9f7a-af2c27ffd0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-687db894-8f19-4c8b-8d29-918123fa3a26,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-257d0337-e559-4973-a790-ad90d9508ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-9b7b9909-f491-4b4d-8459-5e55fa094971,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-08d1d2b9-fddd-4d68-9472-48c131005674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832442770-172.17.0.14-1598342446080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39117,DS-b2c12f43-3af4-47bc-a44f-4a5cbc40e49b,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-541fbd47-cbf2-4947-8290-9f0e583e51b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-e0de2341-34e2-4b73-86b2-a12fb1235528,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-11098927-19e0-4098-84df-9e8b7b230252,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-bf16ddb1-9eb9-4cca-a4be-e503b1507ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-09a4a998-df3a-4033-ad93-577684f35cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-7258dad1-b486-4c5e-afdd-a1d89a4c91a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-4328304f-fd55-481b-98e2-025756dcba2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832442770-172.17.0.14-1598342446080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39117,DS-b2c12f43-3af4-47bc-a44f-4a5cbc40e49b,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-541fbd47-cbf2-4947-8290-9f0e583e51b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-e0de2341-34e2-4b73-86b2-a12fb1235528,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-11098927-19e0-4098-84df-9e8b7b230252,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-bf16ddb1-9eb9-4cca-a4be-e503b1507ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-09a4a998-df3a-4033-ad93-577684f35cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-7258dad1-b486-4c5e-afdd-a1d89a4c91a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-4328304f-fd55-481b-98e2-025756dcba2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-633657370-172.17.0.14-1598342504466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40157,DS-cfe48a36-4cbb-4d45-a8b5-966fa8028886,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-12b7bf92-82ca-433f-979d-b201249c07fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-39026ee2-7512-4f98-b1df-377af22c3904,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-5eb09737-d996-4503-8eba-d47bb3101557,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-12ba1a50-10aa-4fea-b82b-540faf7d476d,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-c3d50a77-2c8b-4037-8836-447bed1faea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-bea83fdd-4c24-4bee-ad6b-9b39576de05d,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-7cc210c2-6965-4f67-baeb-2e475b0db79d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-633657370-172.17.0.14-1598342504466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40157,DS-cfe48a36-4cbb-4d45-a8b5-966fa8028886,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-12b7bf92-82ca-433f-979d-b201249c07fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-39026ee2-7512-4f98-b1df-377af22c3904,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-5eb09737-d996-4503-8eba-d47bb3101557,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-12ba1a50-10aa-4fea-b82b-540faf7d476d,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-c3d50a77-2c8b-4037-8836-447bed1faea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-bea83fdd-4c24-4bee-ad6b-9b39576de05d,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-7cc210c2-6965-4f67-baeb-2e475b0db79d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269481391-172.17.0.14-1598342942959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40208,DS-8a407fae-9d9a-49d0-a04c-7066e0afc1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-5b71c9bd-c48c-452a-806d-b7cc2518d69b,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-b54a643f-3a27-4498-b174-e99d27a7b6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-c16d495e-0006-473b-85a6-eefb3551d05e,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-c2ca4f82-46b3-4c92-9217-2800652f64c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-7274d2ce-786c-4262-ac49-85c9b95be6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-78561b74-5b00-4464-86c0-c328280f4f55,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-bab1f67e-4e91-408d-a67f-cdc903215fb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269481391-172.17.0.14-1598342942959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40208,DS-8a407fae-9d9a-49d0-a04c-7066e0afc1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-5b71c9bd-c48c-452a-806d-b7cc2518d69b,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-b54a643f-3a27-4498-b174-e99d27a7b6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-c16d495e-0006-473b-85a6-eefb3551d05e,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-c2ca4f82-46b3-4c92-9217-2800652f64c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-7274d2ce-786c-4262-ac49-85c9b95be6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-78561b74-5b00-4464-86c0-c328280f4f55,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-bab1f67e-4e91-408d-a67f-cdc903215fb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124138041-172.17.0.14-1598343409810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42067,DS-4be07ef8-c747-463d-9c2b-a9028f68e4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-4651b9cd-40bc-4166-bf7e-d9fb4dc3cfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-09b710c0-e766-475b-b80e-be4b3eb341fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-f3fafa23-6472-4f39-aa6a-42d983ae62d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-21a689af-aa51-4343-9d8a-bb7cb38bdc40,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-2f23e69c-e784-4a6f-a114-f2bdd50cd4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-030e2183-04d4-40c2-868e-abf57dd8e685,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-008ba1b3-1650-4d8d-aa67-f0e90e153ef6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124138041-172.17.0.14-1598343409810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42067,DS-4be07ef8-c747-463d-9c2b-a9028f68e4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-4651b9cd-40bc-4166-bf7e-d9fb4dc3cfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-09b710c0-e766-475b-b80e-be4b3eb341fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-f3fafa23-6472-4f39-aa6a-42d983ae62d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-21a689af-aa51-4343-9d8a-bb7cb38bdc40,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-2f23e69c-e784-4a6f-a114-f2bdd50cd4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-030e2183-04d4-40c2-868e-abf57dd8e685,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-008ba1b3-1650-4d8d-aa67-f0e90e153ef6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106970554-172.17.0.14-1598343451029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45220,DS-324f4864-38c4-4f4e-9d65-010020cccdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-69a6b89f-92db-4b6c-aa46-2ca6347fe674,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-7d68ac30-e570-4d47-8f75-3589b8c3d46d,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-2a7ec36e-bf43-4919-ab09-bd7ca5c6fb36,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-11d97588-10c2-403a-8df6-c60d31307b77,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-a47f594a-2d6f-4db9-a4b5-390c5c1dbf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-093e0a7d-f073-4697-8eb8-eff1e9c9f7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-0ebfc122-c333-4c51-ac3e-2a8e1fde95b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106970554-172.17.0.14-1598343451029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45220,DS-324f4864-38c4-4f4e-9d65-010020cccdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-69a6b89f-92db-4b6c-aa46-2ca6347fe674,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-7d68ac30-e570-4d47-8f75-3589b8c3d46d,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-2a7ec36e-bf43-4919-ab09-bd7ca5c6fb36,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-11d97588-10c2-403a-8df6-c60d31307b77,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-a47f594a-2d6f-4db9-a4b5-390c5c1dbf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-093e0a7d-f073-4697-8eb8-eff1e9c9f7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-0ebfc122-c333-4c51-ac3e-2a8e1fde95b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707388160-172.17.0.14-1598343658512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38341,DS-e736b9d7-9efb-4f03-b321-fca9b4d0e0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-bc61c16c-7873-443c-b473-fd92919b4d86,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-298e54f3-0c41-44ba-9bc0-d6aa81116841,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-bacc0a4e-fd65-4103-b7cd-3b5a42652130,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-c247f89a-369e-4417-989a-e1209b0cde2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-af5536ab-53a4-47f0-9d4f-9a0737ae8746,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-127e5301-65f7-4d55-b195-d8cb73a1501b,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-e059b210-ee98-4a7b-b7d5-50c635a67abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707388160-172.17.0.14-1598343658512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38341,DS-e736b9d7-9efb-4f03-b321-fca9b4d0e0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-bc61c16c-7873-443c-b473-fd92919b4d86,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-298e54f3-0c41-44ba-9bc0-d6aa81116841,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-bacc0a4e-fd65-4103-b7cd-3b5a42652130,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-c247f89a-369e-4417-989a-e1209b0cde2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-af5536ab-53a4-47f0-9d4f-9a0737ae8746,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-127e5301-65f7-4d55-b195-d8cb73a1501b,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-e059b210-ee98-4a7b-b7d5-50c635a67abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157026580-172.17.0.14-1598343730779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41374,DS-03034226-0ad6-4b7e-9993-6e2af2dd3043,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-6fbd1e10-6fc2-4965-b53e-aaa33716106f,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-215d66ca-a63c-46a8-9b2e-b18795d53832,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-7050a9e7-8389-4566-9230-55779112d3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-67091bd5-fd4b-4b32-b33e-d9ee30b676a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-1e64af71-3f2d-4a74-8e35-f6ca04042a66,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-469943df-1fdb-473c-a8fa-cfad60bbb301,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-a425710d-2ab4-4608-9cb7-308729454a0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-157026580-172.17.0.14-1598343730779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41374,DS-03034226-0ad6-4b7e-9993-6e2af2dd3043,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-6fbd1e10-6fc2-4965-b53e-aaa33716106f,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-215d66ca-a63c-46a8-9b2e-b18795d53832,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-7050a9e7-8389-4566-9230-55779112d3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-67091bd5-fd4b-4b32-b33e-d9ee30b676a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-1e64af71-3f2d-4a74-8e35-f6ca04042a66,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-469943df-1fdb-473c-a8fa-cfad60bbb301,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-a425710d-2ab4-4608-9cb7-308729454a0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1471977836-172.17.0.14-1598344007290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46241,DS-f4aced7a-c8c6-412b-9e6a-7283a2b091f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-bd21fbf5-f808-4db9-8959-44215984c5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-75bc7bfe-0af0-4168-959a-929f8f6f8121,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-dc060c28-a9e9-4b7b-979b-07bc6161873d,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-25eb62bd-1297-45d2-b32b-fa752944517e,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-d9bd48ed-3201-4282-bb0b-2cb64cc0bee7,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-ecf36eaf-e864-4393-b2c8-eec98c811ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-7b2b53d2-3221-413d-af53-619ff1163124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1471977836-172.17.0.14-1598344007290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46241,DS-f4aced7a-c8c6-412b-9e6a-7283a2b091f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-bd21fbf5-f808-4db9-8959-44215984c5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-75bc7bfe-0af0-4168-959a-929f8f6f8121,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-dc060c28-a9e9-4b7b-979b-07bc6161873d,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-25eb62bd-1297-45d2-b32b-fa752944517e,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-d9bd48ed-3201-4282-bb0b-2cb64cc0bee7,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-ecf36eaf-e864-4393-b2c8-eec98c811ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-7b2b53d2-3221-413d-af53-619ff1163124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004146601-172.17.0.14-1598344260362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35661,DS-3cd10fe9-a870-457a-8117-ec368a7ce5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-eafdfec7-998d-4f3b-a1ac-416647c2da2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-562fdb1d-fdaf-434a-ae3b-81be3394b7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-85a26b51-c8c7-415f-9246-e8948b17ce05,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-87a3cf6a-1dab-4dcd-9bfa-3a17d28b70fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-4002106a-02d9-4256-b3d2-e45937157043,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-0b4ac974-1323-49c3-9e30-62256f3501a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-e8446b5a-d81f-42aa-9693-9a7e6485a4a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004146601-172.17.0.14-1598344260362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35661,DS-3cd10fe9-a870-457a-8117-ec368a7ce5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-eafdfec7-998d-4f3b-a1ac-416647c2da2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-562fdb1d-fdaf-434a-ae3b-81be3394b7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-85a26b51-c8c7-415f-9246-e8948b17ce05,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-87a3cf6a-1dab-4dcd-9bfa-3a17d28b70fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-4002106a-02d9-4256-b3d2-e45937157043,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-0b4ac974-1323-49c3-9e30-62256f3501a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-e8446b5a-d81f-42aa-9693-9a7e6485a4a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305118746-172.17.0.14-1598344670192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40017,DS-b25a76fb-b263-430c-99bf-1087fb29466b,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-176650cd-7cf0-4da9-9e71-c4ea06a4e95e,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-b343fc34-1b16-4c8a-b70a-0d60a32be06b,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-90383cdf-d4c5-4345-9cce-73f25f241b26,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-9288ab19-df0c-4360-b461-ee5c7132800a,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-e8b08abc-aa17-4b2d-8a2e-64f58c7e9dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-da1aeea4-3718-4171-9079-a054d679d16d,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-997f285f-651b-4c0e-a374-808a11a63f22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305118746-172.17.0.14-1598344670192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40017,DS-b25a76fb-b263-430c-99bf-1087fb29466b,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-176650cd-7cf0-4da9-9e71-c4ea06a4e95e,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-b343fc34-1b16-4c8a-b70a-0d60a32be06b,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-90383cdf-d4c5-4345-9cce-73f25f241b26,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-9288ab19-df0c-4360-b461-ee5c7132800a,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-e8b08abc-aa17-4b2d-8a2e-64f58c7e9dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-da1aeea4-3718-4171-9079-a054d679d16d,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-997f285f-651b-4c0e-a374-808a11a63f22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286058344-172.17.0.14-1598344886985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33382,DS-3936ab57-c731-4eaf-a636-0a62046e2253,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-441939a8-e87f-4227-9fca-b4ad1c8794a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-7d7b1646-7c40-4427-b9dc-9d48cc3ea74f,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-7788d9df-97cc-4be4-ab24-1acfefe48c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-b0e16736-9531-436e-8f0e-12ccac4053d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-686efdc1-87bb-42c9-82df-e0448e087ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-3fdb5948-aa2d-4285-a302-9605b49daeec,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-244d140e-bbd9-4784-b40b-9c4a5f242dac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286058344-172.17.0.14-1598344886985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33382,DS-3936ab57-c731-4eaf-a636-0a62046e2253,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-441939a8-e87f-4227-9fca-b4ad1c8794a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-7d7b1646-7c40-4427-b9dc-9d48cc3ea74f,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-7788d9df-97cc-4be4-ab24-1acfefe48c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-b0e16736-9531-436e-8f0e-12ccac4053d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-686efdc1-87bb-42c9-82df-e0448e087ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-3fdb5948-aa2d-4285-a302-9605b49daeec,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-244d140e-bbd9-4784-b40b-9c4a5f242dac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364205272-172.17.0.14-1598344922392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33237,DS-f7654b20-633b-40a1-b694-cbb6c53bbd35,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-634c9964-34fa-4522-9046-d609fa583407,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-bc416b3a-1d71-4892-bc44-288b3e15b5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-5fd1b276-d836-472c-8af1-0abcad8db78b,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-3e9a35c5-1797-4fc3-b26c-4a00b4f554a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-a6e80347-1adf-4f96-b1e9-4af72a79df57,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-5f03c9e2-c799-4c73-bef3-89095c4ccc74,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-7d311a75-a944-481a-8ccb-3360826fc92f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364205272-172.17.0.14-1598344922392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33237,DS-f7654b20-633b-40a1-b694-cbb6c53bbd35,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-634c9964-34fa-4522-9046-d609fa583407,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-bc416b3a-1d71-4892-bc44-288b3e15b5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-5fd1b276-d836-472c-8af1-0abcad8db78b,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-3e9a35c5-1797-4fc3-b26c-4a00b4f554a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-a6e80347-1adf-4f96-b1e9-4af72a79df57,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-5f03c9e2-c799-4c73-bef3-89095c4ccc74,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-7d311a75-a944-481a-8ccb-3360826fc92f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5285
