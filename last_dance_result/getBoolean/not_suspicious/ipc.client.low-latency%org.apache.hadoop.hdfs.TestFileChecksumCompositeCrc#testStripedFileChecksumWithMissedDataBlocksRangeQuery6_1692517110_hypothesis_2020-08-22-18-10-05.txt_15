reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384058784-172.17.0.13-1598119939182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39123,DS-641d52e9-3a49-4d12-8687-e759060385c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-6f3269b4-050c-413a-a6b9-800052a84fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-b08f48af-d852-4e97-80f8-a00623accee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-ce993a3e-4ad2-4ff3-835f-c928325dd64c,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-5ad2c0f0-d6a9-494b-8fad-a9346a315ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-62329ef1-806c-4af6-998d-c22bcecd1e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-6920b4b3-d8f9-4b64-a674-d76338f6064f,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-238be41d-8f4a-4d92-9166-c21b26135ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384058784-172.17.0.13-1598119939182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39123,DS-641d52e9-3a49-4d12-8687-e759060385c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-6f3269b4-050c-413a-a6b9-800052a84fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-b08f48af-d852-4e97-80f8-a00623accee2,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-ce993a3e-4ad2-4ff3-835f-c928325dd64c,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-5ad2c0f0-d6a9-494b-8fad-a9346a315ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-62329ef1-806c-4af6-998d-c22bcecd1e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-6920b4b3-d8f9-4b64-a674-d76338f6064f,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-238be41d-8f4a-4d92-9166-c21b26135ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445661605-172.17.0.13-1598119975152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35945,DS-e4a370af-623a-4bdd-941e-6689997880c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-ce042a09-6705-45ce-82f5-de33acfe2216,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-8d9685ae-af09-4b73-ac61-cea7fbe037cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-f11b6f5c-d4d0-4932-9779-92d04d78b7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-fcb3d61d-3269-4a8d-a43f-f94b36a0876c,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-3818d276-1c40-4a7d-a374-9156b06c47f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-fc87617b-cce6-4028-8820-37b5fa198b72,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-e9c91abd-348f-45ae-8ae0-9760a83a2821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445661605-172.17.0.13-1598119975152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35945,DS-e4a370af-623a-4bdd-941e-6689997880c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-ce042a09-6705-45ce-82f5-de33acfe2216,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-8d9685ae-af09-4b73-ac61-cea7fbe037cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-f11b6f5c-d4d0-4932-9779-92d04d78b7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-fcb3d61d-3269-4a8d-a43f-f94b36a0876c,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-3818d276-1c40-4a7d-a374-9156b06c47f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-fc87617b-cce6-4028-8820-37b5fa198b72,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-e9c91abd-348f-45ae-8ae0-9760a83a2821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983225456-172.17.0.13-1598120444629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44342,DS-99725e58-70fd-4dc3-b1ec-4b527a222af8,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-87e94cf3-b9b7-45da-a261-4a9f232d1474,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-cfac4922-cdac-408f-afe0-040f22a96bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-ab523de5-dcff-4bb5-9ff0-83417975946b,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-2103a240-c461-4d34-87ac-aeed3e7479ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-3b548f68-8df9-4380-837b-8b356dec8d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-c03760d3-03f7-4c17-94ee-7493161dc71f,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-80c65595-49a8-4b08-83dd-aaf2fc2f2f31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983225456-172.17.0.13-1598120444629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44342,DS-99725e58-70fd-4dc3-b1ec-4b527a222af8,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-87e94cf3-b9b7-45da-a261-4a9f232d1474,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-cfac4922-cdac-408f-afe0-040f22a96bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-ab523de5-dcff-4bb5-9ff0-83417975946b,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-2103a240-c461-4d34-87ac-aeed3e7479ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-3b548f68-8df9-4380-837b-8b356dec8d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-c03760d3-03f7-4c17-94ee-7493161dc71f,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-80c65595-49a8-4b08-83dd-aaf2fc2f2f31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600072898-172.17.0.13-1598120477894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43919,DS-1d06a230-beef-453a-9152-5c7ece70341e,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-da54716e-12c2-490a-b6e7-acf2e4b17d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-05c0eb45-0081-4628-897f-21a20d7715ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-eea2b93f-22a4-4b35-bd31-e6b0cc326a62,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-6dece41f-fbf1-4018-a1f5-d08b1df8b2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-582f8ecc-4f13-4035-8463-98ea6e41f467,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-56a32e4a-2a81-41d1-ba65-e0f3f3372181,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-0ce12af7-9a80-456b-ac14-906105086d2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600072898-172.17.0.13-1598120477894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43919,DS-1d06a230-beef-453a-9152-5c7ece70341e,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-da54716e-12c2-490a-b6e7-acf2e4b17d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-05c0eb45-0081-4628-897f-21a20d7715ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-eea2b93f-22a4-4b35-bd31-e6b0cc326a62,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-6dece41f-fbf1-4018-a1f5-d08b1df8b2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-582f8ecc-4f13-4035-8463-98ea6e41f467,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-56a32e4a-2a81-41d1-ba65-e0f3f3372181,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-0ce12af7-9a80-456b-ac14-906105086d2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371274620-172.17.0.13-1598120514945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36625,DS-3211936d-c40b-4ded-971f-5b0fefaa254a,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-14a9df12-e432-4625-8aa6-c06ff027a8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-6f410e0e-92ef-471e-bdb4-c463f98ef719,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-e38a1137-d89f-47f1-bf41-7cc2c876f26d,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-edbcf6bf-125e-44c3-9cd9-1f4fcfe4bbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-2f6096e2-423e-436c-8b3d-347aa3bfc8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-8f4b7e15-e179-499e-86ff-380ed747bc37,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-e3ac3c53-c5da-4076-9abe-a8a55f143189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371274620-172.17.0.13-1598120514945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36625,DS-3211936d-c40b-4ded-971f-5b0fefaa254a,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-14a9df12-e432-4625-8aa6-c06ff027a8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-6f410e0e-92ef-471e-bdb4-c463f98ef719,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-e38a1137-d89f-47f1-bf41-7cc2c876f26d,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-edbcf6bf-125e-44c3-9cd9-1f4fcfe4bbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-2f6096e2-423e-436c-8b3d-347aa3bfc8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-8f4b7e15-e179-499e-86ff-380ed747bc37,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-e3ac3c53-c5da-4076-9abe-a8a55f143189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647068766-172.17.0.13-1598120551600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44502,DS-0ce1a651-d12c-4b75-a7cb-144b84a493c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-3a3e199c-eedf-4e2b-995b-35a5ac29a55b,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-53e3c3d2-fca2-4418-a3f6-f53eb31f1c05,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-20fb6a3e-3e8c-4952-8908-bf6759ef91cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-1d6f05c7-04b7-44d4-b6e8-69ad027c956d,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-73865480-3de0-47de-b15c-598e22a84c59,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-119278da-f45b-4746-b917-1441615a9d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-cffd774e-da48-4d51-b11c-c6bfc9030ce4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647068766-172.17.0.13-1598120551600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44502,DS-0ce1a651-d12c-4b75-a7cb-144b84a493c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-3a3e199c-eedf-4e2b-995b-35a5ac29a55b,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-53e3c3d2-fca2-4418-a3f6-f53eb31f1c05,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-20fb6a3e-3e8c-4952-8908-bf6759ef91cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-1d6f05c7-04b7-44d4-b6e8-69ad027c956d,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-73865480-3de0-47de-b15c-598e22a84c59,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-119278da-f45b-4746-b917-1441615a9d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-cffd774e-da48-4d51-b11c-c6bfc9030ce4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181965634-172.17.0.13-1598120584829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43102,DS-4a2ce088-7d51-41dd-a4cc-073a3e5cc8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-d380cdd7-10e4-4554-b881-db6123026158,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-2e7fc724-2ecd-4bbb-8fc5-cd806304ef94,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-d2914b58-bf36-4c93-8195-34fee9899d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-1d5cfed4-a3a3-4257-bbef-f04c5df5eea8,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-0f0226e0-ab34-4f97-b451-597893586b21,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-72c0f059-ae7f-4bad-b967-630a6832eed1,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-ffb383aa-c052-47d2-9723-871b82674ee6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181965634-172.17.0.13-1598120584829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43102,DS-4a2ce088-7d51-41dd-a4cc-073a3e5cc8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-d380cdd7-10e4-4554-b881-db6123026158,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-2e7fc724-2ecd-4bbb-8fc5-cd806304ef94,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-d2914b58-bf36-4c93-8195-34fee9899d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-1d5cfed4-a3a3-4257-bbef-f04c5df5eea8,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-0f0226e0-ab34-4f97-b451-597893586b21,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-72c0f059-ae7f-4bad-b967-630a6832eed1,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-ffb383aa-c052-47d2-9723-871b82674ee6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171910401-172.17.0.13-1598120653590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35873,DS-3793a0e5-2386-483b-aae5-c22cc002cb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-b8115079-ef16-40e5-bbc8-6e28818be2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-188936a8-8019-47cc-8955-beca3ef763eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-44e6a56c-7a3c-41a5-9d71-431cd5dafb11,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-049ed36e-9138-4cd2-a7c5-3f3be38af6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-1aae91a5-ccf0-4fca-a7fd-4ccb77d6c39d,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-0d761cc7-bf50-4240-a131-aa3ba098daeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-c46796cc-c77e-4342-a68a-a662de429d2b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171910401-172.17.0.13-1598120653590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35873,DS-3793a0e5-2386-483b-aae5-c22cc002cb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-b8115079-ef16-40e5-bbc8-6e28818be2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-188936a8-8019-47cc-8955-beca3ef763eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-44e6a56c-7a3c-41a5-9d71-431cd5dafb11,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-049ed36e-9138-4cd2-a7c5-3f3be38af6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-1aae91a5-ccf0-4fca-a7fd-4ccb77d6c39d,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-0d761cc7-bf50-4240-a131-aa3ba098daeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-c46796cc-c77e-4342-a68a-a662de429d2b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750392401-172.17.0.13-1598120982010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38077,DS-8e5f48ea-10b3-4a09-a62d-9d7dd55d3a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-b03f75d1-17c4-4ff0-8dba-f2fa1aa3fd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-64ca6afe-6e15-4682-a993-aaaa3ab06245,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-897005fc-38b2-4c25-ab49-d18ad1d69e57,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-bd6054c5-0f6a-405d-bd60-159e58c68560,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-fd6daccd-4352-44df-bd2d-f834933fc847,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-b013f045-0f00-4a22-a5e5-2b8af0b34cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-6816c26e-2135-491c-a815-1c8b04564a39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750392401-172.17.0.13-1598120982010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38077,DS-8e5f48ea-10b3-4a09-a62d-9d7dd55d3a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-b03f75d1-17c4-4ff0-8dba-f2fa1aa3fd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-64ca6afe-6e15-4682-a993-aaaa3ab06245,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-897005fc-38b2-4c25-ab49-d18ad1d69e57,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-bd6054c5-0f6a-405d-bd60-159e58c68560,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-fd6daccd-4352-44df-bd2d-f834933fc847,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-b013f045-0f00-4a22-a5e5-2b8af0b34cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-6816c26e-2135-491c-a815-1c8b04564a39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720297069-172.17.0.13-1598121419163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35843,DS-4673a8e9-247a-4913-88c7-16ad13d5d9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-32467b14-0bd8-43a0-b5ce-e62db661d374,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-beb5e969-8614-491d-ad7a-76d8cae8d2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-a32f5772-262e-4371-8991-69f7a690abfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-1d0a4373-487e-4b35-8faa-cc4306500949,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-89a12920-759b-4747-a74e-1142139b8dae,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-aacf0d4d-2355-4593-9d77-4b2e008ef52b,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-28eeaf84-ae2a-4630-81da-276c65e825e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720297069-172.17.0.13-1598121419163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35843,DS-4673a8e9-247a-4913-88c7-16ad13d5d9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-32467b14-0bd8-43a0-b5ce-e62db661d374,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-beb5e969-8614-491d-ad7a-76d8cae8d2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-a32f5772-262e-4371-8991-69f7a690abfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-1d0a4373-487e-4b35-8faa-cc4306500949,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-89a12920-759b-4747-a74e-1142139b8dae,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-aacf0d4d-2355-4593-9d77-4b2e008ef52b,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-28eeaf84-ae2a-4630-81da-276c65e825e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586010485-172.17.0.13-1598121480604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34365,DS-785f3e2c-65cb-4faf-ab2b-2d6c9fc95fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-14d1ecaf-8e07-4674-930d-cb0ade46caf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-6e4337d1-19bf-47a8-b568-b9ab80b44055,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-265483f5-dcf8-4261-b17a-9c7963c5b744,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-b2923a96-496f-4ded-9c25-ff4fdd934b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-bdaa55e2-5ed3-4a18-b107-f01950e4f07f,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-e4c1f620-3248-4ae7-878a-5ddf24219bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-fa2a0a59-caa0-4fce-aa95-c424978833ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586010485-172.17.0.13-1598121480604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34365,DS-785f3e2c-65cb-4faf-ab2b-2d6c9fc95fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-14d1ecaf-8e07-4674-930d-cb0ade46caf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-6e4337d1-19bf-47a8-b568-b9ab80b44055,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-265483f5-dcf8-4261-b17a-9c7963c5b744,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-b2923a96-496f-4ded-9c25-ff4fdd934b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-bdaa55e2-5ed3-4a18-b107-f01950e4f07f,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-e4c1f620-3248-4ae7-878a-5ddf24219bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-fa2a0a59-caa0-4fce-aa95-c424978833ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47428628-172.17.0.13-1598121754867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38612,DS-c6418394-4d1c-47d9-be30-45cdef1ede3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-fb554173-34f3-400c-93cb-52f6ab727f08,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-4def6a42-2093-4855-b085-0fcdb307e51c,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-55e72db4-dc74-4df4-8375-6ff6282ef74b,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-10107649-71eb-4989-97a0-43a762783c51,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-1c283d48-d110-4516-a00f-1fbb2a05c542,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-bd55dd65-9955-4f58-adf7-bfe65755890d,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-c6a51d0c-7110-47f6-8e41-187540acff78,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47428628-172.17.0.13-1598121754867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38612,DS-c6418394-4d1c-47d9-be30-45cdef1ede3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-fb554173-34f3-400c-93cb-52f6ab727f08,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-4def6a42-2093-4855-b085-0fcdb307e51c,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-55e72db4-dc74-4df4-8375-6ff6282ef74b,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-10107649-71eb-4989-97a0-43a762783c51,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-1c283d48-d110-4516-a00f-1fbb2a05c542,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-bd55dd65-9955-4f58-adf7-bfe65755890d,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-c6a51d0c-7110-47f6-8e41-187540acff78,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665752002-172.17.0.13-1598121789375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41484,DS-2e805a00-14c4-4004-9517-1e28bd12c6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-863ce4c2-1362-4809-9c43-439bcb6683c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-c415213e-dd05-4c56-a987-566162fd6cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-f01005ce-3b02-4264-82c7-f1649467db9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-a201b723-777a-4ecd-a478-59d197ab5970,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-285d20d3-89fc-41b2-819a-3e0fd8af368e,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-23031c5e-a340-4df7-96fb-8ff982f8a201,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-ca721722-1a1e-4bdf-a167-40c24be96667,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665752002-172.17.0.13-1598121789375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41484,DS-2e805a00-14c4-4004-9517-1e28bd12c6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-863ce4c2-1362-4809-9c43-439bcb6683c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-c415213e-dd05-4c56-a987-566162fd6cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-f01005ce-3b02-4264-82c7-f1649467db9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-a201b723-777a-4ecd-a478-59d197ab5970,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-285d20d3-89fc-41b2-819a-3e0fd8af368e,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-23031c5e-a340-4df7-96fb-8ff982f8a201,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-ca721722-1a1e-4bdf-a167-40c24be96667,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647712080-172.17.0.13-1598121823406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40340,DS-28d39e6b-3914-4e11-a00c-832e607669c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-8fbdb1bf-e8b9-4426-8d2c-f176a07291b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-c843a6a2-666d-483a-bcba-ba4b8cf0a097,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-3e7018d3-8f02-4fed-902c-4388fe917823,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-8f65dc84-7d1b-4dcf-b8d3-e72fe1417bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-a446992d-2d60-4589-a990-a51377208787,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-f43d671a-97a4-413b-87a0-b5d76c3d2688,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-3932e16f-3eb6-4349-9918-6b1f3fb96907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647712080-172.17.0.13-1598121823406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40340,DS-28d39e6b-3914-4e11-a00c-832e607669c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-8fbdb1bf-e8b9-4426-8d2c-f176a07291b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-c843a6a2-666d-483a-bcba-ba4b8cf0a097,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-3e7018d3-8f02-4fed-902c-4388fe917823,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-8f65dc84-7d1b-4dcf-b8d3-e72fe1417bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-a446992d-2d60-4589-a990-a51377208787,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-f43d671a-97a4-413b-87a0-b5d76c3d2688,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-3932e16f-3eb6-4349-9918-6b1f3fb96907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115522562-172.17.0.13-1598122094094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38500,DS-5a46ab8f-762c-438d-a57a-a3bf95caa87b,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-0a3562ce-c142-4418-92f8-019df91a10ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-46625737-5e85-4999-b28c-0058858f6b83,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-923f9b22-4196-458f-9d11-61b1e51e7aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-4ac1a1fd-4809-4b3a-8fc2-2f29a68b5141,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-14f8af05-6558-4e5f-b962-c479cbacf0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-69d53d5f-223d-48fc-b68f-ef508276e5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-c22ac31f-a3e2-40e3-9a58-24887a8ea971,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115522562-172.17.0.13-1598122094094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38500,DS-5a46ab8f-762c-438d-a57a-a3bf95caa87b,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-0a3562ce-c142-4418-92f8-019df91a10ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-46625737-5e85-4999-b28c-0058858f6b83,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-923f9b22-4196-458f-9d11-61b1e51e7aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-4ac1a1fd-4809-4b3a-8fc2-2f29a68b5141,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-14f8af05-6558-4e5f-b962-c479cbacf0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-69d53d5f-223d-48fc-b68f-ef508276e5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-c22ac31f-a3e2-40e3-9a58-24887a8ea971,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187654497-172.17.0.13-1598122135110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-49b28d58-e7f7-47bf-819c-911aef3461c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-79ae9f73-fabb-432e-ba96-677f368a90b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-e48369ce-52bd-4292-8f17-456a2af4d6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-fc293e4a-f4e9-4765-8a49-fbf951f8537b,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-8d1dc383-c533-459f-bbb9-167e0d2680a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-c5cf64b3-f69d-4a54-b30d-24a946696aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-418c430b-019b-4640-b820-1ae04d81e60a,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-e01ba8e0-f7ca-4f9f-96bd-ad3a49dd49a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187654497-172.17.0.13-1598122135110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-49b28d58-e7f7-47bf-819c-911aef3461c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-79ae9f73-fabb-432e-ba96-677f368a90b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-e48369ce-52bd-4292-8f17-456a2af4d6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-fc293e4a-f4e9-4765-8a49-fbf951f8537b,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-8d1dc383-c533-459f-bbb9-167e0d2680a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-c5cf64b3-f69d-4a54-b30d-24a946696aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-418c430b-019b-4640-b820-1ae04d81e60a,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-e01ba8e0-f7ca-4f9f-96bd-ad3a49dd49a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800812140-172.17.0.13-1598122250449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33405,DS-0e8f9e1e-fb2f-45f1-989e-49a7b8be47c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-dbf5109c-e096-4ad3-8fb0-5b851732e8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-f8fb3848-a607-4e47-b5ae-30d095231fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-ff316fcf-0588-4ee3-8bff-500ff8413e22,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-adbc4ab9-0dbe-43a4-98a6-d51ce3641a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-2fd6cd48-dfa3-43e8-93fa-2f0ef654ebef,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-96f70bd0-75ac-4d96-9d13-3185858cfc45,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-015c0296-b0f2-468f-b236-ff80d109ff2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800812140-172.17.0.13-1598122250449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33405,DS-0e8f9e1e-fb2f-45f1-989e-49a7b8be47c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-dbf5109c-e096-4ad3-8fb0-5b851732e8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-f8fb3848-a607-4e47-b5ae-30d095231fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-ff316fcf-0588-4ee3-8bff-500ff8413e22,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-adbc4ab9-0dbe-43a4-98a6-d51ce3641a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-2fd6cd48-dfa3-43e8-93fa-2f0ef654ebef,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-96f70bd0-75ac-4d96-9d13-3185858cfc45,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-015c0296-b0f2-468f-b236-ff80d109ff2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044543091-172.17.0.13-1598122287305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-343a6761-3f62-4732-8eee-94b596a5b4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-17132998-8976-4785-b59b-0801f77fe61e,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-94a9a669-425f-4469-ab8c-bc7c524748ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-cca93368-0269-4a9d-9038-ad83df569f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-060cbe25-cf06-405f-802b-e0a7bf1266c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-000f32e0-3b1b-4122-ae54-b977a07bf045,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-dd57ae31-1533-4e17-ac06-b1ec2e89f0df,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-a9d2867b-49f5-453c-9798-9e26bb249933,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044543091-172.17.0.13-1598122287305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-343a6761-3f62-4732-8eee-94b596a5b4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-17132998-8976-4785-b59b-0801f77fe61e,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-94a9a669-425f-4469-ab8c-bc7c524748ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-cca93368-0269-4a9d-9038-ad83df569f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-060cbe25-cf06-405f-802b-e0a7bf1266c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-000f32e0-3b1b-4122-ae54-b977a07bf045,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-dd57ae31-1533-4e17-ac06-b1ec2e89f0df,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-a9d2867b-49f5-453c-9798-9e26bb249933,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393926756-172.17.0.13-1598122504041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46818,DS-e47bc2f9-8ba3-41d3-ad86-0f5f452fb579,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-c41c23c0-bfe3-4982-b59b-bf3b6f3fde2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-d8c9e23f-f104-4b2a-954b-2530623d885b,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-d78bab3a-c3c0-4859-8386-fea33009e6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-b73459f6-750e-4230-8b5d-172e1827d6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-b78dfe7b-4a56-4b5c-96cf-34e1305f2057,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-1f2146ca-10f9-4234-b9ce-39da79355eec,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-9ec9ae61-ceeb-4b68-817d-a619cf4ec24c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393926756-172.17.0.13-1598122504041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46818,DS-e47bc2f9-8ba3-41d3-ad86-0f5f452fb579,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-c41c23c0-bfe3-4982-b59b-bf3b6f3fde2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-d8c9e23f-f104-4b2a-954b-2530623d885b,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-d78bab3a-c3c0-4859-8386-fea33009e6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-b73459f6-750e-4230-8b5d-172e1827d6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-b78dfe7b-4a56-4b5c-96cf-34e1305f2057,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-1f2146ca-10f9-4234-b9ce-39da79355eec,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-9ec9ae61-ceeb-4b68-817d-a619cf4ec24c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791844193-172.17.0.13-1598122664569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41473,DS-e5791f7b-4a1e-4bd5-bbbc-410392badd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-0d76d588-002b-4891-b10f-fca0f9e37456,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-a2cbe6d2-a26d-40ba-a58f-a9b0c9d93738,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-0c6654cb-f33d-48cb-91e7-90c92a295475,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-9d51872c-4d40-434e-b5aa-122ec169951a,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-72ae3c12-b73f-45d1-a07f-b9d90c3609ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-48f4cf8f-0233-44de-9a1c-fc0770d5b35f,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-9ccd103b-a234-4da5-ad8c-9d9268298408,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791844193-172.17.0.13-1598122664569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41473,DS-e5791f7b-4a1e-4bd5-bbbc-410392badd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-0d76d588-002b-4891-b10f-fca0f9e37456,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-a2cbe6d2-a26d-40ba-a58f-a9b0c9d93738,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-0c6654cb-f33d-48cb-91e7-90c92a295475,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-9d51872c-4d40-434e-b5aa-122ec169951a,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-72ae3c12-b73f-45d1-a07f-b9d90c3609ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-48f4cf8f-0233-44de-9a1c-fc0770d5b35f,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-9ccd103b-a234-4da5-ad8c-9d9268298408,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480924935-172.17.0.13-1598122738659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44356,DS-12505bd2-a8fd-41ca-aabc-93055b26b927,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-06648817-117e-4faa-ac7b-8aac8d3a0fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-f9fa8a48-a98e-4b08-910c-5b5b06f8474e,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-a0dc4ca9-4122-4fcc-926b-0345c6f203ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-b02f717e-d81c-4e76-b42e-ee6a3d3afc20,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-47b5d541-0fce-4110-b0eb-c0ea9caf5b92,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-ad06ea63-ab1b-4ef7-8a6f-859495788be2,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-fea7be64-d5a2-4782-852a-ea4bf04d15a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480924935-172.17.0.13-1598122738659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44356,DS-12505bd2-a8fd-41ca-aabc-93055b26b927,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-06648817-117e-4faa-ac7b-8aac8d3a0fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-f9fa8a48-a98e-4b08-910c-5b5b06f8474e,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-a0dc4ca9-4122-4fcc-926b-0345c6f203ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-b02f717e-d81c-4e76-b42e-ee6a3d3afc20,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-47b5d541-0fce-4110-b0eb-c0ea9caf5b92,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-ad06ea63-ab1b-4ef7-8a6f-859495788be2,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-fea7be64-d5a2-4782-852a-ea4bf04d15a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118449428-172.17.0.13-1598122783453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37930,DS-4531ca96-d894-45ed-8b68-20b2b960f4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-a7224f1a-76d2-4010-9ee8-4d83b175c998,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-a1128143-1600-4cd1-84d4-2da8831a649a,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-1099a5ef-0738-4ff4-b010-0f22f99fe96b,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-20dbb728-969c-4030-9a97-ce2430eb8a39,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-324c58e2-4273-4ba2-8f2a-1a03356b34ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-a4778d46-0dfe-4f62-8431-afa3d7215248,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-6d93c140-f5b6-4e08-a5e0-c4ad17d3b7aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118449428-172.17.0.13-1598122783453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37930,DS-4531ca96-d894-45ed-8b68-20b2b960f4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-a7224f1a-76d2-4010-9ee8-4d83b175c998,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-a1128143-1600-4cd1-84d4-2da8831a649a,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-1099a5ef-0738-4ff4-b010-0f22f99fe96b,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-20dbb728-969c-4030-9a97-ce2430eb8a39,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-324c58e2-4273-4ba2-8f2a-1a03356b34ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-a4778d46-0dfe-4f62-8431-afa3d7215248,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-6d93c140-f5b6-4e08-a5e0-c4ad17d3b7aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850862471-172.17.0.13-1598123126613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33663,DS-e62d5f26-b9a2-4b35-84cc-c2d8529a8edb,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-9f77b420-fcfb-4704-87f6-cc1d3cd00c33,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-ee38ff04-8384-4f62-bf5f-ce8d6f2c207c,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-e759d6ba-3367-4e91-8697-5047ec3c1772,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-1a22230d-d261-4a04-a14a-3acb95ba9307,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-54154bc8-3287-4dcd-9ecd-05565cc6c430,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-e7b152e0-2c6f-4ce1-a360-a1bd03a7c132,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-d34ae7b7-f1dd-4b99-900b-0ff738bfaa53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850862471-172.17.0.13-1598123126613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33663,DS-e62d5f26-b9a2-4b35-84cc-c2d8529a8edb,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-9f77b420-fcfb-4704-87f6-cc1d3cd00c33,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-ee38ff04-8384-4f62-bf5f-ce8d6f2c207c,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-e759d6ba-3367-4e91-8697-5047ec3c1772,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-1a22230d-d261-4a04-a14a-3acb95ba9307,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-54154bc8-3287-4dcd-9ecd-05565cc6c430,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-e7b152e0-2c6f-4ce1-a360-a1bd03a7c132,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-d34ae7b7-f1dd-4b99-900b-0ff738bfaa53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026300659-172.17.0.13-1598123370326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41463,DS-b8ab1af1-79bf-4bbe-a14c-8ef504adc9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-7a68d259-fb61-4658-a66f-f4b2b43459d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-9dd5abf1-ee68-44e7-9536-3fe68ed58465,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-eb10e580-7bd4-4c47-a970-8d282c4f6527,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-06bd2dc3-7699-4189-aa7e-a091a8361d83,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-67e678e9-eb5e-45f1-a954-1e31127d5441,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-596a6997-c1eb-4299-ac4c-46324b08374a,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-8b6cdde1-c768-4ffd-b906-bfbdc9a2e456,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026300659-172.17.0.13-1598123370326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41463,DS-b8ab1af1-79bf-4bbe-a14c-8ef504adc9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-7a68d259-fb61-4658-a66f-f4b2b43459d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-9dd5abf1-ee68-44e7-9536-3fe68ed58465,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-eb10e580-7bd4-4c47-a970-8d282c4f6527,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-06bd2dc3-7699-4189-aa7e-a091a8361d83,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-67e678e9-eb5e-45f1-a954-1e31127d5441,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-596a6997-c1eb-4299-ac4c-46324b08374a,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-8b6cdde1-c768-4ffd-b906-bfbdc9a2e456,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726751231-172.17.0.13-1598123539684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37504,DS-84ecbd93-8797-4516-b9fd-6a91dda5aefc,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-fb51d60b-493c-4013-a8a5-90ed48633e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-49b30479-4fdb-44d0-ae46-5b9395b7a455,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-178d486c-7a8d-46b8-845e-6ac380890128,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-0851b940-8954-4da2-923b-9b2ffe87f99e,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-d1b96389-b238-4475-a1df-af2258d35783,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-df445dba-af97-4b32-b2ad-2d5b9873c010,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-07726f01-4f07-49c5-964a-0239549a837a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726751231-172.17.0.13-1598123539684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37504,DS-84ecbd93-8797-4516-b9fd-6a91dda5aefc,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-fb51d60b-493c-4013-a8a5-90ed48633e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-49b30479-4fdb-44d0-ae46-5b9395b7a455,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-178d486c-7a8d-46b8-845e-6ac380890128,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-0851b940-8954-4da2-923b-9b2ffe87f99e,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-d1b96389-b238-4475-a1df-af2258d35783,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-df445dba-af97-4b32-b2ad-2d5b9873c010,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-07726f01-4f07-49c5-964a-0239549a837a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340385716-172.17.0.13-1598123615088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40625,DS-943a4118-e97d-41c7-82dd-5e9d0ae83763,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-bdf10dbd-bfc6-453d-a337-2fd78832d32e,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-ec205130-9fc0-4704-b7e7-3323622a2f84,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-12c41519-10b0-44a6-b3c0-91eb3900c527,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-c22cc5a4-6f60-4936-b600-534213b0991c,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-a48c6352-7500-4079-8b14-7905f6c824ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-e225ee3a-5071-44a1-a9a7-437412f21fab,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-76efe109-f51d-4fc2-8c43-a38355855d07,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340385716-172.17.0.13-1598123615088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40625,DS-943a4118-e97d-41c7-82dd-5e9d0ae83763,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-bdf10dbd-bfc6-453d-a337-2fd78832d32e,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-ec205130-9fc0-4704-b7e7-3323622a2f84,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-12c41519-10b0-44a6-b3c0-91eb3900c527,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-c22cc5a4-6f60-4936-b600-534213b0991c,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-a48c6352-7500-4079-8b14-7905f6c824ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-e225ee3a-5071-44a1-a9a7-437412f21fab,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-76efe109-f51d-4fc2-8c43-a38355855d07,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509045970-172.17.0.13-1598123690310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34528,DS-11a9b6bb-6847-4b8f-928a-f6a12cae0753,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-6605a510-6199-497c-b099-4589ac3688d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-3fff9752-f927-4cf1-af10-991eca804fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-1703de85-1f8d-473d-81ac-37d417b59311,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-9fe946f7-83db-4d95-880b-1dec71196998,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-15df4c5f-6197-429d-9668-482c33bf5c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-e785f4f5-aa74-410a-9cf9-e4fbd3d47b43,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-2c9838d8-b8a5-4f3f-9c8d-4b3b6602e33d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509045970-172.17.0.13-1598123690310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34528,DS-11a9b6bb-6847-4b8f-928a-f6a12cae0753,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-6605a510-6199-497c-b099-4589ac3688d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-3fff9752-f927-4cf1-af10-991eca804fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-1703de85-1f8d-473d-81ac-37d417b59311,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-9fe946f7-83db-4d95-880b-1dec71196998,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-15df4c5f-6197-429d-9668-482c33bf5c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-e785f4f5-aa74-410a-9cf9-e4fbd3d47b43,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-2c9838d8-b8a5-4f3f-9c8d-4b3b6602e33d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786526629-172.17.0.13-1598123976214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43709,DS-431fec9d-2c4b-4a25-be18-e4e5c4adcd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-f274e0fc-9ec2-4798-a8e6-994d7b384de9,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-6b50c90b-6e17-4744-9bd1-66c599874167,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-404cabb1-7a80-4602-9bb8-3725adf8c186,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-93c0e203-91ca-49a2-8f1f-d9b49a8bd6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-1bff95d8-8dc0-4f74-b7a4-41fccf3e7c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-4c4161db-50c2-4577-9f13-405427005701,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-e0b82f50-d71d-42de-ad4a-32af25e00878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786526629-172.17.0.13-1598123976214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43709,DS-431fec9d-2c4b-4a25-be18-e4e5c4adcd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-f274e0fc-9ec2-4798-a8e6-994d7b384de9,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-6b50c90b-6e17-4744-9bd1-66c599874167,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-404cabb1-7a80-4602-9bb8-3725adf8c186,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-93c0e203-91ca-49a2-8f1f-d9b49a8bd6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-1bff95d8-8dc0-4f74-b7a4-41fccf3e7c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-4c4161db-50c2-4577-9f13-405427005701,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-e0b82f50-d71d-42de-ad4a-32af25e00878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610716418-172.17.0.13-1598124053476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41653,DS-9fe067fb-1922-433f-a42b-e724f796a72b,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-4315a404-6282-4cfd-9780-2aa59a76045e,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-5dda7099-abb9-4b23-9128-0e695c3dc639,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-18c68981-9fbb-48ee-b760-646f938820d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-cba7602f-63b0-41c0-9a52-0f8de7a9765d,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-9abfe485-8cab-48f7-9752-5c7b600f0228,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-101be761-4928-424c-822c-835a6c0a7297,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-dd3e2051-e5b7-422e-b19b-d3b63e0c6817,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610716418-172.17.0.13-1598124053476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41653,DS-9fe067fb-1922-433f-a42b-e724f796a72b,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-4315a404-6282-4cfd-9780-2aa59a76045e,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-5dda7099-abb9-4b23-9128-0e695c3dc639,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-18c68981-9fbb-48ee-b760-646f938820d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-cba7602f-63b0-41c0-9a52-0f8de7a9765d,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-9abfe485-8cab-48f7-9752-5c7b600f0228,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-101be761-4928-424c-822c-835a6c0a7297,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-dd3e2051-e5b7-422e-b19b-d3b63e0c6817,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975719859-172.17.0.13-1598124164705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35991,DS-2f6deca5-29c7-4380-b32f-b8bb5d67e356,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-a566e8fd-1bd3-4ec0-b667-b2c9e8ef8acd,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-be62bf51-6f0f-4fee-82d4-d21460758e70,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-1c4f5e02-5127-43db-b26e-1f7ffc2ce67a,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-0dcce4cf-a3a8-4611-8cab-adf4c054aa08,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-d4465020-de31-44cc-a04b-8018c3d3d925,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-f722a835-60c0-4e73-b93a-28981849577e,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-ddc641d7-95ff-4e05-99ec-a7039c0b0e2a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975719859-172.17.0.13-1598124164705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35991,DS-2f6deca5-29c7-4380-b32f-b8bb5d67e356,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-a566e8fd-1bd3-4ec0-b667-b2c9e8ef8acd,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-be62bf51-6f0f-4fee-82d4-d21460758e70,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-1c4f5e02-5127-43db-b26e-1f7ffc2ce67a,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-0dcce4cf-a3a8-4611-8cab-adf4c054aa08,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-d4465020-de31-44cc-a04b-8018c3d3d925,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-f722a835-60c0-4e73-b93a-28981849577e,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-ddc641d7-95ff-4e05-99ec-a7039c0b0e2a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116930992-172.17.0.13-1598124444079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32774,DS-53ec3d1e-d79d-4b78-9178-625c1ef26691,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-b4fcf17b-a0d6-49de-9143-88aaaa7ed405,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-6732c011-7bc7-4220-b835-20f21bc88760,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-c4eec3b2-abf6-4b67-9e3d-68e5082bbef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-300eb0f9-f0e3-4ed7-9d76-0452257b19ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-22724047-1594-4035-b555-4c5f9829fb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-f3d40c0f-aaaf-4519-9518-c7ea4e5f9d32,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-a5a74dab-66d9-4172-a53a-e27cb5afe2e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116930992-172.17.0.13-1598124444079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32774,DS-53ec3d1e-d79d-4b78-9178-625c1ef26691,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-b4fcf17b-a0d6-49de-9143-88aaaa7ed405,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-6732c011-7bc7-4220-b835-20f21bc88760,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-c4eec3b2-abf6-4b67-9e3d-68e5082bbef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-300eb0f9-f0e3-4ed7-9d76-0452257b19ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-22724047-1594-4035-b555-4c5f9829fb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-f3d40c0f-aaaf-4519-9518-c7ea4e5f9d32,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-a5a74dab-66d9-4172-a53a-e27cb5afe2e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501093011-172.17.0.13-1598124517393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-a10222cd-658f-4ee7-8db6-2ed4f74b3ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-ce9ecf71-28af-4d66-9612-ebb05ab4ce23,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-5c6aa187-e17c-4ced-9521-6da12e0741ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-b9c5c517-0bb8-4d3f-a2fd-d3732de4077e,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-7b2cbf12-c60c-4fbd-971a-956fb7218b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-8b4fcff5-ef0e-4907-b9a0-1963a435c968,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-50a9fc0a-ade0-431e-8c39-fecdc96c5c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-226327a2-70fb-4e52-ab54-33fcf7e97695,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501093011-172.17.0.13-1598124517393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-a10222cd-658f-4ee7-8db6-2ed4f74b3ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-ce9ecf71-28af-4d66-9612-ebb05ab4ce23,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-5c6aa187-e17c-4ced-9521-6da12e0741ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-b9c5c517-0bb8-4d3f-a2fd-d3732de4077e,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-7b2cbf12-c60c-4fbd-971a-956fb7218b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-8b4fcff5-ef0e-4907-b9a0-1963a435c968,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-50a9fc0a-ade0-431e-8c39-fecdc96c5c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-226327a2-70fb-4e52-ab54-33fcf7e97695,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292626946-172.17.0.13-1598124620207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32806,DS-5c33ea87-d830-4849-b535-a54c41e60310,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-6f611458-5efa-4003-a819-7c9e478461ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-ffb25b82-4bb9-446b-ae83-a2a9af5e950b,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-396ce7fc-ee59-4582-bb05-8b05ca5aabf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-3dc889e6-6e78-4419-beb0-da9ead50d98b,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-3ddc5406-654e-4b6d-9792-a9b93400b628,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-19259212-9d27-4d0f-babe-930909133131,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-e5b84b48-6bca-4392-938e-cda4d5c4768b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292626946-172.17.0.13-1598124620207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32806,DS-5c33ea87-d830-4849-b535-a54c41e60310,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-6f611458-5efa-4003-a819-7c9e478461ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-ffb25b82-4bb9-446b-ae83-a2a9af5e950b,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-396ce7fc-ee59-4582-bb05-8b05ca5aabf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-3dc889e6-6e78-4419-beb0-da9ead50d98b,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-3ddc5406-654e-4b6d-9792-a9b93400b628,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-19259212-9d27-4d0f-babe-930909133131,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-e5b84b48-6bca-4392-938e-cda4d5c4768b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460288736-172.17.0.13-1598124682120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42579,DS-9a49c67e-da32-465c-a49d-3e220374ef71,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-3abe190f-edc1-4a35-88ff-36c46d5dc772,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-dfe3923a-4646-490b-8752-1797fa13e134,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-2e6522c4-0094-4c43-a137-070b6ecde007,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-46b63069-1bde-4fae-8df9-b48dd06ccc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-83a92585-85a9-4945-a15a-30fb6ea638d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-f709cb35-1bea-4398-b3cc-cd365dadf018,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-4d023ac0-a53a-4fbb-b84a-d63351ecfec5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460288736-172.17.0.13-1598124682120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42579,DS-9a49c67e-da32-465c-a49d-3e220374ef71,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-3abe190f-edc1-4a35-88ff-36c46d5dc772,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-dfe3923a-4646-490b-8752-1797fa13e134,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-2e6522c4-0094-4c43-a137-070b6ecde007,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-46b63069-1bde-4fae-8df9-b48dd06ccc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-83a92585-85a9-4945-a15a-30fb6ea638d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-f709cb35-1bea-4398-b3cc-cd365dadf018,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-4d023ac0-a53a-4fbb-b84a-d63351ecfec5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439248372-172.17.0.13-1598124883171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38855,DS-1f2eea55-2e06-43eb-8523-aac43cafab45,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-90c35cb1-0e61-4c6c-9668-92b0d8c235b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-0d9d5837-eab9-45b8-b282-80dcc779b467,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-96e31db7-9aa9-462c-97fb-689388529f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-65020f32-02b4-4b64-a763-ce0eb6731f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-9ce5688a-eb9f-49bf-a49d-d2d6ba08ec00,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-835e9cba-898d-4b83-a455-90e8510e8474,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-73e7c7e1-621f-4a09-8bb9-0918f14d1ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439248372-172.17.0.13-1598124883171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38855,DS-1f2eea55-2e06-43eb-8523-aac43cafab45,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-90c35cb1-0e61-4c6c-9668-92b0d8c235b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-0d9d5837-eab9-45b8-b282-80dcc779b467,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-96e31db7-9aa9-462c-97fb-689388529f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-65020f32-02b4-4b64-a763-ce0eb6731f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-9ce5688a-eb9f-49bf-a49d-d2d6ba08ec00,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-835e9cba-898d-4b83-a455-90e8510e8474,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-73e7c7e1-621f-4a09-8bb9-0918f14d1ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5349
