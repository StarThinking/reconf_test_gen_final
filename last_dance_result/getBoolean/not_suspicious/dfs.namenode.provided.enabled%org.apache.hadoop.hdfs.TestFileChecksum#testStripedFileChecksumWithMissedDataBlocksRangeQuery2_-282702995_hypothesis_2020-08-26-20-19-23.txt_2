reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665910881-172.17.0.15-1598473315336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44305,DS-d034f117-61f8-4cc6-a4fa-ca90ca74ed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-2f4a2d23-047c-4e32-8840-f54105af975e,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-ae446646-f6c2-4a84-93c2-6e36aac91711,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-87be338b-d0b6-48eb-b8a8-cc0a1ebffe66,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-e65349df-e109-45ee-bbc7-9e5ce5b1605c,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-fe22e4d4-cb7f-4767-b4dd-390b034b995b,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-4c9b8119-d009-4a7b-9dbd-a5dd754f746a,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-f3951e50-bf11-4af3-bf55-54d65a03cd91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665910881-172.17.0.15-1598473315336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44305,DS-d034f117-61f8-4cc6-a4fa-ca90ca74ed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-2f4a2d23-047c-4e32-8840-f54105af975e,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-ae446646-f6c2-4a84-93c2-6e36aac91711,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-87be338b-d0b6-48eb-b8a8-cc0a1ebffe66,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-e65349df-e109-45ee-bbc7-9e5ce5b1605c,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-fe22e4d4-cb7f-4767-b4dd-390b034b995b,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-4c9b8119-d009-4a7b-9dbd-a5dd754f746a,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-f3951e50-bf11-4af3-bf55-54d65a03cd91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188339867-172.17.0.15-1598473552266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34345,DS-e02d63a5-abb0-4599-91ac-380517f54c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-40f827d9-4673-43ce-a586-00023dfb5373,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-3e63ea6c-119d-46fe-aba8-c9245114fab6,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-85ec2b9c-e828-4909-ae13-7d1f00666d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-fa3411c0-115f-4205-8218-a055b0040d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-2fd33999-32d0-40fd-87fb-d9346bf7d8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-b923c7ab-5097-4038-8a7e-6d48a03b98cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-88f32150-1058-4f9e-8cac-fa7d667bb7e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188339867-172.17.0.15-1598473552266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34345,DS-e02d63a5-abb0-4599-91ac-380517f54c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-40f827d9-4673-43ce-a586-00023dfb5373,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-3e63ea6c-119d-46fe-aba8-c9245114fab6,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-85ec2b9c-e828-4909-ae13-7d1f00666d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-fa3411c0-115f-4205-8218-a055b0040d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-2fd33999-32d0-40fd-87fb-d9346bf7d8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-b923c7ab-5097-4038-8a7e-6d48a03b98cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-88f32150-1058-4f9e-8cac-fa7d667bb7e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59158677-172.17.0.15-1598473654755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36298,DS-2b3029ba-decf-4564-81e9-9452a203d69f,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-ad46d714-36af-4bec-bc0d-d262ac2d4a46,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-3e11a88f-3de5-4662-ab0a-d35ac41d583d,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-639ba9af-a192-46cd-95b1-dc6697e00bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-ffefabd4-2201-4782-bbf4-f6e662bbe579,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-5c01670b-8135-4554-bbda-4d029d6cd7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-4b4bff57-81da-474d-becb-bacc353a638b,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-dacc809b-3075-4232-af79-2f56bd5795d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59158677-172.17.0.15-1598473654755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36298,DS-2b3029ba-decf-4564-81e9-9452a203d69f,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-ad46d714-36af-4bec-bc0d-d262ac2d4a46,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-3e11a88f-3de5-4662-ab0a-d35ac41d583d,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-639ba9af-a192-46cd-95b1-dc6697e00bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-ffefabd4-2201-4782-bbf4-f6e662bbe579,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-5c01670b-8135-4554-bbda-4d029d6cd7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-4b4bff57-81da-474d-becb-bacc353a638b,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-dacc809b-3075-4232-af79-2f56bd5795d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-674019832-172.17.0.15-1598473825086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34715,DS-0bb1e618-5926-4459-81a6-c588ee941f48,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-7b4df476-85bd-4c41-bee8-5cca6827a38d,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-ff8d0612-df16-4568-9718-42dcce41f294,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-5e38b172-df91-4986-b80e-23c9df84a221,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-ebde8da4-afcf-4d91-b53d-a419b15a13a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-6207f758-c376-497f-977c-af43e4632ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-0a72a655-fa75-4cb4-8801-f446d9587212,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-d9675d5d-1bd0-4b97-9c17-4c1bb5f42880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-674019832-172.17.0.15-1598473825086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34715,DS-0bb1e618-5926-4459-81a6-c588ee941f48,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-7b4df476-85bd-4c41-bee8-5cca6827a38d,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-ff8d0612-df16-4568-9718-42dcce41f294,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-5e38b172-df91-4986-b80e-23c9df84a221,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-ebde8da4-afcf-4d91-b53d-a419b15a13a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-6207f758-c376-497f-977c-af43e4632ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-0a72a655-fa75-4cb4-8801-f446d9587212,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-d9675d5d-1bd0-4b97-9c17-4c1bb5f42880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788042617-172.17.0.15-1598473877560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33688,DS-a57a0275-1c36-4b16-8b35-ca8da9cda4db,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-4d8524c8-b7ce-46b8-ae88-708f0967942c,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-201b6db7-486d-43b9-bf0a-ea8cd8a5e916,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-1dace59f-a8c0-4e64-8988-4a08aeccd920,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-6ba91971-135d-4146-8fbf-c8ac8e734c89,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-62904e50-529c-4440-9826-889a9bf3561d,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-44086fcd-3d23-4343-b531-8339da81c444,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-65d7b9a9-ac16-463d-89fb-407515622507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788042617-172.17.0.15-1598473877560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33688,DS-a57a0275-1c36-4b16-8b35-ca8da9cda4db,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-4d8524c8-b7ce-46b8-ae88-708f0967942c,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-201b6db7-486d-43b9-bf0a-ea8cd8a5e916,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-1dace59f-a8c0-4e64-8988-4a08aeccd920,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-6ba91971-135d-4146-8fbf-c8ac8e734c89,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-62904e50-529c-4440-9826-889a9bf3561d,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-44086fcd-3d23-4343-b531-8339da81c444,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-65d7b9a9-ac16-463d-89fb-407515622507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461638325-172.17.0.15-1598474048671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39411,DS-75994560-b52b-42bc-b907-9dd8d867c397,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-d5d2d813-a1c9-4b1f-954b-051ada49a93f,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-475dde01-7d33-4dd7-9415-c0176fb2a22e,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-ebdd6bc3-2408-4925-b0e8-fab96247e674,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-7be86094-913c-43e8-a979-cdf7408a71b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-cff6a51f-8412-4136-a009-3d72bae10059,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-dade824f-b6c6-4383-a1d2-7068be72ac03,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-c8da5ca5-8a79-4864-97d9-29972d7d6109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461638325-172.17.0.15-1598474048671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39411,DS-75994560-b52b-42bc-b907-9dd8d867c397,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-d5d2d813-a1c9-4b1f-954b-051ada49a93f,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-475dde01-7d33-4dd7-9415-c0176fb2a22e,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-ebdd6bc3-2408-4925-b0e8-fab96247e674,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-7be86094-913c-43e8-a979-cdf7408a71b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-cff6a51f-8412-4136-a009-3d72bae10059,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-dade824f-b6c6-4383-a1d2-7068be72ac03,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-c8da5ca5-8a79-4864-97d9-29972d7d6109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034636792-172.17.0.15-1598474116862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38945,DS-c721f58f-d12a-4fbd-b934-88979285b15c,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-a0f4e802-073e-4d20-9b4a-6d30322e4c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-1e160158-7edc-46e7-ab52-eff1d1e4f7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-c4f41d4f-3648-42e7-9f06-61378c4617b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-03a259ac-bd6c-4362-bddd-980c98b79e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-f6cd2951-1a76-42bd-8db4-fc1e53bdcbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-77e6eff5-c44b-4d04-adea-834c9da37c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-0c3226ae-e132-4f66-9c88-88d0ba810a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034636792-172.17.0.15-1598474116862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38945,DS-c721f58f-d12a-4fbd-b934-88979285b15c,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-a0f4e802-073e-4d20-9b4a-6d30322e4c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-1e160158-7edc-46e7-ab52-eff1d1e4f7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-c4f41d4f-3648-42e7-9f06-61378c4617b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-03a259ac-bd6c-4362-bddd-980c98b79e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-f6cd2951-1a76-42bd-8db4-fc1e53bdcbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-77e6eff5-c44b-4d04-adea-834c9da37c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-0c3226ae-e132-4f66-9c88-88d0ba810a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334987185-172.17.0.15-1598474169239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36858,DS-dc7560da-c2d0-4e55-9b4b-abd08339ed8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-e57b2bbb-8a4e-4821-a981-29e6e1e31157,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-26de3970-eb43-45c7-b30e-83ce0faa77d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-86c75215-a5d3-4ce6-97bc-75106ef27a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-afbe1549-1295-4f08-bd99-577f2e61ae41,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-a2740bc7-3db6-4717-ae2c-cbb97412af24,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-54188f7d-855e-4a0f-93dd-552a82886445,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-a519b6b6-53e7-48ea-97b6-a82a30ce739a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334987185-172.17.0.15-1598474169239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36858,DS-dc7560da-c2d0-4e55-9b4b-abd08339ed8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-e57b2bbb-8a4e-4821-a981-29e6e1e31157,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-26de3970-eb43-45c7-b30e-83ce0faa77d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-86c75215-a5d3-4ce6-97bc-75106ef27a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-afbe1549-1295-4f08-bd99-577f2e61ae41,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-a2740bc7-3db6-4717-ae2c-cbb97412af24,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-54188f7d-855e-4a0f-93dd-552a82886445,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-a519b6b6-53e7-48ea-97b6-a82a30ce739a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526340073-172.17.0.15-1598474220267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33614,DS-472d85a3-423f-4004-bab7-e653df64f336,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-464c07f5-91bc-4003-9fab-c407f70ffd96,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-637bfa82-32da-42bd-a62a-c358d577781c,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-4002e4b6-f8d3-4e1a-824e-b0fa817aadfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-f81ee89d-c7e7-4e7d-96d9-ebbf2dfdde91,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-5b0a0c1d-e9af-4d4a-8be0-89612ffdd0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-e6219a56-9bd2-4ecf-aeea-69aee3f304a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-fd368d27-46fb-4684-8090-d9b74a8cda36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526340073-172.17.0.15-1598474220267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33614,DS-472d85a3-423f-4004-bab7-e653df64f336,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-464c07f5-91bc-4003-9fab-c407f70ffd96,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-637bfa82-32da-42bd-a62a-c358d577781c,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-4002e4b6-f8d3-4e1a-824e-b0fa817aadfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-f81ee89d-c7e7-4e7d-96d9-ebbf2dfdde91,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-5b0a0c1d-e9af-4d4a-8be0-89612ffdd0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-e6219a56-9bd2-4ecf-aeea-69aee3f304a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-fd368d27-46fb-4684-8090-d9b74a8cda36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856356597-172.17.0.15-1598474339497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35001,DS-c3c83133-163e-4124-9e4a-7c0e9fa6733c,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-e9c44c95-53f8-4cfa-9f5a-429934063143,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-9ecb294c-5fa5-45b8-a858-e0eae774ea4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-4a6b42dd-85fb-4545-b6d0-d2b59b9b1fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-66238b14-81ba-4f10-9bb4-bffda2b5c846,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-4d68f800-9d1e-4b54-b511-0377cd25d521,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-af3ecd72-fb14-46ae-ad68-9f5d09c786f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-8f22c994-a71a-482c-acec-0d5f5b9313e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856356597-172.17.0.15-1598474339497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35001,DS-c3c83133-163e-4124-9e4a-7c0e9fa6733c,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-e9c44c95-53f8-4cfa-9f5a-429934063143,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-9ecb294c-5fa5-45b8-a858-e0eae774ea4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-4a6b42dd-85fb-4545-b6d0-d2b59b9b1fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-66238b14-81ba-4f10-9bb4-bffda2b5c846,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-4d68f800-9d1e-4b54-b511-0377cd25d521,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-af3ecd72-fb14-46ae-ad68-9f5d09c786f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-8f22c994-a71a-482c-acec-0d5f5b9313e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434606649-172.17.0.15-1598474871754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-286702fe-82a2-47c7-a075-84982d5b3514,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-4da64c08-491e-4b25-ac6d-5b13f807406b,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-e469990c-1556-44dc-8bb3-af76c6c323ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-8f129a3a-28a8-418c-a90c-2d9366811647,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-455157ac-20e2-44f2-adcd-001a107a7d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-76a965a2-d7dd-4304-bc0d-9a326a9a4d48,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-2d3076f4-9668-4e00-8747-aef06990776a,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-4d8bc8d8-877f-455c-9c31-cc0198e56c71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434606649-172.17.0.15-1598474871754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-286702fe-82a2-47c7-a075-84982d5b3514,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-4da64c08-491e-4b25-ac6d-5b13f807406b,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-e469990c-1556-44dc-8bb3-af76c6c323ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-8f129a3a-28a8-418c-a90c-2d9366811647,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-455157ac-20e2-44f2-adcd-001a107a7d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-76a965a2-d7dd-4304-bc0d-9a326a9a4d48,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-2d3076f4-9668-4e00-8747-aef06990776a,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-4d8bc8d8-877f-455c-9c31-cc0198e56c71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330012206-172.17.0.15-1598474889987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40300,DS-58386eb8-ed27-4118-a9b0-1c6f7b821305,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-04820c9e-3c28-4057-a4ef-017ccf06af3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-5cdebb90-2664-4b1b-9b1d-de56a45db742,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-36f651aa-fae4-4f57-ac9b-45eccd753a23,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-d25176d0-43b7-453f-8346-f711d5371077,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-008a1922-9767-44df-b9f4-f5cede6faab3,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-37ffcd00-c65f-48fe-9e95-18fdd426ae10,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-44d185d7-0ba4-4f95-b4c8-2de5db014a6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330012206-172.17.0.15-1598474889987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40300,DS-58386eb8-ed27-4118-a9b0-1c6f7b821305,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-04820c9e-3c28-4057-a4ef-017ccf06af3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-5cdebb90-2664-4b1b-9b1d-de56a45db742,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-36f651aa-fae4-4f57-ac9b-45eccd753a23,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-d25176d0-43b7-453f-8346-f711d5371077,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-008a1922-9767-44df-b9f4-f5cede6faab3,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-37ffcd00-c65f-48fe-9e95-18fdd426ae10,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-44d185d7-0ba4-4f95-b4c8-2de5db014a6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543621033-172.17.0.15-1598475078096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38138,DS-fc8c3245-abb7-47d4-a42b-3a67bbba1c96,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-a1717f37-0850-46b2-a75d-162c7ac5d4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-a31d72a6-4126-406a-bf15-8d4c558e2880,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-7c5f4d16-f893-4f9e-9c17-8b0242d31bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-f398e6b5-a23b-4626-afb9-c18b970f003d,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-c0566d7d-cf99-4066-9ded-790960389830,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-0c1a7768-cb36-4efa-90a1-cd27f344953e,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-54a5f496-ddef-4470-929f-be579f44e28f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543621033-172.17.0.15-1598475078096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38138,DS-fc8c3245-abb7-47d4-a42b-3a67bbba1c96,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-a1717f37-0850-46b2-a75d-162c7ac5d4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-a31d72a6-4126-406a-bf15-8d4c558e2880,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-7c5f4d16-f893-4f9e-9c17-8b0242d31bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-f398e6b5-a23b-4626-afb9-c18b970f003d,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-c0566d7d-cf99-4066-9ded-790960389830,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-0c1a7768-cb36-4efa-90a1-cd27f344953e,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-54a5f496-ddef-4470-929f-be579f44e28f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231467360-172.17.0.15-1598475112667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40861,DS-5a3b779a-0321-49d8-b260-9c21fcdef804,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-1e450011-e6b2-4c40-9d11-5fd3ca295f61,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-603a20b7-4b95-4377-9271-60ea950d76b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-5ce25998-cf00-48ab-8eed-fdba25927197,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-3d637e6e-15dd-45a1-90a7-9b0eeb8412ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-5c27c45e-d419-4fe6-97a4-5475f6772461,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-0012157b-1931-4190-99f7-e6671a470f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-365cf12b-0903-47c1-8f4f-c75df0eb1d87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231467360-172.17.0.15-1598475112667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40861,DS-5a3b779a-0321-49d8-b260-9c21fcdef804,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-1e450011-e6b2-4c40-9d11-5fd3ca295f61,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-603a20b7-4b95-4377-9271-60ea950d76b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-5ce25998-cf00-48ab-8eed-fdba25927197,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-3d637e6e-15dd-45a1-90a7-9b0eeb8412ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-5c27c45e-d419-4fe6-97a4-5475f6772461,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-0012157b-1931-4190-99f7-e6671a470f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-365cf12b-0903-47c1-8f4f-c75df0eb1d87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523084265-172.17.0.15-1598475233646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37631,DS-d5995cf0-7ecd-40c2-9539-6ad2469b1f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-34950f21-0165-47e7-b18d-d52d63860124,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-5e7b4332-e599-418f-adc8-d02c26fd81ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-dc9e524e-5057-4cad-95ab-f8536faeccf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-f8c16e16-64e9-4acc-a71f-8cc001ba2767,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-9282f11f-45f7-4a82-93d7-a947d0ba9d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-ca63f9ac-6edd-4661-aaae-b3925fb147b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-ea0f3cc3-ae8c-4631-aedd-7b8361789d60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523084265-172.17.0.15-1598475233646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37631,DS-d5995cf0-7ecd-40c2-9539-6ad2469b1f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-34950f21-0165-47e7-b18d-d52d63860124,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-5e7b4332-e599-418f-adc8-d02c26fd81ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-dc9e524e-5057-4cad-95ab-f8536faeccf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-f8c16e16-64e9-4acc-a71f-8cc001ba2767,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-9282f11f-45f7-4a82-93d7-a947d0ba9d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-ca63f9ac-6edd-4661-aaae-b3925fb147b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-ea0f3cc3-ae8c-4631-aedd-7b8361789d60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710019706-172.17.0.15-1598475421256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37218,DS-4c886851-2148-481e-957f-e29f7b7db62c,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-a326557c-5b55-4df5-a10c-01d5ce173859,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-b93db2a0-30d2-43b1-820c-c021a11cd7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-5e76a12d-2b41-49c0-9645-7c4b014fb735,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-bc94af94-2e44-4d4d-8aae-42479c5780bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-ba7b6dab-cded-424a-8242-4bddc6d54f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-acfefb7c-53b1-4623-bf13-6941914fc3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-0fd995a5-b005-4686-acb3-4e042d48e1ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710019706-172.17.0.15-1598475421256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37218,DS-4c886851-2148-481e-957f-e29f7b7db62c,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-a326557c-5b55-4df5-a10c-01d5ce173859,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-b93db2a0-30d2-43b1-820c-c021a11cd7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-5e76a12d-2b41-49c0-9645-7c4b014fb735,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-bc94af94-2e44-4d4d-8aae-42479c5780bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-ba7b6dab-cded-424a-8242-4bddc6d54f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-acfefb7c-53b1-4623-bf13-6941914fc3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-0fd995a5-b005-4686-acb3-4e042d48e1ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196126249-172.17.0.15-1598475438219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-3b359a72-da7f-40e8-a739-1b7f94f9b4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-7e218b96-cefd-4506-b7dd-060946fc6398,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-a7b4d10a-cab1-471c-b255-b1bbb9b81639,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-ce09f836-5a95-48ff-a087-efd3a2a529f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-76900e10-b9a3-4378-a86a-80e06c381bed,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-37c62493-1d51-4b61-abd0-d4d904f17089,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-75cf20f1-333c-497d-858a-af3586e716fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-25a801dc-66ca-42be-9777-bd447af3377b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196126249-172.17.0.15-1598475438219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-3b359a72-da7f-40e8-a739-1b7f94f9b4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-7e218b96-cefd-4506-b7dd-060946fc6398,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-a7b4d10a-cab1-471c-b255-b1bbb9b81639,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-ce09f836-5a95-48ff-a087-efd3a2a529f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-76900e10-b9a3-4378-a86a-80e06c381bed,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-37c62493-1d51-4b61-abd0-d4d904f17089,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-75cf20f1-333c-497d-858a-af3586e716fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-25a801dc-66ca-42be-9777-bd447af3377b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793186669-172.17.0.15-1598475455521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41401,DS-f2bdab30-b0f4-438c-aae9-f518a1fa3393,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-73ec9651-bcab-4df5-a6a0-60b88a068314,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-2ac3f6cf-5a05-4505-bba7-e9b969ab30ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-4c10b15f-c04b-4c0e-a9f8-3f4bf3ed8dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-91661ba2-d734-416c-a779-629c899be95b,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-4913cb7b-6c9d-4a45-958f-a891b62c7544,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-fca491bb-feed-4a77-aa86-752680a4720a,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-204e22d3-c911-4de2-b57a-c185b214cf55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793186669-172.17.0.15-1598475455521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41401,DS-f2bdab30-b0f4-438c-aae9-f518a1fa3393,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-73ec9651-bcab-4df5-a6a0-60b88a068314,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-2ac3f6cf-5a05-4505-bba7-e9b969ab30ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-4c10b15f-c04b-4c0e-a9f8-3f4bf3ed8dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-91661ba2-d734-416c-a779-629c899be95b,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-4913cb7b-6c9d-4a45-958f-a891b62c7544,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-fca491bb-feed-4a77-aa86-752680a4720a,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-204e22d3-c911-4de2-b57a-c185b214cf55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1233445319-172.17.0.15-1598475473561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39855,DS-3c82b846-319d-4f0b-9f61-a9e69cf141d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-b6bc0607-c695-4de6-9773-99419e2f69de,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-0cec8408-495c-4031-a88d-7fd14ff1f328,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-cac54b40-90bf-48c7-9524-20fe7066653c,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-eef59b25-5cd8-4207-ad3b-4f57bed2c54a,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-d0e9f85d-d174-4850-927c-344bcfe06cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-b4be1639-d799-46f5-8c25-6b60b36f06f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-75f2e786-4ba8-420e-890f-c06246906ee5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1233445319-172.17.0.15-1598475473561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39855,DS-3c82b846-319d-4f0b-9f61-a9e69cf141d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-b6bc0607-c695-4de6-9773-99419e2f69de,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-0cec8408-495c-4031-a88d-7fd14ff1f328,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-cac54b40-90bf-48c7-9524-20fe7066653c,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-eef59b25-5cd8-4207-ad3b-4f57bed2c54a,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-d0e9f85d-d174-4850-927c-344bcfe06cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-b4be1639-d799-46f5-8c25-6b60b36f06f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-75f2e786-4ba8-420e-890f-c06246906ee5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341306255-172.17.0.15-1598475507217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39884,DS-41be6ca4-428b-401e-a313-84df80d012df,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-a6388f6a-1b46-4ea5-aeef-b7d1875ffff8,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-657e25f5-6b2c-43aa-bd4e-009846353b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-af5646bb-cb89-4785-b291-911a1b24e7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-71c58d2f-3ec1-4fe9-874f-ef47834bc05f,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-858369a4-56f1-4bcc-bfec-d8dd5e1c0b16,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-80b1cec0-94ee-4760-a8c4-7e13853ea29c,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-750273eb-d4fc-4031-a8be-6af799fb0ce8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341306255-172.17.0.15-1598475507217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39884,DS-41be6ca4-428b-401e-a313-84df80d012df,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-a6388f6a-1b46-4ea5-aeef-b7d1875ffff8,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-657e25f5-6b2c-43aa-bd4e-009846353b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-af5646bb-cb89-4785-b291-911a1b24e7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-71c58d2f-3ec1-4fe9-874f-ef47834bc05f,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-858369a4-56f1-4bcc-bfec-d8dd5e1c0b16,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-80b1cec0-94ee-4760-a8c4-7e13853ea29c,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-750273eb-d4fc-4031-a8be-6af799fb0ce8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-833449213-172.17.0.15-1598475610003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34110,DS-9105aaaa-076c-49c3-a58d-ce8eced44f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-6e7a8907-afe9-4883-9ded-28bd87288b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-1da52d6c-ec17-4768-b78c-b7459d3fba55,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-db632a48-8f64-4660-a914-77ff5abea0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-ffec71c0-0385-4259-aa77-c1e92ac7f2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-a7931a9e-9d20-4e91-bf97-1d72d8ea48e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-080de7de-7953-455b-9cee-79690161dcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-1abe0e73-50d8-496b-b3e5-664847c57298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-833449213-172.17.0.15-1598475610003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34110,DS-9105aaaa-076c-49c3-a58d-ce8eced44f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-6e7a8907-afe9-4883-9ded-28bd87288b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-1da52d6c-ec17-4768-b78c-b7459d3fba55,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-db632a48-8f64-4660-a914-77ff5abea0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-ffec71c0-0385-4259-aa77-c1e92ac7f2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-a7931a9e-9d20-4e91-bf97-1d72d8ea48e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-080de7de-7953-455b-9cee-79690161dcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-1abe0e73-50d8-496b-b3e5-664847c57298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415498560-172.17.0.15-1598475797220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44980,DS-327f8ad4-213b-4268-870e-d82d1f4dd6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-5aa5e16c-4c22-4041-90ff-634364424204,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-5f4abaf5-4a11-43b5-b5c4-756f88ef678c,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-518ddbe3-abdb-42da-9a55-2b89633b3e63,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-96645e9e-3f6b-4851-9e4b-e36b9804f717,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-616d5c67-e012-40e6-bb4d-d1c5b5be506a,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-76bf5f3a-d9a7-4dcb-988f-c175e56e465f,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-f43ab6a0-7d6e-41b9-a07e-1d7d11212f37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415498560-172.17.0.15-1598475797220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44980,DS-327f8ad4-213b-4268-870e-d82d1f4dd6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-5aa5e16c-4c22-4041-90ff-634364424204,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-5f4abaf5-4a11-43b5-b5c4-756f88ef678c,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-518ddbe3-abdb-42da-9a55-2b89633b3e63,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-96645e9e-3f6b-4851-9e4b-e36b9804f717,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-616d5c67-e012-40e6-bb4d-d1c5b5be506a,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-76bf5f3a-d9a7-4dcb-988f-c175e56e465f,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-f43ab6a0-7d6e-41b9-a07e-1d7d11212f37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 2747
