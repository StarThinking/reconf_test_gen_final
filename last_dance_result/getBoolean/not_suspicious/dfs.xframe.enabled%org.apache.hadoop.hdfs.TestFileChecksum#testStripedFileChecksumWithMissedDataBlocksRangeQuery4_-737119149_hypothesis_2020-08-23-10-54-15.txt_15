reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148101583-172.17.0.11-1598180121800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-b0a249ef-6783-4782-a541-4a98e1302663,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-648c1e4e-a098-44a4-b636-a13772e3d8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-47df6828-1775-4d04-bbfe-e6c2b3c9c026,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-7b0cbcad-4e92-43de-b276-d781e51db29a,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-628349b0-1584-440c-8d6c-3fc025ceff58,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-19ef3291-8d32-4349-bf53-c2925e52b5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-eebf7c73-4a0c-41e5-8229-d14b50239e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-1e4bcc2f-e1f3-473d-979d-f333d9db0e79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148101583-172.17.0.11-1598180121800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-b0a249ef-6783-4782-a541-4a98e1302663,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-648c1e4e-a098-44a4-b636-a13772e3d8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-47df6828-1775-4d04-bbfe-e6c2b3c9c026,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-7b0cbcad-4e92-43de-b276-d781e51db29a,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-628349b0-1584-440c-8d6c-3fc025ceff58,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-19ef3291-8d32-4349-bf53-c2925e52b5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-eebf7c73-4a0c-41e5-8229-d14b50239e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-1e4bcc2f-e1f3-473d-979d-f333d9db0e79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780488822-172.17.0.11-1598180759906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39489,DS-fd6bb2aa-44a4-48c0-a044-4c4908509b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-796dae7b-987a-4cce-8a72-8b6f8e1db454,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-5a15401b-1600-40b1-9189-281e6925b1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-0d83ff3a-e72f-45b8-b2be-d9ae283f0aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-298a50d9-e42a-426c-b4c8-52f508c2f20a,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-6dae7438-ae95-4742-87f5-9b08a2ee8331,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-b958bbb5-8599-4021-a6af-6bb9cafa2ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-03fd5b2f-3fb7-4b7f-8181-41fa48c9216b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780488822-172.17.0.11-1598180759906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39489,DS-fd6bb2aa-44a4-48c0-a044-4c4908509b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-796dae7b-987a-4cce-8a72-8b6f8e1db454,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-5a15401b-1600-40b1-9189-281e6925b1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-0d83ff3a-e72f-45b8-b2be-d9ae283f0aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-298a50d9-e42a-426c-b4c8-52f508c2f20a,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-6dae7438-ae95-4742-87f5-9b08a2ee8331,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-b958bbb5-8599-4021-a6af-6bb9cafa2ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-03fd5b2f-3fb7-4b7f-8181-41fa48c9216b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-993227179-172.17.0.11-1598180888465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44838,DS-58b02936-10a5-4a29-a6d0-7943e3191476,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-2b557105-0d37-468f-b0bc-db9ac423a4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-dca1a5ad-52e0-4a50-9c6c-0aae57e03848,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-44101546-d539-4332-b27f-840c561aad14,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-f62b73a5-b6de-4a52-a4b1-7f252c54e353,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-de1f7b46-5d86-42ae-b1ae-65c63172c6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-a621f044-5e0a-4644-8dc3-803ca7fbae8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-acfefe58-b338-484b-a19a-9b28d4a1cf15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-993227179-172.17.0.11-1598180888465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44838,DS-58b02936-10a5-4a29-a6d0-7943e3191476,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-2b557105-0d37-468f-b0bc-db9ac423a4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-dca1a5ad-52e0-4a50-9c6c-0aae57e03848,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-44101546-d539-4332-b27f-840c561aad14,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-f62b73a5-b6de-4a52-a4b1-7f252c54e353,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-de1f7b46-5d86-42ae-b1ae-65c63172c6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-a621f044-5e0a-4644-8dc3-803ca7fbae8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-acfefe58-b338-484b-a19a-9b28d4a1cf15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570287774-172.17.0.11-1598180930711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34344,DS-a9f54770-e3c8-46da-802e-f499f4585f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-26a237c5-0236-4379-a2a1-2c8b31e4d505,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-53975f8f-cae3-4823-8394-3491c304b28f,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-eadb74de-87ba-4624-bf29-1cba1c96eac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-7e6a1272-23f1-46b1-9120-6f7cabf21daf,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-a7f2816d-8979-4624-bf6a-88fae336c3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-08ad8168-086f-4812-a115-e9e1083a7bce,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-4ec0e835-177f-4993-be42-97713d17229d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570287774-172.17.0.11-1598180930711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34344,DS-a9f54770-e3c8-46da-802e-f499f4585f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-26a237c5-0236-4379-a2a1-2c8b31e4d505,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-53975f8f-cae3-4823-8394-3491c304b28f,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-eadb74de-87ba-4624-bf29-1cba1c96eac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-7e6a1272-23f1-46b1-9120-6f7cabf21daf,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-a7f2816d-8979-4624-bf6a-88fae336c3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-08ad8168-086f-4812-a115-e9e1083a7bce,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-4ec0e835-177f-4993-be42-97713d17229d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133669923-172.17.0.11-1598181883475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38445,DS-8251acd0-af7d-43df-ad30-54ba28dd0143,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-eaaadd01-155d-4775-95bc-0e497fda8ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-86a7f81a-0b71-4357-be1a-48f93bef68d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-96564782-f0fd-4ed0-b672-0de1c98b5fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-8a7f3772-a9b3-4303-b42f-474edf22b5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-01cba2c5-14be-41f1-a98c-a343a1774c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-4c8e9c5e-426d-4b80-8dc3-1b989080a7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-33e774e6-337f-48f9-a154-2e51a5ddb5ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133669923-172.17.0.11-1598181883475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38445,DS-8251acd0-af7d-43df-ad30-54ba28dd0143,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-eaaadd01-155d-4775-95bc-0e497fda8ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-86a7f81a-0b71-4357-be1a-48f93bef68d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-96564782-f0fd-4ed0-b672-0de1c98b5fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-8a7f3772-a9b3-4303-b42f-474edf22b5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-01cba2c5-14be-41f1-a98c-a343a1774c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-4c8e9c5e-426d-4b80-8dc3-1b989080a7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-33e774e6-337f-48f9-a154-2e51a5ddb5ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091580351-172.17.0.11-1598182360133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36291,DS-fed9a196-1615-41ad-8897-9e4519716062,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-a7cf7faf-14ed-4ab7-baaf-84e75013697b,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-1f0b77ab-7321-4a04-8ec6-eca65c4e59fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-d2df8c08-8dcb-41fd-b166-f3c34692df4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-bb41d17a-26c9-48b3-9a9c-07f3ca809a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-7af9cab1-e849-4ac6-97df-086db2b2c69b,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-96d14d87-74ca-4309-b84e-92d27b7cd2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-54fbe23b-0c32-43f5-815a-c002ae48dd38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091580351-172.17.0.11-1598182360133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36291,DS-fed9a196-1615-41ad-8897-9e4519716062,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-a7cf7faf-14ed-4ab7-baaf-84e75013697b,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-1f0b77ab-7321-4a04-8ec6-eca65c4e59fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-d2df8c08-8dcb-41fd-b166-f3c34692df4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-bb41d17a-26c9-48b3-9a9c-07f3ca809a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-7af9cab1-e849-4ac6-97df-086db2b2c69b,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-96d14d87-74ca-4309-b84e-92d27b7cd2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-54fbe23b-0c32-43f5-815a-c002ae48dd38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010049943-172.17.0.11-1598182882241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44467,DS-97709c96-c617-4847-b784-c6d5e33b830f,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-07c12c53-0fcd-4293-abdb-b89cf94973d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-a6479cf5-d746-4f70-a56c-14a69ab94011,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-b14f7d7e-ac3b-4c39-9434-23f56f14d220,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-59d1c12c-d213-497a-b800-e70b47e7528b,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-638fed5e-33d5-4dfc-92c8-ce8e6d437764,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-3714669f-9f1c-4dc2-b89c-6e2427e68314,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-a09b8d17-2601-4229-b2d8-8f49d6f93bd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010049943-172.17.0.11-1598182882241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44467,DS-97709c96-c617-4847-b784-c6d5e33b830f,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-07c12c53-0fcd-4293-abdb-b89cf94973d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-a6479cf5-d746-4f70-a56c-14a69ab94011,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-b14f7d7e-ac3b-4c39-9434-23f56f14d220,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-59d1c12c-d213-497a-b800-e70b47e7528b,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-638fed5e-33d5-4dfc-92c8-ce8e6d437764,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-3714669f-9f1c-4dc2-b89c-6e2427e68314,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-a09b8d17-2601-4229-b2d8-8f49d6f93bd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168355592-172.17.0.11-1598183231849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43509,DS-5d140c71-7060-403f-9f41-a801da104055,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-73dd15b2-1f68-4e58-a53d-8bf89a51b63b,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-84abdf6e-7093-40ed-b495-736df7160dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-41cc2213-ed6f-4f48-a2ab-d65280ed1e69,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-3aaceb28-12a5-405d-9ab7-9b83b9d46623,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-0aa39e01-19c7-4906-9d28-397708db3864,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-2730dc3a-815d-4002-b105-055999e2e23b,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-18556b02-b0e2-411f-81c5-9f83bf8d497b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168355592-172.17.0.11-1598183231849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43509,DS-5d140c71-7060-403f-9f41-a801da104055,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-73dd15b2-1f68-4e58-a53d-8bf89a51b63b,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-84abdf6e-7093-40ed-b495-736df7160dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-41cc2213-ed6f-4f48-a2ab-d65280ed1e69,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-3aaceb28-12a5-405d-9ab7-9b83b9d46623,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-0aa39e01-19c7-4906-9d28-397708db3864,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-2730dc3a-815d-4002-b105-055999e2e23b,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-18556b02-b0e2-411f-81c5-9f83bf8d497b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301873092-172.17.0.11-1598184062603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41721,DS-5683c23c-ed7b-4879-a58a-2d14cf804207,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-ce3d6a49-c5d6-4849-ab2a-253eaea37c76,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-e0b1104e-e034-4679-8a4c-99e4127767e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-2a3ab58a-5fe0-4bec-bbff-ac88a53ff3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-da6b27da-b75c-4031-b6c7-c235761280d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-d7deb738-1619-491f-87ae-5d52b93808d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-a45d8277-daa6-4257-9897-3193a46b8505,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-59598976-9c44-49be-9a20-4975581e6774,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301873092-172.17.0.11-1598184062603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41721,DS-5683c23c-ed7b-4879-a58a-2d14cf804207,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-ce3d6a49-c5d6-4849-ab2a-253eaea37c76,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-e0b1104e-e034-4679-8a4c-99e4127767e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-2a3ab58a-5fe0-4bec-bbff-ac88a53ff3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-da6b27da-b75c-4031-b6c7-c235761280d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-d7deb738-1619-491f-87ae-5d52b93808d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-a45d8277-daa6-4257-9897-3193a46b8505,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-59598976-9c44-49be-9a20-4975581e6774,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614777208-172.17.0.11-1598184773256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37856,DS-ff98f3d7-b322-46ae-8995-b02971a79da2,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-9bf7cef2-41e8-4262-bfdc-1b7b78c43b23,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-654ea2b9-ccb1-4398-a3dc-d8bf159530ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-457e5dbe-aa4c-46c5-9964-e638b4253308,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-103ade34-a620-4719-b47b-a26039aa4661,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-2c55a681-7ec8-4afc-a4a1-df136349cc17,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-ac918028-e768-4078-8e46-33a1c8f31c21,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-4105d5f6-7425-48f3-b676-39b716e1a8f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614777208-172.17.0.11-1598184773256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37856,DS-ff98f3d7-b322-46ae-8995-b02971a79da2,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-9bf7cef2-41e8-4262-bfdc-1b7b78c43b23,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-654ea2b9-ccb1-4398-a3dc-d8bf159530ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-457e5dbe-aa4c-46c5-9964-e638b4253308,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-103ade34-a620-4719-b47b-a26039aa4661,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-2c55a681-7ec8-4afc-a4a1-df136349cc17,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-ac918028-e768-4078-8e46-33a1c8f31c21,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-4105d5f6-7425-48f3-b676-39b716e1a8f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1802837859-172.17.0.11-1598185438022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46082,DS-a40817ce-aae7-4a36-97dd-933c2823d648,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-7885c0f4-8247-456b-986c-63ee432f03c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-d55354bb-59b6-4981-9a9c-6e74c0c5570f,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-a1ec1fb6-eac6-4f54-90f7-f45930e723ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-41a0e304-4d46-4633-8a65-4884a4cd3e88,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-83d1a693-6e12-4d69-8426-283447dbe824,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-1e1e714f-62bc-4aea-9bd9-db317401efee,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-9a86b097-ea78-4312-970b-ad70acfe3d5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1802837859-172.17.0.11-1598185438022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46082,DS-a40817ce-aae7-4a36-97dd-933c2823d648,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-7885c0f4-8247-456b-986c-63ee432f03c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-d55354bb-59b6-4981-9a9c-6e74c0c5570f,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-a1ec1fb6-eac6-4f54-90f7-f45930e723ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-41a0e304-4d46-4633-8a65-4884a4cd3e88,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-83d1a693-6e12-4d69-8426-283447dbe824,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-1e1e714f-62bc-4aea-9bd9-db317401efee,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-9a86b097-ea78-4312-970b-ad70acfe3d5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935783291-172.17.0.11-1598185514982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40008,DS-2fb9cb69-bb44-4051-b30b-a5adf94d5726,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-a21bfb5f-84ed-43b4-af80-93633cea5a94,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-be69080b-1c89-4669-8820-270b964a945e,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-bb90e916-bebc-4807-8c56-8e6d8c030d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-ebf25356-fa9a-48b2-bf24-ba2dd7f9cc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-36ab5a0a-3e52-46b8-9c3e-c4d246b7ee4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-b682ac3a-e4a5-4dca-b525-258c4214e217,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-958259b0-e065-4a4b-a03a-f9e2cca531b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935783291-172.17.0.11-1598185514982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40008,DS-2fb9cb69-bb44-4051-b30b-a5adf94d5726,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-a21bfb5f-84ed-43b4-af80-93633cea5a94,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-be69080b-1c89-4669-8820-270b964a945e,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-bb90e916-bebc-4807-8c56-8e6d8c030d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-ebf25356-fa9a-48b2-bf24-ba2dd7f9cc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-36ab5a0a-3e52-46b8-9c3e-c4d246b7ee4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-b682ac3a-e4a5-4dca-b525-258c4214e217,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-958259b0-e065-4a4b-a03a-f9e2cca531b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5648
