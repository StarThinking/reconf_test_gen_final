reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258210297-172.17.0.19-1598121202930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34064,DS-dc8a00ff-3197-4000-b7d5-7388ee4fbde1,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-f9fccfa8-12de-4dc3-b699-d5103387157a,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-f8bd7fab-3572-495f-9776-7515c935b1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-eeda728a-3f6a-485b-9402-9056d91563d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-551f81af-b0ec-46ba-af66-5a5880f6f1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-7c306dd7-b5bd-4b7a-abd3-12f1dbbef2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-0cef16bf-e565-48fe-8a1f-bf5caae5a515,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-7072e33c-f097-491e-a4d2-30e0ec101f00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258210297-172.17.0.19-1598121202930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34064,DS-dc8a00ff-3197-4000-b7d5-7388ee4fbde1,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-f9fccfa8-12de-4dc3-b699-d5103387157a,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-f8bd7fab-3572-495f-9776-7515c935b1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-eeda728a-3f6a-485b-9402-9056d91563d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-551f81af-b0ec-46ba-af66-5a5880f6f1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-7c306dd7-b5bd-4b7a-abd3-12f1dbbef2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-0cef16bf-e565-48fe-8a1f-bf5caae5a515,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-7072e33c-f097-491e-a4d2-30e0ec101f00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944594560-172.17.0.19-1598121516964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39124,DS-e241f487-7be4-4548-b11f-7a76e002a100,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-15753c37-69b5-410d-8b63-3014292df7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-f51b3845-0bde-437f-8ab3-be5ad51f3e62,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-f7d732eb-24f1-4f29-bc24-8739e0408afe,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-77fc74f5-9022-4b10-b725-fb2fd644a080,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-8570cd39-a7af-4e48-bde3-7a6767b78f12,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-e6f6c9be-1e52-4aad-9de4-ffa6990c74f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-a08f5bda-a5a3-4fec-b7fe-5c4311221ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944594560-172.17.0.19-1598121516964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39124,DS-e241f487-7be4-4548-b11f-7a76e002a100,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-15753c37-69b5-410d-8b63-3014292df7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-f51b3845-0bde-437f-8ab3-be5ad51f3e62,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-f7d732eb-24f1-4f29-bc24-8739e0408afe,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-77fc74f5-9022-4b10-b725-fb2fd644a080,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-8570cd39-a7af-4e48-bde3-7a6767b78f12,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-e6f6c9be-1e52-4aad-9de4-ffa6990c74f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-a08f5bda-a5a3-4fec-b7fe-5c4311221ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308007598-172.17.0.19-1598122260303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34178,DS-a13cfa12-4b82-464d-989a-b7577df3c8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-c3ea2289-5fea-41b8-b301-ab2ca99a5bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-2d5b3c27-4342-4b8f-8416-924d7fb13517,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-1096ce0f-334f-40f4-b4c8-690c7858f835,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-85821256-6c47-4bc3-b02f-7bb59361903e,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-e9146fdb-f1f9-45b6-8c57-524d9439317b,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-b30175fb-5ec3-4be1-9a64-09e2a5717836,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-07f6bf70-8f1e-44d3-af80-c950a2a61dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308007598-172.17.0.19-1598122260303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34178,DS-a13cfa12-4b82-464d-989a-b7577df3c8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-c3ea2289-5fea-41b8-b301-ab2ca99a5bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-2d5b3c27-4342-4b8f-8416-924d7fb13517,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-1096ce0f-334f-40f4-b4c8-690c7858f835,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-85821256-6c47-4bc3-b02f-7bb59361903e,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-e9146fdb-f1f9-45b6-8c57-524d9439317b,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-b30175fb-5ec3-4be1-9a64-09e2a5717836,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-07f6bf70-8f1e-44d3-af80-c950a2a61dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-660160104-172.17.0.19-1598122302718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41608,DS-d7baa433-bbe2-413d-9990-2a76a9dfb173,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-dae1aac0-12ca-41cc-9bcc-3676fca4d3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-35e8021f-b221-4f2e-a50b-08e42eea5644,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-120a4907-9ba4-4919-abb0-86a7f7efa750,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-f6c6e7c0-4344-4bc2-9ab0-a1582908f7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-ba5bf730-a09d-4adb-bcf8-bf6242eed455,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-ecfc8738-f176-402f-8354-3347d0da761f,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-9228deb7-c4d2-4f75-91b8-6925dd15fff9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-660160104-172.17.0.19-1598122302718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41608,DS-d7baa433-bbe2-413d-9990-2a76a9dfb173,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-dae1aac0-12ca-41cc-9bcc-3676fca4d3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-35e8021f-b221-4f2e-a50b-08e42eea5644,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-120a4907-9ba4-4919-abb0-86a7f7efa750,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-f6c6e7c0-4344-4bc2-9ab0-a1582908f7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-ba5bf730-a09d-4adb-bcf8-bf6242eed455,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-ecfc8738-f176-402f-8354-3347d0da761f,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-9228deb7-c4d2-4f75-91b8-6925dd15fff9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378459693-172.17.0.19-1598122379785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38364,DS-7cbb2408-deb7-443f-8a72-fdfe6dc593ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-1742009d-889c-438f-ab52-efd04892287f,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-b83455a1-f5da-48fe-a245-65028510bb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-cf44ed2e-e992-4bc9-a093-f33fd7b424c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-94a55405-50b1-4642-bcbf-12f166a8d31f,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-ceaaeb27-90d0-47cc-bac7-f34cb3d4a393,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-8270eed0-1892-44b2-b49b-f976c3fe4607,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-e273f712-7e6d-4c37-a2d6-76ab89ebce7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378459693-172.17.0.19-1598122379785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38364,DS-7cbb2408-deb7-443f-8a72-fdfe6dc593ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-1742009d-889c-438f-ab52-efd04892287f,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-b83455a1-f5da-48fe-a245-65028510bb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-cf44ed2e-e992-4bc9-a093-f33fd7b424c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-94a55405-50b1-4642-bcbf-12f166a8d31f,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-ceaaeb27-90d0-47cc-bac7-f34cb3d4a393,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-8270eed0-1892-44b2-b49b-f976c3fe4607,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-e273f712-7e6d-4c37-a2d6-76ab89ebce7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129052882-172.17.0.19-1598122547514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46776,DS-5022e179-cecd-4def-9200-b0c05c428a42,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-ff960ab9-e61b-4802-8c78-4e4a7534e753,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-c0d6acb7-50d5-48f8-a8ac-a0d6551f36ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-f3fa6c87-39a0-4f0a-b936-a19da827213b,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-fa2b7275-865a-4578-9fce-a3b3e2df45fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-883791bd-2c64-4644-8209-d10653e3900e,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-cee538f4-36bc-4e72-954f-debbafd0c68a,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-c62702f2-1db6-403e-89f2-fae359e4f50c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129052882-172.17.0.19-1598122547514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46776,DS-5022e179-cecd-4def-9200-b0c05c428a42,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-ff960ab9-e61b-4802-8c78-4e4a7534e753,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-c0d6acb7-50d5-48f8-a8ac-a0d6551f36ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-f3fa6c87-39a0-4f0a-b936-a19da827213b,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-fa2b7275-865a-4578-9fce-a3b3e2df45fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-883791bd-2c64-4644-8209-d10653e3900e,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-cee538f4-36bc-4e72-954f-debbafd0c68a,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-c62702f2-1db6-403e-89f2-fae359e4f50c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069538720-172.17.0.19-1598122796656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42951,DS-5280269d-3df1-46f2-b3b0-4a760333a5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-99757379-07e9-4f53-9ad2-ef39f3c2c784,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-2c6bbb58-3aea-4ca4-bf1d-a6209699bb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-8730c2f9-05e4-4eab-9ef1-59660f7fb49b,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-3154d66d-ecdd-4b7c-b2e5-eb0ac03ade64,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-ea347343-e1c7-4eac-b41e-a6992d3d940f,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-59469f4d-143b-48eb-8555-f225f33d695c,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-6e2b61cf-62f9-43d1-8930-4bdb0b13d1eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069538720-172.17.0.19-1598122796656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42951,DS-5280269d-3df1-46f2-b3b0-4a760333a5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-99757379-07e9-4f53-9ad2-ef39f3c2c784,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-2c6bbb58-3aea-4ca4-bf1d-a6209699bb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-8730c2f9-05e4-4eab-9ef1-59660f7fb49b,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-3154d66d-ecdd-4b7c-b2e5-eb0ac03ade64,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-ea347343-e1c7-4eac-b41e-a6992d3d940f,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-59469f4d-143b-48eb-8555-f225f33d695c,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-6e2b61cf-62f9-43d1-8930-4bdb0b13d1eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44507208-172.17.0.19-1598123331190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34612,DS-84bf285c-f4aa-4b7a-b471-30a378aefdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-4927b097-05bb-409c-a8a0-878f52d7f209,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-8c2fc454-bc7b-425c-8dc8-46b73dd85c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-4490b502-9017-408c-8b3f-7586e23a2ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-1dc7aae0-c663-48d9-ab93-d6b95c4e7b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-59e29a3d-eccf-4357-b1df-a6f33eddd6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-27487a6f-24aa-4bd8-9894-54bae728d27b,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-22a250fd-f41a-4b8c-b4d8-0b75452805ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44507208-172.17.0.19-1598123331190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34612,DS-84bf285c-f4aa-4b7a-b471-30a378aefdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-4927b097-05bb-409c-a8a0-878f52d7f209,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-8c2fc454-bc7b-425c-8dc8-46b73dd85c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-4490b502-9017-408c-8b3f-7586e23a2ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-1dc7aae0-c663-48d9-ab93-d6b95c4e7b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-59e29a3d-eccf-4357-b1df-a6f33eddd6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-27487a6f-24aa-4bd8-9894-54bae728d27b,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-22a250fd-f41a-4b8c-b4d8-0b75452805ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611744115-172.17.0.19-1598123711514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-a1413284-12cd-4fa6-a65d-62a340648c67,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-a9382f36-f36f-42d1-9ed6-d79b119d844a,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-c0cfeb6a-e6d5-4890-8075-65023469fca6,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-28b1efe3-c075-4600-a8f6-1f34b7020278,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-7f8d242c-a8c5-4e09-afdb-2c07abdd8582,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-cce36388-3cf7-482c-b134-5bed8fe17e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-2be59bc9-a4ff-447a-85ef-c4b005535996,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-4f2fea58-1352-4a91-b338-f9563421ebd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611744115-172.17.0.19-1598123711514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-a1413284-12cd-4fa6-a65d-62a340648c67,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-a9382f36-f36f-42d1-9ed6-d79b119d844a,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-c0cfeb6a-e6d5-4890-8075-65023469fca6,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-28b1efe3-c075-4600-a8f6-1f34b7020278,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-7f8d242c-a8c5-4e09-afdb-2c07abdd8582,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-cce36388-3cf7-482c-b134-5bed8fe17e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-2be59bc9-a4ff-447a-85ef-c4b005535996,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-4f2fea58-1352-4a91-b338-f9563421ebd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778420816-172.17.0.19-1598123745543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38870,DS-3114cf05-5563-4b74-994f-336f830936e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-ca3e5124-14ea-466d-b459-eb2e3a21c2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-68b84e49-5a13-4de0-9794-863a7dc24e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-7a917eb4-5023-4da2-b155-d9f2be399521,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-b1f71ca9-9385-450e-8b03-51dbc6222653,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-dfed459f-c857-48a8-b5ed-5b1dead63031,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-63a20b52-a949-4c7b-a5b0-dc020c689392,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-e7280eb4-0004-4b51-a951-288eca90d067,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778420816-172.17.0.19-1598123745543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38870,DS-3114cf05-5563-4b74-994f-336f830936e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-ca3e5124-14ea-466d-b459-eb2e3a21c2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-68b84e49-5a13-4de0-9794-863a7dc24e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-7a917eb4-5023-4da2-b155-d9f2be399521,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-b1f71ca9-9385-450e-8b03-51dbc6222653,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-dfed459f-c857-48a8-b5ed-5b1dead63031,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-63a20b52-a949-4c7b-a5b0-dc020c689392,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-e7280eb4-0004-4b51-a951-288eca90d067,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650840586-172.17.0.19-1598123861150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45420,DS-12ca044d-6266-4dc5-bdcb-30d205da6433,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-459feac1-1ffc-4b1c-9a57-38a4c4229ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-fea1f509-af6f-4b7e-aa87-d9a3899db509,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-a0b36ba1-0893-49be-bd56-fd45db945f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-334e8004-f624-474d-af33-703fabad5db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-b0930f04-976d-4e4b-a4e6-1c6e986d7ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-aab9c209-0224-47f9-a495-7888a2938498,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-0fb2c1d1-01d1-4fad-bb9a-74712f344984,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650840586-172.17.0.19-1598123861150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45420,DS-12ca044d-6266-4dc5-bdcb-30d205da6433,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-459feac1-1ffc-4b1c-9a57-38a4c4229ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-fea1f509-af6f-4b7e-aa87-d9a3899db509,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-a0b36ba1-0893-49be-bd56-fd45db945f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-334e8004-f624-474d-af33-703fabad5db7,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-b0930f04-976d-4e4b-a4e6-1c6e986d7ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-aab9c209-0224-47f9-a495-7888a2938498,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-0fb2c1d1-01d1-4fad-bb9a-74712f344984,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881197586-172.17.0.19-1598124775703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38115,DS-ac64acf5-cd26-447a-8faf-b55a21fba229,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-dc8aad4a-43ba-41ef-b7d6-9a91e8bb2d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-665dae1c-17a1-498d-a9ee-e8ce8ba86aef,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-a917c172-4708-4b0a-8680-573a0b132a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-470003ed-bdc8-462b-83a1-d53910165cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-9ee5a573-d075-4a3a-be1f-34b287e4b9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-46fdab67-5c1e-4799-99cb-f2100a187cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-b1326ef9-7bd7-4911-ae51-1f71e8c60002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881197586-172.17.0.19-1598124775703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38115,DS-ac64acf5-cd26-447a-8faf-b55a21fba229,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-dc8aad4a-43ba-41ef-b7d6-9a91e8bb2d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-665dae1c-17a1-498d-a9ee-e8ce8ba86aef,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-a917c172-4708-4b0a-8680-573a0b132a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-470003ed-bdc8-462b-83a1-d53910165cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-9ee5a573-d075-4a3a-be1f-34b287e4b9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-46fdab67-5c1e-4799-99cb-f2100a187cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-b1326ef9-7bd7-4911-ae51-1f71e8c60002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185472280-172.17.0.19-1598125686831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36841,DS-b2a91596-a701-4a7b-983c-bffb21a09adb,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-ced40674-5aae-4c8d-b879-dee23d56bb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-b80b3fbc-1875-40c3-b283-48a041c67043,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-20e2209d-f278-4eca-8dab-efad3185753b,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-f01e84ea-2fc0-4df4-99aa-0efecbd17169,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-58a2a603-1175-451e-b18c-dfe4fa27e2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-72ff3a75-1182-4365-949d-d35d2892bcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-d4f573aa-49d4-4767-b8c6-07ab5fe82a0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185472280-172.17.0.19-1598125686831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36841,DS-b2a91596-a701-4a7b-983c-bffb21a09adb,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-ced40674-5aae-4c8d-b879-dee23d56bb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-b80b3fbc-1875-40c3-b283-48a041c67043,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-20e2209d-f278-4eca-8dab-efad3185753b,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-f01e84ea-2fc0-4df4-99aa-0efecbd17169,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-58a2a603-1175-451e-b18c-dfe4fa27e2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-72ff3a75-1182-4365-949d-d35d2892bcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-d4f573aa-49d4-4767-b8c6-07ab5fe82a0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067585472-172.17.0.19-1598126180240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34435,DS-24cb8d8b-33d1-47b3-8032-6631adaa73d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-0f778030-255e-4e10-a5ef-8080923a1cef,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-75a30699-585a-4ab8-b669-058e383d5b70,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-640d42e0-d5d9-472c-a5c9-f4eb3ec72533,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-2ac803f3-cf7d-4c17-83f6-3608cefbe943,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-95de78b4-d134-4e4b-8fec-49e5085c5089,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-c1522a70-b76d-4fcc-835e-c5346d2f4d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-0c01a6ff-8cc7-4435-9439-6bba9fc480da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067585472-172.17.0.19-1598126180240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34435,DS-24cb8d8b-33d1-47b3-8032-6631adaa73d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-0f778030-255e-4e10-a5ef-8080923a1cef,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-75a30699-585a-4ab8-b669-058e383d5b70,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-640d42e0-d5d9-472c-a5c9-f4eb3ec72533,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-2ac803f3-cf7d-4c17-83f6-3608cefbe943,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-95de78b4-d134-4e4b-8fec-49e5085c5089,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-c1522a70-b76d-4fcc-835e-c5346d2f4d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-0c01a6ff-8cc7-4435-9439-6bba9fc480da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639397838-172.17.0.19-1598126348518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-48c9ad52-7755-455a-82fd-297d627ec700,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-6cb8acb5-def2-47ef-a79a-d40abab81fea,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-8680fc0a-b3a1-49ac-9beb-592938a66026,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-09d40d7e-ebd4-4033-895b-b44b296662a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-7b7c2f25-b09b-43e0-bc39-04b90fdc1944,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-27840b76-3ddb-4311-89ec-a1184f332154,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-342d78e7-087b-4b70-957a-9f2d30cc4722,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-9cfe2165-61b9-434f-b396-d1a7618c4fa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639397838-172.17.0.19-1598126348518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45373,DS-48c9ad52-7755-455a-82fd-297d627ec700,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-6cb8acb5-def2-47ef-a79a-d40abab81fea,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-8680fc0a-b3a1-49ac-9beb-592938a66026,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-09d40d7e-ebd4-4033-895b-b44b296662a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-7b7c2f25-b09b-43e0-bc39-04b90fdc1944,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-27840b76-3ddb-4311-89ec-a1184f332154,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-342d78e7-087b-4b70-957a-9f2d30cc4722,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-9cfe2165-61b9-434f-b396-d1a7618c4fa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5314
