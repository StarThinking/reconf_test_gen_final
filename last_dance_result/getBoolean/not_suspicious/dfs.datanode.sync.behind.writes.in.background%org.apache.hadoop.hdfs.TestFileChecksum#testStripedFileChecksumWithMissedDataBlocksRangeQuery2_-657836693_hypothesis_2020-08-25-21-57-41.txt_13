reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412119857-172.17.0.5-1598392709539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39906,DS-5f60d638-2ff9-4341-93c1-a929512aa34e,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-b26a4fd5-81ae-417b-9db5-ff1426ac6e44,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-0435b405-7604-47f5-99db-806b5a672cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-33ce22b8-b803-4372-8feb-9a00057d2ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-0e9110ed-2eec-47b9-a6e4-f335e54ccc40,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-3e86fa07-7647-47ec-93a8-f89291792863,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-55e52234-688b-4180-afb9-e726359ebc70,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-e70b9849-ab44-4d68-855c-596fa11cdd36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412119857-172.17.0.5-1598392709539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39906,DS-5f60d638-2ff9-4341-93c1-a929512aa34e,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-b26a4fd5-81ae-417b-9db5-ff1426ac6e44,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-0435b405-7604-47f5-99db-806b5a672cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-33ce22b8-b803-4372-8feb-9a00057d2ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-0e9110ed-2eec-47b9-a6e4-f335e54ccc40,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-3e86fa07-7647-47ec-93a8-f89291792863,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-55e52234-688b-4180-afb9-e726359ebc70,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-e70b9849-ab44-4d68-855c-596fa11cdd36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406909056-172.17.0.5-1598392786676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43219,DS-7c14e9a3-ef62-4ed4-984a-6589b4bfb3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-1f0b0ca6-8f4c-4e0b-8874-5e48b1849400,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-91c3097a-99ee-4b00-b223-3e21ba29b398,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-5da70d33-9d10-4eff-9ec3-340476930fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-8422ecb9-3255-4973-aca9-d89d56ee4ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-7bcf6032-dc86-4635-bc2a-a0282d6d2cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-bac510c0-59c3-435a-bb80-e0841042ccb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-c0607b66-1e77-45c3-a77b-a7f8eb091384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406909056-172.17.0.5-1598392786676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43219,DS-7c14e9a3-ef62-4ed4-984a-6589b4bfb3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-1f0b0ca6-8f4c-4e0b-8874-5e48b1849400,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-91c3097a-99ee-4b00-b223-3e21ba29b398,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-5da70d33-9d10-4eff-9ec3-340476930fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-8422ecb9-3255-4973-aca9-d89d56ee4ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-7bcf6032-dc86-4635-bc2a-a0282d6d2cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-bac510c0-59c3-435a-bb80-e0841042ccb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-c0607b66-1e77-45c3-a77b-a7f8eb091384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325450539-172.17.0.5-1598393325043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-f4c1e320-f591-4cf3-a5cf-75d0e57b56db,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-35930e12-2914-4425-ab7f-0d75d157a74b,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-5c6e8a86-ff3f-4d03-8728-7f1466954599,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-b148608e-5681-4f37-b685-78affa18b0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-346e090d-afc0-47ef-9db4-592806dfd4df,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-449a978a-8d99-4ef4-b946-b0d8365fd9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-8c83b444-8312-4b1d-be19-c0529b428d70,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-becc736b-c2ba-4ae1-a890-21b3b25a1f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325450539-172.17.0.5-1598393325043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-f4c1e320-f591-4cf3-a5cf-75d0e57b56db,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-35930e12-2914-4425-ab7f-0d75d157a74b,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-5c6e8a86-ff3f-4d03-8728-7f1466954599,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-b148608e-5681-4f37-b685-78affa18b0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-346e090d-afc0-47ef-9db4-592806dfd4df,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-449a978a-8d99-4ef4-b946-b0d8365fd9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-8c83b444-8312-4b1d-be19-c0529b428d70,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-becc736b-c2ba-4ae1-a890-21b3b25a1f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906688081-172.17.0.5-1598394526119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35022,DS-17092996-cc35-4955-9b9a-5b0ff0f0e9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-799b7d3f-a9f1-47c1-896e-3c2faa62c93a,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-eab18e5f-6df8-47fb-bc61-4a9c19adf4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-4e26e589-2b86-4c41-aea0-72c80fd0f1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-7809804c-8ef6-4f10-8b66-36e693aa8d16,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-19d6b1b9-6427-4d31-a61d-73b342f33bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-d408ccd6-ed9a-4bbf-a8ba-109a49b9be94,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-89feef7b-333a-427e-afe9-222b3ba1e1f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906688081-172.17.0.5-1598394526119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35022,DS-17092996-cc35-4955-9b9a-5b0ff0f0e9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-799b7d3f-a9f1-47c1-896e-3c2faa62c93a,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-eab18e5f-6df8-47fb-bc61-4a9c19adf4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-4e26e589-2b86-4c41-aea0-72c80fd0f1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-7809804c-8ef6-4f10-8b66-36e693aa8d16,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-19d6b1b9-6427-4d31-a61d-73b342f33bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-d408ccd6-ed9a-4bbf-a8ba-109a49b9be94,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-89feef7b-333a-427e-afe9-222b3ba1e1f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343970404-172.17.0.5-1598395262290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42825,DS-ba02a73d-3258-4a53-9614-c841ff8a799e,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-277d9606-f2e0-453f-9098-d3ea6d03aee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-61f32e20-6ab7-42fb-87fc-1b9cdad83e18,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-6a502c78-193c-472f-8f6f-7ad0df50aa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-4e1e8bd8-19db-4a46-819b-4445b13975f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-9498b4d5-11df-4cbc-937c-20df69b6d201,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-50d7aba3-6391-4bc6-8efb-0aebe8102284,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-5f11030e-13eb-4068-93ca-7af68f1a4ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343970404-172.17.0.5-1598395262290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42825,DS-ba02a73d-3258-4a53-9614-c841ff8a799e,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-277d9606-f2e0-453f-9098-d3ea6d03aee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-61f32e20-6ab7-42fb-87fc-1b9cdad83e18,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-6a502c78-193c-472f-8f6f-7ad0df50aa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-4e1e8bd8-19db-4a46-819b-4445b13975f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-9498b4d5-11df-4cbc-937c-20df69b6d201,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-50d7aba3-6391-4bc6-8efb-0aebe8102284,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-5f11030e-13eb-4068-93ca-7af68f1a4ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837952166-172.17.0.5-1598395531903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41589,DS-5a140e44-6a15-47f9-8117-ee76f686e4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-65327aaa-baa3-42dd-8447-9605d9f9fd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-025ec5d8-457b-4793-9db0-7dbd22a42cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-0d1eb90c-736f-4bbc-9046-c433e632b2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-f6d9fa98-146c-4016-adb3-6503c9b73bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-6da5a75a-3186-488b-81c6-3d018ac6b695,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-ec957a2e-58b2-4f8d-841a-4f216e53ac9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-ff59d92b-3692-4f50-a0fb-0a4975185eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837952166-172.17.0.5-1598395531903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41589,DS-5a140e44-6a15-47f9-8117-ee76f686e4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-65327aaa-baa3-42dd-8447-9605d9f9fd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-025ec5d8-457b-4793-9db0-7dbd22a42cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-0d1eb90c-736f-4bbc-9046-c433e632b2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-f6d9fa98-146c-4016-adb3-6503c9b73bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-6da5a75a-3186-488b-81c6-3d018ac6b695,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-ec957a2e-58b2-4f8d-841a-4f216e53ac9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-ff59d92b-3692-4f50-a0fb-0a4975185eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1312282314-172.17.0.5-1598395737481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37333,DS-e03534da-d25a-4f4a-a1e3-4c28078b9a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-cefd2df8-c706-471c-b363-1b373f038874,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-b21f9522-172f-4544-aef0-06111f8cd5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-781b1362-07f3-4afc-8c5e-1acff4a5845d,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-1ab28ae4-2cde-4cd0-b3e4-e6eb6c7e2bec,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-317d2c91-d614-45a0-bcb4-f36e9e47c972,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-a3ba0809-1f09-4891-8824-f2971b786aba,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-142fc865-db14-43a0-88bb-e094b7b9bdaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1312282314-172.17.0.5-1598395737481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37333,DS-e03534da-d25a-4f4a-a1e3-4c28078b9a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-cefd2df8-c706-471c-b363-1b373f038874,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-b21f9522-172f-4544-aef0-06111f8cd5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-781b1362-07f3-4afc-8c5e-1acff4a5845d,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-1ab28ae4-2cde-4cd0-b3e4-e6eb6c7e2bec,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-317d2c91-d614-45a0-bcb4-f36e9e47c972,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-a3ba0809-1f09-4891-8824-f2971b786aba,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-142fc865-db14-43a0-88bb-e094b7b9bdaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553190503-172.17.0.5-1598395947350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36458,DS-4f060e04-cec9-44a8-b0f6-a6b4be011434,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-1f4802f9-8554-421b-a35f-c2f05b2c544a,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-e35c05de-f966-4ba9-89ca-99cf583576d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-dd7d0f36-f1f4-4cbb-b1cf-ad60b2878811,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-74a05946-1db8-4fc8-82e0-5a67dc36919c,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-c826563b-cce1-46a1-839c-80b9245dd85d,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-fc46a19d-effa-41c6-8be5-03fcac21351a,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-71c3300f-6f8b-4943-b6d8-8ea6844b1e67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553190503-172.17.0.5-1598395947350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36458,DS-4f060e04-cec9-44a8-b0f6-a6b4be011434,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-1f4802f9-8554-421b-a35f-c2f05b2c544a,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-e35c05de-f966-4ba9-89ca-99cf583576d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-dd7d0f36-f1f4-4cbb-b1cf-ad60b2878811,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-74a05946-1db8-4fc8-82e0-5a67dc36919c,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-c826563b-cce1-46a1-839c-80b9245dd85d,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-fc46a19d-effa-41c6-8be5-03fcac21351a,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-71c3300f-6f8b-4943-b6d8-8ea6844b1e67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853696894-172.17.0.5-1598395986754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36265,DS-f6ee4cc8-c48a-43a2-9f88-09f443a506c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-5d59b90a-6026-4c31-bd19-a4b803605992,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-932525c8-d242-44f9-a96f-bcc2dff48c56,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-9b47a75b-2b93-41fb-a34c-3b92da7bb5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-37e87e28-fcd8-4d94-ad95-678d12bf6b74,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-8a2a3f26-aadf-46a2-9d34-3c93c598c508,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-8d1fc2fb-e00b-47da-be44-7f9c431284d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-d7b2e143-f577-48fe-a3a3-c661a7b36a19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853696894-172.17.0.5-1598395986754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36265,DS-f6ee4cc8-c48a-43a2-9f88-09f443a506c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-5d59b90a-6026-4c31-bd19-a4b803605992,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-932525c8-d242-44f9-a96f-bcc2dff48c56,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-9b47a75b-2b93-41fb-a34c-3b92da7bb5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-37e87e28-fcd8-4d94-ad95-678d12bf6b74,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-8a2a3f26-aadf-46a2-9d34-3c93c598c508,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-8d1fc2fb-e00b-47da-be44-7f9c431284d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-d7b2e143-f577-48fe-a3a3-c661a7b36a19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580153771-172.17.0.5-1598396026730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41945,DS-14843b0d-4137-4e2f-8952-11914b3d21c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-73e3375e-a3bc-48b5-918e-60b84aa62363,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-75b269d5-07bc-42fc-aa3f-c25839c8a09e,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-49af6028-801e-416a-816d-b29aea0eb087,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-c733d77f-dbab-4bbe-b24c-1616b5aa3afb,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-2e84cdc2-5fa6-41f7-a6e4-b4072b357dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-63fe9db2-078b-4d51-88c7-a5438ba3ac01,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-76ba09ab-b18f-4d20-b3ef-2eced3600a87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580153771-172.17.0.5-1598396026730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41945,DS-14843b0d-4137-4e2f-8952-11914b3d21c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-73e3375e-a3bc-48b5-918e-60b84aa62363,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-75b269d5-07bc-42fc-aa3f-c25839c8a09e,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-49af6028-801e-416a-816d-b29aea0eb087,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-c733d77f-dbab-4bbe-b24c-1616b5aa3afb,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-2e84cdc2-5fa6-41f7-a6e4-b4072b357dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-63fe9db2-078b-4d51-88c7-a5438ba3ac01,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-76ba09ab-b18f-4d20-b3ef-2eced3600a87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-402745944-172.17.0.5-1598396094836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36804,DS-2d5ceba1-aa94-4796-a7ef-a0dff14d576b,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-c7f086fb-feaa-4258-9649-d295fa78f290,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-eb4d6ea2-4f89-48d2-bcf5-a5aa502d08a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-2ace5048-7f12-4ca5-a6d2-5410d540e0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-1a78000b-505f-489d-bc67-0222f22e05a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-d51a1443-7255-4791-b4d8-778c39efbd65,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-1c1ba83d-2e0b-463f-95a0-5076ca73d728,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-e365f81b-828e-46f3-a327-04dae3b31697,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-402745944-172.17.0.5-1598396094836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36804,DS-2d5ceba1-aa94-4796-a7ef-a0dff14d576b,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-c7f086fb-feaa-4258-9649-d295fa78f290,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-eb4d6ea2-4f89-48d2-bcf5-a5aa502d08a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-2ace5048-7f12-4ca5-a6d2-5410d540e0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-1a78000b-505f-489d-bc67-0222f22e05a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-d51a1443-7255-4791-b4d8-778c39efbd65,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-1c1ba83d-2e0b-463f-95a0-5076ca73d728,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-e365f81b-828e-46f3-a327-04dae3b31697,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896876101-172.17.0.5-1598396392714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37219,DS-a2d8f14d-59c2-4345-841e-37c27ee0d54a,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-98196dba-47a7-457e-8a17-49261eaec158,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-a7371a53-10a8-4f9c-b1b4-fcb766935ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-42557781-301f-4a61-9e51-094c83621d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-cdebf907-41d7-48d4-8cf3-bd53bf1d5a73,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-027426c0-acdc-4bd6-9a50-417bc9142cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-890b9f0d-8090-40c2-a56d-b329a6f9824e,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-312a797f-3376-4e31-85ae-745ed6d6a41b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896876101-172.17.0.5-1598396392714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37219,DS-a2d8f14d-59c2-4345-841e-37c27ee0d54a,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-98196dba-47a7-457e-8a17-49261eaec158,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-a7371a53-10a8-4f9c-b1b4-fcb766935ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-42557781-301f-4a61-9e51-094c83621d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-cdebf907-41d7-48d4-8cf3-bd53bf1d5a73,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-027426c0-acdc-4bd6-9a50-417bc9142cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-890b9f0d-8090-40c2-a56d-b329a6f9824e,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-312a797f-3376-4e31-85ae-745ed6d6a41b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083548825-172.17.0.5-1598396865435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39853,DS-4ce39367-1024-4097-b668-84e2e73b1138,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-37065f57-a109-41b4-8685-8ae9b3c881d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-0a272b1e-1830-4991-8008-a34f30aa5804,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-d6a067f1-4800-4f3a-91cd-6a6a9f3181c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-f2aef0c0-f01e-44a5-a9de-4056a00aa568,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-7df14f5d-eec9-4109-a804-13671296fd16,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-124e3d4f-5eac-4aa8-b82b-8c6ca28ebd18,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-5c83aaa0-7fe0-4f0b-9896-43d9a7d71cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083548825-172.17.0.5-1598396865435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39853,DS-4ce39367-1024-4097-b668-84e2e73b1138,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-37065f57-a109-41b4-8685-8ae9b3c881d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-0a272b1e-1830-4991-8008-a34f30aa5804,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-d6a067f1-4800-4f3a-91cd-6a6a9f3181c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-f2aef0c0-f01e-44a5-a9de-4056a00aa568,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-7df14f5d-eec9-4109-a804-13671296fd16,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-124e3d4f-5eac-4aa8-b82b-8c6ca28ebd18,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-5c83aaa0-7fe0-4f0b-9896-43d9a7d71cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853375442-172.17.0.5-1598397088448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46748,DS-fc7b2c80-124a-43d0-89e8-ee12b4bafaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-ca5fe04d-2c8a-4c1a-af28-3d3d90c9055e,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-4a204195-2dde-46fa-b979-a5a9fb9e5558,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-d85a231e-3146-4b77-81f4-8938f583b232,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-274b6bec-2808-44cd-a4b2-4d50f6c17871,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-2235f564-d0b5-4d75-88dd-3922e33987ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-75390c75-a157-47a8-9e2a-bdc68f0c881e,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-5b416204-7f67-44e7-8b47-6ce5aed26349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853375442-172.17.0.5-1598397088448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46748,DS-fc7b2c80-124a-43d0-89e8-ee12b4bafaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-ca5fe04d-2c8a-4c1a-af28-3d3d90c9055e,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-4a204195-2dde-46fa-b979-a5a9fb9e5558,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-d85a231e-3146-4b77-81f4-8938f583b232,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-274b6bec-2808-44cd-a4b2-4d50f6c17871,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-2235f564-d0b5-4d75-88dd-3922e33987ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-75390c75-a157-47a8-9e2a-bdc68f0c881e,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-5b416204-7f67-44e7-8b47-6ce5aed26349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708725316-172.17.0.5-1598397919776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43598,DS-7c05244e-dfdd-49c2-ae7d-e2577fa2d703,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-403440c4-8525-4847-96bc-a47fda40a49d,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-740a50f0-b01d-4abc-8d2e-d9f15ca0c6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-00b6b230-3199-4c48-98da-e3fcb2cdbe83,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-f4b8bff6-ce9c-4c8e-b75a-8b72a531d3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-df69c65a-dda6-4385-be92-79d4af714971,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-ec7db936-c400-4618-a27b-e50fab8d39cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-b939d75b-8a43-4b72-8268-08e3bc2c23e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708725316-172.17.0.5-1598397919776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43598,DS-7c05244e-dfdd-49c2-ae7d-e2577fa2d703,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-403440c4-8525-4847-96bc-a47fda40a49d,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-740a50f0-b01d-4abc-8d2e-d9f15ca0c6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-00b6b230-3199-4c48-98da-e3fcb2cdbe83,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-f4b8bff6-ce9c-4c8e-b75a-8b72a531d3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-df69c65a-dda6-4385-be92-79d4af714971,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-ec7db936-c400-4618-a27b-e50fab8d39cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-b939d75b-8a43-4b72-8268-08e3bc2c23e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928345474-172.17.0.5-1598398034999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42681,DS-5fbf0de6-6087-4617-b1d6-c34d6cd5b3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-c0aff271-f1ca-4bc5-afbe-20cfbbf5c051,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-d66547cd-95b9-482b-b589-12fc755bf355,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-06e78bac-faa2-4aab-9430-53a54b567be4,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-a00d2c49-40d7-46af-8d03-dd6c683d9a64,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-a52092e4-d20f-494c-b7b6-ebe3864aac1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-2299cbad-f3ac-4012-8f30-65aac3a19e82,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-55791501-9a07-4dc1-8d6a-7e3de47d6b38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928345474-172.17.0.5-1598398034999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42681,DS-5fbf0de6-6087-4617-b1d6-c34d6cd5b3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-c0aff271-f1ca-4bc5-afbe-20cfbbf5c051,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-d66547cd-95b9-482b-b589-12fc755bf355,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-06e78bac-faa2-4aab-9430-53a54b567be4,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-a00d2c49-40d7-46af-8d03-dd6c683d9a64,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-a52092e4-d20f-494c-b7b6-ebe3864aac1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-2299cbad-f3ac-4012-8f30-65aac3a19e82,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-55791501-9a07-4dc1-8d6a-7e3de47d6b38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5600
