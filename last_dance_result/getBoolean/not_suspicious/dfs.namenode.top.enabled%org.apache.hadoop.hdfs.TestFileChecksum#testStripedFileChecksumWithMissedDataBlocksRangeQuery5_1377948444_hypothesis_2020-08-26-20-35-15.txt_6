reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583843372-172.17.0.2-1598474244996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-f043a7c0-0ff5-4984-a929-2119e8fa4ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-09c103b2-8bd2-4263-823e-20786b104dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-b11e6537-0dfe-4c53-8ba7-02c852e76fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-1e113286-807c-4488-a764-1c392b21bd87,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-40546f9d-9230-48b9-a88f-086e0341e956,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-51da9669-9e75-4aaa-8066-b4a40da1a33e,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-57d0167e-1ad2-476a-9ffa-d51c8fadcf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-c02930d2-7448-4ff2-9aff-8ba96fb4caf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583843372-172.17.0.2-1598474244996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-f043a7c0-0ff5-4984-a929-2119e8fa4ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-09c103b2-8bd2-4263-823e-20786b104dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-b11e6537-0dfe-4c53-8ba7-02c852e76fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-1e113286-807c-4488-a764-1c392b21bd87,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-40546f9d-9230-48b9-a88f-086e0341e956,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-51da9669-9e75-4aaa-8066-b4a40da1a33e,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-57d0167e-1ad2-476a-9ffa-d51c8fadcf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-c02930d2-7448-4ff2-9aff-8ba96fb4caf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425284903-172.17.0.2-1598474468548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33152,DS-84db2c2d-e528-43a7-9cc4-9fc3c8721120,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-acc991e1-dba1-4065-98c0-fcacb251b50b,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-1ac071f6-c35e-49b1-acb7-0c95300403b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-42bb8645-4fdf-4483-8c9e-5aac2d1d5954,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-4fe5fb09-64d8-4834-af79-64ea7efc71b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-78f2c838-df2e-490f-8705-402714f566be,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-0a518660-d495-4eed-a2fc-43f20a0ca758,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-3d8a9ea7-3116-49ce-b0ce-dc5cd0054348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425284903-172.17.0.2-1598474468548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33152,DS-84db2c2d-e528-43a7-9cc4-9fc3c8721120,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-acc991e1-dba1-4065-98c0-fcacb251b50b,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-1ac071f6-c35e-49b1-acb7-0c95300403b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-42bb8645-4fdf-4483-8c9e-5aac2d1d5954,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-4fe5fb09-64d8-4834-af79-64ea7efc71b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-78f2c838-df2e-490f-8705-402714f566be,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-0a518660-d495-4eed-a2fc-43f20a0ca758,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-3d8a9ea7-3116-49ce-b0ce-dc5cd0054348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733127027-172.17.0.2-1598474705510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34836,DS-78d2a026-6044-438a-9d83-e5177ce9d98b,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-e7f4bd9d-a212-4245-882b-85f497f9af16,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-045b4ffb-8e90-44e5-ad3c-cbdf5e702a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-d4f0a5ec-269d-4430-b05d-b1468531e3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-e96ec7db-a7f7-4273-914a-50235aef7146,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-713b904f-48cd-45e2-aeea-b4584521ab51,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-1fe7da7e-844c-4faf-a767-5e7b3be658a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-911122c8-e9a9-492c-b065-d5555e4bd297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733127027-172.17.0.2-1598474705510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34836,DS-78d2a026-6044-438a-9d83-e5177ce9d98b,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-e7f4bd9d-a212-4245-882b-85f497f9af16,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-045b4ffb-8e90-44e5-ad3c-cbdf5e702a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-d4f0a5ec-269d-4430-b05d-b1468531e3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-e96ec7db-a7f7-4273-914a-50235aef7146,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-713b904f-48cd-45e2-aeea-b4584521ab51,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-1fe7da7e-844c-4faf-a767-5e7b3be658a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-911122c8-e9a9-492c-b065-d5555e4bd297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315996212-172.17.0.2-1598474722877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33635,DS-f21dac65-a478-42bf-a9ce-7236c80e4df4,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-f951fea4-9c45-4617-a7ac-3a27663b4a19,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-57a6ca68-fe7c-4072-93dc-7752c4c1c681,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-ef23e26e-50bf-459b-a72a-a2530e4e4d11,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-161f2870-1e12-441f-83dd-33d9c7a4b8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-b2359986-b65a-4153-a67a-3e40a9932d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-69de9913-0c85-4291-84fd-47104635a044,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-16358597-7d89-43b1-a705-18c38029d4f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315996212-172.17.0.2-1598474722877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33635,DS-f21dac65-a478-42bf-a9ce-7236c80e4df4,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-f951fea4-9c45-4617-a7ac-3a27663b4a19,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-57a6ca68-fe7c-4072-93dc-7752c4c1c681,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-ef23e26e-50bf-459b-a72a-a2530e4e4d11,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-161f2870-1e12-441f-83dd-33d9c7a4b8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-b2359986-b65a-4153-a67a-3e40a9932d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-69de9913-0c85-4291-84fd-47104635a044,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-16358597-7d89-43b1-a705-18c38029d4f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256930198-172.17.0.2-1598474826118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37607,DS-1ab09272-3f5d-4823-9c82-7085d69bab8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-bfc5bebf-aeab-4af9-8434-193dbc2387b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-fbc96bc1-8bb1-447c-8e7f-59685f2bd4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-4e4f90b6-f80f-4577-b052-f596a15252a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-4f336954-5f71-452a-96ea-136a7af47fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-85dc6a7d-e569-4ea5-8a58-e2422f142183,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-0fabcc1f-a698-44f0-ab9c-1a8cefb44206,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-8944cc4d-0397-4cb1-b583-6eedee1433bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256930198-172.17.0.2-1598474826118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37607,DS-1ab09272-3f5d-4823-9c82-7085d69bab8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-bfc5bebf-aeab-4af9-8434-193dbc2387b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-fbc96bc1-8bb1-447c-8e7f-59685f2bd4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-4e4f90b6-f80f-4577-b052-f596a15252a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-4f336954-5f71-452a-96ea-136a7af47fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-85dc6a7d-e569-4ea5-8a58-e2422f142183,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-0fabcc1f-a698-44f0-ab9c-1a8cefb44206,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-8944cc4d-0397-4cb1-b583-6eedee1433bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173405061-172.17.0.2-1598474912413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40249,DS-e8f96574-d22c-4f8e-8698-c052f0b35c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-d08c8b5d-089c-450a-b95d-e1769e2c5975,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-c46b6df6-a7bc-4873-8e1b-7af672ec9d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-55604ee7-764c-47f4-8228-1106e6526dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-8b619694-f3f3-4732-b7ea-d67f530b75b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-cb15ca73-7f3c-46f1-8942-d7c2a822500e,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-8f5bf6ed-1dd0-4212-bfac-271dcc56b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-4f3b4805-627d-4da2-8cd9-6b74b894588b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173405061-172.17.0.2-1598474912413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40249,DS-e8f96574-d22c-4f8e-8698-c052f0b35c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-d08c8b5d-089c-450a-b95d-e1769e2c5975,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-c46b6df6-a7bc-4873-8e1b-7af672ec9d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-55604ee7-764c-47f4-8228-1106e6526dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-8b619694-f3f3-4732-b7ea-d67f530b75b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-cb15ca73-7f3c-46f1-8942-d7c2a822500e,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-8f5bf6ed-1dd0-4212-bfac-271dcc56b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-4f3b4805-627d-4da2-8cd9-6b74b894588b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913607236-172.17.0.2-1598475115801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46078,DS-72f43ea8-8b07-4369-8d79-fdac32e95e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-d3a81d0f-e433-4067-8365-2440e8152bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-ceb773f3-7c87-4cf4-9945-c5ba92fffc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-ab40b1a1-e6c6-4f2f-94ae-e1ee8c778106,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-9f5a7bc0-3952-4875-9516-606afd99d339,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-c2372c5f-04e0-4ed9-b9b0-2fdeb15e100d,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-0384ba0b-73f7-4d0d-97cc-5620da1f95f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-b5df9ad6-4681-4601-9166-cbd8c78c7b1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913607236-172.17.0.2-1598475115801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46078,DS-72f43ea8-8b07-4369-8d79-fdac32e95e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-d3a81d0f-e433-4067-8365-2440e8152bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-ceb773f3-7c87-4cf4-9945-c5ba92fffc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-ab40b1a1-e6c6-4f2f-94ae-e1ee8c778106,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-9f5a7bc0-3952-4875-9516-606afd99d339,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-c2372c5f-04e0-4ed9-b9b0-2fdeb15e100d,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-0384ba0b-73f7-4d0d-97cc-5620da1f95f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-b5df9ad6-4681-4601-9166-cbd8c78c7b1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576627151-172.17.0.2-1598475149810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33665,DS-ea782f92-d76f-4027-8a4d-7f88b527575b,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-a65a80d5-820f-458c-9500-7b43f770a805,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-524cb56e-e1fe-4b3c-95d7-950d7a2e6f38,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-3c62084e-6c60-4773-b76d-fe5db34c2a48,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-407b7674-02d6-4287-99a6-2da6dba3479a,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-946e65f5-a44e-41f8-8fc3-0bee73d5bd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-d5599f0d-55f5-47d7-8992-6b2dbcf3eb37,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-ae4f72c2-d7c2-41c5-8b90-4d7bcc0ec9ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576627151-172.17.0.2-1598475149810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33665,DS-ea782f92-d76f-4027-8a4d-7f88b527575b,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-a65a80d5-820f-458c-9500-7b43f770a805,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-524cb56e-e1fe-4b3c-95d7-950d7a2e6f38,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-3c62084e-6c60-4773-b76d-fe5db34c2a48,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-407b7674-02d6-4287-99a6-2da6dba3479a,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-946e65f5-a44e-41f8-8fc3-0bee73d5bd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-d5599f0d-55f5-47d7-8992-6b2dbcf3eb37,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-ae4f72c2-d7c2-41c5-8b90-4d7bcc0ec9ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825881405-172.17.0.2-1598475201205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33303,DS-3711611d-1d0d-42ea-b8dd-e81ee243fb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-ecaf2f1d-12bf-479c-8a9a-3e6875ee6742,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-0fcd5d46-e30c-46c0-89f8-8851dbc3c009,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-30bdbc31-3840-4c62-862b-f8aa46655251,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-a18127da-132d-4a00-a1dc-45078038d411,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-a13338ed-95fc-4cbd-a4c1-4a43dc046934,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-99a4d80c-de21-48ec-951a-761b21f03461,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-6ff12333-3057-4815-9805-c00d0022e9b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825881405-172.17.0.2-1598475201205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33303,DS-3711611d-1d0d-42ea-b8dd-e81ee243fb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-ecaf2f1d-12bf-479c-8a9a-3e6875ee6742,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-0fcd5d46-e30c-46c0-89f8-8851dbc3c009,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-30bdbc31-3840-4c62-862b-f8aa46655251,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-a18127da-132d-4a00-a1dc-45078038d411,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-a13338ed-95fc-4cbd-a4c1-4a43dc046934,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-99a4d80c-de21-48ec-951a-761b21f03461,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-6ff12333-3057-4815-9805-c00d0022e9b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249011000-172.17.0.2-1598475371253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45542,DS-2570b9e6-6340-4401-bce6-aea42cd7fac8,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-e00751ab-15f5-410c-b493-c0a228096093,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-969b1b9c-d908-4398-b47d-83785d87ef00,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-31bfec93-2ffc-4753-a6ed-f896f4bafb65,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-e0b48386-811a-4c4a-9960-28b99c8dd9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-78a165f9-f465-4388-94b8-b0941f75bd35,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-a9af98c3-e3be-4784-b698-c39ebb3a3d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-cf74c6e3-4718-4739-8cc3-d49d8d0a7aec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249011000-172.17.0.2-1598475371253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45542,DS-2570b9e6-6340-4401-bce6-aea42cd7fac8,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-e00751ab-15f5-410c-b493-c0a228096093,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-969b1b9c-d908-4398-b47d-83785d87ef00,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-31bfec93-2ffc-4753-a6ed-f896f4bafb65,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-e0b48386-811a-4c4a-9960-28b99c8dd9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-78a165f9-f465-4388-94b8-b0941f75bd35,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-a9af98c3-e3be-4784-b698-c39ebb3a3d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-cf74c6e3-4718-4739-8cc3-d49d8d0a7aec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117521540-172.17.0.2-1598475507333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43542,DS-903c9508-09a1-4eed-ac0e-dce9bef7518d,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-cf267440-3865-418c-89c3-8acc48f74926,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-b1f93270-d6c3-41ee-a648-a08055ee113a,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-c9ee5b52-1628-42d3-9fcb-f32abf24c548,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-779f05c9-b53a-4507-859f-cbbb2c382bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-cb8af9c9-c383-4090-b885-35c9defec556,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-d8fd4a43-382e-4427-ad84-087776ab8979,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-bcf1ec7d-2451-40b9-ae64-74ca89010b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117521540-172.17.0.2-1598475507333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43542,DS-903c9508-09a1-4eed-ac0e-dce9bef7518d,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-cf267440-3865-418c-89c3-8acc48f74926,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-b1f93270-d6c3-41ee-a648-a08055ee113a,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-c9ee5b52-1628-42d3-9fcb-f32abf24c548,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-779f05c9-b53a-4507-859f-cbbb2c382bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-cb8af9c9-c383-4090-b885-35c9defec556,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-d8fd4a43-382e-4427-ad84-087776ab8979,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-bcf1ec7d-2451-40b9-ae64-74ca89010b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912194504-172.17.0.2-1598475592683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37762,DS-a2ea38d3-a65f-48da-a5f4-c9941d43d71f,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-effd7048-e4da-4d43-8574-040f4234dba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-bd052d19-6386-4a97-9b6e-9d0f57202d79,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-70f4d80a-3638-4480-b460-f23b640d8e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-53bd317a-ea72-4f76-b3f6-40bd5b4cc248,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-60f3e1fe-7a7c-4265-914d-3b2ecab63dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-bdeff784-7807-4ba0-a17e-596c783db6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-5c9bac3d-8c90-469f-abdd-a58024246e0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912194504-172.17.0.2-1598475592683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37762,DS-a2ea38d3-a65f-48da-a5f4-c9941d43d71f,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-effd7048-e4da-4d43-8574-040f4234dba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-bd052d19-6386-4a97-9b6e-9d0f57202d79,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-70f4d80a-3638-4480-b460-f23b640d8e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-53bd317a-ea72-4f76-b3f6-40bd5b4cc248,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-60f3e1fe-7a7c-4265-914d-3b2ecab63dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-bdeff784-7807-4ba0-a17e-596c783db6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-5c9bac3d-8c90-469f-abdd-a58024246e0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613608050-172.17.0.2-1598475841418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45772,DS-8465210f-9c56-491c-bd0d-14d4d6b772f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-39214f8d-50bc-4df8-8125-47a6a8e4717c,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-86f345bf-3898-45a0-82c4-5889820da410,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-745115fa-ce15-4e6c-83f6-3f5735a3827a,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-7e3c9bcc-9f5c-4013-bc96-0a2b9832e84b,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-869e42a7-84fb-4c12-a5ab-a892d0bd5b74,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-f065ecaa-e63b-4e03-9ace-9f5d77b126fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-819014ba-731e-4a3f-b7a6-f52434d7d622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613608050-172.17.0.2-1598475841418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45772,DS-8465210f-9c56-491c-bd0d-14d4d6b772f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-39214f8d-50bc-4df8-8125-47a6a8e4717c,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-86f345bf-3898-45a0-82c4-5889820da410,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-745115fa-ce15-4e6c-83f6-3f5735a3827a,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-7e3c9bcc-9f5c-4013-bc96-0a2b9832e84b,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-869e42a7-84fb-4c12-a5ab-a892d0bd5b74,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-f065ecaa-e63b-4e03-9ace-9f5d77b126fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-819014ba-731e-4a3f-b7a6-f52434d7d622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461425620-172.17.0.2-1598475971000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46375,DS-d00e2d3e-8a47-42e6-b3d6-20ed219d956e,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-bb4b3bd2-0d37-421b-a073-a3ad3b5123af,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-c970b325-ab3b-4834-980e-143356fc3bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-cfa4678f-19a3-4717-9fc2-2e1f4863f0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-9ecb6a91-ab52-4f4c-916a-d4e6ca9d656c,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-0ab61610-81a1-452e-85f3-0aacc43f32c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-f48f3ae6-e9fb-4bd6-87ce-a66e2d6ce662,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-2f0574a8-ce41-466c-96ba-0a8cd4a2502b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461425620-172.17.0.2-1598475971000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46375,DS-d00e2d3e-8a47-42e6-b3d6-20ed219d956e,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-bb4b3bd2-0d37-421b-a073-a3ad3b5123af,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-c970b325-ab3b-4834-980e-143356fc3bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-cfa4678f-19a3-4717-9fc2-2e1f4863f0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-9ecb6a91-ab52-4f4c-916a-d4e6ca9d656c,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-0ab61610-81a1-452e-85f3-0aacc43f32c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-f48f3ae6-e9fb-4bd6-87ce-a66e2d6ce662,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-2f0574a8-ce41-466c-96ba-0a8cd4a2502b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123314538-172.17.0.2-1598476097244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36048,DS-eb9692a0-527f-4d54-ad37-d467b920c0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-7c785632-dd89-4a2e-921e-f962d3f77183,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-860a0141-2cbe-471a-ab5c-ae7def2477ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-0b5942f1-9474-4e0d-98c7-c6808a0ecfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-be226605-6b07-4293-b834-0cd0206b9b43,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-fb696921-894c-4cbb-aa81-3f3a2a013349,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-02173928-10e3-4c11-bc74-4693f0a9c8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-5cb4a89f-dced-4d6f-a8fc-881793d2fc31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123314538-172.17.0.2-1598476097244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36048,DS-eb9692a0-527f-4d54-ad37-d467b920c0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-7c785632-dd89-4a2e-921e-f962d3f77183,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-860a0141-2cbe-471a-ab5c-ae7def2477ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-0b5942f1-9474-4e0d-98c7-c6808a0ecfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-be226605-6b07-4293-b834-0cd0206b9b43,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-fb696921-894c-4cbb-aa81-3f3a2a013349,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-02173928-10e3-4c11-bc74-4693f0a9c8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-5cb4a89f-dced-4d6f-a8fc-881793d2fc31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351218709-172.17.0.2-1598476207627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46394,DS-3aca0f43-66c3-4e5e-aebf-c351e0b591e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-e21a8c88-5754-4e98-a6a4-bfb84e2fead6,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-c9e03ab5-47b7-4343-9e84-a04ec5f532da,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-82c15218-711e-4ee1-aa12-e73013cd3252,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-7818a3fe-1ce0-4a5f-a766-7673de7a93eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-0364103c-b61e-4e62-910e-8cfa5e5e9c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-d82e4d24-d3e3-4134-8d36-4f020e6ce5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-c7a7dfbd-2168-41fa-9be4-d35153209384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351218709-172.17.0.2-1598476207627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46394,DS-3aca0f43-66c3-4e5e-aebf-c351e0b591e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-e21a8c88-5754-4e98-a6a4-bfb84e2fead6,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-c9e03ab5-47b7-4343-9e84-a04ec5f532da,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-82c15218-711e-4ee1-aa12-e73013cd3252,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-7818a3fe-1ce0-4a5f-a766-7673de7a93eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-0364103c-b61e-4e62-910e-8cfa5e5e9c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-d82e4d24-d3e3-4134-8d36-4f020e6ce5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-c7a7dfbd-2168-41fa-9be4-d35153209384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135851317-172.17.0.2-1598476476327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43594,DS-13b81299-cc6a-444b-8324-63d22ab5ec4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-535c9963-8fca-4db6-8d86-e803bbc9a4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-e339a78a-57c6-4be4-a3fa-3cce158c8add,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-17b504d8-46f7-4643-ab71-4d7a76657261,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-c1400df5-04ca-4458-bb5e-e996c858ec2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-26d32e2d-d35c-4176-902d-49015ff24869,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-7a40b8c0-3f17-44bc-bdb8-19be9fbd95ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-7061891a-463c-4522-a3a7-be8cfe5bdc8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135851317-172.17.0.2-1598476476327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43594,DS-13b81299-cc6a-444b-8324-63d22ab5ec4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-535c9963-8fca-4db6-8d86-e803bbc9a4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-e339a78a-57c6-4be4-a3fa-3cce158c8add,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-17b504d8-46f7-4643-ab71-4d7a76657261,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-c1400df5-04ca-4458-bb5e-e996c858ec2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-26d32e2d-d35c-4176-902d-49015ff24869,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-7a40b8c0-3f17-44bc-bdb8-19be9fbd95ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-7061891a-463c-4522-a3a7-be8cfe5bdc8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90148636-172.17.0.2-1598476634519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46508,DS-13dfd170-4ba5-4a10-9591-dd3845af5104,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-63cf51b7-8622-47bb-af44-7c7de0a5ea3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-35a18856-edd8-449a-a4b5-f5f48332c93f,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-ac0b8587-3a8c-4d44-8b43-fbe575c49123,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-bbe249b7-748d-4570-ba04-8dd89c16f02a,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-b85517f5-46f8-488b-8970-de15d269088f,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-6a39cc44-9307-48f0-8f7b-9cff558e0331,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-864632db-689c-4f2d-8866-8362a0c41295,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90148636-172.17.0.2-1598476634519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46508,DS-13dfd170-4ba5-4a10-9591-dd3845af5104,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-63cf51b7-8622-47bb-af44-7c7de0a5ea3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-35a18856-edd8-449a-a4b5-f5f48332c93f,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-ac0b8587-3a8c-4d44-8b43-fbe575c49123,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-bbe249b7-748d-4570-ba04-8dd89c16f02a,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-b85517f5-46f8-488b-8970-de15d269088f,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-6a39cc44-9307-48f0-8f7b-9cff558e0331,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-864632db-689c-4f2d-8866-8362a0c41295,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237065193-172.17.0.2-1598476698155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45147,DS-847c4c13-77f3-46e3-9d3c-05b240ae0c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-c282c6ab-c514-461b-b743-fd30ea590b82,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-0f6dbc79-900b-498d-87b0-d5f5954a0598,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-b491e629-3191-428b-9b65-c2631b984ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-d01b76a0-347f-4590-8d1f-c1647cf4735f,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-f177cc41-f5b5-4e80-895c-fde771f31b69,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-70f7e973-ad1c-4fc7-bb8c-9113b8dbe8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-366ef896-3e4f-4dcc-a746-edc64a5124e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237065193-172.17.0.2-1598476698155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45147,DS-847c4c13-77f3-46e3-9d3c-05b240ae0c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-c282c6ab-c514-461b-b743-fd30ea590b82,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-0f6dbc79-900b-498d-87b0-d5f5954a0598,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-b491e629-3191-428b-9b65-c2631b984ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-d01b76a0-347f-4590-8d1f-c1647cf4735f,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-f177cc41-f5b5-4e80-895c-fde771f31b69,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-70f7e973-ad1c-4fc7-bb8c-9113b8dbe8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-366ef896-3e4f-4dcc-a746-edc64a5124e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433460090-172.17.0.2-1598476777796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39639,DS-f92c5860-d079-4384-bcfa-c293183830a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-2924bdee-0c3e-4802-8653-2e141a03b6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-16cd482c-bfcd-4f22-8ce5-f5070be4a302,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-52817a05-3230-451a-8455-f5c294b0a54f,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-aa629067-b6c0-414e-992d-c65555caa9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-b0150bcc-d6c1-49a3-8c9e-dff97108e667,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-774a8fcc-9ab1-4a40-95a5-c3c3dc646a08,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-75d795c9-e0de-43c5-8278-27cdd399fdb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433460090-172.17.0.2-1598476777796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39639,DS-f92c5860-d079-4384-bcfa-c293183830a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-2924bdee-0c3e-4802-8653-2e141a03b6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-16cd482c-bfcd-4f22-8ce5-f5070be4a302,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-52817a05-3230-451a-8455-f5c294b0a54f,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-aa629067-b6c0-414e-992d-c65555caa9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-b0150bcc-d6c1-49a3-8c9e-dff97108e667,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-774a8fcc-9ab1-4a40-95a5-c3c3dc646a08,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-75d795c9-e0de-43c5-8278-27cdd399fdb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391227710-172.17.0.2-1598476825373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43383,DS-b571491c-60f9-4cf7-a1ec-0791c64cbbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-b0a534a4-f16e-4ad7-b023-73b1456af3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-26d5738d-8402-4810-9a9b-7bde0901a5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-a97e6d90-5e5f-475a-9503-24ad1c2bdc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-d5174d74-68ff-4753-bcdc-6901dc7d6679,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-07d60696-b70d-42d7-b09a-96f2e48e7f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-c84f1755-f015-42ec-b328-6034da851ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-3068a10e-9ae6-42f9-bec0-8e825a1d97c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391227710-172.17.0.2-1598476825373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43383,DS-b571491c-60f9-4cf7-a1ec-0791c64cbbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-b0a534a4-f16e-4ad7-b023-73b1456af3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-26d5738d-8402-4810-9a9b-7bde0901a5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-a97e6d90-5e5f-475a-9503-24ad1c2bdc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-d5174d74-68ff-4753-bcdc-6901dc7d6679,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-07d60696-b70d-42d7-b09a-96f2e48e7f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-c84f1755-f015-42ec-b328-6034da851ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-3068a10e-9ae6-42f9-bec0-8e825a1d97c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 2735
