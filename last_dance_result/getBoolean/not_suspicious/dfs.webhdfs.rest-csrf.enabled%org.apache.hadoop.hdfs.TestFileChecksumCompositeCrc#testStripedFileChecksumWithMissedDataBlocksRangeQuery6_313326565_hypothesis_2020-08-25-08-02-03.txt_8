reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448631051-172.17.0.3-1598342535734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38090,DS-4c14cb43-f04e-4561-8bfb-8ac23c92de6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-483e0439-f819-4494-a606-70395bd19532,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-dbdd28ce-b646-4595-beea-35158d359257,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-a2d0ef17-19ff-406d-8c4d-f80d0927716d,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-f1da9488-8bd0-42f1-a852-0e8a0e2fb2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-f36cbf36-9ca6-4398-944b-3bc06af0810d,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-2fc33eec-a74a-4de3-8b47-4bd48a174087,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-9f5e7158-9651-45f6-8f35-a5396adf2493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448631051-172.17.0.3-1598342535734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38090,DS-4c14cb43-f04e-4561-8bfb-8ac23c92de6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-483e0439-f819-4494-a606-70395bd19532,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-dbdd28ce-b646-4595-beea-35158d359257,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-a2d0ef17-19ff-406d-8c4d-f80d0927716d,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-f1da9488-8bd0-42f1-a852-0e8a0e2fb2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-f36cbf36-9ca6-4398-944b-3bc06af0810d,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-2fc33eec-a74a-4de3-8b47-4bd48a174087,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-9f5e7158-9651-45f6-8f35-a5396adf2493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646573767-172.17.0.3-1598342570084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39596,DS-b1f9188b-5c54-445a-a6a4-90d716457ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-16d317d6-8921-470a-b6a9-1fe38d8ba98e,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-e5375535-1461-4c2b-9c56-5c29b31d750c,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-ee91fe1c-4fb4-40d1-bcf2-ecee8666fadd,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-9caafea0-cac3-498b-9d44-484c16da302f,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-7fdc1674-5449-4b2c-bfbc-13ff650312e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-dee8ad1c-7339-41db-9b97-bef907a6bb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-683ad025-08f7-47db-86dc-021c2ef68d28,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646573767-172.17.0.3-1598342570084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39596,DS-b1f9188b-5c54-445a-a6a4-90d716457ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-16d317d6-8921-470a-b6a9-1fe38d8ba98e,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-e5375535-1461-4c2b-9c56-5c29b31d750c,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-ee91fe1c-4fb4-40d1-bcf2-ecee8666fadd,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-9caafea0-cac3-498b-9d44-484c16da302f,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-7fdc1674-5449-4b2c-bfbc-13ff650312e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-dee8ad1c-7339-41db-9b97-bef907a6bb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-683ad025-08f7-47db-86dc-021c2ef68d28,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142942833-172.17.0.3-1598342598802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35178,DS-59aa34ca-30b4-481b-ad63-718c381c10b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-484f282e-cc24-4f72-a9c1-8fdb30280754,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-b325d2b4-0924-4341-8cb6-905b5abe1885,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-807e3f7f-cfdb-4753-b657-f313a0e5a790,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-3641e6f9-8ca6-4eb1-87ce-0918fa324521,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-a907ddd0-7fde-47de-84cb-61876555dfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-64f68003-bba9-42f8-92d1-449707eb35f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-028cb837-4aff-4a88-899e-01e37dae9697,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142942833-172.17.0.3-1598342598802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35178,DS-59aa34ca-30b4-481b-ad63-718c381c10b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-484f282e-cc24-4f72-a9c1-8fdb30280754,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-b325d2b4-0924-4341-8cb6-905b5abe1885,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-807e3f7f-cfdb-4753-b657-f313a0e5a790,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-3641e6f9-8ca6-4eb1-87ce-0918fa324521,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-a907ddd0-7fde-47de-84cb-61876555dfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-64f68003-bba9-42f8-92d1-449707eb35f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-028cb837-4aff-4a88-899e-01e37dae9697,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065004935-172.17.0.3-1598342853243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46424,DS-e9ed7534-776d-45b8-b5d5-ca8446a18cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-96bb4d8a-c88c-4151-9cbc-58c8c1d5d0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-d091192f-beb5-487f-81df-3016d1a2ad9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-762f483e-1cf5-4209-9447-e16d3ca9b8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-c0aa93bc-dd67-496a-8477-439742898c18,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-3f3a64aa-d1ac-4830-98fc-bf83768c811a,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-126b8036-a474-4af9-98dc-c203f6497e06,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-a2f9f859-c984-4b71-8527-6bed9397e508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065004935-172.17.0.3-1598342853243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46424,DS-e9ed7534-776d-45b8-b5d5-ca8446a18cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-96bb4d8a-c88c-4151-9cbc-58c8c1d5d0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-d091192f-beb5-487f-81df-3016d1a2ad9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-762f483e-1cf5-4209-9447-e16d3ca9b8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-c0aa93bc-dd67-496a-8477-439742898c18,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-3f3a64aa-d1ac-4830-98fc-bf83768c811a,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-126b8036-a474-4af9-98dc-c203f6497e06,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-a2f9f859-c984-4b71-8527-6bed9397e508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283668689-172.17.0.3-1598342887955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38359,DS-5c183660-0f1e-43ea-ba5f-d96b47cbef40,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-b4a77a0e-5bff-4f08-9613-cfa5d2c3bad9,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-9a2a3cb4-6eb8-4062-ba84-2578a321bb55,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-a54bbf3f-4df2-487e-b484-12edb8b3e219,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-98172b01-bb91-468d-85f7-e523968041f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-0b61c948-1950-4354-84b1-ee75b83443a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-d71c678f-0826-4bab-8ec0-7dc17cb2695c,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-a300cca8-f8b5-4223-afa2-a3211656c089,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283668689-172.17.0.3-1598342887955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38359,DS-5c183660-0f1e-43ea-ba5f-d96b47cbef40,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-b4a77a0e-5bff-4f08-9613-cfa5d2c3bad9,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-9a2a3cb4-6eb8-4062-ba84-2578a321bb55,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-a54bbf3f-4df2-487e-b484-12edb8b3e219,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-98172b01-bb91-468d-85f7-e523968041f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-0b61c948-1950-4354-84b1-ee75b83443a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-d71c678f-0826-4bab-8ec0-7dc17cb2695c,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-a300cca8-f8b5-4223-afa2-a3211656c089,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624777040-172.17.0.3-1598343075947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38532,DS-7f746c7b-fdec-43f5-a693-ac73339f1c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-745fe9b9-829a-46dd-83d8-daf20dfdc370,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-29005a4f-8809-4d43-b6d4-d61025adb0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-8062d368-1e80-48b2-9a74-276aec03b973,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-eb7a9fbe-ebb8-4e8d-a5f7-41f311b9b744,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-d0a69bd0-361c-422b-ad6a-dbb97d1108e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-d67a7de6-a56e-49e2-b018-ad1446ac4acb,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-84add965-3d89-4492-b4b2-f93832118f75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624777040-172.17.0.3-1598343075947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38532,DS-7f746c7b-fdec-43f5-a693-ac73339f1c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-745fe9b9-829a-46dd-83d8-daf20dfdc370,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-29005a4f-8809-4d43-b6d4-d61025adb0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-8062d368-1e80-48b2-9a74-276aec03b973,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-eb7a9fbe-ebb8-4e8d-a5f7-41f311b9b744,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-d0a69bd0-361c-422b-ad6a-dbb97d1108e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-d67a7de6-a56e-49e2-b018-ad1446ac4acb,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-84add965-3d89-4492-b4b2-f93832118f75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-78362195-172.17.0.3-1598343333735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40949,DS-98d4de06-baa4-414b-bcae-e20b7de92d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-5b9d2de8-0ecb-4f87-935f-3d4fec88fdff,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-9251e047-38b0-413a-a873-4f7ba7793620,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-de251320-fa34-409d-9911-9b771bad7bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-1a700549-19f2-4bab-98ec-d7797d837aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-b1ee282f-7c3d-418a-a713-3e10b3944bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-b02f8aee-0ac5-483d-bb75-1433bddd2b57,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-6f76ffd1-cc66-4194-ac96-28ffae508942,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-78362195-172.17.0.3-1598343333735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40949,DS-98d4de06-baa4-414b-bcae-e20b7de92d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-5b9d2de8-0ecb-4f87-935f-3d4fec88fdff,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-9251e047-38b0-413a-a873-4f7ba7793620,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-de251320-fa34-409d-9911-9b771bad7bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-1a700549-19f2-4bab-98ec-d7797d837aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-b1ee282f-7c3d-418a-a713-3e10b3944bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-b02f8aee-0ac5-483d-bb75-1433bddd2b57,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-6f76ffd1-cc66-4194-ac96-28ffae508942,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111974009-172.17.0.3-1598343371721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33425,DS-66aac2c5-021f-4d6b-8d44-d639404ba866,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-34fbf315-f73b-458f-b0a5-425e67a87158,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-8908f5bf-5030-48f9-bb9d-3611f42e73ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-13be754c-4893-4ea1-b9bf-5621500b36e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-22dc1bec-d5d0-43a7-ad5f-d110c9c6cbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-15241964-c715-48d0-b990-812e23b4588c,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-0663e19c-e1a8-4860-84b6-89996ef7d8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-56f41807-fab8-4f4a-ac66-915d1924da6c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111974009-172.17.0.3-1598343371721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33425,DS-66aac2c5-021f-4d6b-8d44-d639404ba866,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-34fbf315-f73b-458f-b0a5-425e67a87158,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-8908f5bf-5030-48f9-bb9d-3611f42e73ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-13be754c-4893-4ea1-b9bf-5621500b36e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-22dc1bec-d5d0-43a7-ad5f-d110c9c6cbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-15241964-c715-48d0-b990-812e23b4588c,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-0663e19c-e1a8-4860-84b6-89996ef7d8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-56f41807-fab8-4f4a-ac66-915d1924da6c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899526827-172.17.0.3-1598343603013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38755,DS-331752df-fb8e-4df4-89b1-66ea82d96988,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-9dbb0bde-0b55-47b0-93a1-1ae61a583832,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-078df11d-8cf7-4f0f-8509-012ac4511218,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-7b414499-5de8-42a5-b121-03eca3be697a,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-3a707b48-fc6d-4571-9dd2-1c6f8a3efc48,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-c2ac4360-9ea9-4612-b360-0d199613bc24,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-113d4608-5c6e-4ea4-bca6-09989e6b096f,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-6f24a000-cdb1-4abc-8039-273cef9a468a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899526827-172.17.0.3-1598343603013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38755,DS-331752df-fb8e-4df4-89b1-66ea82d96988,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-9dbb0bde-0b55-47b0-93a1-1ae61a583832,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-078df11d-8cf7-4f0f-8509-012ac4511218,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-7b414499-5de8-42a5-b121-03eca3be697a,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-3a707b48-fc6d-4571-9dd2-1c6f8a3efc48,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-c2ac4360-9ea9-4612-b360-0d199613bc24,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-113d4608-5c6e-4ea4-bca6-09989e6b096f,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-6f24a000-cdb1-4abc-8039-273cef9a468a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208991049-172.17.0.3-1598343667686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33014,DS-496d9bcb-53fe-45ec-9060-dfe710d49b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-fe9676b3-b04f-4b28-99e0-0cb99653ffdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-4c0f028d-a08b-4b54-a5ec-05b9deac522b,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-c74264cd-e281-4ca7-9467-38350b310435,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-d2919eb7-879a-491c-b242-df9ba981fc49,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-1ed049d6-9168-4890-8b58-427a7aa23035,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-0097cb55-6f85-4481-a8bb-9d65b325b65f,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-5e8b3dbf-c110-4b8f-b66c-86d6b6dba81b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208991049-172.17.0.3-1598343667686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33014,DS-496d9bcb-53fe-45ec-9060-dfe710d49b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-fe9676b3-b04f-4b28-99e0-0cb99653ffdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-4c0f028d-a08b-4b54-a5ec-05b9deac522b,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-c74264cd-e281-4ca7-9467-38350b310435,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-d2919eb7-879a-491c-b242-df9ba981fc49,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-1ed049d6-9168-4890-8b58-427a7aa23035,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-0097cb55-6f85-4481-a8bb-9d65b325b65f,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-5e8b3dbf-c110-4b8f-b66c-86d6b6dba81b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600753672-172.17.0.3-1598343785398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39775,DS-848c074c-5a14-47cb-92c7-5a03aa73b018,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-227a927b-2ddd-4cf8-a732-95c8d5e39250,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-2508f170-2fff-4ab6-b80e-6105b3ad982b,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-c141f7de-f738-4ae7-954a-05561aecf167,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-8cf927de-0725-4e90-b12d-25556a368fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-98ba9d20-dc4f-4516-aa28-b618da340536,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-6ce9b1c0-8c0a-4810-aaf6-2b0f934dbacb,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-e15a7ccb-d131-431f-99f3-42ac316204cb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600753672-172.17.0.3-1598343785398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39775,DS-848c074c-5a14-47cb-92c7-5a03aa73b018,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-227a927b-2ddd-4cf8-a732-95c8d5e39250,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-2508f170-2fff-4ab6-b80e-6105b3ad982b,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-c141f7de-f738-4ae7-954a-05561aecf167,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-8cf927de-0725-4e90-b12d-25556a368fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-98ba9d20-dc4f-4516-aa28-b618da340536,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-6ce9b1c0-8c0a-4810-aaf6-2b0f934dbacb,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-e15a7ccb-d131-431f-99f3-42ac316204cb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451482929-172.17.0.3-1598343896645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36914,DS-131ffeaa-5a8d-4e05-87cd-7456be85dbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-fc044ce5-81a7-41c2-9240-04b591e0e042,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-63b89626-ce09-442b-9a0c-05915b81da1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-db0a264f-b928-4a5f-ad17-44991ceee336,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-fe92cf5b-bbbb-401a-bae2-f8dbd68ee7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-9cc6426f-f706-422e-8df0-46f31dc4dd37,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-60f79c0a-f57f-4fef-bd77-5aa38b5d85d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-b6634f9f-cd15-47d4-9523-381c2b59b017,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451482929-172.17.0.3-1598343896645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36914,DS-131ffeaa-5a8d-4e05-87cd-7456be85dbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-fc044ce5-81a7-41c2-9240-04b591e0e042,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-63b89626-ce09-442b-9a0c-05915b81da1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-db0a264f-b928-4a5f-ad17-44991ceee336,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-fe92cf5b-bbbb-401a-bae2-f8dbd68ee7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-9cc6426f-f706-422e-8df0-46f31dc4dd37,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-60f79c0a-f57f-4fef-bd77-5aa38b5d85d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-b6634f9f-cd15-47d4-9523-381c2b59b017,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679505548-172.17.0.3-1598344433683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37268,DS-5bdd808f-f418-4919-914b-f936b882a2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-8289a360-05e9-4de9-8a51-d7e54342809e,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-6530dbb0-7f34-4917-8807-c3bbd71a32d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-24342544-073f-45b5-9dfb-f6116abe4d19,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-66c7be26-36b2-4e85-9b8d-6cfb88afcdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-d34ddbfc-7c39-4995-993f-d0fe4eb8d097,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-17d9ed01-814b-4651-b5d4-aa7d8faeaa85,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-6fdd44f7-379b-4b14-9342-1072e76d5775,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679505548-172.17.0.3-1598344433683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37268,DS-5bdd808f-f418-4919-914b-f936b882a2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-8289a360-05e9-4de9-8a51-d7e54342809e,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-6530dbb0-7f34-4917-8807-c3bbd71a32d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-24342544-073f-45b5-9dfb-f6116abe4d19,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-66c7be26-36b2-4e85-9b8d-6cfb88afcdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-d34ddbfc-7c39-4995-993f-d0fe4eb8d097,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-17d9ed01-814b-4651-b5d4-aa7d8faeaa85,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-6fdd44f7-379b-4b14-9342-1072e76d5775,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351688020-172.17.0.3-1598344471449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39952,DS-8c733dc7-4879-4b2f-85ae-b1026bc428d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-b73241bd-5e57-45a8-a289-b14280e9cbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-a98ccf8c-1c2f-4f0c-95ce-07f7f03e9f75,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-6aa88276-022b-458d-affd-38ff8117be8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-1c508d61-014f-4975-b9dc-983de547cd17,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-9ecdd3e7-c78c-40e1-9424-c7aea1b79f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-e769dec5-62da-4310-9706-6801a98e942f,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-5718b934-ec46-46ab-9ab6-6743712cfb3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351688020-172.17.0.3-1598344471449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39952,DS-8c733dc7-4879-4b2f-85ae-b1026bc428d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-b73241bd-5e57-45a8-a289-b14280e9cbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-a98ccf8c-1c2f-4f0c-95ce-07f7f03e9f75,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-6aa88276-022b-458d-affd-38ff8117be8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-1c508d61-014f-4975-b9dc-983de547cd17,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-9ecdd3e7-c78c-40e1-9424-c7aea1b79f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-e769dec5-62da-4310-9706-6801a98e942f,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-5718b934-ec46-46ab-9ab6-6743712cfb3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871698238-172.17.0.3-1598344614684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45885,DS-63d2a965-c930-4e77-a2b8-042084f6b7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-2a6e610b-6f0c-48b4-9ce3-568ebd63cef5,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-aa1941d4-4ff0-4a61-b7e3-4dc5fb7a7671,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-86bfc080-3d3e-4212-9b9e-c9b1a31069bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-c82300ad-9628-4aaa-b967-48bd18ca99ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-f217730a-1df3-4d0e-bed3-f43a476cb993,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-1a3a0995-2aed-444f-ab35-e01878ae0bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-2a964e29-75a4-4ca6-9b7d-1e45f7a96f38,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871698238-172.17.0.3-1598344614684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45885,DS-63d2a965-c930-4e77-a2b8-042084f6b7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-2a6e610b-6f0c-48b4-9ce3-568ebd63cef5,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-aa1941d4-4ff0-4a61-b7e3-4dc5fb7a7671,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-86bfc080-3d3e-4212-9b9e-c9b1a31069bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-c82300ad-9628-4aaa-b967-48bd18ca99ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-f217730a-1df3-4d0e-bed3-f43a476cb993,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-1a3a0995-2aed-444f-ab35-e01878ae0bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-2a964e29-75a4-4ca6-9b7d-1e45f7a96f38,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75216249-172.17.0.3-1598345004032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33050,DS-647106c8-e69a-4ecb-83d2-2fc594369ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-9353356d-333d-424c-8c8d-592c7ebec8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-a8ad2305-4889-4d4a-a35a-e6a4dec5b24c,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-68ab26dd-cf25-4237-b00e-a8b9d28b2f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-f5efb8ca-1f18-4254-8e8d-204984049668,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-5b0bf87c-fbea-41e4-8b58-458658fc71ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-d732c588-927b-4ec1-bcf7-250a9fa8c602,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-e4eda284-06cb-45f4-bb4c-5f49c0f7aaef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75216249-172.17.0.3-1598345004032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33050,DS-647106c8-e69a-4ecb-83d2-2fc594369ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-9353356d-333d-424c-8c8d-592c7ebec8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-a8ad2305-4889-4d4a-a35a-e6a4dec5b24c,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-68ab26dd-cf25-4237-b00e-a8b9d28b2f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-f5efb8ca-1f18-4254-8e8d-204984049668,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-5b0bf87c-fbea-41e4-8b58-458658fc71ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-d732c588-927b-4ec1-bcf7-250a9fa8c602,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-e4eda284-06cb-45f4-bb4c-5f49c0f7aaef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273220927-172.17.0.3-1598345044012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36607,DS-9d55d9b0-7698-4ac7-9a0b-67650028a710,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-397564c4-7d2a-4ac7-bf85-34ce900942a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-bd381f03-cde5-4f35-861a-9be7134905d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-56434d39-8245-4ba4-a224-e69240e7e94a,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-05566c98-dfa5-4c55-868d-0ded4e13baab,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-3d471454-1eff-4369-ac66-827848f9f8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-316af711-0280-43d7-bf09-7a30dd6a60bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-e7a3e5f2-76e0-4484-a798-327792c4fde1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273220927-172.17.0.3-1598345044012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36607,DS-9d55d9b0-7698-4ac7-9a0b-67650028a710,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-397564c4-7d2a-4ac7-bf85-34ce900942a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-bd381f03-cde5-4f35-861a-9be7134905d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-56434d39-8245-4ba4-a224-e69240e7e94a,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-05566c98-dfa5-4c55-868d-0ded4e13baab,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-3d471454-1eff-4369-ac66-827848f9f8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-316af711-0280-43d7-bf09-7a30dd6a60bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-e7a3e5f2-76e0-4484-a798-327792c4fde1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117769911-172.17.0.3-1598345141681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45405,DS-db169d6c-7dd7-491c-9e54-1341366dffeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-b7559da2-d60f-4ea7-b5fd-d1e9765b933a,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-e729a733-72a1-4ac2-ae1a-1d40d8bf5f02,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-ed9007d9-7f2a-4458-8d57-bfdfc08a1d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-a6cac661-5349-4f6a-9760-07bed523c24b,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-59cac71c-b900-47eb-bb41-5159757a0c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-82f22e08-d7d8-4074-b945-2b72461e4174,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-2921c928-29df-4fb1-be7e-8824f5c56161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117769911-172.17.0.3-1598345141681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45405,DS-db169d6c-7dd7-491c-9e54-1341366dffeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-b7559da2-d60f-4ea7-b5fd-d1e9765b933a,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-e729a733-72a1-4ac2-ae1a-1d40d8bf5f02,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-ed9007d9-7f2a-4458-8d57-bfdfc08a1d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-a6cac661-5349-4f6a-9760-07bed523c24b,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-59cac71c-b900-47eb-bb41-5159757a0c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-82f22e08-d7d8-4074-b945-2b72461e4174,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-2921c928-29df-4fb1-be7e-8824f5c56161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305269317-172.17.0.3-1598345265968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42010,DS-f22328e2-6973-460f-9d45-591b66c5613e,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-920f1b9d-141b-4544-bb29-e4c717f2c363,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-44599434-c6f8-4a5d-9488-50a12c0a7275,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-579e11ae-4987-4543-bccc-9ffa29319d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-7d3d196d-7950-43b1-b2be-e088d40f2587,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-55cedcbd-031c-46af-b975-c9a4900b9ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-0bf24ba6-61e0-4397-af84-7c1517c8f869,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-9ebc6085-5c2e-4487-a6f0-1d55600de599,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305269317-172.17.0.3-1598345265968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42010,DS-f22328e2-6973-460f-9d45-591b66c5613e,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-920f1b9d-141b-4544-bb29-e4c717f2c363,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-44599434-c6f8-4a5d-9488-50a12c0a7275,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-579e11ae-4987-4543-bccc-9ffa29319d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-7d3d196d-7950-43b1-b2be-e088d40f2587,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-55cedcbd-031c-46af-b975-c9a4900b9ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-0bf24ba6-61e0-4397-af84-7c1517c8f869,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-9ebc6085-5c2e-4487-a6f0-1d55600de599,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650988583-172.17.0.3-1598345359223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39818,DS-8731a822-e1f0-42b8-a013-1165bbe5f637,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-a39fca42-f9c0-46d3-b92e-4a24efa43fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-2612d308-e223-4ef1-af60-d55562d85e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-8c75f190-c0c5-4e2f-9e13-8b29ec4282c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-d0a35001-63a9-451b-ba49-a4b23d96ea59,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-17c2a13a-ce58-4d74-b5d2-85d332df5ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-801a156f-937e-4e32-a271-493abf6736aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-ce09fecf-bca0-49cf-a7bc-601d4011c0ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650988583-172.17.0.3-1598345359223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39818,DS-8731a822-e1f0-42b8-a013-1165bbe5f637,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-a39fca42-f9c0-46d3-b92e-4a24efa43fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-2612d308-e223-4ef1-af60-d55562d85e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-8c75f190-c0c5-4e2f-9e13-8b29ec4282c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-d0a35001-63a9-451b-ba49-a4b23d96ea59,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-17c2a13a-ce58-4d74-b5d2-85d332df5ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-801a156f-937e-4e32-a271-493abf6736aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-ce09fecf-bca0-49cf-a7bc-601d4011c0ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017549639-172.17.0.3-1598345541199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44618,DS-55c7b50f-90a6-4ede-85fe-0c6a1de3c64a,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-dd31f055-d11e-479c-b2e9-12b390c8db93,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-9503e5fe-59a9-46ec-a12a-9c7cc3b981df,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-bc116c97-e26e-45a3-80a7-2971a184689a,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-bff4bba7-35d4-47e1-b000-4dbfc5b01537,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-f138d67f-037e-43c9-98c6-6687b8e8ca63,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-f0a03ea0-dce7-46dd-8727-4bf4deac5a68,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-20931a85-b087-4672-8259-08db0f75c006,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017549639-172.17.0.3-1598345541199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44618,DS-55c7b50f-90a6-4ede-85fe-0c6a1de3c64a,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-dd31f055-d11e-479c-b2e9-12b390c8db93,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-9503e5fe-59a9-46ec-a12a-9c7cc3b981df,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-bc116c97-e26e-45a3-80a7-2971a184689a,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-bff4bba7-35d4-47e1-b000-4dbfc5b01537,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-f138d67f-037e-43c9-98c6-6687b8e8ca63,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-f0a03ea0-dce7-46dd-8727-4bf4deac5a68,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-20931a85-b087-4672-8259-08db0f75c006,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060479503-172.17.0.3-1598345609804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40326,DS-7722c989-7c40-4d9a-a7a2-4b573f48d249,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-19c0f2fe-8913-4bfc-bee5-8eeced2ce2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-3a58fad3-39ea-489c-bba9-438f42834c39,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-22c3427c-36ce-4ff7-82bd-ce8211289953,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-51f2c551-e383-44b2-8fce-cfdfc6633d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-18d4bfc6-0df7-4b71-a690-139bebcfa722,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-e6872682-e6ac-42f7-a612-65cde44d8fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-c70e622b-8574-437a-a05d-405ab64ba2cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060479503-172.17.0.3-1598345609804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40326,DS-7722c989-7c40-4d9a-a7a2-4b573f48d249,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-19c0f2fe-8913-4bfc-bee5-8eeced2ce2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-3a58fad3-39ea-489c-bba9-438f42834c39,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-22c3427c-36ce-4ff7-82bd-ce8211289953,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-51f2c551-e383-44b2-8fce-cfdfc6633d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-18d4bfc6-0df7-4b71-a690-139bebcfa722,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-e6872682-e6ac-42f7-a612-65cde44d8fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-c70e622b-8574-437a-a05d-405ab64ba2cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496627222-172.17.0.3-1598345742131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41577,DS-477255b6-3ec2-4892-b04f-9715712090e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-409c71f0-6079-45e9-8aa2-1688bf1dcbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-889b79f2-a733-4565-a7ed-c616ed3f453d,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-cdf6705f-d720-4d28-b2df-2998260a6cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-4605b70e-106c-44ef-ab81-6d5952d1c77b,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-4405d4c6-b443-45d8-9285-84cc9e61a393,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-97000efc-c998-479f-8e6b-096926e8e42b,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-ae5a1932-13f2-4471-94b8-810eb548d8a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496627222-172.17.0.3-1598345742131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41577,DS-477255b6-3ec2-4892-b04f-9715712090e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-409c71f0-6079-45e9-8aa2-1688bf1dcbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-889b79f2-a733-4565-a7ed-c616ed3f453d,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-cdf6705f-d720-4d28-b2df-2998260a6cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-4605b70e-106c-44ef-ab81-6d5952d1c77b,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-4405d4c6-b443-45d8-9285-84cc9e61a393,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-97000efc-c998-479f-8e6b-096926e8e42b,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-ae5a1932-13f2-4471-94b8-810eb548d8a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-6746555-172.17.0.3-1598346014991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44293,DS-a62f085d-c280-4e7c-9769-b38dab723b84,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-cf349347-15e5-4dd6-884f-105f83b99bee,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-547a07d8-01af-41d3-ab13-609a5d7570b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-69e92636-72f0-42c4-b191-66f1c6d547a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-c51526fd-48aa-4930-b577-f0ed2a65d8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-5bf9ffa2-eeb0-44dc-b636-35bb179ff5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-103ef0a8-7a66-463f-8d5f-126667c8d2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-b7611281-3fdf-459a-8ed0-e6c3028f734e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-6746555-172.17.0.3-1598346014991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44293,DS-a62f085d-c280-4e7c-9769-b38dab723b84,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-cf349347-15e5-4dd6-884f-105f83b99bee,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-547a07d8-01af-41d3-ab13-609a5d7570b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-69e92636-72f0-42c4-b191-66f1c6d547a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-c51526fd-48aa-4930-b577-f0ed2a65d8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-5bf9ffa2-eeb0-44dc-b636-35bb179ff5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-103ef0a8-7a66-463f-8d5f-126667c8d2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-b7611281-3fdf-459a-8ed0-e6c3028f734e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105430842-172.17.0.3-1598346042857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45604,DS-7b34eab6-8ef3-4fba-a87d-20adce867992,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-cacf3320-af36-4d42-97da-688aec0d8530,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-6880d33c-8461-4392-9959-dc54595a3179,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-7abcc41b-235d-440d-8689-948d5f6a5caa,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-619594f4-9c09-463c-a748-aef7b67ce5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-e9f98396-93c4-474d-8507-e7fdb08bf9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-32f28866-40de-49f6-816a-1327d1b1c02b,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-aaafbd6b-475e-4066-bfef-f7ebf590e7cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105430842-172.17.0.3-1598346042857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45604,DS-7b34eab6-8ef3-4fba-a87d-20adce867992,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-cacf3320-af36-4d42-97da-688aec0d8530,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-6880d33c-8461-4392-9959-dc54595a3179,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-7abcc41b-235d-440d-8689-948d5f6a5caa,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-619594f4-9c09-463c-a748-aef7b67ce5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-e9f98396-93c4-474d-8507-e7fdb08bf9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-32f28866-40de-49f6-816a-1327d1b1c02b,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-aaafbd6b-475e-4066-bfef-f7ebf590e7cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999123989-172.17.0.3-1598346075230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37016,DS-f4626eaa-6e6b-405f-92fc-6f3cad697421,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-19cb6fb5-d26e-4193-9c6d-d321964ca111,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-ccbdd113-f9a3-43a1-8580-3d5723de02e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-0908ea41-6c75-473d-a743-2cfd1967797e,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-881d9cd7-ea7a-40d8-a81b-633d3d8cb6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-f122a313-8211-4e54-a431-a89c023087e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-23703d8c-6868-48b1-8d8c-c2118d330e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-45bcc3d8-5a2c-42d0-95db-d098ea60fbe3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999123989-172.17.0.3-1598346075230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37016,DS-f4626eaa-6e6b-405f-92fc-6f3cad697421,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-19cb6fb5-d26e-4193-9c6d-d321964ca111,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-ccbdd113-f9a3-43a1-8580-3d5723de02e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-0908ea41-6c75-473d-a743-2cfd1967797e,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-881d9cd7-ea7a-40d8-a81b-633d3d8cb6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-f122a313-8211-4e54-a431-a89c023087e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-23703d8c-6868-48b1-8d8c-c2118d330e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-45bcc3d8-5a2c-42d0-95db-d098ea60fbe3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214415238-172.17.0.3-1598346430591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-dab84f33-e14f-4b33-9574-1875a3f8fc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-35cebff7-0dc8-4545-bf35-c5378c071fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-38f13d7c-77f3-4d03-b39a-878f6011d101,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-1899013e-be21-4ca9-9bb5-1b927f0eb2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-228701fd-0e29-47ad-a362-12228c951935,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-894d960f-3b95-4bf3-b132-e51e7ccac49e,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-2761c5e3-bec6-4015-9896-50aa76c8a0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-f50a540c-25f2-49d5-85a7-f1587555cc3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214415238-172.17.0.3-1598346430591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-dab84f33-e14f-4b33-9574-1875a3f8fc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-35cebff7-0dc8-4545-bf35-c5378c071fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-38f13d7c-77f3-4d03-b39a-878f6011d101,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-1899013e-be21-4ca9-9bb5-1b927f0eb2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-228701fd-0e29-47ad-a362-12228c951935,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-894d960f-3b95-4bf3-b132-e51e7ccac49e,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-2761c5e3-bec6-4015-9896-50aa76c8a0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-f50a540c-25f2-49d5-85a7-f1587555cc3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208532492-172.17.0.3-1598346612075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37812,DS-f490e4fd-333f-4293-8857-9c2faeb01f96,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-2b5f70f1-07f8-453c-aae0-4e2c5d273232,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-75a8af8b-5f91-4cf4-8b24-aac4c1b0f45b,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-1ef4e183-da05-465a-80e8-7a6b5e59758e,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-98923327-7cd8-430b-b322-70b0b713d2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-c6a103d7-0a78-4e58-aa0d-c44943b02d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-a3a84718-b57f-4d57-a5c2-d36c5337c44b,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-95ecb930-1f5e-4673-9fc9-dc255967f72d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208532492-172.17.0.3-1598346612075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37812,DS-f490e4fd-333f-4293-8857-9c2faeb01f96,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-2b5f70f1-07f8-453c-aae0-4e2c5d273232,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-75a8af8b-5f91-4cf4-8b24-aac4c1b0f45b,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-1ef4e183-da05-465a-80e8-7a6b5e59758e,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-98923327-7cd8-430b-b322-70b0b713d2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-c6a103d7-0a78-4e58-aa0d-c44943b02d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-a3a84718-b57f-4d57-a5c2-d36c5337c44b,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-95ecb930-1f5e-4673-9fc9-dc255967f72d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939222162-172.17.0.3-1598346684139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39961,DS-6112566d-ba42-479f-8878-efe58ec151d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-44d6ef23-074f-42cb-a116-294c7a3e7921,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-43cc6508-ce76-4457-8469-d940279e56d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-1f7aedb4-5aef-4606-9e78-908f8efca880,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-5ba668fd-9b7d-4cd5-8530-7fba84deeac2,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-1572c0b6-9f6d-4c85-a05e-c72fb6fd8a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-f6a35d8f-d916-497b-a840-d17125d9b776,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-86cb21da-1cce-4c7d-a303-89f4a1a8a52c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939222162-172.17.0.3-1598346684139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39961,DS-6112566d-ba42-479f-8878-efe58ec151d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-44d6ef23-074f-42cb-a116-294c7a3e7921,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-43cc6508-ce76-4457-8469-d940279e56d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-1f7aedb4-5aef-4606-9e78-908f8efca880,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-5ba668fd-9b7d-4cd5-8530-7fba84deeac2,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-1572c0b6-9f6d-4c85-a05e-c72fb6fd8a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-f6a35d8f-d916-497b-a840-d17125d9b776,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-86cb21da-1cce-4c7d-a303-89f4a1a8a52c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570612932-172.17.0.3-1598346832094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45742,DS-10178636-d2dc-4144-b4f7-cb557eaff0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-dc44980d-f6da-4c90-8e86-e13e214578f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-6d882ec4-7a49-4bc0-9e8f-7c4cabf6b6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-5a5dae12-4d05-47af-910f-b8f92be5797b,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-f22eaeb8-370e-4f3f-99c0-b1a90129019d,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-11283e6f-5b78-4742-a119-43cde1d9a0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-679cf1d4-602e-48bb-83f6-93400c53b606,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-89598a43-a5a9-4645-99ac-6f700eab0a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570612932-172.17.0.3-1598346832094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45742,DS-10178636-d2dc-4144-b4f7-cb557eaff0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-dc44980d-f6da-4c90-8e86-e13e214578f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-6d882ec4-7a49-4bc0-9e8f-7c4cabf6b6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-5a5dae12-4d05-47af-910f-b8f92be5797b,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-f22eaeb8-370e-4f3f-99c0-b1a90129019d,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-11283e6f-5b78-4742-a119-43cde1d9a0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-679cf1d4-602e-48bb-83f6-93400c53b606,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-89598a43-a5a9-4645-99ac-6f700eab0a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420009450-172.17.0.3-1598347029111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45469,DS-8db5ccf8-3132-40f9-81e4-b7ea7e55e347,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-d3b0fe03-3ba2-42b3-a023-6d1b82472489,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-ec99efe8-e525-44bc-98bd-9b8d87eb18a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-326b0c87-2701-4497-b006-0f0c83f00325,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-27b082cb-2005-40cc-80cf-5fb18a2caa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-e5aea9c4-68c2-4f4f-b275-dc50ee244c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-fd6fa027-5313-468e-b8a3-ec9bff060cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-5a52751e-68f6-4d9d-8121-3962a4fefbb4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420009450-172.17.0.3-1598347029111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45469,DS-8db5ccf8-3132-40f9-81e4-b7ea7e55e347,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-d3b0fe03-3ba2-42b3-a023-6d1b82472489,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-ec99efe8-e525-44bc-98bd-9b8d87eb18a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-326b0c87-2701-4497-b006-0f0c83f00325,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-27b082cb-2005-40cc-80cf-5fb18a2caa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-e5aea9c4-68c2-4f4f-b275-dc50ee244c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-fd6fa027-5313-468e-b8a3-ec9bff060cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-5a52751e-68f6-4d9d-8121-3962a4fefbb4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444797034-172.17.0.3-1598347277800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42020,DS-7f0420c7-aee1-42ee-8407-8bad9bbd9640,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-ec0224d4-bac3-4236-81af-b312fd1f3972,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-42ebdd03-1915-496a-af78-d6a374865666,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-e5e70f91-b911-440a-980f-19ed9e63b4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-9791db31-286f-4b38-b841-6d584f590cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-310517e3-8ec1-4dcc-a1ee-b35e556435ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-15b204c6-c67a-4b40-bb41-0eae31a4131d,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-7476575c-3872-48b9-90c6-af42db3ac1fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444797034-172.17.0.3-1598347277800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42020,DS-7f0420c7-aee1-42ee-8407-8bad9bbd9640,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-ec0224d4-bac3-4236-81af-b312fd1f3972,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-42ebdd03-1915-496a-af78-d6a374865666,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-e5e70f91-b911-440a-980f-19ed9e63b4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-9791db31-286f-4b38-b841-6d584f590cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-310517e3-8ec1-4dcc-a1ee-b35e556435ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-15b204c6-c67a-4b40-bb41-0eae31a4131d,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-7476575c-3872-48b9-90c6-af42db3ac1fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066769626-172.17.0.3-1598347415816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37984,DS-9dcf5552-5740-41ae-954f-629f8dbc0336,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-7fa7e747-8b7f-4835-a2ee-ce3cb547b193,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-78f48a93-9727-423f-9951-7e4ab5528de5,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-e3cc689f-b11f-4bc6-b2c0-d6f2707f9620,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-d44b32a7-1060-452b-a21d-5a059961fad5,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-73b8806b-0893-4153-ae3e-1dda9b993ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-5d711957-6cd6-44b0-a633-0b8cb67a6e35,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-a3e65173-f65d-4a16-ba40-70a542cafaa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066769626-172.17.0.3-1598347415816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37984,DS-9dcf5552-5740-41ae-954f-629f8dbc0336,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-7fa7e747-8b7f-4835-a2ee-ce3cb547b193,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-78f48a93-9727-423f-9951-7e4ab5528de5,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-e3cc689f-b11f-4bc6-b2c0-d6f2707f9620,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-d44b32a7-1060-452b-a21d-5a059961fad5,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-73b8806b-0893-4153-ae3e-1dda9b993ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-5d711957-6cd6-44b0-a633-0b8cb67a6e35,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-a3e65173-f65d-4a16-ba40-70a542cafaa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742754986-172.17.0.3-1598347719087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35294,DS-8f99150e-8e41-45d6-8448-76af240f4bda,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-969757b9-4337-4ac6-8db5-6ec19c78d0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-4619dec0-b1ba-4387-8536-c88c3e700055,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-57324941-f49e-4909-a641-accabe8bb729,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-3452835d-61bf-4c02-8251-36042782639b,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-f112f085-6c79-4795-b83d-2304d6a6c5df,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-5b27504f-9b64-426d-aecb-84198fe3f07f,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-68578c21-0c1b-4e17-814c-54a8a0e1dbe6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742754986-172.17.0.3-1598347719087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35294,DS-8f99150e-8e41-45d6-8448-76af240f4bda,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-969757b9-4337-4ac6-8db5-6ec19c78d0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-4619dec0-b1ba-4387-8536-c88c3e700055,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-57324941-f49e-4909-a641-accabe8bb729,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-3452835d-61bf-4c02-8251-36042782639b,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-f112f085-6c79-4795-b83d-2304d6a6c5df,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-5b27504f-9b64-426d-aecb-84198fe3f07f,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-68578c21-0c1b-4e17-814c-54a8a0e1dbe6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846692201-172.17.0.3-1598347751403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41432,DS-f68b0dec-0b88-4d4f-9565-bf8070b7884f,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-b814617d-e5ec-469a-afc2-dcda5b98fbec,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-6f75c9f6-3ba6-4d98-baf7-f35c2b197cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-4c8c1a58-e451-4456-8b8c-2c73f75f1675,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-11a550d8-4bb9-4f2d-b3a8-51233747ff21,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-013852fb-8013-4a7a-959a-9bd1dcfc1ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-21cd0bb9-1e4f-4982-a530-9ea8ce037bef,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-97094b25-5a82-415a-ad8a-9f806440a553,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846692201-172.17.0.3-1598347751403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41432,DS-f68b0dec-0b88-4d4f-9565-bf8070b7884f,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-b814617d-e5ec-469a-afc2-dcda5b98fbec,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-6f75c9f6-3ba6-4d98-baf7-f35c2b197cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-4c8c1a58-e451-4456-8b8c-2c73f75f1675,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-11a550d8-4bb9-4f2d-b3a8-51233747ff21,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-013852fb-8013-4a7a-959a-9bd1dcfc1ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-21cd0bb9-1e4f-4982-a530-9ea8ce037bef,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-97094b25-5a82-415a-ad8a-9f806440a553,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5243
