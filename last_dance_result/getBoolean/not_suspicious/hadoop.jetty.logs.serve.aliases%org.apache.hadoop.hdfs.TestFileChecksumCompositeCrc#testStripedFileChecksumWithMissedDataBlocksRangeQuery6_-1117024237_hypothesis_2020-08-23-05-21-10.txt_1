reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133337419-172.17.0.6-1598160373905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42124,DS-722f1f2d-0f3b-49e2-b2df-d3b0d0e056fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-8ea54395-5170-4cb1-836c-7ee72fda5003,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-f4420c11-c136-4141-b20e-ba148c6f66ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-f77a83d4-43ae-4d84-9085-097c29468991,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-95040dec-b1c4-4a9f-ac8a-b1772b47b5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-4d9bc2ec-d51e-4318-822b-7f13c709fbee,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-80251832-a660-4711-b6b5-a7af9cb58ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-655e7794-74ed-469f-9c56-0ed971ee0225,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133337419-172.17.0.6-1598160373905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42124,DS-722f1f2d-0f3b-49e2-b2df-d3b0d0e056fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-8ea54395-5170-4cb1-836c-7ee72fda5003,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-f4420c11-c136-4141-b20e-ba148c6f66ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-f77a83d4-43ae-4d84-9085-097c29468991,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-95040dec-b1c4-4a9f-ac8a-b1772b47b5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-4d9bc2ec-d51e-4318-822b-7f13c709fbee,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-80251832-a660-4711-b6b5-a7af9cb58ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-655e7794-74ed-469f-9c56-0ed971ee0225,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600123307-172.17.0.6-1598160443326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40218,DS-18c391e1-c5bb-48d1-958e-caa9658bd450,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-bed5199f-0447-444e-bdc6-773b98ecfca8,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-3a57bdf7-7c27-40ac-85c5-1d37e7f9c9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-fd2cd844-f5f8-4e9a-9c24-770c5250ac0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-daa2107e-c399-4172-b9ad-9c1b224f510d,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-78de38c5-6c68-40e5-b5f8-a21c01f706fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-a5da8de8-8e4d-44f1-91c8-f82dcee78db6,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-e8768244-338b-4f31-90d5-85cee630d9c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600123307-172.17.0.6-1598160443326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40218,DS-18c391e1-c5bb-48d1-958e-caa9658bd450,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-bed5199f-0447-444e-bdc6-773b98ecfca8,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-3a57bdf7-7c27-40ac-85c5-1d37e7f9c9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-fd2cd844-f5f8-4e9a-9c24-770c5250ac0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-daa2107e-c399-4172-b9ad-9c1b224f510d,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-78de38c5-6c68-40e5-b5f8-a21c01f706fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-a5da8de8-8e4d-44f1-91c8-f82dcee78db6,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-e8768244-338b-4f31-90d5-85cee630d9c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178302600-172.17.0.6-1598160562287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40581,DS-c8b87c96-e854-460b-b089-cffe63ea9dab,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-bfd80c4b-4312-4e2c-9d28-0df3512d81b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-a0d2958a-a4bc-47a2-95ec-724b2f43d2de,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-18681e13-fa92-451f-9858-dfc2f75f6ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-7dd7f1ee-6f76-4c74-8d58-bd75e40573de,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-a88481cf-134f-499e-9055-513743972cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-d7f8054c-eada-4835-ae2f-49378ad5c61d,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-2f72c14d-12ca-48e2-9f97-5443ac932023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178302600-172.17.0.6-1598160562287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40581,DS-c8b87c96-e854-460b-b089-cffe63ea9dab,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-bfd80c4b-4312-4e2c-9d28-0df3512d81b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-a0d2958a-a4bc-47a2-95ec-724b2f43d2de,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-18681e13-fa92-451f-9858-dfc2f75f6ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-7dd7f1ee-6f76-4c74-8d58-bd75e40573de,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-a88481cf-134f-499e-9055-513743972cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-d7f8054c-eada-4835-ae2f-49378ad5c61d,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-2f72c14d-12ca-48e2-9f97-5443ac932023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692938193-172.17.0.6-1598160720755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45325,DS-e91c9549-2b22-4734-9674-769badd4af00,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-1b975a02-b863-448c-b691-176c09b8f040,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-15d921b0-11f4-4a55-b69c-367564426fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-ce3e053c-4040-48f7-9438-df4c48eb980d,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-c940cf85-72cb-4678-81dd-dffd31a64800,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-020c5b08-3a03-4d3f-bf27-5da5b3b436f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-56d0f78f-8ea2-4130-a474-2f1a5f9b9d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-80b0956b-a1ac-4a7f-9612-224718d81a30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692938193-172.17.0.6-1598160720755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45325,DS-e91c9549-2b22-4734-9674-769badd4af00,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-1b975a02-b863-448c-b691-176c09b8f040,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-15d921b0-11f4-4a55-b69c-367564426fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-ce3e053c-4040-48f7-9438-df4c48eb980d,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-c940cf85-72cb-4678-81dd-dffd31a64800,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-020c5b08-3a03-4d3f-bf27-5da5b3b436f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-56d0f78f-8ea2-4130-a474-2f1a5f9b9d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-80b0956b-a1ac-4a7f-9612-224718d81a30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983315246-172.17.0.6-1598160758793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40031,DS-354b96ec-5713-45dc-87b1-1d9b7e654176,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-15c2706e-254e-4873-9b6a-304d80d279ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-4c4b9e27-d730-419f-8a2d-50bca07242f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-8b4b70ec-9631-49f0-bd84-12efb0aa8b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-ea82d830-9742-437d-9071-26c1debec58e,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-0c75ed82-2372-471a-bd21-2141770965a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-de40f64f-f578-4198-8e4a-2f6161eea062,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-2f93f891-d1ea-41a2-ada8-7747357e32b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983315246-172.17.0.6-1598160758793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40031,DS-354b96ec-5713-45dc-87b1-1d9b7e654176,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-15c2706e-254e-4873-9b6a-304d80d279ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-4c4b9e27-d730-419f-8a2d-50bca07242f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-8b4b70ec-9631-49f0-bd84-12efb0aa8b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-ea82d830-9742-437d-9071-26c1debec58e,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-0c75ed82-2372-471a-bd21-2141770965a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-de40f64f-f578-4198-8e4a-2f6161eea062,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-2f93f891-d1ea-41a2-ada8-7747357e32b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314784051-172.17.0.6-1598160838041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41298,DS-2fcfd324-7716-4c99-b447-fae882253a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-5b35efe7-a94a-4e55-b97c-d47a0c233863,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-20316e44-fd77-42e5-92e4-8f06a7e7bb91,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-3f0d3488-d7eb-406e-84d7-3186c58be24d,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-df2e9fd1-85e4-422e-a26c-2b0772cc3236,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-a1ffd96f-cbd0-4de0-a83d-fc7f57556679,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-3d5b4d24-c6fc-4c72-9e08-14d16af86db1,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-4b6aba2a-19fe-4413-a680-b01e0aa2651d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314784051-172.17.0.6-1598160838041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41298,DS-2fcfd324-7716-4c99-b447-fae882253a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-5b35efe7-a94a-4e55-b97c-d47a0c233863,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-20316e44-fd77-42e5-92e4-8f06a7e7bb91,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-3f0d3488-d7eb-406e-84d7-3186c58be24d,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-df2e9fd1-85e4-422e-a26c-2b0772cc3236,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-a1ffd96f-cbd0-4de0-a83d-fc7f57556679,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-3d5b4d24-c6fc-4c72-9e08-14d16af86db1,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-4b6aba2a-19fe-4413-a680-b01e0aa2651d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085697296-172.17.0.6-1598160962527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36611,DS-1b7783ad-7bc4-4102-8359-0c61656288db,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-2de18ba2-c7c7-421a-b6b1-cd831cb8a772,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-479792dc-f378-41f2-a486-95492a02d0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-097e586c-858d-4bda-8187-7797f72a247d,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-8bd54607-81d3-43ac-a88d-e5c9ab7ea382,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-9b10d8f7-715a-4a55-b120-356e181e62fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-8e8f6712-7a12-484a-b041-c8a4d934f7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-10001dcc-4a00-42ab-b1ad-135392736173,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085697296-172.17.0.6-1598160962527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36611,DS-1b7783ad-7bc4-4102-8359-0c61656288db,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-2de18ba2-c7c7-421a-b6b1-cd831cb8a772,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-479792dc-f378-41f2-a486-95492a02d0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-097e586c-858d-4bda-8187-7797f72a247d,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-8bd54607-81d3-43ac-a88d-e5c9ab7ea382,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-9b10d8f7-715a-4a55-b120-356e181e62fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-8e8f6712-7a12-484a-b041-c8a4d934f7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-10001dcc-4a00-42ab-b1ad-135392736173,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782657548-172.17.0.6-1598161034706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38359,DS-e27483c7-d0ce-49a8-b645-1f6cf56f588e,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-206e8609-ac69-493f-962d-818b077dc3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-4d98e9c3-597f-4256-a7a0-2f378c5de9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-aca962fc-1e14-42f9-be62-ecbc7d75865e,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-7e05ec7c-4632-412f-82a3-2f50b08b2de4,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-399520b8-0c62-4691-a91d-052362f027d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-acdde049-02ca-4b33-9ea2-f933eb2798f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-67782dee-9243-496a-81b7-93cd77b77ef1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782657548-172.17.0.6-1598161034706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38359,DS-e27483c7-d0ce-49a8-b645-1f6cf56f588e,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-206e8609-ac69-493f-962d-818b077dc3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-4d98e9c3-597f-4256-a7a0-2f378c5de9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-aca962fc-1e14-42f9-be62-ecbc7d75865e,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-7e05ec7c-4632-412f-82a3-2f50b08b2de4,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-399520b8-0c62-4691-a91d-052362f027d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-acdde049-02ca-4b33-9ea2-f933eb2798f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-67782dee-9243-496a-81b7-93cd77b77ef1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192915964-172.17.0.6-1598161405228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36510,DS-caf3be50-16cd-4bbf-b35e-213618ef1918,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-99efecd8-2def-4aeb-aae4-33e1e7b738a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-b58740ab-7aff-4d1c-9e0f-6de5e1c3fe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-3f1e0b27-07a6-4eca-9059-0916131293c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-1a7dce27-bec9-46ea-b630-0a9e61120de9,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-261563a1-57d2-4aea-9760-ed24043af35b,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-c4f281ce-e2cc-4cc8-a4f9-87477a968a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-87caf5c2-70e2-4d00-a385-653e373b2f30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192915964-172.17.0.6-1598161405228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36510,DS-caf3be50-16cd-4bbf-b35e-213618ef1918,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-99efecd8-2def-4aeb-aae4-33e1e7b738a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-b58740ab-7aff-4d1c-9e0f-6de5e1c3fe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-3f1e0b27-07a6-4eca-9059-0916131293c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-1a7dce27-bec9-46ea-b630-0a9e61120de9,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-261563a1-57d2-4aea-9760-ed24043af35b,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-c4f281ce-e2cc-4cc8-a4f9-87477a968a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-87caf5c2-70e2-4d00-a385-653e373b2f30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546453661-172.17.0.6-1598161449271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36019,DS-17903b52-fdc5-4b87-9fd4-828d31462bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-bea17cec-85de-47b9-aee9-cd060cc6c360,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-aa4bf6e1-f9c7-4e1e-a505-22fcb3594677,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-20aadc46-36af-4287-ba65-eef5af003a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-5b1d77d3-0495-4bae-8fc5-53cf5bb3fb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-2b1f050f-3b18-4906-98c4-357e38970f89,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-d8e82a0f-e4ed-4c48-a437-e0a1c44235ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-99fd2b4f-6f8e-4b4e-a7f4-82846832b33b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546453661-172.17.0.6-1598161449271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36019,DS-17903b52-fdc5-4b87-9fd4-828d31462bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-bea17cec-85de-47b9-aee9-cd060cc6c360,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-aa4bf6e1-f9c7-4e1e-a505-22fcb3594677,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-20aadc46-36af-4287-ba65-eef5af003a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-5b1d77d3-0495-4bae-8fc5-53cf5bb3fb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-2b1f050f-3b18-4906-98c4-357e38970f89,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-d8e82a0f-e4ed-4c48-a437-e0a1c44235ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-99fd2b4f-6f8e-4b4e-a7f4-82846832b33b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786877083-172.17.0.6-1598161490058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43654,DS-b7008a55-8574-4ba6-9786-aa17ae2bc0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-e0bddb84-746f-4c5d-afb2-746cffdd4246,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-a382ee04-5187-4cd9-ba8a-bfe75c8106ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-a7280730-a844-41d4-b5ee-40495b658641,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-0b364e65-d180-47ef-9c38-4d740ba834b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-0a883709-d756-4a70-9826-42a43b7143f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-0ffe5578-ef45-4b1c-8f15-65aff7ae2ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-4c644aa7-bb84-45a4-a15b-0d0b085ea3dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786877083-172.17.0.6-1598161490058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43654,DS-b7008a55-8574-4ba6-9786-aa17ae2bc0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-e0bddb84-746f-4c5d-afb2-746cffdd4246,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-a382ee04-5187-4cd9-ba8a-bfe75c8106ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-a7280730-a844-41d4-b5ee-40495b658641,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-0b364e65-d180-47ef-9c38-4d740ba834b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-0a883709-d756-4a70-9826-42a43b7143f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-0ffe5578-ef45-4b1c-8f15-65aff7ae2ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-4c644aa7-bb84-45a4-a15b-0d0b085ea3dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608255130-172.17.0.6-1598161598932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40392,DS-b69370e0-aa9d-4b98-ab4d-7f79f43a71fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-4bce1b0a-00e9-4011-9dbf-8d16802a1103,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-9e9d90dc-6e8a-4778-9c9e-acb893688a41,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-38604e5e-fc73-4d20-94eb-8f4c373f0c47,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-24708088-c992-4a4f-8f65-d036c0ba18c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-0e1868e8-794a-4013-b2f7-810b5fe16682,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-c9f6848f-9b34-420a-8a27-bc15d5c1c0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-311d3435-142e-4db2-94c2-42a600539bc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608255130-172.17.0.6-1598161598932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40392,DS-b69370e0-aa9d-4b98-ab4d-7f79f43a71fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-4bce1b0a-00e9-4011-9dbf-8d16802a1103,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-9e9d90dc-6e8a-4778-9c9e-acb893688a41,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-38604e5e-fc73-4d20-94eb-8f4c373f0c47,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-24708088-c992-4a4f-8f65-d036c0ba18c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-0e1868e8-794a-4013-b2f7-810b5fe16682,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-c9f6848f-9b34-420a-8a27-bc15d5c1c0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-311d3435-142e-4db2-94c2-42a600539bc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643530366-172.17.0.6-1598161788825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43269,DS-a2a55d21-8939-4a5c-a0ce-e2a61d703f72,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-e9485b7c-1701-43ec-b2a6-2735d172bbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-1b6aed78-684a-425e-9859-338dd7c23e43,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-71cc8628-f5b4-480e-b557-34f438ccd160,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-422d7545-19ad-4243-851d-2982fed3a323,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-3456fc8c-78ec-4125-ae44-aba62faf6955,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-e634b0f8-2424-4142-86f6-02655a9e9078,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-1de54803-586e-48ab-8e55-879c7c1eb90b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643530366-172.17.0.6-1598161788825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43269,DS-a2a55d21-8939-4a5c-a0ce-e2a61d703f72,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-e9485b7c-1701-43ec-b2a6-2735d172bbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-1b6aed78-684a-425e-9859-338dd7c23e43,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-71cc8628-f5b4-480e-b557-34f438ccd160,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-422d7545-19ad-4243-851d-2982fed3a323,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-3456fc8c-78ec-4125-ae44-aba62faf6955,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-e634b0f8-2424-4142-86f6-02655a9e9078,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-1de54803-586e-48ab-8e55-879c7c1eb90b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337825739-172.17.0.6-1598161859039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-4c5ee2bf-60d3-4a63-a317-f15660bb51d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-d69621c5-3eea-4d65-95a7-70fd3ccaaeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-21731680-66ce-4af8-b96a-5a966ea4d52c,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-0cd2beba-bd03-4825-938f-8fd1b480c78d,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-032a6d70-ffbc-44b5-bd39-3fc5cb278e45,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-a2f1dd9f-2058-4e77-917a-8dd0d63262c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-1fb842ea-aba3-425f-97ca-0f19023493bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-b3f73fcc-5e05-4e94-9a1a-835bdf9ebd00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337825739-172.17.0.6-1598161859039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-4c5ee2bf-60d3-4a63-a317-f15660bb51d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-d69621c5-3eea-4d65-95a7-70fd3ccaaeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-21731680-66ce-4af8-b96a-5a966ea4d52c,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-0cd2beba-bd03-4825-938f-8fd1b480c78d,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-032a6d70-ffbc-44b5-bd39-3fc5cb278e45,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-a2f1dd9f-2058-4e77-917a-8dd0d63262c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-1fb842ea-aba3-425f-97ca-0f19023493bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-b3f73fcc-5e05-4e94-9a1a-835bdf9ebd00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519619959-172.17.0.6-1598162200649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44130,DS-ddc3c2fa-90b2-4633-a471-d81ce0949c22,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-165500ac-d121-41d9-be87-91de9301f494,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-5a5b6807-63d3-434d-94c2-2cfa21ffbe19,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-cba5408e-9296-4d54-91d7-c5fe487f41b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-9444c8f2-43ec-4ffb-9061-763b0c8ecad4,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-72db7f84-4061-4378-a602-dc097f71bbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-d375c399-87ea-4cf9-8843-0ef9b1376927,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-ae7e2f09-256e-4928-963e-ef9345cfe9ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519619959-172.17.0.6-1598162200649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44130,DS-ddc3c2fa-90b2-4633-a471-d81ce0949c22,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-165500ac-d121-41d9-be87-91de9301f494,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-5a5b6807-63d3-434d-94c2-2cfa21ffbe19,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-cba5408e-9296-4d54-91d7-c5fe487f41b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-9444c8f2-43ec-4ffb-9061-763b0c8ecad4,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-72db7f84-4061-4378-a602-dc097f71bbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-d375c399-87ea-4cf9-8843-0ef9b1376927,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-ae7e2f09-256e-4928-963e-ef9345cfe9ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967706760-172.17.0.6-1598162376553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44554,DS-b4fe161b-aa0c-4520-a6fd-0220baadf38b,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-e0dab08e-9284-4ce0-bb60-ee0946afcb06,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-b7a5c9b1-2955-4b4c-8291-fa44f8c717b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-7f62b589-8db4-40cb-b785-63c429feac8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-68af1c63-8a02-432b-b7ef-7dea948f01ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-d50dbc46-ebd8-415f-9cc7-b4afda8fdb57,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-44fb9455-a538-48f2-834c-ef559b52575e,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-f2d3d0f8-1eff-4e1c-8780-96a00ff2c89f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967706760-172.17.0.6-1598162376553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44554,DS-b4fe161b-aa0c-4520-a6fd-0220baadf38b,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-e0dab08e-9284-4ce0-bb60-ee0946afcb06,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-b7a5c9b1-2955-4b4c-8291-fa44f8c717b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-7f62b589-8db4-40cb-b785-63c429feac8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-68af1c63-8a02-432b-b7ef-7dea948f01ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-d50dbc46-ebd8-415f-9cc7-b4afda8fdb57,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-44fb9455-a538-48f2-834c-ef559b52575e,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-f2d3d0f8-1eff-4e1c-8780-96a00ff2c89f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969099047-172.17.0.6-1598162592137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39194,DS-4798693f-20a3-414e-b393-5c0f23194bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-206adec7-7bf7-4299-84f7-4cf219e9eb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-d57e854a-e85a-4e6c-9afb-f71862ec0376,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-dc658ddb-339c-4501-8f2e-25740ae7f884,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-e6c5d445-1967-426d-bdda-1d372ae70919,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-2773eafd-8e2b-4154-b461-0928f470fe21,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-810c5f2a-6ce9-4c3a-92e4-89d785aa8d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-49231a07-9bfb-4c22-b629-5342824cdbb7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969099047-172.17.0.6-1598162592137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39194,DS-4798693f-20a3-414e-b393-5c0f23194bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-206adec7-7bf7-4299-84f7-4cf219e9eb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-d57e854a-e85a-4e6c-9afb-f71862ec0376,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-dc658ddb-339c-4501-8f2e-25740ae7f884,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-e6c5d445-1967-426d-bdda-1d372ae70919,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-2773eafd-8e2b-4154-b461-0928f470fe21,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-810c5f2a-6ce9-4c3a-92e4-89d785aa8d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-49231a07-9bfb-4c22-b629-5342824cdbb7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945927556-172.17.0.6-1598162724234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46499,DS-a7937eb8-461a-41c5-84fd-5b99d0717fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-89acd31d-233f-408d-baed-a9c5ce3ff9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-cafd562c-330b-4628-93a6-ba3bd87f753c,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-5edc40ff-b891-4ad8-a178-630742bda1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-5bc3cec7-98c8-4af4-8f6a-6385c5d319bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-67d3d92c-f154-4bd5-85e1-b07c48bb3299,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-68c0975b-7814-4ae4-91bd-4be890ac3f09,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-929cc448-aa88-41d4-900b-5eb81a648baa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945927556-172.17.0.6-1598162724234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46499,DS-a7937eb8-461a-41c5-84fd-5b99d0717fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-89acd31d-233f-408d-baed-a9c5ce3ff9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-cafd562c-330b-4628-93a6-ba3bd87f753c,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-5edc40ff-b891-4ad8-a178-630742bda1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-5bc3cec7-98c8-4af4-8f6a-6385c5d319bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-67d3d92c-f154-4bd5-85e1-b07c48bb3299,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-68c0975b-7814-4ae4-91bd-4be890ac3f09,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-929cc448-aa88-41d4-900b-5eb81a648baa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475686404-172.17.0.6-1598162907208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34914,DS-e84ff22d-44a9-412b-9bba-4506d82d798f,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-aebd77a6-9416-4ad2-832a-bb7dad691767,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-d0755616-644d-4d7c-bf0a-a7840101e687,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-0c4dee39-bd08-4f80-92c8-1fd346c638ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-b0260049-70b4-43db-81bd-a28b5947cfff,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-5135ff69-7ff2-4356-a1de-7c61261e2ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-90f67980-d4fc-41aa-95c9-beb958b5ef76,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-e9287374-c14e-4825-b9b4-990c081bbb49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475686404-172.17.0.6-1598162907208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34914,DS-e84ff22d-44a9-412b-9bba-4506d82d798f,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-aebd77a6-9416-4ad2-832a-bb7dad691767,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-d0755616-644d-4d7c-bf0a-a7840101e687,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-0c4dee39-bd08-4f80-92c8-1fd346c638ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-b0260049-70b4-43db-81bd-a28b5947cfff,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-5135ff69-7ff2-4356-a1de-7c61261e2ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-90f67980-d4fc-41aa-95c9-beb958b5ef76,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-e9287374-c14e-4825-b9b4-990c081bbb49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802575906-172.17.0.6-1598163101193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45837,DS-648db503-9432-4538-871a-662b7fc5e20a,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-66b4a55d-1452-48f6-8790-d01925335264,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-770005be-e275-41d0-b2c3-bcea947d5e18,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-c08ea24e-7977-4b17-bab6-39bacfd2c95b,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-37f6669d-5615-48b7-ac06-6e3a6a19c8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-38e66168-7c6a-4696-acad-412aa4fe2aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-003d62a2-f23d-4411-8591-c1cea3e7214c,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-dce32e9b-d782-41a5-bc6d-bce9926a7941,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802575906-172.17.0.6-1598163101193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45837,DS-648db503-9432-4538-871a-662b7fc5e20a,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-66b4a55d-1452-48f6-8790-d01925335264,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-770005be-e275-41d0-b2c3-bcea947d5e18,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-c08ea24e-7977-4b17-bab6-39bacfd2c95b,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-37f6669d-5615-48b7-ac06-6e3a6a19c8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-38e66168-7c6a-4696-acad-412aa4fe2aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-003d62a2-f23d-4411-8591-c1cea3e7214c,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-dce32e9b-d782-41a5-bc6d-bce9926a7941,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565134512-172.17.0.6-1598163180655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36776,DS-b8a5eee8-e34d-44fc-913f-5f5018b0b36b,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-e551c18d-5baf-45c7-ac4c-506fffe15bff,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-0158371f-7780-46f3-8ba1-95b4d1c2ea33,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-0fd75e70-c182-4495-8fbe-f802717de122,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-643e88bb-4631-4827-a0e2-e101808fd2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-c67a54c9-5551-4b81-aad2-20101a2f5b32,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-2974d38d-7249-458f-83ea-32ec59fdebaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-5ecca450-7f99-48b9-b6a1-1aaab894b623,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565134512-172.17.0.6-1598163180655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36776,DS-b8a5eee8-e34d-44fc-913f-5f5018b0b36b,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-e551c18d-5baf-45c7-ac4c-506fffe15bff,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-0158371f-7780-46f3-8ba1-95b4d1c2ea33,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-0fd75e70-c182-4495-8fbe-f802717de122,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-643e88bb-4631-4827-a0e2-e101808fd2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-c67a54c9-5551-4b81-aad2-20101a2f5b32,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-2974d38d-7249-458f-83ea-32ec59fdebaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-5ecca450-7f99-48b9-b6a1-1aaab894b623,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439415499-172.17.0.6-1598163803309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44324,DS-d95d062e-ab8c-47c8-b4fc-c19d2cc420e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-c5eb0c51-c59e-4106-8c34-04d477c9f237,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-fa042974-e5b2-42ac-8543-e3200de2df32,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-22389694-4e36-4fe6-a13f-a5e5c8752e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-ac83c65d-54d2-4115-a974-56b70c9ac7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-de371b35-8a59-4f51-8d5a-18bfea7fba88,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-719b8e55-e44e-4c08-8e96-463ce3a157c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-6ce633e9-616e-42dc-a735-7de3d767d92a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439415499-172.17.0.6-1598163803309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44324,DS-d95d062e-ab8c-47c8-b4fc-c19d2cc420e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-c5eb0c51-c59e-4106-8c34-04d477c9f237,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-fa042974-e5b2-42ac-8543-e3200de2df32,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-22389694-4e36-4fe6-a13f-a5e5c8752e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-ac83c65d-54d2-4115-a974-56b70c9ac7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-de371b35-8a59-4f51-8d5a-18bfea7fba88,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-719b8e55-e44e-4c08-8e96-463ce3a157c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-6ce633e9-616e-42dc-a735-7de3d767d92a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996733526-172.17.0.6-1598163988535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37857,DS-51b4c194-7977-4165-ab59-2a963f6d15f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-364407bc-b121-45d8-a87d-b68d7a462412,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-e802495b-3255-4d5c-aed1-bc64f2275548,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-45c47a1f-a1b2-46f7-8d6d-d7a68355271a,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-000aeb90-7674-4645-9d11-c610fbd83933,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-b7c2bc3f-c0c6-4dbb-b027-cc0342d628a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-19f1b030-5160-4daa-8c78-ddbb60e2c230,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-92744506-9714-438d-a555-e736da804a53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996733526-172.17.0.6-1598163988535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37857,DS-51b4c194-7977-4165-ab59-2a963f6d15f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-364407bc-b121-45d8-a87d-b68d7a462412,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-e802495b-3255-4d5c-aed1-bc64f2275548,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-45c47a1f-a1b2-46f7-8d6d-d7a68355271a,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-000aeb90-7674-4645-9d11-c610fbd83933,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-b7c2bc3f-c0c6-4dbb-b027-cc0342d628a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-19f1b030-5160-4daa-8c78-ddbb60e2c230,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-92744506-9714-438d-a555-e736da804a53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626322778-172.17.0.6-1598164058004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38012,DS-0ba51572-e05c-4055-bb4f-d76f059eab5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-e104199f-0c3c-456f-9a58-eb3794a781f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-ed8470d8-89f3-4279-99ae-6412e736ee8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-f4180446-0939-47cc-83c0-76e8f62f23d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-c54d39c5-3315-4090-b557-d4c2f7fdfa37,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-124afaf7-4502-4eee-ba14-1f8c90a648cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-36225b7a-0614-43c2-a9c1-61fbbb017b53,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-cc2a6392-7375-4221-a43f-105934acd7ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626322778-172.17.0.6-1598164058004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38012,DS-0ba51572-e05c-4055-bb4f-d76f059eab5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-e104199f-0c3c-456f-9a58-eb3794a781f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-ed8470d8-89f3-4279-99ae-6412e736ee8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-f4180446-0939-47cc-83c0-76e8f62f23d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-c54d39c5-3315-4090-b557-d4c2f7fdfa37,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-124afaf7-4502-4eee-ba14-1f8c90a648cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-36225b7a-0614-43c2-a9c1-61fbbb017b53,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-cc2a6392-7375-4221-a43f-105934acd7ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285212149-172.17.0.6-1598164100196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44233,DS-7d436db6-2a18-4800-94b2-6277a3f65d44,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-ba8f15ea-85c4-4fc4-8c65-404a6330770b,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-021b84b4-b4f2-4476-a1d1-2257bc068698,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-9e2ca927-b083-485a-a578-27364392632b,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-de399330-ece1-4f26-be4f-73a33fb899be,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-c094f884-5565-4157-b7e8-a7eba2ee1521,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-ac5fb628-f173-448c-9b68-cc0e86c1dffe,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-b5af357b-8d1b-4757-be72-8703fda9a7ec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285212149-172.17.0.6-1598164100196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44233,DS-7d436db6-2a18-4800-94b2-6277a3f65d44,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-ba8f15ea-85c4-4fc4-8c65-404a6330770b,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-021b84b4-b4f2-4476-a1d1-2257bc068698,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-9e2ca927-b083-485a-a578-27364392632b,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-de399330-ece1-4f26-be4f-73a33fb899be,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-c094f884-5565-4157-b7e8-a7eba2ee1521,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-ac5fb628-f173-448c-9b68-cc0e86c1dffe,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-b5af357b-8d1b-4757-be72-8703fda9a7ec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1197511710-172.17.0.6-1598164211913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40553,DS-6ef65e4d-0d7c-42b6-881b-809945adf56f,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-e0de23d3-20a6-4e99-bb59-edea3c353fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-436b0d3c-6879-4a1d-b90e-d4f82cdf3114,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-da70a451-f810-4a2c-9ed6-32a3de0491a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-66ca09d5-d35c-4b09-be0e-06bd7954a478,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-5322e04d-75db-4891-98b4-d99fa6330aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-1c37b05a-672d-42f7-82cf-a5234519acf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-bdce79ab-8218-453d-8164-23b3d9b902c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1197511710-172.17.0.6-1598164211913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40553,DS-6ef65e4d-0d7c-42b6-881b-809945adf56f,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-e0de23d3-20a6-4e99-bb59-edea3c353fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-436b0d3c-6879-4a1d-b90e-d4f82cdf3114,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-da70a451-f810-4a2c-9ed6-32a3de0491a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-66ca09d5-d35c-4b09-be0e-06bd7954a478,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-5322e04d-75db-4891-98b4-d99fa6330aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-1c37b05a-672d-42f7-82cf-a5234519acf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-bdce79ab-8218-453d-8164-23b3d9b902c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940272561-172.17.0.6-1598164468941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40429,DS-f7a4260a-f221-4cbc-b938-93b65e48c066,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-871c950b-b82a-4cca-9b09-1a9ccb0e35ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-3f5e2875-f0ab-4c0b-b896-030cc47487f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-a1f08865-6706-4aaa-9e56-6537b42db043,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-d336f32e-44ff-46ec-b53b-e7780ec15d77,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-6a3b0808-357a-4551-83aa-6b4da58219ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-4ebb7709-bf46-4098-958c-99b04108b70e,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-a1329fd4-e66b-4a36-8ca2-3b93395cd4fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940272561-172.17.0.6-1598164468941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40429,DS-f7a4260a-f221-4cbc-b938-93b65e48c066,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-871c950b-b82a-4cca-9b09-1a9ccb0e35ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-3f5e2875-f0ab-4c0b-b896-030cc47487f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-a1f08865-6706-4aaa-9e56-6537b42db043,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-d336f32e-44ff-46ec-b53b-e7780ec15d77,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-6a3b0808-357a-4551-83aa-6b4da58219ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-4ebb7709-bf46-4098-958c-99b04108b70e,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-a1329fd4-e66b-4a36-8ca2-3b93395cd4fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186687549-172.17.0.6-1598164578479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35226,DS-1d25c15c-0956-40fb-8c5a-3aef2bee10ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-3275fcfc-847a-48c0-a6ba-f5a1a60ca46d,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-8e0e951d-c076-45cf-a04a-1be2f200b76c,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-ed626797-e50b-42b8-8ab1-f04abeb70593,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-44bf78da-eadb-4d16-8d3b-8649fee0e274,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-a2c668fc-b43c-4297-af1d-f2307fbf752a,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-570b3ac4-594e-4829-822e-5e51628536e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-44f3649a-e6b7-4dae-aca3-f3521abffd89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186687549-172.17.0.6-1598164578479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35226,DS-1d25c15c-0956-40fb-8c5a-3aef2bee10ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-3275fcfc-847a-48c0-a6ba-f5a1a60ca46d,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-8e0e951d-c076-45cf-a04a-1be2f200b76c,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-ed626797-e50b-42b8-8ab1-f04abeb70593,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-44bf78da-eadb-4d16-8d3b-8649fee0e274,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-a2c668fc-b43c-4297-af1d-f2307fbf752a,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-570b3ac4-594e-4829-822e-5e51628536e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-44f3649a-e6b7-4dae-aca3-f3521abffd89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030484626-172.17.0.6-1598165145315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43972,DS-e126d668-ca82-482f-861e-79efe53f5f42,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-8e077f83-bd4d-4772-9452-ff6a767efdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-450e95e6-87c1-4ea8-9f92-183d5f008820,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-3bc7c46f-621a-4c37-85b2-d692ccb9eee6,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-cb8bc1a9-767b-4a25-9522-b48697224b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-d4cbbdba-cd67-4d18-a028-f4fa1de326e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-7f85de93-3e20-40ff-b2e2-3ba6683b5249,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-4a33b5de-10f1-4424-a828-e5540c07378a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030484626-172.17.0.6-1598165145315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43972,DS-e126d668-ca82-482f-861e-79efe53f5f42,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-8e077f83-bd4d-4772-9452-ff6a767efdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-450e95e6-87c1-4ea8-9f92-183d5f008820,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-3bc7c46f-621a-4c37-85b2-d692ccb9eee6,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-cb8bc1a9-767b-4a25-9522-b48697224b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-d4cbbdba-cd67-4d18-a028-f4fa1de326e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-7f85de93-3e20-40ff-b2e2-3ba6683b5249,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-4a33b5de-10f1-4424-a828-e5540c07378a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232069081-172.17.0.6-1598165365322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43630,DS-cb3f503a-10cc-4760-bb7e-d4fe98d7f284,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-0f0dff2d-b881-440f-b906-d35b88ddb06a,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-440305fb-a997-4dd6-b174-1a8866f45970,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-2c100a61-860d-4f33-88ec-a89974f22316,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-2d2f6453-af7e-4c02-8b8b-38786fd92acb,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-fcfc9e22-1bca-453e-8e0d-d4ff589ec635,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-eabaf5f1-e311-4a35-84f3-af1ee38afb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-67e372d5-4c21-4d8c-bf14-672d9cff3635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232069081-172.17.0.6-1598165365322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43630,DS-cb3f503a-10cc-4760-bb7e-d4fe98d7f284,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-0f0dff2d-b881-440f-b906-d35b88ddb06a,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-440305fb-a997-4dd6-b174-1a8866f45970,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-2c100a61-860d-4f33-88ec-a89974f22316,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-2d2f6453-af7e-4c02-8b8b-38786fd92acb,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-fcfc9e22-1bca-453e-8e0d-d4ff589ec635,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-eabaf5f1-e311-4a35-84f3-af1ee38afb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-67e372d5-4c21-4d8c-bf14-672d9cff3635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844031673-172.17.0.6-1598165433928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-002273d8-7d78-4bc8-9158-0450d31efef5,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-cb3ee62e-25a6-45b1-86ff-5e23956e21cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-8e1e798c-1e5e-44b7-a360-975e90ea0052,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-40125b91-30ea-43fd-8117-676d1786edf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-646ed271-8156-4433-9163-f51f6324e8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-b2904e4b-0156-401d-b54e-91009f85527f,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-f0a56384-245f-435c-ba71-c522aa05e74b,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-d51ce652-a904-4c1e-94d0-c0e76449496a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844031673-172.17.0.6-1598165433928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-002273d8-7d78-4bc8-9158-0450d31efef5,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-cb3ee62e-25a6-45b1-86ff-5e23956e21cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-8e1e798c-1e5e-44b7-a360-975e90ea0052,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-40125b91-30ea-43fd-8117-676d1786edf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-646ed271-8156-4433-9163-f51f6324e8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-b2904e4b-0156-401d-b54e-91009f85527f,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-f0a56384-245f-435c-ba71-c522aa05e74b,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-d51ce652-a904-4c1e-94d0-c0e76449496a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-820446595-172.17.0.6-1598165477670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-c94576ed-e09a-4279-9fde-dc4cc86d2b58,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-88fe0b94-33ce-4d07-8d98-b2beb6d8f0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-bde9b173-3765-4d79-9f75-0a72168b13ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-7195bd86-da57-4bb0-ae7f-d32bfb2bc633,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-592f0f0f-8f83-4afd-9a6e-6009f2e10a61,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-95ccfd15-e778-4c24-a466-02d73d7cf0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-ce3b7052-8af2-4ec9-ba50-5543b6e05593,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-3952212a-cb33-4bba-af3c-e66832dda182,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-820446595-172.17.0.6-1598165477670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-c94576ed-e09a-4279-9fde-dc4cc86d2b58,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-88fe0b94-33ce-4d07-8d98-b2beb6d8f0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-bde9b173-3765-4d79-9f75-0a72168b13ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-7195bd86-da57-4bb0-ae7f-d32bfb2bc633,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-592f0f0f-8f83-4afd-9a6e-6009f2e10a61,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-95ccfd15-e778-4c24-a466-02d73d7cf0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-ce3b7052-8af2-4ec9-ba50-5543b6e05593,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-3952212a-cb33-4bba-af3c-e66832dda182,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: false positive !!!
Total execution time in seconds : 5582
