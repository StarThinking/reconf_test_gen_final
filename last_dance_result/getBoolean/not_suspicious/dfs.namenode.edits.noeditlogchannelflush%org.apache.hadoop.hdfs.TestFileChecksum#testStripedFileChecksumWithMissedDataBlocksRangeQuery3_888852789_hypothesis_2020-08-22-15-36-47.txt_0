reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492372938-172.17.0.17-1598111184652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43503,DS-1e525e5b-c5b6-4ba5-b3e5-2289690b68be,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-f90cadc9-87f6-4400-8e92-675d9f5fe77c,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-a60ab66a-2fb4-4b44-8fd5-6115ad2abd82,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-a35531ae-d257-4a83-96ec-d30bcae57e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-9cd0bb39-7f6e-4e69-b349-24c75ca0120a,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-02ff435c-1389-4676-ab95-8613880c87d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-dde81002-cf52-4b55-8d9b-af700f06fdde,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-86d37e0a-ef78-4e56-a0b4-0bb69bfa16f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492372938-172.17.0.17-1598111184652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43503,DS-1e525e5b-c5b6-4ba5-b3e5-2289690b68be,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-f90cadc9-87f6-4400-8e92-675d9f5fe77c,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-a60ab66a-2fb4-4b44-8fd5-6115ad2abd82,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-a35531ae-d257-4a83-96ec-d30bcae57e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-9cd0bb39-7f6e-4e69-b349-24c75ca0120a,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-02ff435c-1389-4676-ab95-8613880c87d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-dde81002-cf52-4b55-8d9b-af700f06fdde,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-86d37e0a-ef78-4e56-a0b4-0bb69bfa16f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894876688-172.17.0.17-1598111283673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34949,DS-284d5209-8c73-4d49-9ef4-ac08722ad6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-ac2e34de-49d7-4b82-938b-b93a61f6c7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-73de8ca0-ad6b-497a-89e5-4f20324129f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-7b3ab91a-dd1d-47ff-9ce5-79c20062b1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-e4524884-6268-4353-a121-f4ef7e7b4986,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-e45a739d-bd66-4cc6-a1f4-4c056e29bab8,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-33aba128-59f1-4414-a13b-54bdab7211a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-a9baf1c4-5fd6-4b59-81fc-4a668e59f35e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894876688-172.17.0.17-1598111283673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34949,DS-284d5209-8c73-4d49-9ef4-ac08722ad6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-ac2e34de-49d7-4b82-938b-b93a61f6c7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-73de8ca0-ad6b-497a-89e5-4f20324129f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-7b3ab91a-dd1d-47ff-9ce5-79c20062b1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-e4524884-6268-4353-a121-f4ef7e7b4986,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-e45a739d-bd66-4cc6-a1f4-4c056e29bab8,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-33aba128-59f1-4414-a13b-54bdab7211a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-a9baf1c4-5fd6-4b59-81fc-4a668e59f35e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154842394-172.17.0.17-1598111318334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45778,DS-6c2d3f56-5450-442b-93e9-38a0a677a21e,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-848b0802-1624-444e-b8fc-f6e463ee6f31,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-e4b5204e-1967-40e2-829e-954699ec047e,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-f8eed560-fa1b-4b8b-913a-0c0237aa708c,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-1b14fe18-34cc-4e66-8574-55bc35fd78f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-c503dfd7-4945-4cd5-992c-f2f8d6238aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-698d545c-5590-4ae6-97eb-e46a89c62ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-c81952e8-5bca-41df-bd90-ace2fb0ae388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154842394-172.17.0.17-1598111318334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45778,DS-6c2d3f56-5450-442b-93e9-38a0a677a21e,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-848b0802-1624-444e-b8fc-f6e463ee6f31,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-e4b5204e-1967-40e2-829e-954699ec047e,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-f8eed560-fa1b-4b8b-913a-0c0237aa708c,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-1b14fe18-34cc-4e66-8574-55bc35fd78f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-c503dfd7-4945-4cd5-992c-f2f8d6238aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-698d545c-5590-4ae6-97eb-e46a89c62ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-c81952e8-5bca-41df-bd90-ace2fb0ae388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831931299-172.17.0.17-1598111355717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40680,DS-d535b9c2-a365-45b0-8921-17626c904e59,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-384d0e2b-9351-4d2c-9b7f-f804c107e512,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-4c29f279-c8ad-435c-8d63-cbbca7465bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-aa4d561d-bdae-47c6-940f-4443d46fc7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-94cdc8d1-5842-4941-a72c-8fa5bc1cd223,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-d801f322-5ee8-43d7-b182-a06e2a920957,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-5bcf50cc-4013-4092-bcec-c85a1ba60586,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-aef0d8e2-d373-454d-aeb5-4040a4232be3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831931299-172.17.0.17-1598111355717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40680,DS-d535b9c2-a365-45b0-8921-17626c904e59,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-384d0e2b-9351-4d2c-9b7f-f804c107e512,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-4c29f279-c8ad-435c-8d63-cbbca7465bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-aa4d561d-bdae-47c6-940f-4443d46fc7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-94cdc8d1-5842-4941-a72c-8fa5bc1cd223,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-d801f322-5ee8-43d7-b182-a06e2a920957,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-5bcf50cc-4013-4092-bcec-c85a1ba60586,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-aef0d8e2-d373-454d-aeb5-4040a4232be3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828965658-172.17.0.17-1598111393989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43700,DS-c28d3e37-9f24-46a9-83b3-a77a059efbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-7f395b5d-fb7c-44a0-96fd-207d202f2069,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-4dcfccb9-2369-4ffa-8022-dc66097e4a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-3c208860-9457-40c1-a57d-058784c86e71,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-79b13bd4-626a-4080-afe0-3a8fa6015721,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-cf335ae4-e65e-4d2f-9795-cf47751420b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-adc6378e-7b9d-43e7-8832-d376813fd5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-8472caa1-cdd1-4199-9de7-72515f33401a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828965658-172.17.0.17-1598111393989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43700,DS-c28d3e37-9f24-46a9-83b3-a77a059efbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-7f395b5d-fb7c-44a0-96fd-207d202f2069,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-4dcfccb9-2369-4ffa-8022-dc66097e4a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-3c208860-9457-40c1-a57d-058784c86e71,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-79b13bd4-626a-4080-afe0-3a8fa6015721,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-cf335ae4-e65e-4d2f-9795-cf47751420b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-adc6378e-7b9d-43e7-8832-d376813fd5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-8472caa1-cdd1-4199-9de7-72515f33401a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931899527-172.17.0.17-1598112837309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37324,DS-135ce2de-6491-43db-9282-08a92c6af7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-ea88c52a-b326-4a96-8b62-039ebf8551a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-7c71172c-d562-4b27-a7c2-c68d249a7b54,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-3c4f142c-d776-45dd-980e-be32de79e64e,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-a38186bc-60e4-4411-9dd4-4958e45016f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-4432fe5e-a835-44d9-8b94-79b6ad95b43b,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-e237d073-de18-4d72-bde1-393fa95ffb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-a3636baf-b2f7-473c-9056-3a79439d7882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931899527-172.17.0.17-1598112837309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37324,DS-135ce2de-6491-43db-9282-08a92c6af7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-ea88c52a-b326-4a96-8b62-039ebf8551a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-7c71172c-d562-4b27-a7c2-c68d249a7b54,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-3c4f142c-d776-45dd-980e-be32de79e64e,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-a38186bc-60e4-4411-9dd4-4958e45016f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-4432fe5e-a835-44d9-8b94-79b6ad95b43b,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-e237d073-de18-4d72-bde1-393fa95ffb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-a3636baf-b2f7-473c-9056-3a79439d7882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241390402-172.17.0.17-1598113287306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35368,DS-06bb6b9f-191d-44a4-bcb2-4c37fd849cff,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-b3d9b65d-3939-4058-8943-796d2c28e4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-d35ca10c-6d4b-4b5f-a186-97e453689333,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-1a306643-53da-4d48-b391-d9142e55413a,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-7c3ac137-59ed-4b1d-a9de-89caf5da3fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-b599ecc3-6d55-4308-a63e-30f176bf4b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-a9929932-7eee-43ad-8d5b-5998cc519144,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-6f8f561d-d773-4bb9-8523-e1c1aa352a5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241390402-172.17.0.17-1598113287306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35368,DS-06bb6b9f-191d-44a4-bcb2-4c37fd849cff,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-b3d9b65d-3939-4058-8943-796d2c28e4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-d35ca10c-6d4b-4b5f-a186-97e453689333,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-1a306643-53da-4d48-b391-d9142e55413a,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-7c3ac137-59ed-4b1d-a9de-89caf5da3fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-b599ecc3-6d55-4308-a63e-30f176bf4b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-a9929932-7eee-43ad-8d5b-5998cc519144,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-6f8f561d-d773-4bb9-8523-e1c1aa352a5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904894196-172.17.0.17-1598113716566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38836,DS-940c97da-b927-4e80-baa4-d81a5ebf45a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-aec8f2be-58ea-4754-bda9-7c4dcf068718,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-f2dc4fbc-8886-445f-bc99-80ea26b7f6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-dbc95505-8634-49db-857e-9653f7127cde,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-d9c66996-fd3e-4f69-b362-c03d32cbbe01,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-4c48da4b-e374-4488-86ee-70e9a2c9fe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-5838f74c-8bfe-447c-990a-fc6c9e9604fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-0bb7332b-156d-4637-9fc6-4db61eab01a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904894196-172.17.0.17-1598113716566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38836,DS-940c97da-b927-4e80-baa4-d81a5ebf45a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-aec8f2be-58ea-4754-bda9-7c4dcf068718,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-f2dc4fbc-8886-445f-bc99-80ea26b7f6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-dbc95505-8634-49db-857e-9653f7127cde,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-d9c66996-fd3e-4f69-b362-c03d32cbbe01,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-4c48da4b-e374-4488-86ee-70e9a2c9fe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-5838f74c-8bfe-447c-990a-fc6c9e9604fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-0bb7332b-156d-4637-9fc6-4db61eab01a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790436384-172.17.0.17-1598113759243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39980,DS-ed742254-1a22-4137-a71d-0011b90bfec2,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-1f04edf5-a969-4349-8a6f-cc5652f31d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-a1450e5e-0d3c-44ea-bc05-eb160167c7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-510553e0-6b73-4ed4-824f-12b404259e36,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-766f2a03-61fb-467f-8649-32fe243a88ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-a73e7880-f87d-401c-a245-14a126974096,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-930f4b59-3134-4dba-83bf-d04a04db77e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-ad763731-2b2e-4983-8407-9948371e972b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790436384-172.17.0.17-1598113759243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39980,DS-ed742254-1a22-4137-a71d-0011b90bfec2,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-1f04edf5-a969-4349-8a6f-cc5652f31d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-a1450e5e-0d3c-44ea-bc05-eb160167c7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-510553e0-6b73-4ed4-824f-12b404259e36,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-766f2a03-61fb-467f-8649-32fe243a88ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-a73e7880-f87d-401c-a245-14a126974096,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-930f4b59-3134-4dba-83bf-d04a04db77e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-ad763731-2b2e-4983-8407-9948371e972b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147828558-172.17.0.17-1598114081803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33408,DS-0f91fe61-9310-4717-89e6-aa3f882e1c85,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-6d791b8e-6042-4d29-a952-a26956f0cc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-27c4e8d3-e8b6-41e5-8365-83633cdd23aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-a942c017-b2cd-453a-b7b9-22e8d92c96df,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-61edddb2-d5e5-49d6-82b8-e363d139dac9,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-2cf3636d-c014-47a6-ab4d-e021bd01279e,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-b446faf5-8852-4d90-8429-400703235609,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-00d0a2a8-2c73-486e-b37f-02b1e909b579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147828558-172.17.0.17-1598114081803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33408,DS-0f91fe61-9310-4717-89e6-aa3f882e1c85,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-6d791b8e-6042-4d29-a952-a26956f0cc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-27c4e8d3-e8b6-41e5-8365-83633cdd23aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-a942c017-b2cd-453a-b7b9-22e8d92c96df,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-61edddb2-d5e5-49d6-82b8-e363d139dac9,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-2cf3636d-c014-47a6-ab4d-e021bd01279e,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-b446faf5-8852-4d90-8429-400703235609,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-00d0a2a8-2c73-486e-b37f-02b1e909b579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760636163-172.17.0.17-1598114193607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35591,DS-95a1a18a-886b-4792-b824-931d9955836b,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-e40b24f5-cc71-4fcb-99ad-22194c56fcb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-f45efa92-5c3e-4c96-8adb-97ff33819916,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-c28a66d4-d625-4683-a2b9-1d0330a5c56c,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-f5bbb7b9-3623-46b8-9a94-e2abac216171,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-f2d4ad6d-2d35-43cd-9aff-1e8106c0a20b,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-de1b0b3a-dcd5-419f-ac46-2b84e4a285ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-cbdfb7d6-4d65-470f-b853-05954c92690e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760636163-172.17.0.17-1598114193607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35591,DS-95a1a18a-886b-4792-b824-931d9955836b,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-e40b24f5-cc71-4fcb-99ad-22194c56fcb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-f45efa92-5c3e-4c96-8adb-97ff33819916,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-c28a66d4-d625-4683-a2b9-1d0330a5c56c,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-f5bbb7b9-3623-46b8-9a94-e2abac216171,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-f2d4ad6d-2d35-43cd-9aff-1e8106c0a20b,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-de1b0b3a-dcd5-419f-ac46-2b84e4a285ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-cbdfb7d6-4d65-470f-b853-05954c92690e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455689600-172.17.0.17-1598114295135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34915,DS-52ab5cdf-44fc-453e-ba73-92b55cd3e87f,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-a2c264e4-6438-433d-96aa-0c335f30cb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-0bf0aa8f-415d-4ff8-886c-1e8bd17094ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-de581b42-6bfe-47c9-bb0c-f10e5ba12863,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-434a16f7-fbb0-4d13-bbf8-d68ac400ae21,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-197a4103-c612-4efc-800b-30ac3a38d33f,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-c7291d3d-12e7-4b01-9b79-40b7dbe6bbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-ac0e6f1a-b429-4b80-bd8f-7bb2d0c6923a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455689600-172.17.0.17-1598114295135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34915,DS-52ab5cdf-44fc-453e-ba73-92b55cd3e87f,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-a2c264e4-6438-433d-96aa-0c335f30cb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-0bf0aa8f-415d-4ff8-886c-1e8bd17094ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-de581b42-6bfe-47c9-bb0c-f10e5ba12863,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-434a16f7-fbb0-4d13-bbf8-d68ac400ae21,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-197a4103-c612-4efc-800b-30ac3a38d33f,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-c7291d3d-12e7-4b01-9b79-40b7dbe6bbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-ac0e6f1a-b429-4b80-bd8f-7bb2d0c6923a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712947666-172.17.0.17-1598114335581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37187,DS-3a6e3e4c-d321-4fd8-8035-922e190b7c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-3b553922-9cf6-4a84-b95a-cd6e98fee3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-2cd38c5f-dec4-4485-9e88-2e0f2b0fd3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-b386a640-e84d-4503-8adf-f9f07c38228e,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-c350b61a-bd56-4677-889b-7482f4fcee20,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-e1d2d8fa-44c9-403a-acfb-f210ed5b5cee,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-d2a9edcb-fa4f-4725-ad72-4062a1cb18e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-bb701e02-9c02-4a4a-8bc5-c8dc740022ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712947666-172.17.0.17-1598114335581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37187,DS-3a6e3e4c-d321-4fd8-8035-922e190b7c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-3b553922-9cf6-4a84-b95a-cd6e98fee3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-2cd38c5f-dec4-4485-9e88-2e0f2b0fd3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-b386a640-e84d-4503-8adf-f9f07c38228e,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-c350b61a-bd56-4677-889b-7482f4fcee20,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-e1d2d8fa-44c9-403a-acfb-f210ed5b5cee,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-d2a9edcb-fa4f-4725-ad72-4062a1cb18e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-bb701e02-9c02-4a4a-8bc5-c8dc740022ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906820026-172.17.0.17-1598114550173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40610,DS-3ff0cdf5-f545-47a8-a90d-e0cc5d03d860,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-a1a53e5d-e39f-44b5-b042-722aaba7d7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-bd987422-02dd-4e13-ac76-a9c6aed3a048,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-75116b1d-5ef9-41bb-aa99-4d6b5db2e024,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-8a64d0da-c093-4b8c-8b88-55c99cce58c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-76dbe5e4-9644-4981-8831-2a1d0104e55b,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-4508fa8d-195c-4e43-877a-a67da7d83f18,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-43e1c912-4d73-4fd3-b3f1-155346dae0b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906820026-172.17.0.17-1598114550173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40610,DS-3ff0cdf5-f545-47a8-a90d-e0cc5d03d860,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-a1a53e5d-e39f-44b5-b042-722aaba7d7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-bd987422-02dd-4e13-ac76-a9c6aed3a048,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-75116b1d-5ef9-41bb-aa99-4d6b5db2e024,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-8a64d0da-c093-4b8c-8b88-55c99cce58c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-76dbe5e4-9644-4981-8831-2a1d0104e55b,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-4508fa8d-195c-4e43-877a-a67da7d83f18,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-43e1c912-4d73-4fd3-b3f1-155346dae0b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838454925-172.17.0.17-1598114582099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37910,DS-56c14de6-4c8a-470f-ab64-112e25a87bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-89a8afa5-37e6-43fd-a8b9-118168f7c08a,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-ea56ce8b-d300-486e-b0ef-2c0ab2067a57,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-917b25ea-acb5-4637-9eca-f158971f80f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-2286fcc2-1f90-4336-a692-70fc8ae72a31,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-2a6f7216-6b9b-4d68-aeca-079235101bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-9412ce99-0eb5-45fd-811e-aad848223072,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-af3131b6-8001-4797-818e-9242177dec2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838454925-172.17.0.17-1598114582099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37910,DS-56c14de6-4c8a-470f-ab64-112e25a87bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-89a8afa5-37e6-43fd-a8b9-118168f7c08a,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-ea56ce8b-d300-486e-b0ef-2c0ab2067a57,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-917b25ea-acb5-4637-9eca-f158971f80f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-2286fcc2-1f90-4336-a692-70fc8ae72a31,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-2a6f7216-6b9b-4d68-aeca-079235101bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-9412ce99-0eb5-45fd-811e-aad848223072,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-af3131b6-8001-4797-818e-9242177dec2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072333553-172.17.0.17-1598114678609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33717,DS-8ea8cdaa-3476-4169-95df-84c6b43bc28a,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-fbe3d91b-7f46-4f21-b85e-d6ace54d855e,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-9ab318c7-15ba-447b-b0a5-9b29e50116ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-3aa2db22-1d1e-48f3-b931-318ab76d88be,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-6e6e8b21-7fe5-4e2e-aeac-10db1fd25ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-d614bddf-7c59-4e88-8ac7-86f27e9391f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-50def7c3-23a4-4964-8846-4e3566226407,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-be09d1de-b119-4458-bbf7-a02af4adce7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072333553-172.17.0.17-1598114678609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33717,DS-8ea8cdaa-3476-4169-95df-84c6b43bc28a,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-fbe3d91b-7f46-4f21-b85e-d6ace54d855e,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-9ab318c7-15ba-447b-b0a5-9b29e50116ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-3aa2db22-1d1e-48f3-b931-318ab76d88be,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-6e6e8b21-7fe5-4e2e-aeac-10db1fd25ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-d614bddf-7c59-4e88-8ac7-86f27e9391f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-50def7c3-23a4-4964-8846-4e3566226407,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-be09d1de-b119-4458-bbf7-a02af4adce7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750485434-172.17.0.17-1598114712756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37234,DS-ab2c0d67-052e-4ec9-98e3-5393696d07f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-4b314fd2-eb8c-4d03-bd8f-bbd0d8bdaaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-f5e9dfd8-4924-4ef3-be6b-1e8af2577e89,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-98078061-7c21-4476-b72c-ddbe788c2137,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-ecb12a98-0d1a-4449-8627-bb645fe50701,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-c9f02495-a5ae-4a64-8c77-f43df026cff2,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-2047f5b2-9a46-44bf-b95e-d7288d286a42,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-2da5b970-5d57-4eb1-9022-65e6a7274762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750485434-172.17.0.17-1598114712756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37234,DS-ab2c0d67-052e-4ec9-98e3-5393696d07f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-4b314fd2-eb8c-4d03-bd8f-bbd0d8bdaaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-f5e9dfd8-4924-4ef3-be6b-1e8af2577e89,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-98078061-7c21-4476-b72c-ddbe788c2137,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-ecb12a98-0d1a-4449-8627-bb645fe50701,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-c9f02495-a5ae-4a64-8c77-f43df026cff2,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-2047f5b2-9a46-44bf-b95e-d7288d286a42,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-2da5b970-5d57-4eb1-9022-65e6a7274762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475229722-172.17.0.17-1598115312480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43167,DS-5b7b2ae5-59bf-4513-9ef3-474d51e1143d,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-5115b13b-ff3b-4f9b-813a-11f204924ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-db40835a-32c4-46a6-81c2-186f6c8ba823,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-27a0dfcf-6edc-421f-9197-3a1599f0e968,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-3e809921-4a47-48ed-a76a-9c1f79100371,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-c6f494d3-c291-46ff-854e-9eb7e304af5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-7a2b4492-a2f3-4007-b474-ccbc043672c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-199a8201-3346-41de-9775-3d6138744637,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475229722-172.17.0.17-1598115312480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43167,DS-5b7b2ae5-59bf-4513-9ef3-474d51e1143d,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-5115b13b-ff3b-4f9b-813a-11f204924ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-db40835a-32c4-46a6-81c2-186f6c8ba823,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-27a0dfcf-6edc-421f-9197-3a1599f0e968,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-3e809921-4a47-48ed-a76a-9c1f79100371,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-c6f494d3-c291-46ff-854e-9eb7e304af5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-7a2b4492-a2f3-4007-b474-ccbc043672c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-199a8201-3346-41de-9775-3d6138744637,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585434133-172.17.0.17-1598115567034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36085,DS-4ad289ac-c1f3-4e12-a2b6-84a312ea1687,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-2966efd2-35a8-45c6-b206-d1f03d8e5498,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-63eac3d2-1bad-4516-97eb-311cdc07c61f,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-420d0e8a-67c4-4490-9dd2-3f3ba87b5fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-8aa5efda-bc08-466f-b321-b34a1869dbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-17d46373-7cf9-430d-9684-b3bc0f959574,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-7144c9a2-fe29-478e-852c-8efc00d20431,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-113f686b-4c23-412e-916a-9e51dc02942d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585434133-172.17.0.17-1598115567034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36085,DS-4ad289ac-c1f3-4e12-a2b6-84a312ea1687,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-2966efd2-35a8-45c6-b206-d1f03d8e5498,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-63eac3d2-1bad-4516-97eb-311cdc07c61f,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-420d0e8a-67c4-4490-9dd2-3f3ba87b5fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-8aa5efda-bc08-466f-b321-b34a1869dbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-17d46373-7cf9-430d-9684-b3bc0f959574,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-7144c9a2-fe29-478e-852c-8efc00d20431,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-113f686b-4c23-412e-916a-9e51dc02942d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911361442-172.17.0.17-1598115732855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42514,DS-d2c71c7d-c6c8-4fbd-9bfa-5186f1b2e97d,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-99ffebdd-85f1-4b8c-bcdb-e521fcb22973,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-d160901d-f68a-4dd4-9346-79d4c0d9b349,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-612dd10e-2d0a-40ad-9e1e-cbe2b56067ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-b6d5c9fd-3e4f-4abd-94d9-198684b13557,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-5e9edf47-5e16-4460-bc54-4e68683685f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-2a9ad155-4fbb-4492-96a8-a8d2b7e92224,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-7b7bd0ab-c98d-4fda-b39f-b28bb0f8c80c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911361442-172.17.0.17-1598115732855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42514,DS-d2c71c7d-c6c8-4fbd-9bfa-5186f1b2e97d,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-99ffebdd-85f1-4b8c-bcdb-e521fcb22973,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-d160901d-f68a-4dd4-9346-79d4c0d9b349,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-612dd10e-2d0a-40ad-9e1e-cbe2b56067ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-b6d5c9fd-3e4f-4abd-94d9-198684b13557,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-5e9edf47-5e16-4460-bc54-4e68683685f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-2a9ad155-4fbb-4492-96a8-a8d2b7e92224,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-7b7bd0ab-c98d-4fda-b39f-b28bb0f8c80c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536183594-172.17.0.17-1598115879984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34341,DS-babaed3b-683c-4d72-bc87-70d7524c0c32,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-ab3fd625-af65-48ae-b983-b0a85b0b33c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-edcc701d-5fa0-4ffb-9923-0383a790a969,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-70fc625c-5765-41fc-b324-5a1359154df9,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-9c88b41a-bc9e-4a9d-9c34-a9b2ddf53a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-ce193302-f9f9-4ac1-a037-170383960d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-0befea0a-b9e0-4cdb-bda7-626d615b7fac,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-04e28692-d928-488e-afc8-7c2e6dfbdd71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536183594-172.17.0.17-1598115879984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34341,DS-babaed3b-683c-4d72-bc87-70d7524c0c32,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-ab3fd625-af65-48ae-b983-b0a85b0b33c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-edcc701d-5fa0-4ffb-9923-0383a790a969,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-70fc625c-5765-41fc-b324-5a1359154df9,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-9c88b41a-bc9e-4a9d-9c34-a9b2ddf53a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-ce193302-f9f9-4ac1-a037-170383960d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-0befea0a-b9e0-4cdb-bda7-626d615b7fac,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-04e28692-d928-488e-afc8-7c2e6dfbdd71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5403
