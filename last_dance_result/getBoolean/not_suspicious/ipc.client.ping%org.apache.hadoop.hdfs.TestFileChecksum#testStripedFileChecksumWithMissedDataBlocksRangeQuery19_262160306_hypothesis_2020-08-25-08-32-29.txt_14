reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-892886765-172.17.0.11-1598344478985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36277,DS-4ea34d65-5f06-44ab-a827-7403b2257983,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-56830941-1072-4336-83fe-4d77bb613fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-0d4b2cd6-5901-43c0-8073-e71f562642bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-42f5ada9-b4d5-481d-b5d2-ed944ded5052,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-41f3b840-d0c2-4e4c-a523-a0c29a9463cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-52b5cf59-268a-4a4d-b34d-e5e6d4a838d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-6bf464fa-c4ee-42b2-8b85-0a4f16174286,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-e262cd5d-86b5-4f99-a56c-bd880dc7b97d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-892886765-172.17.0.11-1598344478985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36277,DS-4ea34d65-5f06-44ab-a827-7403b2257983,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-56830941-1072-4336-83fe-4d77bb613fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-0d4b2cd6-5901-43c0-8073-e71f562642bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-42f5ada9-b4d5-481d-b5d2-ed944ded5052,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-41f3b840-d0c2-4e4c-a523-a0c29a9463cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-52b5cf59-268a-4a4d-b34d-e5e6d4a838d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-6bf464fa-c4ee-42b2-8b85-0a4f16174286,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-e262cd5d-86b5-4f99-a56c-bd880dc7b97d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246787193-172.17.0.11-1598344581775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38014,DS-14caf0d1-8c5f-4fa6-8bdf-0894af42f8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-f323ab60-7912-4761-8677-f3080c88108d,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-8a2b36e9-6849-4d6f-9a47-1818683530f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-82234fda-fec9-4ee1-863c-34f012870e18,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-24405422-edde-4838-9575-49f9719ae547,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-d0043d41-c686-4538-86dd-9f77a823f6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-5e37b126-5433-4dd4-bcb4-b93df9c945eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-5d09fae2-eb29-427a-a355-3db957115d7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246787193-172.17.0.11-1598344581775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38014,DS-14caf0d1-8c5f-4fa6-8bdf-0894af42f8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-f323ab60-7912-4761-8677-f3080c88108d,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-8a2b36e9-6849-4d6f-9a47-1818683530f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-82234fda-fec9-4ee1-863c-34f012870e18,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-24405422-edde-4838-9575-49f9719ae547,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-d0043d41-c686-4538-86dd-9f77a823f6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-5e37b126-5433-4dd4-bcb4-b93df9c945eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-5d09fae2-eb29-427a-a355-3db957115d7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-230165596-172.17.0.11-1598344845838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39393,DS-0fee41ca-1b9c-418c-93a1-be351040647e,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-9278b16c-3d0c-4190-9533-2a0e1d1e59c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-7f6ebddb-f971-44d4-b1b6-ceb096b8a106,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-2d11bd64-232c-4bfe-9c33-255bb9095ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-f8010814-f0d5-4b38-9905-31d37eb70a40,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-7a6d3180-26a1-449a-b24c-026bbd7cf6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-9203c25e-0d98-44ee-a0cd-3d68af385376,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-f9a22ad6-1500-434b-8743-30c6f37d055b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-230165596-172.17.0.11-1598344845838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39393,DS-0fee41ca-1b9c-418c-93a1-be351040647e,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-9278b16c-3d0c-4190-9533-2a0e1d1e59c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-7f6ebddb-f971-44d4-b1b6-ceb096b8a106,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-2d11bd64-232c-4bfe-9c33-255bb9095ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-f8010814-f0d5-4b38-9905-31d37eb70a40,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-7a6d3180-26a1-449a-b24c-026bbd7cf6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-9203c25e-0d98-44ee-a0cd-3d68af385376,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-f9a22ad6-1500-434b-8743-30c6f37d055b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829993273-172.17.0.11-1598344882078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45859,DS-3ca047ec-b77d-4b42-bef8-788a0cdc819a,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-2bae27e7-8384-48e6-93bc-afe5b381719c,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-730b438f-95f2-439f-946d-1ce83761e77d,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-aa62d3d1-e6a7-4e23-ac24-9a578d981139,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-44f77618-0bee-4e0a-8427-c3c2fadf7b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-d2dd0240-b01f-4564-ba1a-72c4acdabbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-21714f7e-4106-4af3-b1d5-f59cadab145d,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-3e7f1bd1-a5d3-4f6e-849e-587f2800ad80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829993273-172.17.0.11-1598344882078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45859,DS-3ca047ec-b77d-4b42-bef8-788a0cdc819a,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-2bae27e7-8384-48e6-93bc-afe5b381719c,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-730b438f-95f2-439f-946d-1ce83761e77d,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-aa62d3d1-e6a7-4e23-ac24-9a578d981139,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-44f77618-0bee-4e0a-8427-c3c2fadf7b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-d2dd0240-b01f-4564-ba1a-72c4acdabbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-21714f7e-4106-4af3-b1d5-f59cadab145d,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-3e7f1bd1-a5d3-4f6e-849e-587f2800ad80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311373175-172.17.0.11-1598345195150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42167,DS-8107d861-2db6-46bc-8f3b-f02451b7cdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-c6845c5a-0658-4ce3-b09d-fff4d3e71d57,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-098f6e6f-18db-4755-987f-56f00b110846,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-6089a2bc-3d8f-4a13-9a6e-9e72bedb025c,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-3c3fecc7-e4a2-4163-ab35-bbb494a85d11,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-95279cd1-6891-4dd7-a575-3626e876ed95,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-43c3d515-a91e-4b36-8c59-dc99d9777f22,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-d002d4ad-bc62-4382-8df0-1954daa67d3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311373175-172.17.0.11-1598345195150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42167,DS-8107d861-2db6-46bc-8f3b-f02451b7cdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-c6845c5a-0658-4ce3-b09d-fff4d3e71d57,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-098f6e6f-18db-4755-987f-56f00b110846,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-6089a2bc-3d8f-4a13-9a6e-9e72bedb025c,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-3c3fecc7-e4a2-4163-ab35-bbb494a85d11,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-95279cd1-6891-4dd7-a575-3626e876ed95,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-43c3d515-a91e-4b36-8c59-dc99d9777f22,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-d002d4ad-bc62-4382-8df0-1954daa67d3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042366706-172.17.0.11-1598345784112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35914,DS-6d9a4136-702f-43ac-a547-f05b9d2cf9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-73aa7010-7df6-49e0-8f4b-f47d2aa3753c,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-e181164a-0773-4fee-aaab-c06d7d6e693f,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-85bb4863-ee30-410f-8e4d-51372ac798cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-f5531800-72d6-4b47-940e-60ce45a515e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-2cbe5dd1-4a55-4493-8e0e-224bcc397e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-0382398f-6357-42b4-a46a-d0d802435595,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-c61565fb-1d51-4964-87d3-38d4ea3a0e7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042366706-172.17.0.11-1598345784112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35914,DS-6d9a4136-702f-43ac-a547-f05b9d2cf9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-73aa7010-7df6-49e0-8f4b-f47d2aa3753c,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-e181164a-0773-4fee-aaab-c06d7d6e693f,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-85bb4863-ee30-410f-8e4d-51372ac798cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-f5531800-72d6-4b47-940e-60ce45a515e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-2cbe5dd1-4a55-4493-8e0e-224bcc397e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-0382398f-6357-42b4-a46a-d0d802435595,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-c61565fb-1d51-4964-87d3-38d4ea3a0e7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1381818551-172.17.0.11-1598345845820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37003,DS-ed08a185-2a15-410b-9ec0-c312514c3d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-106fbfac-4c8c-4526-8267-09cfcb168f60,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-f08f5573-11c0-4101-9be8-8e6f073725d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-b029315a-52ab-40f3-a05b-a6b4cf32ab4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-501d3d0f-6b89-4886-959e-1acfcf90ba76,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-f75f0b86-43ec-4246-90a5-80d40ab0056e,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-189ba788-2b92-4b8b-a55b-c153d7e940a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-1401ec76-41aa-4a93-ab97-483936700980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1381818551-172.17.0.11-1598345845820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37003,DS-ed08a185-2a15-410b-9ec0-c312514c3d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-106fbfac-4c8c-4526-8267-09cfcb168f60,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-f08f5573-11c0-4101-9be8-8e6f073725d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-b029315a-52ab-40f3-a05b-a6b4cf32ab4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-501d3d0f-6b89-4886-959e-1acfcf90ba76,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-f75f0b86-43ec-4246-90a5-80d40ab0056e,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-189ba788-2b92-4b8b-a55b-c153d7e940a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-1401ec76-41aa-4a93-ab97-483936700980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234549599-172.17.0.11-1598346168158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38909,DS-b35f5a66-61f5-4e2e-a393-50e8ed38989e,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-a327ff92-87d4-4b75-b3a3-32aa44ca2081,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-77011d40-05fe-4148-8d4c-0e1175f95ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-42eaff20-4d58-4364-9f63-95568430ff3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-8a2553bd-cc61-4975-bd08-b87cf61fb488,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-8f75fcc9-465a-4832-832d-0cfd44d7e6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-b6a341fd-82bc-4a93-8e22-12746d880c52,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-9a2dcf4d-98ae-4119-a347-e1ebae588b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234549599-172.17.0.11-1598346168158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38909,DS-b35f5a66-61f5-4e2e-a393-50e8ed38989e,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-a327ff92-87d4-4b75-b3a3-32aa44ca2081,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-77011d40-05fe-4148-8d4c-0e1175f95ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-42eaff20-4d58-4364-9f63-95568430ff3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-8a2553bd-cc61-4975-bd08-b87cf61fb488,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-8f75fcc9-465a-4832-832d-0cfd44d7e6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-b6a341fd-82bc-4a93-8e22-12746d880c52,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-9a2dcf4d-98ae-4119-a347-e1ebae588b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542718353-172.17.0.11-1598346420851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41095,DS-5934b6e5-2017-4feb-914c-efb6f41633ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-de12f1f1-6993-4c45-8fca-e4834e429698,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-978462ca-0b19-44dc-951f-0b1c9c8e3c56,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-032c472d-228b-44b7-817d-2e72f8d0c758,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-06b32a6e-4692-4956-b4d7-320a8dd2ee80,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-3c57d2aa-d957-4a55-bc94-cbdba5a086fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-6aef43c1-df95-4eb7-b56f-18187335a5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-77077c7d-3e38-4dd7-893d-f907a80ef0b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542718353-172.17.0.11-1598346420851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41095,DS-5934b6e5-2017-4feb-914c-efb6f41633ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-de12f1f1-6993-4c45-8fca-e4834e429698,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-978462ca-0b19-44dc-951f-0b1c9c8e3c56,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-032c472d-228b-44b7-817d-2e72f8d0c758,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-06b32a6e-4692-4956-b4d7-320a8dd2ee80,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-3c57d2aa-d957-4a55-bc94-cbdba5a086fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-6aef43c1-df95-4eb7-b56f-18187335a5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-77077c7d-3e38-4dd7-893d-f907a80ef0b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-890265754-172.17.0.11-1598346461630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42304,DS-7af1a7bf-512a-4e60-b11b-0091540fabc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-41183800-ef54-41b4-afa4-5e73bdbc4985,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-ac96d63f-a422-4f12-814b-cfe000e497f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-8480827a-0317-4dad-9ac5-c75a9353222e,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-ed616f4f-b5e0-4db6-8e1e-9bb03c241181,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-450772dd-4007-4872-8d38-9fa987ba3101,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-8225b1f7-b644-42b7-b171-08ce6c00a5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-a01b21ee-0047-4dba-961a-6d58987e232f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-890265754-172.17.0.11-1598346461630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42304,DS-7af1a7bf-512a-4e60-b11b-0091540fabc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-41183800-ef54-41b4-afa4-5e73bdbc4985,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-ac96d63f-a422-4f12-814b-cfe000e497f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-8480827a-0317-4dad-9ac5-c75a9353222e,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-ed616f4f-b5e0-4db6-8e1e-9bb03c241181,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-450772dd-4007-4872-8d38-9fa987ba3101,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-8225b1f7-b644-42b7-b171-08ce6c00a5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-a01b21ee-0047-4dba-961a-6d58987e232f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416982486-172.17.0.11-1598346641978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33706,DS-2fff59c5-ad2c-409e-a066-6af76969ec97,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-bed79834-32bc-40df-82eb-52cfc17270af,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-6cf0e9ac-0e8c-4ad0-9d1b-65992a708ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-002db502-bca9-4ba9-8b23-ed23def8ac3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-bb913daa-5f48-45b6-a08a-e2f04e265650,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-7df84717-96a9-45ff-81ba-373968ace5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-41d37673-81c5-47d7-b2e7-390b37afb634,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-13ec9a76-e2fa-439e-8fc0-3f4613e2e82a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416982486-172.17.0.11-1598346641978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33706,DS-2fff59c5-ad2c-409e-a066-6af76969ec97,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-bed79834-32bc-40df-82eb-52cfc17270af,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-6cf0e9ac-0e8c-4ad0-9d1b-65992a708ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-002db502-bca9-4ba9-8b23-ed23def8ac3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-bb913daa-5f48-45b6-a08a-e2f04e265650,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-7df84717-96a9-45ff-81ba-373968ace5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-41d37673-81c5-47d7-b2e7-390b37afb634,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-13ec9a76-e2fa-439e-8fc0-3f4613e2e82a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285290108-172.17.0.11-1598346682532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-00154b61-1915-4406-b487-f7f05997a929,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-68da06d5-0b37-4479-a8d6-a5bc7c7c297f,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-fcb47a8f-92c4-43b5-bd3c-9e74cf75af70,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-a7e522f9-ba9a-4ea1-9a3a-5d829694ff53,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-9d68cea2-c0b2-4c2e-9897-925958155513,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-2723df0a-9c39-49ac-be3a-eaa622a50dca,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-8c332e21-60ce-43ec-8b59-e6e54be10cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-c7750473-7860-4bc3-b803-dbcac664910c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285290108-172.17.0.11-1598346682532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-00154b61-1915-4406-b487-f7f05997a929,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-68da06d5-0b37-4479-a8d6-a5bc7c7c297f,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-fcb47a8f-92c4-43b5-bd3c-9e74cf75af70,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-a7e522f9-ba9a-4ea1-9a3a-5d829694ff53,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-9d68cea2-c0b2-4c2e-9897-925958155513,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-2723df0a-9c39-49ac-be3a-eaa622a50dca,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-8c332e21-60ce-43ec-8b59-e6e54be10cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-c7750473-7860-4bc3-b803-dbcac664910c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2049475613-172.17.0.11-1598347437238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41152,DS-32f8b82d-d4a8-4bfb-8aac-5bc420681e39,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-d204cf3b-d483-4a9c-a7a9-b223f57b7b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-7ef00047-3f31-42e9-90d7-962cefb4b87e,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-bde3325b-0544-4134-b7f4-2d19ac442cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-0b9288f5-efb0-4da7-8da0-ee37fb89fd27,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-e57f6b06-3614-492d-9cde-c733fdf339c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-7a9b0c5b-af14-4acf-8c89-74b4288c1585,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-19450093-304b-4d01-8eb1-b7ba84b0cbae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2049475613-172.17.0.11-1598347437238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41152,DS-32f8b82d-d4a8-4bfb-8aac-5bc420681e39,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-d204cf3b-d483-4a9c-a7a9-b223f57b7b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-7ef00047-3f31-42e9-90d7-962cefb4b87e,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-bde3325b-0544-4134-b7f4-2d19ac442cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-0b9288f5-efb0-4da7-8da0-ee37fb89fd27,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-e57f6b06-3614-492d-9cde-c733fdf339c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-7a9b0c5b-af14-4acf-8c89-74b4288c1585,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-19450093-304b-4d01-8eb1-b7ba84b0cbae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698532317-172.17.0.11-1598348431521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34644,DS-9ca767db-9a03-436a-92d8-f0839a5b8672,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-809a8946-ca36-433b-a8fc-15f4dc55d8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-0d043568-7616-46d5-a821-8ea137201eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-5e38b9f8-0b2a-488f-9380-c7241abf1866,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-fb2411d6-c2a9-4d5c-b81f-691c4b6fbaff,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-368ab9e2-b912-4220-8bfc-b33816053554,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-d7034abd-9eb2-462b-b133-e9939fcff155,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-dd660422-5788-42b2-960b-1a98c73eff66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698532317-172.17.0.11-1598348431521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34644,DS-9ca767db-9a03-436a-92d8-f0839a5b8672,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-809a8946-ca36-433b-a8fc-15f4dc55d8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-0d043568-7616-46d5-a821-8ea137201eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-5e38b9f8-0b2a-488f-9380-c7241abf1866,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-fb2411d6-c2a9-4d5c-b81f-691c4b6fbaff,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-368ab9e2-b912-4220-8bfc-b33816053554,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-d7034abd-9eb2-462b-b133-e9939fcff155,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-dd660422-5788-42b2-960b-1a98c73eff66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-894148721-172.17.0.11-1598348759514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40622,DS-59e17859-8038-4584-90f7-098c5ce070ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-e09037d2-8f18-41e0-9d26-3c4033acbfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-184f3a6e-dacd-4702-927c-08a5ea29f5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-050d9ee4-05a7-4b9d-a42d-668512879066,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-cd446cde-0b35-461c-8147-f8995ee4cba4,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-d5656336-2ff3-48a6-8987-0d3c46b2de6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-708c421e-eb39-494e-aa80-a7da3f88b20d,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-4fd83188-60a9-468f-a23a-4acb0b95bdd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-894148721-172.17.0.11-1598348759514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40622,DS-59e17859-8038-4584-90f7-098c5ce070ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-e09037d2-8f18-41e0-9d26-3c4033acbfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-184f3a6e-dacd-4702-927c-08a5ea29f5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-050d9ee4-05a7-4b9d-a42d-668512879066,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-cd446cde-0b35-461c-8147-f8995ee4cba4,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-d5656336-2ff3-48a6-8987-0d3c46b2de6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-708c421e-eb39-494e-aa80-a7da3f88b20d,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-4fd83188-60a9-468f-a23a-4acb0b95bdd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977498944-172.17.0.11-1598348905612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35559,DS-11ae8786-9844-48ba-b990-9508d3f35ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-4db01757-f036-4a24-8a3a-7441ef6ec869,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-2acb917c-bdb8-4b34-9cf2-28825e9b745b,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-d19a1e7c-fbb2-4ba1-8356-e1e11add462d,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-da1b210c-0911-4dc8-a2eb-f1ce2bd3850a,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-dd3ed2c1-e466-45c4-bae8-87425269f43f,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-310905df-e653-4b59-bc83-25a1eb92133c,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-c8a80541-4a81-495a-8f95-7ff550f2dae9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977498944-172.17.0.11-1598348905612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35559,DS-11ae8786-9844-48ba-b990-9508d3f35ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-4db01757-f036-4a24-8a3a-7441ef6ec869,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-2acb917c-bdb8-4b34-9cf2-28825e9b745b,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-d19a1e7c-fbb2-4ba1-8356-e1e11add462d,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-da1b210c-0911-4dc8-a2eb-f1ce2bd3850a,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-dd3ed2c1-e466-45c4-bae8-87425269f43f,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-310905df-e653-4b59-bc83-25a1eb92133c,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-c8a80541-4a81-495a-8f95-7ff550f2dae9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362361200-172.17.0.11-1598349049117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45057,DS-79254a8a-fc78-4ace-83d2-93cf45adbe49,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-2a643f62-b42b-42fa-be38-9dafabb067d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-3779e75c-dfd7-4e9f-8bf7-4a3a4a54f047,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-46a34301-3eb9-4757-8c61-726f2150d97d,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-57ae63ec-fb22-4af4-a68f-e10dc2d57896,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-b33332aa-7b7e-4bb6-8479-69edffe5c92b,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-43ab6693-f8b7-448b-9b07-01708a28fe0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-de997cc5-2e37-47b2-80c1-6e2395171a36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362361200-172.17.0.11-1598349049117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45057,DS-79254a8a-fc78-4ace-83d2-93cf45adbe49,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-2a643f62-b42b-42fa-be38-9dafabb067d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-3779e75c-dfd7-4e9f-8bf7-4a3a4a54f047,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-46a34301-3eb9-4757-8c61-726f2150d97d,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-57ae63ec-fb22-4af4-a68f-e10dc2d57896,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-b33332aa-7b7e-4bb6-8479-69edffe5c92b,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-43ab6693-f8b7-448b-9b07-01708a28fe0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-de997cc5-2e37-47b2-80c1-6e2395171a36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841576102-172.17.0.11-1598349551585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38444,DS-d2b7a94f-14f1-4645-b63a-561d1f072c89,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-f53b4890-132f-4cbc-b6ab-a4163dded300,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-98cf5db1-6293-4685-8de4-7c43d1fda5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-66dbc9be-22cc-4167-88a3-298092867cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-9d8b66f7-c5b5-4a73-8cf9-6c021a0a4a49,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-4d6e7ae1-084b-441b-b5e3-db05ac253869,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-24c73586-98a6-44a3-b00b-9b5acd4061de,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-6cefff59-bfba-43af-9cd2-69908871441f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841576102-172.17.0.11-1598349551585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38444,DS-d2b7a94f-14f1-4645-b63a-561d1f072c89,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-f53b4890-132f-4cbc-b6ab-a4163dded300,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-98cf5db1-6293-4685-8de4-7c43d1fda5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-66dbc9be-22cc-4167-88a3-298092867cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-9d8b66f7-c5b5-4a73-8cf9-6c021a0a4a49,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-4d6e7ae1-084b-441b-b5e3-db05ac253869,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-24c73586-98a6-44a3-b00b-9b5acd4061de,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-6cefff59-bfba-43af-9cd2-69908871441f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5374
