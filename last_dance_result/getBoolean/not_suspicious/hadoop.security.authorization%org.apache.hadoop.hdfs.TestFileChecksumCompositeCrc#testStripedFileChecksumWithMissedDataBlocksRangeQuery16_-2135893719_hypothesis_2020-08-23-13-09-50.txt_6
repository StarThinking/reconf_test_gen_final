reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-230244483-172.17.0.2-1598188262789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34829,DS-f53105cc-16fd-42f0-b912-90b758aa6599,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-73655902-d0aa-4132-8b84-c46b274ef324,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-da815203-fd3a-40e0-b4b2-c25d1230025e,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-1df62ef0-0127-4676-84b3-486430461702,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-fe725ea5-d9e2-40af-bc3a-6aba4b925dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-df476a79-50d5-4daa-b2f3-25e29eebe967,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-cb5d9905-734e-440a-8b37-e4fc731d4372,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-16c900e4-f59a-4900-b7e8-7d63f0d52e8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-230244483-172.17.0.2-1598188262789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34829,DS-f53105cc-16fd-42f0-b912-90b758aa6599,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-73655902-d0aa-4132-8b84-c46b274ef324,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-da815203-fd3a-40e0-b4b2-c25d1230025e,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-1df62ef0-0127-4676-84b3-486430461702,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-fe725ea5-d9e2-40af-bc3a-6aba4b925dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-df476a79-50d5-4daa-b2f3-25e29eebe967,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-cb5d9905-734e-440a-8b37-e4fc731d4372,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-16c900e4-f59a-4900-b7e8-7d63f0d52e8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971756279-172.17.0.2-1598188303213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35313,DS-9045b9f7-dd43-48f9-853a-252bb15f06e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-e1289096-7847-46c5-b007-17d322fccf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-486fc0ed-5d0c-4397-814a-83052cbb119d,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-be54a9c8-3190-46a5-8d9e-b71064d99f77,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-1a4e4bb6-975f-46ab-8571-35a2b5eb3fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-edf66a76-91d7-4de5-bbb8-e0547de00c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-7c776c66-077b-42f2-9df9-2583b32f790f,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-c5e05435-e9fd-48fe-b857-2eaf8af1be8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971756279-172.17.0.2-1598188303213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35313,DS-9045b9f7-dd43-48f9-853a-252bb15f06e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-e1289096-7847-46c5-b007-17d322fccf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-486fc0ed-5d0c-4397-814a-83052cbb119d,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-be54a9c8-3190-46a5-8d9e-b71064d99f77,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-1a4e4bb6-975f-46ab-8571-35a2b5eb3fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-edf66a76-91d7-4de5-bbb8-e0547de00c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-7c776c66-077b-42f2-9df9-2583b32f790f,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-c5e05435-e9fd-48fe-b857-2eaf8af1be8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1605748949-172.17.0.2-1598189112583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40367,DS-dda56e6e-4458-4b40-b4b1-1f927fdf2175,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-4dfafb23-b257-489c-84db-4c776cb5a8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-4b0165ce-b801-421f-80d9-4f1aa3f1e577,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-1299dd3f-ed4d-412e-b29a-94cb209b60c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-56847b82-a01e-4a36-a627-9154a5f82a43,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-d82d9010-430b-4bea-b71e-6faed534acb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-c7589fe0-52a3-43a9-9e6f-e1f1674bac30,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-476e4eec-bd47-43bc-b697-9e10c1a48300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1605748949-172.17.0.2-1598189112583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40367,DS-dda56e6e-4458-4b40-b4b1-1f927fdf2175,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-4dfafb23-b257-489c-84db-4c776cb5a8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-4b0165ce-b801-421f-80d9-4f1aa3f1e577,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-1299dd3f-ed4d-412e-b29a-94cb209b60c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-56847b82-a01e-4a36-a627-9154a5f82a43,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-d82d9010-430b-4bea-b71e-6faed534acb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-c7589fe0-52a3-43a9-9e6f-e1f1674bac30,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-476e4eec-bd47-43bc-b697-9e10c1a48300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2038806374-172.17.0.2-1598189285721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38887,DS-ad5f4a04-adef-4950-885f-6fba1a71b299,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-0a529ce9-8a6f-4d85-ab48-144cd0e04a69,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-dc167f24-debc-4c35-a951-3f18f3ea1323,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-3c4c1fc9-103d-419b-a01d-bdaf2de9273c,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-bf9d9789-583b-4496-b125-b7a03faac277,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-d0d58dbe-853f-43d4-8b0e-9c52b42c76e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-35b008da-6f65-4eca-8568-a6bb2ded0104,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-50526efe-8b20-40ce-bf41-fa3e512e3b32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2038806374-172.17.0.2-1598189285721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38887,DS-ad5f4a04-adef-4950-885f-6fba1a71b299,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-0a529ce9-8a6f-4d85-ab48-144cd0e04a69,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-dc167f24-debc-4c35-a951-3f18f3ea1323,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-3c4c1fc9-103d-419b-a01d-bdaf2de9273c,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-bf9d9789-583b-4496-b125-b7a03faac277,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-d0d58dbe-853f-43d4-8b0e-9c52b42c76e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-35b008da-6f65-4eca-8568-a6bb2ded0104,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-50526efe-8b20-40ce-bf41-fa3e512e3b32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973462073-172.17.0.2-1598189571659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-ad5daa23-714d-4eba-bf0e-8d1bb889c363,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-5fe438d7-4219-42bd-833a-ca86836b8299,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-faa678fe-d467-4081-83b8-cd91666c2d46,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-32f3a42f-b2b0-4c3d-be3d-340b4a128df1,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-18c57f6e-01c1-43cf-94d6-6579d794cf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-428c6629-93ec-4e0a-8996-66fa045ef40b,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-92cd76d5-9c18-4d72-8179-0e634bdd9f12,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-85b949d2-729d-484f-bae8-f9364835e48b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973462073-172.17.0.2-1598189571659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-ad5daa23-714d-4eba-bf0e-8d1bb889c363,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-5fe438d7-4219-42bd-833a-ca86836b8299,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-faa678fe-d467-4081-83b8-cd91666c2d46,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-32f3a42f-b2b0-4c3d-be3d-340b4a128df1,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-18c57f6e-01c1-43cf-94d6-6579d794cf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-428c6629-93ec-4e0a-8996-66fa045ef40b,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-92cd76d5-9c18-4d72-8179-0e634bdd9f12,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-85b949d2-729d-484f-bae8-f9364835e48b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-217124621-172.17.0.2-1598190079521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42522,DS-4abddc2e-7bfb-427d-b257-6da64357309d,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-70184cb1-45eb-486e-9573-013430358bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-36676dab-5422-4d78-aed1-48f886d734cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-e12c0353-ec05-4f94-9d5c-8ffc7fa9a323,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-77fa12c2-6880-4908-a947-ff2939a1deb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-681f926b-96b5-45dc-ab97-ddebc264c77c,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-537b0ea2-d111-4a09-94e6-88a6c582634c,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-43936f2b-db60-415e-af9d-7bd7d7a93171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-217124621-172.17.0.2-1598190079521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42522,DS-4abddc2e-7bfb-427d-b257-6da64357309d,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-70184cb1-45eb-486e-9573-013430358bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-36676dab-5422-4d78-aed1-48f886d734cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-e12c0353-ec05-4f94-9d5c-8ffc7fa9a323,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-77fa12c2-6880-4908-a947-ff2939a1deb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-681f926b-96b5-45dc-ab97-ddebc264c77c,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-537b0ea2-d111-4a09-94e6-88a6c582634c,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-43936f2b-db60-415e-af9d-7bd7d7a93171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-956139801-172.17.0.2-1598190340985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42042,DS-dec443a0-f882-42bf-8b12-106824f4d529,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-b93b2e8a-84d1-4a7b-a732-cd8ee46f9ada,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-cc67f567-7275-4013-a520-c0ecf351ad7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-bdb64e70-435a-4751-950f-909fb5a37056,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-107165c7-8d1b-48ac-b2e0-bb1fe63a4bae,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-9dd49ce3-cf49-4322-ad0d-12562304a7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-28435ca6-a6dc-4f3d-86a8-0108dd4ecd36,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-e850e650-0ec4-4108-a453-38237f7a77d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-956139801-172.17.0.2-1598190340985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42042,DS-dec443a0-f882-42bf-8b12-106824f4d529,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-b93b2e8a-84d1-4a7b-a732-cd8ee46f9ada,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-cc67f567-7275-4013-a520-c0ecf351ad7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-bdb64e70-435a-4751-950f-909fb5a37056,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-107165c7-8d1b-48ac-b2e0-bb1fe63a4bae,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-9dd49ce3-cf49-4322-ad0d-12562304a7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-28435ca6-a6dc-4f3d-86a8-0108dd4ecd36,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-e850e650-0ec4-4108-a453-38237f7a77d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1508407001-172.17.0.2-1598191003160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42092,DS-34d31e1b-0a08-4f92-9fe9-3d13bf9a8a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-76cb4dd9-a6ff-4fca-b93a-5a59af6c219c,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-44a4a89a-970c-4cdb-9059-7ab36cc4d717,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-e0e83107-6548-4eea-a5c8-24c26d4db000,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-ef15b1ed-6f6d-481e-a93b-114a83a27571,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-78b2cf31-c691-404a-bee4-4bc3d57c6995,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-6925a7e9-3c20-447b-83f2-7972e2ca14ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-c3a6c27b-3c49-416a-9a11-b9d28cf6a5fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1508407001-172.17.0.2-1598191003160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42092,DS-34d31e1b-0a08-4f92-9fe9-3d13bf9a8a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-76cb4dd9-a6ff-4fca-b93a-5a59af6c219c,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-44a4a89a-970c-4cdb-9059-7ab36cc4d717,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-e0e83107-6548-4eea-a5c8-24c26d4db000,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-ef15b1ed-6f6d-481e-a93b-114a83a27571,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-78b2cf31-c691-404a-bee4-4bc3d57c6995,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-6925a7e9-3c20-447b-83f2-7972e2ca14ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-c3a6c27b-3c49-416a-9a11-b9d28cf6a5fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-380312382-172.17.0.2-1598191150787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42221,DS-2a529384-19b3-4ded-a141-ba12b1ef4195,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-4c27d172-be90-4c4a-a38c-12cbaed026a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-f35eaa79-ba76-4b01-9a6f-5d80eb51d703,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-3298a3b1-d3c4-4f72-9c96-eb11bd663b42,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-1ea08396-915b-47c0-8d98-4b8a3ad027ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-87dfcb6c-8a0a-466d-99fe-796bdf13ab23,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-a8d7b053-8b89-48b8-8fe8-dbd131f656c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-cdfba153-2cbc-430b-8265-c3706d0bdd6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-380312382-172.17.0.2-1598191150787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42221,DS-2a529384-19b3-4ded-a141-ba12b1ef4195,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-4c27d172-be90-4c4a-a38c-12cbaed026a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-f35eaa79-ba76-4b01-9a6f-5d80eb51d703,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-3298a3b1-d3c4-4f72-9c96-eb11bd663b42,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-1ea08396-915b-47c0-8d98-4b8a3ad027ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-87dfcb6c-8a0a-466d-99fe-796bdf13ab23,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-a8d7b053-8b89-48b8-8fe8-dbd131f656c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-cdfba153-2cbc-430b-8265-c3706d0bdd6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100753735-172.17.0.2-1598191380692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32858,DS-34d96571-5415-4cd9-b6b6-9588e84b6ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-a6c489f6-aa40-472e-8860-c45a95ec181c,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-8079c74e-de5a-4fd5-90b7-63699cb3b0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-f102c638-a317-4b3a-94d3-f8323d4c0350,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-d492b4b2-e138-44f7-a6c8-850068360c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-4d313e9d-d84f-4f4e-a5b1-00efa5055e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-9f12d992-2859-4a10-a05a-8b693c3539e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-2c254713-5bf8-4f01-83a1-1b1796a1d892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100753735-172.17.0.2-1598191380692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32858,DS-34d96571-5415-4cd9-b6b6-9588e84b6ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-a6c489f6-aa40-472e-8860-c45a95ec181c,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-8079c74e-de5a-4fd5-90b7-63699cb3b0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-f102c638-a317-4b3a-94d3-f8323d4c0350,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-d492b4b2-e138-44f7-a6c8-850068360c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-4d313e9d-d84f-4f4e-a5b1-00efa5055e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-9f12d992-2859-4a10-a05a-8b693c3539e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-2c254713-5bf8-4f01-83a1-1b1796a1d892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1120241979-172.17.0.2-1598191798336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41006,DS-940160f2-df73-4116-ac74-c61a1e1e024a,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-3d78c7bc-62f7-449b-8d0f-bb1056a15967,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-cd78b11b-d82f-49b3-aaf4-c9e885bf48ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-325a7648-d551-4552-8aee-5b40971fe28b,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-655e978a-f1c9-4fe2-9234-3a913113a7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-8e98164c-eb0f-43b8-b12b-33a50526a5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-1e8ae640-a560-43e9-bee0-bfa41dd72202,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-70f4c325-517b-475e-8218-15265e008752,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1120241979-172.17.0.2-1598191798336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41006,DS-940160f2-df73-4116-ac74-c61a1e1e024a,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-3d78c7bc-62f7-449b-8d0f-bb1056a15967,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-cd78b11b-d82f-49b3-aaf4-c9e885bf48ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-325a7648-d551-4552-8aee-5b40971fe28b,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-655e978a-f1c9-4fe2-9234-3a913113a7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-8e98164c-eb0f-43b8-b12b-33a50526a5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-1e8ae640-a560-43e9-bee0-bfa41dd72202,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-70f4c325-517b-475e-8218-15265e008752,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958797874-172.17.0.2-1598191844639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40303,DS-043602c7-7ed4-4c62-8e7d-065d0f2ce48d,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-b1685154-8788-456c-a6b2-44748df830a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-60458784-d98b-454d-8973-266145aedfda,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-db154fc1-fb34-4f3e-ab90-99fa80b41878,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-14d9da92-03e5-4bcf-b1ac-8633ce85306e,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-7da107f4-14b5-487d-9e38-fccd35cec7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-48aa25c2-ad37-416c-802b-e33c4e0a26a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-bb285177-3e7b-4e7a-bea7-b7a292be2c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958797874-172.17.0.2-1598191844639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40303,DS-043602c7-7ed4-4c62-8e7d-065d0f2ce48d,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-b1685154-8788-456c-a6b2-44748df830a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-60458784-d98b-454d-8973-266145aedfda,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-db154fc1-fb34-4f3e-ab90-99fa80b41878,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-14d9da92-03e5-4bcf-b1ac-8633ce85306e,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-7da107f4-14b5-487d-9e38-fccd35cec7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-48aa25c2-ad37-416c-802b-e33c4e0a26a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-bb285177-3e7b-4e7a-bea7-b7a292be2c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542119714-172.17.0.2-1598191885248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44803,DS-6f3de92d-0207-4cd1-8422-3e3a46badca2,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-f6279825-49b6-4710-9198-f5db13f407e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-f98c80b7-4bc4-4558-bbe6-c57f908aeda9,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-7306fffe-861d-4ba2-899f-560234e7060b,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-fb3d46f8-f2b2-45f4-9a65-77dc303c039c,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-bdc9d699-cf94-4e00-bc98-2e36ca1af1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-84f12965-eb3f-4cd3-ba5d-58ae6b65bf27,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-0a5a0383-4db6-4b55-ab18-ad598c729da8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542119714-172.17.0.2-1598191885248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44803,DS-6f3de92d-0207-4cd1-8422-3e3a46badca2,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-f6279825-49b6-4710-9198-f5db13f407e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-f98c80b7-4bc4-4558-bbe6-c57f908aeda9,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-7306fffe-861d-4ba2-899f-560234e7060b,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-fb3d46f8-f2b2-45f4-9a65-77dc303c039c,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-bdc9d699-cf94-4e00-bc98-2e36ca1af1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-84f12965-eb3f-4cd3-ba5d-58ae6b65bf27,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-0a5a0383-4db6-4b55-ab18-ad598c729da8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-948687190-172.17.0.2-1598192098538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38230,DS-a23679d4-e78d-4b55-a892-e6be0468dd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-c21e3cc1-13a6-4ebd-801a-a201a1756ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-5c972d13-52d1-406f-864f-b2fd42cf65e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-91adc275-48db-4763-8f8e-5cacfecc3e86,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-b3b73c10-ab37-48d6-a56e-600dd9b877ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-9376c206-946a-4c1f-ae1a-ebaac73f4325,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-fb671cfa-0848-46d2-a16f-a1fde41e3836,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-b82421db-4c6e-4683-b0a4-8aebb6bf3486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-948687190-172.17.0.2-1598192098538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38230,DS-a23679d4-e78d-4b55-a892-e6be0468dd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-c21e3cc1-13a6-4ebd-801a-a201a1756ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-5c972d13-52d1-406f-864f-b2fd42cf65e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-91adc275-48db-4763-8f8e-5cacfecc3e86,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-b3b73c10-ab37-48d6-a56e-600dd9b877ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-9376c206-946a-4c1f-ae1a-ebaac73f4325,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-fb671cfa-0848-46d2-a16f-a1fde41e3836,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-b82421db-4c6e-4683-b0a4-8aebb6bf3486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1114588338-172.17.0.2-1598192828730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43429,DS-e6cca85c-1e8e-46d6-8355-9ef8100f47ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-caf5a141-ef35-48f8-8825-2412c94d7be5,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-30b6e828-27b9-4e0c-8da4-f7d421735d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-1b251ab9-3a33-4f1e-80e1-02c1d3af2e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-e19d9f3d-1df3-4583-8ec8-ab299a732ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-d0bed0fa-98df-41f4-b01d-935e432ed2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-f1131aed-1434-4d52-9560-8002527c397d,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-9cd4e779-88b6-4293-bf65-2ce61f9ce723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1114588338-172.17.0.2-1598192828730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43429,DS-e6cca85c-1e8e-46d6-8355-9ef8100f47ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-caf5a141-ef35-48f8-8825-2412c94d7be5,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-30b6e828-27b9-4e0c-8da4-f7d421735d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-1b251ab9-3a33-4f1e-80e1-02c1d3af2e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-e19d9f3d-1df3-4583-8ec8-ab299a732ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-d0bed0fa-98df-41f4-b01d-935e432ed2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-f1131aed-1434-4d52-9560-8002527c397d,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-9cd4e779-88b6-4293-bf65-2ce61f9ce723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340978075-172.17.0.2-1598193339684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39967,DS-2ce47ac6-972b-4036-981d-98738ccf0a07,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-73439409-e4ee-4ad8-826a-ed87307151b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-5ad44ca1-d1a2-4e0c-864a-d90c37d5a51d,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-d5e18b62-3039-496b-9d02-23876ee2c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-8a5cdd65-a249-4bfe-a900-fc9fbbed4395,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-2c63ce02-cdd8-42fd-a655-89a02e749c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-02e49058-ab24-40af-9abc-dd8c00962854,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-c5c79956-35fd-41ab-b72e-88617e36b15b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340978075-172.17.0.2-1598193339684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39967,DS-2ce47ac6-972b-4036-981d-98738ccf0a07,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-73439409-e4ee-4ad8-826a-ed87307151b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-5ad44ca1-d1a2-4e0c-864a-d90c37d5a51d,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-d5e18b62-3039-496b-9d02-23876ee2c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-8a5cdd65-a249-4bfe-a900-fc9fbbed4395,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-2c63ce02-cdd8-42fd-a655-89a02e749c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-02e49058-ab24-40af-9abc-dd8c00962854,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-c5c79956-35fd-41ab-b72e-88617e36b15b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693054651-172.17.0.2-1598194040822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36926,DS-c479c993-3a3f-4792-b9f5-17b2d6d849b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-73de1638-66e6-42bb-a449-10b9fff40346,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-9669599f-9e84-4591-b67a-757af0ddbc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-496cd154-1e68-4e0b-93bf-d79ea8920d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-7722e9e3-dd52-4cca-951e-690bd9534150,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-e52f53f6-8049-42e6-9e4d-292df7209113,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-1e1a23ef-f989-456a-a478-7315d60021ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-24502668-376e-4baa-a1f6-f19bf92b056d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693054651-172.17.0.2-1598194040822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36926,DS-c479c993-3a3f-4792-b9f5-17b2d6d849b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-73de1638-66e6-42bb-a449-10b9fff40346,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-9669599f-9e84-4591-b67a-757af0ddbc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-496cd154-1e68-4e0b-93bf-d79ea8920d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-7722e9e3-dd52-4cca-951e-690bd9534150,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-e52f53f6-8049-42e6-9e4d-292df7209113,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-1e1a23ef-f989-456a-a478-7315d60021ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-24502668-376e-4baa-a1f6-f19bf92b056d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071399371-172.17.0.2-1598194171862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46594,DS-5ad280df-9812-48ed-900c-f413c28648b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-ec666507-ea78-48e3-9b33-67c754c50b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-57e190a8-f525-4024-acc6-06bb8b734913,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-cc53f64c-4553-4ac1-b90f-d31e9f9af731,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-612a8b30-ea15-472c-bd5f-e4b2c264a1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-3f0e649c-6351-4160-81d2-a6f87c62450f,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-0d537456-5293-4481-b62c-b9135c158089,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-17cac154-509c-430f-a0a6-c224cf128fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071399371-172.17.0.2-1598194171862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46594,DS-5ad280df-9812-48ed-900c-f413c28648b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-ec666507-ea78-48e3-9b33-67c754c50b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-57e190a8-f525-4024-acc6-06bb8b734913,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-cc53f64c-4553-4ac1-b90f-d31e9f9af731,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-612a8b30-ea15-472c-bd5f-e4b2c264a1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-3f0e649c-6351-4160-81d2-a6f87c62450f,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-0d537456-5293-4481-b62c-b9135c158089,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-17cac154-509c-430f-a0a6-c224cf128fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759253496-172.17.0.2-1598194340865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45051,DS-97ad0855-f352-4acb-9f21-dba280509cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-7ccae3a7-d3be-42aa-b651-3b0cd379b54c,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-9b49b9aa-b84d-4426-bab9-c91f8d873a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-7eb3faee-3c3f-4399-b6cf-385fbdc6cd95,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-1e61b4cd-f4c7-4086-893f-8be3c3acc340,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-de5a95b0-8896-460c-adb0-ee9e4c9c54b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-bc481e13-d307-47a5-b7b2-d67c7402ef9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-72344f17-fbb7-4581-8193-70b5955187e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759253496-172.17.0.2-1598194340865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45051,DS-97ad0855-f352-4acb-9f21-dba280509cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-7ccae3a7-d3be-42aa-b651-3b0cd379b54c,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-9b49b9aa-b84d-4426-bab9-c91f8d873a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-7eb3faee-3c3f-4399-b6cf-385fbdc6cd95,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-1e61b4cd-f4c7-4086-893f-8be3c3acc340,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-de5a95b0-8896-460c-adb0-ee9e4c9c54b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-bc481e13-d307-47a5-b7b2-d67c7402ef9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-72344f17-fbb7-4581-8193-70b5955187e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2087135365-172.17.0.2-1598194828663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42020,DS-653f579c-3748-4bed-8e90-ba6d530a864e,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-2dedc61f-435f-4cdf-87a2-7c14614d0d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-4b6bb22c-679e-4856-ba19-eb681f25dfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-4b56dfbb-0076-4baa-90ff-3ef8937c6721,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-74073f7e-8480-4f7e-aaa8-0b11e55d9f15,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-ce826881-865c-4d55-9cb6-af6ecf736d98,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-31c425fa-769a-4b97-a9e0-17af2981993c,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-1679de8d-2274-48a9-9e5b-41c6f02dcd28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2087135365-172.17.0.2-1598194828663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42020,DS-653f579c-3748-4bed-8e90-ba6d530a864e,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-2dedc61f-435f-4cdf-87a2-7c14614d0d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-4b6bb22c-679e-4856-ba19-eb681f25dfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-4b56dfbb-0076-4baa-90ff-3ef8937c6721,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-74073f7e-8480-4f7e-aaa8-0b11e55d9f15,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-ce826881-865c-4d55-9cb6-af6ecf736d98,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-31c425fa-769a-4b97-a9e0-17af2981993c,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-1679de8d-2274-48a9-9e5b-41c6f02dcd28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-688447613-172.17.0.2-1598195129603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35275,DS-0b9051c2-f4bd-4249-b224-2e930bf43a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-225c0633-7a47-41f6-8cb2-9af6b3e16cca,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-ad0fcbdc-6d1d-4327-8fce-3a9ae22647cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-26b56951-5f16-49fc-bf33-0db82bc2061e,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-0dedbce1-9855-40ad-b612-a7d5ba9fce02,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-b36c9690-0e20-4b48-aab5-293fd49a4171,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-1b669d31-b63b-4212-8790-36de501e7161,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-2b059247-7bca-4ca1-8ccd-a3f4585bc965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-688447613-172.17.0.2-1598195129603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35275,DS-0b9051c2-f4bd-4249-b224-2e930bf43a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-225c0633-7a47-41f6-8cb2-9af6b3e16cca,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-ad0fcbdc-6d1d-4327-8fce-3a9ae22647cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-26b56951-5f16-49fc-bf33-0db82bc2061e,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-0dedbce1-9855-40ad-b612-a7d5ba9fce02,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-b36c9690-0e20-4b48-aab5-293fd49a4171,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-1b669d31-b63b-4212-8790-36de501e7161,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-2b059247-7bca-4ca1-8ccd-a3f4585bc965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 7099
