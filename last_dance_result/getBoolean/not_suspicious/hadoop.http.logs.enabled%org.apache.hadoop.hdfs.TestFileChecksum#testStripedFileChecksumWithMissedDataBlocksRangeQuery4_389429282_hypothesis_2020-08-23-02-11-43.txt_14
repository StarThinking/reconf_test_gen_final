reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115225558-172.17.0.17-1598148922624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37141,DS-f99fb9ad-cc11-4c5e-904e-4ce31df18a39,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-2d16538e-f586-47ab-a4cc-fb2f1e288905,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-753d9838-4c8c-41f1-bdcb-c89e91f2a802,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-a2ddbac7-a67f-4e90-9cfe-7539136afc70,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-5054f8e5-8f88-489b-b5c7-9629d7d81349,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-cc7dc4d1-7fde-42c1-92fb-9a12b7571185,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-678d887f-5f0e-439d-b4d6-a63b538fe9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-41c5f0bf-ada8-42fe-bae0-d81b7f710fdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115225558-172.17.0.17-1598148922624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37141,DS-f99fb9ad-cc11-4c5e-904e-4ce31df18a39,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-2d16538e-f586-47ab-a4cc-fb2f1e288905,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-753d9838-4c8c-41f1-bdcb-c89e91f2a802,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-a2ddbac7-a67f-4e90-9cfe-7539136afc70,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-5054f8e5-8f88-489b-b5c7-9629d7d81349,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-cc7dc4d1-7fde-42c1-92fb-9a12b7571185,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-678d887f-5f0e-439d-b4d6-a63b538fe9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-41c5f0bf-ada8-42fe-bae0-d81b7f710fdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268858992-172.17.0.17-1598148969090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37919,DS-130d7ab9-99fc-4091-908b-1be71a939444,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-32c3e737-4889-420f-8aa3-2a3fdf1b9185,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-e5f0735a-d299-4f61-b84d-67b6fb526abf,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-21346788-6451-4911-ace2-f92f3dd2931b,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-32c13bc1-533a-4f27-b86d-a81e9ac576ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-a48a6686-38f5-4305-9a25-cd239800e92c,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-78e1f761-0a7e-497d-a60a-911772dc553f,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-ea35164c-1ecd-42b9-a752-51a9db2401ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268858992-172.17.0.17-1598148969090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37919,DS-130d7ab9-99fc-4091-908b-1be71a939444,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-32c3e737-4889-420f-8aa3-2a3fdf1b9185,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-e5f0735a-d299-4f61-b84d-67b6fb526abf,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-21346788-6451-4911-ace2-f92f3dd2931b,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-32c13bc1-533a-4f27-b86d-a81e9ac576ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-a48a6686-38f5-4305-9a25-cd239800e92c,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-78e1f761-0a7e-497d-a60a-911772dc553f,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-ea35164c-1ecd-42b9-a752-51a9db2401ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650608349-172.17.0.17-1598149740974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38013,DS-35fa40d4-a4d8-41a6-9ffe-36285002aa17,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-5e3fa757-7c07-45dd-bf94-f3b6d2a2503e,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-5821784b-748b-485d-8bb1-78b444881069,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-577a08d8-e020-4774-9ef7-cee3508deffd,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-dc1e81e8-53e3-411a-b532-823b46fafe28,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-0a4680bc-78d9-41c0-90fb-40df06b72e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-51fbb9d2-bff5-469e-9f48-abbed3bcce4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-77ff0b0c-9427-4f0c-9c4b-714f29fca8f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650608349-172.17.0.17-1598149740974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38013,DS-35fa40d4-a4d8-41a6-9ffe-36285002aa17,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-5e3fa757-7c07-45dd-bf94-f3b6d2a2503e,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-5821784b-748b-485d-8bb1-78b444881069,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-577a08d8-e020-4774-9ef7-cee3508deffd,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-dc1e81e8-53e3-411a-b532-823b46fafe28,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-0a4680bc-78d9-41c0-90fb-40df06b72e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-51fbb9d2-bff5-469e-9f48-abbed3bcce4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-77ff0b0c-9427-4f0c-9c4b-714f29fca8f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1591363421-172.17.0.17-1598150112362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33812,DS-fcbadf7d-532b-4387-aca9-f04a097bc798,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-db35805b-5dcb-47f0-8349-a976e3ccc191,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-93441dc6-2620-4fef-9c72-a05a68b9ac71,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-ae0531be-cbfb-4ddf-8357-256e551209d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-15bf430a-8abb-4185-8933-2ab0ae9daa94,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-6adeb5e6-f562-46e7-add2-929c460af1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-fd5722fd-474a-4c7d-bac5-07ea39806b58,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-7e323092-1282-418a-a89a-aaed3dcf8699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1591363421-172.17.0.17-1598150112362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33812,DS-fcbadf7d-532b-4387-aca9-f04a097bc798,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-db35805b-5dcb-47f0-8349-a976e3ccc191,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-93441dc6-2620-4fef-9c72-a05a68b9ac71,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-ae0531be-cbfb-4ddf-8357-256e551209d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-15bf430a-8abb-4185-8933-2ab0ae9daa94,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-6adeb5e6-f562-46e7-add2-929c460af1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-fd5722fd-474a-4c7d-bac5-07ea39806b58,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-7e323092-1282-418a-a89a-aaed3dcf8699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508002146-172.17.0.17-1598150402699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37948,DS-9f818955-2dd4-4c9e-9e59-a437cb990466,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-7d467645-760b-4a4f-b46a-33c4596d175c,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-508e6569-632c-4536-9e66-660d95f7904c,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-7421b509-11cc-4ad9-9404-b116d53a28c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-ac8b2e01-f5d0-46e6-9d57-881003243689,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-7d568dda-0de6-4558-95fe-9e8011fb3de4,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-dffdefa4-ecb5-442b-9a5b-9fd5f4c8c332,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-35aff76d-1d5f-4da9-be54-c5456a68ed7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508002146-172.17.0.17-1598150402699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37948,DS-9f818955-2dd4-4c9e-9e59-a437cb990466,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-7d467645-760b-4a4f-b46a-33c4596d175c,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-508e6569-632c-4536-9e66-660d95f7904c,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-7421b509-11cc-4ad9-9404-b116d53a28c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-ac8b2e01-f5d0-46e6-9d57-881003243689,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-7d568dda-0de6-4558-95fe-9e8011fb3de4,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-dffdefa4-ecb5-442b-9a5b-9fd5f4c8c332,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-35aff76d-1d5f-4da9-be54-c5456a68ed7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992405944-172.17.0.17-1598150632650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44916,DS-4cdfbb6b-f6c6-4c91-92bf-436719c57372,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-a2ebe333-d911-4eac-933a-f7e7b77000e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-3f591d00-78cd-4858-ab04-8c1c60b77f16,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-50976bbb-9d74-48e2-89e2-a24f71789e64,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-ac05301c-2ba6-49d5-840c-9aca7b421434,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-f22e2d3e-48fb-4d46-831c-3a19a7fc675e,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-65631269-d6a9-4b86-a120-8e177f132264,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-5d849905-ad85-4c25-8a70-2b5196503a4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992405944-172.17.0.17-1598150632650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44916,DS-4cdfbb6b-f6c6-4c91-92bf-436719c57372,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-a2ebe333-d911-4eac-933a-f7e7b77000e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-3f591d00-78cd-4858-ab04-8c1c60b77f16,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-50976bbb-9d74-48e2-89e2-a24f71789e64,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-ac05301c-2ba6-49d5-840c-9aca7b421434,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-f22e2d3e-48fb-4d46-831c-3a19a7fc675e,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-65631269-d6a9-4b86-a120-8e177f132264,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-5d849905-ad85-4c25-8a70-2b5196503a4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797131043-172.17.0.17-1598150984240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33941,DS-8f145b84-50db-40bc-8060-03f2ef916c32,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-0dc36822-9825-4536-a963-7591a0bf1dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-83ffa332-463a-4804-bdf2-150a726fca82,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-c52017a4-0e96-41ad-afd7-3d55759b00d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-c431f361-47cf-4513-8063-9532094a54b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-28a1e04b-c04b-4964-ba79-ba1ca03562de,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-147509e3-13e3-4d6a-8f8e-e580e787c331,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-669afe1f-aade-4d76-86ec-7e22332a2eb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797131043-172.17.0.17-1598150984240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33941,DS-8f145b84-50db-40bc-8060-03f2ef916c32,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-0dc36822-9825-4536-a963-7591a0bf1dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-83ffa332-463a-4804-bdf2-150a726fca82,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-c52017a4-0e96-41ad-afd7-3d55759b00d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-c431f361-47cf-4513-8063-9532094a54b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-28a1e04b-c04b-4964-ba79-ba1ca03562de,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-147509e3-13e3-4d6a-8f8e-e580e787c331,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-669afe1f-aade-4d76-86ec-7e22332a2eb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156262176-172.17.0.17-1598151060376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45884,DS-664a6e80-923e-411d-92a2-7592ce9d026e,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-13c86795-0747-4894-a61d-63bb8d13b783,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-bd9ff4c1-018f-41fb-a262-5d4864295d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-efb7c075-8a15-4744-b993-0ca931ed269d,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-687f912c-e7a1-41ab-a962-2cb5db776bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-0b190e76-7d10-4fea-ba37-e70363b59548,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-b15ddcfb-4c01-4ea4-9f1e-c649702634a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-27f042fb-136b-4a11-8844-e40e0bbb3af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156262176-172.17.0.17-1598151060376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45884,DS-664a6e80-923e-411d-92a2-7592ce9d026e,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-13c86795-0747-4894-a61d-63bb8d13b783,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-bd9ff4c1-018f-41fb-a262-5d4864295d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-efb7c075-8a15-4744-b993-0ca931ed269d,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-687f912c-e7a1-41ab-a962-2cb5db776bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-0b190e76-7d10-4fea-ba37-e70363b59548,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-b15ddcfb-4c01-4ea4-9f1e-c649702634a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-27f042fb-136b-4a11-8844-e40e0bbb3af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603473133-172.17.0.17-1598151165672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32934,DS-c62a42cb-a8d5-4e6b-9a89-51465d12ff11,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-2527b3eb-7d07-4f8d-9cf1-33d1afd65cee,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-53ed4dfd-c8ca-44ab-9757-aae6d98eb2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-bd856eda-a598-4f94-a2fe-bdfb9d1c6be2,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-3853d77e-c431-4270-ad7b-a974ee6d7af8,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-8cd8fe18-eba9-4e3e-827e-d97a40ce2e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-55b4db37-c5b6-4d5e-b8f3-f933a5a49271,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-63d9af1f-61c9-4337-9b11-538156549871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603473133-172.17.0.17-1598151165672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32934,DS-c62a42cb-a8d5-4e6b-9a89-51465d12ff11,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-2527b3eb-7d07-4f8d-9cf1-33d1afd65cee,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-53ed4dfd-c8ca-44ab-9757-aae6d98eb2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-bd856eda-a598-4f94-a2fe-bdfb9d1c6be2,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-3853d77e-c431-4270-ad7b-a974ee6d7af8,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-8cd8fe18-eba9-4e3e-827e-d97a40ce2e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-55b4db37-c5b6-4d5e-b8f3-f933a5a49271,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-63d9af1f-61c9-4337-9b11-538156549871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339548047-172.17.0.17-1598151511264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41157,DS-b0567aef-72e4-44e4-988f-1097d86f361b,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-77791972-d2bb-4494-893e-e2e1e1bdbadd,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-9ee37ac5-811c-4bf6-9ae1-dbb1e4672948,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-f11b3dcb-24c5-4b3c-9559-8bf28362c5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-b5852499-ccfb-4ceb-b8f7-c26dbf9e174a,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-4b51b17c-840d-4041-a0aa-a74ed272514c,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-5dff810d-8354-45a3-bed2-27eb0e7df0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-100766be-8233-436b-b011-9a4bbfd72381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339548047-172.17.0.17-1598151511264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41157,DS-b0567aef-72e4-44e4-988f-1097d86f361b,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-77791972-d2bb-4494-893e-e2e1e1bdbadd,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-9ee37ac5-811c-4bf6-9ae1-dbb1e4672948,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-f11b3dcb-24c5-4b3c-9559-8bf28362c5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-b5852499-ccfb-4ceb-b8f7-c26dbf9e174a,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-4b51b17c-840d-4041-a0aa-a74ed272514c,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-5dff810d-8354-45a3-bed2-27eb0e7df0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-100766be-8233-436b-b011-9a4bbfd72381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553557108-172.17.0.17-1598151768286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32976,DS-0959a3a1-5524-47dc-bbf9-e6d261b41819,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-0de7ab08-8948-4a36-bb35-bf3091bbee1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-41d553e5-fe80-4a9d-99bf-ccf43b732e81,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-5b055e91-f26d-4d68-9485-5ec74482aa75,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-dcec0e92-c935-4943-97a5-c7ca61b65f75,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-4903701c-54b1-4607-b86e-cf4204ac111b,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-2571d151-1b9f-4eb5-b2d7-29e279575c13,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-ca45d434-ee06-42b9-b250-a0c4c3633269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553557108-172.17.0.17-1598151768286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32976,DS-0959a3a1-5524-47dc-bbf9-e6d261b41819,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-0de7ab08-8948-4a36-bb35-bf3091bbee1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-41d553e5-fe80-4a9d-99bf-ccf43b732e81,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-5b055e91-f26d-4d68-9485-5ec74482aa75,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-dcec0e92-c935-4943-97a5-c7ca61b65f75,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-4903701c-54b1-4607-b86e-cf4204ac111b,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-2571d151-1b9f-4eb5-b2d7-29e279575c13,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-ca45d434-ee06-42b9-b250-a0c4c3633269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148120058-172.17.0.17-1598153000673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44175,DS-f8ccd26f-784f-4149-ad00-3d11c4ca512b,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-60c0af71-997a-4705-8021-f1305b17430d,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-f08d5da7-9464-495f-88c7-949b3ea1aef7,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-9bf06d44-6113-4f3a-bd8b-10841e83d01c,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-cccb2ab9-f9b5-414f-b634-608762f4a7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-1eb3f354-060f-4971-96ed-4142677f247a,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-164d8ac9-d6c9-44ff-b0b3-504da50859ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-5ad748f6-b63a-455a-9307-982d9b04d361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148120058-172.17.0.17-1598153000673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44175,DS-f8ccd26f-784f-4149-ad00-3d11c4ca512b,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-60c0af71-997a-4705-8021-f1305b17430d,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-f08d5da7-9464-495f-88c7-949b3ea1aef7,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-9bf06d44-6113-4f3a-bd8b-10841e83d01c,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-cccb2ab9-f9b5-414f-b634-608762f4a7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-1eb3f354-060f-4971-96ed-4142677f247a,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-164d8ac9-d6c9-44ff-b0b3-504da50859ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-5ad748f6-b63a-455a-9307-982d9b04d361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343001621-172.17.0.17-1598154152781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34118,DS-4ba9cff5-cfb1-4b7f-a57b-1390bd453e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-053d9c10-8bcc-4474-8785-58e25e5ad63b,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-3fe92cfb-e31c-41ad-9ae1-ebc0304da352,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-e152fbcf-4d52-48e4-8579-f5d1533fc38a,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-eda0e31e-257d-41ae-9e5e-fdb2a90f1f22,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-e060a36e-8197-42dc-8dbe-322b2b70e889,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-2785e8b0-04ab-4637-a290-fb9306eb8713,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-02d657be-be86-4ead-b7dd-2dbdde0ec386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343001621-172.17.0.17-1598154152781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34118,DS-4ba9cff5-cfb1-4b7f-a57b-1390bd453e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-053d9c10-8bcc-4474-8785-58e25e5ad63b,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-3fe92cfb-e31c-41ad-9ae1-ebc0304da352,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-e152fbcf-4d52-48e4-8579-f5d1533fc38a,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-eda0e31e-257d-41ae-9e5e-fdb2a90f1f22,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-e060a36e-8197-42dc-8dbe-322b2b70e889,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-2785e8b0-04ab-4637-a290-fb9306eb8713,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-02d657be-be86-4ead-b7dd-2dbdde0ec386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214099321-172.17.0.17-1598154400261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43035,DS-3912e065-1612-48fd-a7b3-6671c0c0caa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-f3531444-7959-46e5-b211-3287b5b87ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-34c87091-ae37-474f-a1e0-147ab3f63bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-8a5c3eac-787e-4650-a6af-4dceb34b47ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-44100b5b-6a3e-4bf9-ba7e-7bf8ec388da9,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-5565e171-0d3e-4dfd-89a0-7b5531634c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-a8e760b0-0cda-48bd-88eb-e420a9aae499,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-ceef5d4d-43e6-4875-9560-ea1ffa542784,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214099321-172.17.0.17-1598154400261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43035,DS-3912e065-1612-48fd-a7b3-6671c0c0caa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-f3531444-7959-46e5-b211-3287b5b87ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-34c87091-ae37-474f-a1e0-147ab3f63bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-8a5c3eac-787e-4650-a6af-4dceb34b47ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-44100b5b-6a3e-4bf9-ba7e-7bf8ec388da9,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-5565e171-0d3e-4dfd-89a0-7b5531634c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-a8e760b0-0cda-48bd-88eb-e420a9aae499,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-ceef5d4d-43e6-4875-9560-ea1ffa542784,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 6434
