reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136443360-172.17.0.18-1598153445407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-dce041b8-1c10-4ac3-8fc6-79e2bb293760,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-5c71fce8-8aa4-42fa-a02f-76e6723d990b,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-5b1b1d97-3610-4dd0-809f-9fec10c67c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-3f6ab1f3-779b-498e-8b32-05a9fdfe8c88,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-0dfce257-3c26-41ed-ac79-932214cf5ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-5b9be52b-4318-433e-a2cc-a6f4e6960ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-2a511079-6208-45fc-85a7-b1764411e945,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-afadab92-0356-475f-bd0b-519cf7b74636,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136443360-172.17.0.18-1598153445407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-dce041b8-1c10-4ac3-8fc6-79e2bb293760,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-5c71fce8-8aa4-42fa-a02f-76e6723d990b,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-5b1b1d97-3610-4dd0-809f-9fec10c67c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-3f6ab1f3-779b-498e-8b32-05a9fdfe8c88,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-0dfce257-3c26-41ed-ac79-932214cf5ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-5b9be52b-4318-433e-a2cc-a6f4e6960ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-2a511079-6208-45fc-85a7-b1764411e945,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-afadab92-0356-475f-bd0b-519cf7b74636,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339713585-172.17.0.18-1598153619093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35898,DS-da05cb3f-4338-4dcd-b582-6babaff023ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-cef0708a-644c-4c85-ace5-a8584bac5116,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-c1f516c1-6c6b-48ac-8166-2ab5048e370f,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-4aca4bb8-e0de-408f-be62-69e0bce3ffd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-9870d6a4-5fe3-4890-ab70-61bfdaf71c95,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-ca31c99f-329d-4335-9996-b90167f58851,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-d14b1270-1f05-45bc-b9e3-fcd269689448,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-f7b8110b-4dbb-449b-a8c7-1ec5ff36f0be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339713585-172.17.0.18-1598153619093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35898,DS-da05cb3f-4338-4dcd-b582-6babaff023ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-cef0708a-644c-4c85-ace5-a8584bac5116,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-c1f516c1-6c6b-48ac-8166-2ab5048e370f,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-4aca4bb8-e0de-408f-be62-69e0bce3ffd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-9870d6a4-5fe3-4890-ab70-61bfdaf71c95,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-ca31c99f-329d-4335-9996-b90167f58851,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-d14b1270-1f05-45bc-b9e3-fcd269689448,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-f7b8110b-4dbb-449b-a8c7-1ec5ff36f0be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798313652-172.17.0.18-1598153965632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44676,DS-5bc7888b-7d3f-4442-9c86-fad4a01356bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-9db9504f-0587-4d84-b3e6-854d8c043e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-7e820b1f-8b42-4107-a725-01c68ff53ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-d1a64cf3-504e-4142-9bff-c419f6855aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-294f30a9-bcd9-4ca5-842b-888020a03333,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-ed4c911c-20d4-4a4f-8c33-e11fd447ffe6,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-831a424b-0b93-4a96-bbef-3640a09cd087,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-d94b2dfc-5c28-43cf-ac1c-fa0b425c2ad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798313652-172.17.0.18-1598153965632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44676,DS-5bc7888b-7d3f-4442-9c86-fad4a01356bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-9db9504f-0587-4d84-b3e6-854d8c043e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-7e820b1f-8b42-4107-a725-01c68ff53ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-d1a64cf3-504e-4142-9bff-c419f6855aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-294f30a9-bcd9-4ca5-842b-888020a03333,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-ed4c911c-20d4-4a4f-8c33-e11fd447ffe6,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-831a424b-0b93-4a96-bbef-3640a09cd087,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-d94b2dfc-5c28-43cf-ac1c-fa0b425c2ad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1616012319-172.17.0.18-1598154653107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42258,DS-72c5f644-42d1-431a-8363-1298c04b1479,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-a849a618-2b08-4a06-b7f0-5456ee083f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-22687f84-f308-433a-8bf0-0bd256218126,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-5534423f-2658-4880-9f92-f581626f8681,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-66b9731c-cefc-4e86-aeb8-01712a1cf98e,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-074572b7-9931-4dc4-8c86-bd4d03e78a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-b6e00e02-81e7-4a02-87a5-1192ab12fb27,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-e5f452ed-85e2-46b2-a044-1edce698214b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1616012319-172.17.0.18-1598154653107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42258,DS-72c5f644-42d1-431a-8363-1298c04b1479,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-a849a618-2b08-4a06-b7f0-5456ee083f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-22687f84-f308-433a-8bf0-0bd256218126,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-5534423f-2658-4880-9f92-f581626f8681,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-66b9731c-cefc-4e86-aeb8-01712a1cf98e,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-074572b7-9931-4dc4-8c86-bd4d03e78a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-b6e00e02-81e7-4a02-87a5-1192ab12fb27,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-e5f452ed-85e2-46b2-a044-1edce698214b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-757207799-172.17.0.18-1598155123805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44352,DS-27f4ecf1-0c98-4927-be76-0fa08dfe20c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-f5a7f034-a6c1-47f4-bd2e-e6f4c92b33eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-757eef1c-5b1e-48f4-8ee8-2df0e7cf0dda,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-ed328b5c-0eae-4069-937e-15cb332bfea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-29e94478-b971-499c-a241-0c573cd6378a,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-7efc24ab-1cc7-4e6c-8b7f-e662489557b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-e607cff7-3f8d-4dc9-8bb7-a3f2128d974d,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-380442b6-6ced-4d3b-ba84-644ec1100860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-757207799-172.17.0.18-1598155123805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44352,DS-27f4ecf1-0c98-4927-be76-0fa08dfe20c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-f5a7f034-a6c1-47f4-bd2e-e6f4c92b33eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-757eef1c-5b1e-48f4-8ee8-2df0e7cf0dda,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-ed328b5c-0eae-4069-937e-15cb332bfea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-29e94478-b971-499c-a241-0c573cd6378a,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-7efc24ab-1cc7-4e6c-8b7f-e662489557b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-e607cff7-3f8d-4dc9-8bb7-a3f2128d974d,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-380442b6-6ced-4d3b-ba84-644ec1100860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-797876822-172.17.0.18-1598155634378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39944,DS-efa5ffac-3da5-4cdc-bda6-0c138736849c,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-df234fc5-e5b6-4391-888a-de58f00b022d,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-19b26efe-533d-4d47-89a2-59c684e44ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-f834916d-bb2b-4280-af25-ddfd8385b052,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-ddb6fbbc-2d93-4f1a-9a16-c4a1cbd6332c,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-c75d7d10-192a-42aa-b5e1-303c98aad830,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-e21bf16b-fd9a-4085-91ec-3e10722ff7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-398795e9-a704-44d0-abb1-f3536b43fba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-797876822-172.17.0.18-1598155634378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39944,DS-efa5ffac-3da5-4cdc-bda6-0c138736849c,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-df234fc5-e5b6-4391-888a-de58f00b022d,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-19b26efe-533d-4d47-89a2-59c684e44ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-f834916d-bb2b-4280-af25-ddfd8385b052,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-ddb6fbbc-2d93-4f1a-9a16-c4a1cbd6332c,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-c75d7d10-192a-42aa-b5e1-303c98aad830,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-e21bf16b-fd9a-4085-91ec-3e10722ff7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-398795e9-a704-44d0-abb1-f3536b43fba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539509794-172.17.0.18-1598156035458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40047,DS-0b6bd70a-b182-4eec-9eeb-c45cfc42aef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-9cb44b3b-160e-47cd-84f6-590cb497657c,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-62a45531-d729-4b5a-bc20-a1e164bdbeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-3fa90a5e-e910-4ec2-8f9a-4dcb0872d232,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-f070e1b5-ecbf-40b3-9a1a-b9d0536fe1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-8b971e39-697f-471b-9784-d103c78ad125,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-2262b390-c8a8-4b47-9cb4-03697908a87e,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-dbfe4a8a-ded7-4b39-83ed-9598bb289f08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539509794-172.17.0.18-1598156035458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40047,DS-0b6bd70a-b182-4eec-9eeb-c45cfc42aef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-9cb44b3b-160e-47cd-84f6-590cb497657c,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-62a45531-d729-4b5a-bc20-a1e164bdbeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-3fa90a5e-e910-4ec2-8f9a-4dcb0872d232,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-f070e1b5-ecbf-40b3-9a1a-b9d0536fe1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-8b971e39-697f-471b-9784-d103c78ad125,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-2262b390-c8a8-4b47-9cb4-03697908a87e,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-dbfe4a8a-ded7-4b39-83ed-9598bb289f08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096442750-172.17.0.18-1598156380121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37376,DS-650fc86e-4c98-437b-814f-29383cd5feab,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-963db02a-ce19-4603-9a7d-c162a5879979,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-57256c93-1faf-408b-b115-c654c3fe6271,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-6d985e0c-401f-4009-8829-fd4648fe03cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-f047fcdd-42e3-41fb-8665-9b16ed8f8c00,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-61ec9783-ef61-411b-8d26-59322e54ff05,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-d4badcfc-2923-4cd1-82a8-d194a8a0fb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-f3a0ccc4-2aa9-434e-9972-21eb87084d12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096442750-172.17.0.18-1598156380121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37376,DS-650fc86e-4c98-437b-814f-29383cd5feab,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-963db02a-ce19-4603-9a7d-c162a5879979,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-57256c93-1faf-408b-b115-c654c3fe6271,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-6d985e0c-401f-4009-8829-fd4648fe03cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-f047fcdd-42e3-41fb-8665-9b16ed8f8c00,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-61ec9783-ef61-411b-8d26-59322e54ff05,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-d4badcfc-2923-4cd1-82a8-d194a8a0fb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-f3a0ccc4-2aa9-434e-9972-21eb87084d12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-640341332-172.17.0.18-1598157480787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37533,DS-4b3f541f-fa14-4dc2-a167-05a7d8dfad69,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-7a3cb54d-75d9-40aa-9e95-0f58d5910bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-a47b5703-4bd9-4d0d-93eb-2e4789664514,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-c4eddc6d-993a-4d6f-adf0-16a9058c4fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-b52e31f6-00bb-4814-9dd2-2d8ff49e8f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-96a6b349-e7a9-4f89-abb0-6bd766fddb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-a866e751-170d-498c-86ce-0f25b09e54b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-d68732c9-b15a-45f3-853b-3d11f86f9d7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-640341332-172.17.0.18-1598157480787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37533,DS-4b3f541f-fa14-4dc2-a167-05a7d8dfad69,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-7a3cb54d-75d9-40aa-9e95-0f58d5910bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-a47b5703-4bd9-4d0d-93eb-2e4789664514,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-c4eddc6d-993a-4d6f-adf0-16a9058c4fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-b52e31f6-00bb-4814-9dd2-2d8ff49e8f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34235,DS-96a6b349-e7a9-4f89-abb0-6bd766fddb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-a866e751-170d-498c-86ce-0f25b09e54b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-d68732c9-b15a-45f3-853b-3d11f86f9d7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242587859-172.17.0.18-1598157516191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36973,DS-f765bbb8-b6c0-4db0-ac2e-d6251eff8054,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-c62f4808-5379-4c97-937b-811d67706415,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-97c27320-94c4-42a1-926d-3719f884d4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-70ba8a95-d11d-440c-b3b0-70ef0d99b99e,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-44256622-4a7b-40d4-b527-d5309e0bf573,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-1875991d-447f-497b-988c-e56157a85531,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-0d46e22a-b5f7-4224-a655-082b492aee2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-eb107f24-afbf-4a87-bcaa-230d7eb70846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242587859-172.17.0.18-1598157516191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36973,DS-f765bbb8-b6c0-4db0-ac2e-d6251eff8054,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-c62f4808-5379-4c97-937b-811d67706415,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-97c27320-94c4-42a1-926d-3719f884d4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-70ba8a95-d11d-440c-b3b0-70ef0d99b99e,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-44256622-4a7b-40d4-b527-d5309e0bf573,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-1875991d-447f-497b-988c-e56157a85531,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-0d46e22a-b5f7-4224-a655-082b492aee2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-eb107f24-afbf-4a87-bcaa-230d7eb70846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829658328-172.17.0.18-1598158001687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46355,DS-62616a83-8f15-4de5-a149-b3ca0f7ec958,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-1a5ea8d7-e93b-43cd-8368-839d686c1023,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-5e8279f3-5de1-4da6-9f83-03c7e7409f29,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-fe3e9c6f-e52f-4c28-8f77-a7d9f4beb2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-5aaa9725-1d68-4ecd-8217-5ff602bc8912,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-17b5743f-64f6-4251-a00f-50b12645982b,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-63dfe91b-0041-478d-9b5e-5d2d810b800f,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-f70e1e62-2308-4429-a055-d057d472501c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829658328-172.17.0.18-1598158001687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46355,DS-62616a83-8f15-4de5-a149-b3ca0f7ec958,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-1a5ea8d7-e93b-43cd-8368-839d686c1023,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-5e8279f3-5de1-4da6-9f83-03c7e7409f29,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-fe3e9c6f-e52f-4c28-8f77-a7d9f4beb2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-5aaa9725-1d68-4ecd-8217-5ff602bc8912,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-17b5743f-64f6-4251-a00f-50b12645982b,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-63dfe91b-0041-478d-9b5e-5d2d810b800f,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-f70e1e62-2308-4429-a055-d057d472501c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496502623-172.17.0.18-1598158574009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45763,DS-33d5e6f4-1777-4c31-bbb6-772a22b7e622,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-958bd923-f055-4159-a5a8-2e733bd518ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-33d08b84-bd9c-47bf-99d8-56fbfcfcc41a,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-cd54010b-748d-4427-99cb-e5163a26b422,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-36e47d6b-cc22-4587-b662-10a73004bf30,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-7282138e-ec34-4b6a-b944-bcf35669f011,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-11ecd1b2-1765-4f48-ab04-4cc34e538986,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-ebd5a33e-f8fd-4830-a75d-18a4cc69c0e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496502623-172.17.0.18-1598158574009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45763,DS-33d5e6f4-1777-4c31-bbb6-772a22b7e622,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-958bd923-f055-4159-a5a8-2e733bd518ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-33d08b84-bd9c-47bf-99d8-56fbfcfcc41a,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-cd54010b-748d-4427-99cb-e5163a26b422,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-36e47d6b-cc22-4587-b662-10a73004bf30,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-7282138e-ec34-4b6a-b944-bcf35669f011,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-11ecd1b2-1765-4f48-ab04-4cc34e538986,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-ebd5a33e-f8fd-4830-a75d-18a4cc69c0e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513111438-172.17.0.18-1598158724977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41127,DS-3ebee310-dd88-4277-aca6-dfabc9e89c04,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-a573389a-0bc8-4317-893e-8811c731ce3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-f305f1a5-7b83-449c-a790-18734fbed098,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-a4a048c3-9771-4121-853d-d874f312ca38,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-c5d6e4b2-4015-4fc4-81f1-1d76f7a32fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-3460633b-0998-4e09-8641-6625caeffa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-78653c67-f731-4044-baa8-1c70b901699b,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-0c8e5008-f3b2-4c47-af63-75b6264192ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513111438-172.17.0.18-1598158724977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41127,DS-3ebee310-dd88-4277-aca6-dfabc9e89c04,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-a573389a-0bc8-4317-893e-8811c731ce3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-f305f1a5-7b83-449c-a790-18734fbed098,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-a4a048c3-9771-4121-853d-d874f312ca38,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-c5d6e4b2-4015-4fc4-81f1-1d76f7a32fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-3460633b-0998-4e09-8641-6625caeffa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-78653c67-f731-4044-baa8-1c70b901699b,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-0c8e5008-f3b2-4c47-af63-75b6264192ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5353
