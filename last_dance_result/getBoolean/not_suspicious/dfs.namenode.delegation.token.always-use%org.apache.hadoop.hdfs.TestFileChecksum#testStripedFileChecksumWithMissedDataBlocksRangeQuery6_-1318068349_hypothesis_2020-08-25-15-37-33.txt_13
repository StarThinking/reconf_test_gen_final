reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41587029-172.17.0.19-1598369939441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40319,DS-3c0d6fd7-1881-4366-b6e4-46fcd334f521,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-7186578f-5169-4507-ba67-c351faa17e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-97482e68-6e40-422a-82c2-16d8e2f56f19,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-61dc7ab1-61bf-4439-8f7e-9f71aedf5c35,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-9526e16c-88b2-486a-9f4c-9a8228a5ca56,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-da577c28-c667-4afb-995c-0b996b15d387,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-4423e944-efa0-4870-9355-4a34a09cabd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-2b4aea21-9bbe-4900-a957-01e0be46a754,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41587029-172.17.0.19-1598369939441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40319,DS-3c0d6fd7-1881-4366-b6e4-46fcd334f521,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-7186578f-5169-4507-ba67-c351faa17e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-97482e68-6e40-422a-82c2-16d8e2f56f19,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-61dc7ab1-61bf-4439-8f7e-9f71aedf5c35,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-9526e16c-88b2-486a-9f4c-9a8228a5ca56,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-da577c28-c667-4afb-995c-0b996b15d387,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-4423e944-efa0-4870-9355-4a34a09cabd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-2b4aea21-9bbe-4900-a957-01e0be46a754,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304134620-172.17.0.19-1598370201236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37167,DS-c14dba99-f498-4d81-baaa-dbefedf417f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-297e87b2-c280-47ae-8c0e-99cc9233ed36,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-1e2d57fb-5993-4f36-82bc-dc5cf20ef79a,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-39b7b547-844f-4c8a-9819-befa53e7d91f,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-e0de7cdd-31e6-4647-8a08-d12b11e2a7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-081fff7d-b017-4a97-b623-ef55d5c208c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-f0f8ffaf-63fe-4dec-be78-dd029cef0419,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-1b258fc0-4158-4c22-b5f6-4b1e29a437c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304134620-172.17.0.19-1598370201236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37167,DS-c14dba99-f498-4d81-baaa-dbefedf417f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-297e87b2-c280-47ae-8c0e-99cc9233ed36,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-1e2d57fb-5993-4f36-82bc-dc5cf20ef79a,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-39b7b547-844f-4c8a-9819-befa53e7d91f,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-e0de7cdd-31e6-4647-8a08-d12b11e2a7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-081fff7d-b017-4a97-b623-ef55d5c208c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-f0f8ffaf-63fe-4dec-be78-dd029cef0419,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-1b258fc0-4158-4c22-b5f6-4b1e29a437c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256790435-172.17.0.19-1598370449713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44524,DS-e2c27252-2e1e-4296-892f-7452ec0321c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-c59670b5-9573-4dba-b285-fa6ae0b0de4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-fe3d87da-36b6-45d8-b4a4-5cd1adb8f04f,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-70d5dfe9-1f71-432e-a906-80b9389bd71d,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-e7469081-21db-4403-b120-e215152bd273,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-86a725d4-e513-4281-a728-e3b069c55e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-1c30f49d-d4e1-4f52-b161-50a9a67230c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-fb9d33ea-1434-490f-bf69-da5567740f53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256790435-172.17.0.19-1598370449713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44524,DS-e2c27252-2e1e-4296-892f-7452ec0321c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-c59670b5-9573-4dba-b285-fa6ae0b0de4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-fe3d87da-36b6-45d8-b4a4-5cd1adb8f04f,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-70d5dfe9-1f71-432e-a906-80b9389bd71d,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-e7469081-21db-4403-b120-e215152bd273,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-86a725d4-e513-4281-a728-e3b069c55e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-1c30f49d-d4e1-4f52-b161-50a9a67230c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-fb9d33ea-1434-490f-bf69-da5567740f53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114170546-172.17.0.19-1598370630555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38060,DS-f595c538-04d9-4fdf-a974-ce176e135e10,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-7abfe6d3-b687-4978-8dae-f76b1c165380,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-14fa13f3-1dc3-453e-9e9d-61762b691fae,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-14dde76b-73c2-49b7-919f-9dd374ed9f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-f4f6e354-4970-4847-82cd-f31fefb52948,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-48bee43d-8892-4d0f-95f6-680999e87f99,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-d191895e-8da2-4f5d-949c-533bddbe3a51,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-1c966110-2110-4afb-8781-581e84bcb035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114170546-172.17.0.19-1598370630555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38060,DS-f595c538-04d9-4fdf-a974-ce176e135e10,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-7abfe6d3-b687-4978-8dae-f76b1c165380,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-14fa13f3-1dc3-453e-9e9d-61762b691fae,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-14dde76b-73c2-49b7-919f-9dd374ed9f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-f4f6e354-4970-4847-82cd-f31fefb52948,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-48bee43d-8892-4d0f-95f6-680999e87f99,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-d191895e-8da2-4f5d-949c-533bddbe3a51,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-1c966110-2110-4afb-8781-581e84bcb035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438695122-172.17.0.19-1598370702284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40625,DS-cfe7aaf6-f969-4851-a0f8-8ee7ddf36a83,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-4e97a884-dd2f-41aa-a4b0-66b95db66996,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-4d7d2c8e-ead2-4adb-831b-7a8b9bd76c68,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-8636edaf-21dd-49b4-9821-8d0987547d86,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-67f634c0-5fb6-4113-b0b2-08ff1c534980,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-4c87d7f2-7e58-4523-9d39-a17001c0d36b,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-d7044a20-c4ef-44c7-85d9-154e0b4c8cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-17a3edf5-19e1-4fca-96ef-3625acc9997d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1438695122-172.17.0.19-1598370702284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40625,DS-cfe7aaf6-f969-4851-a0f8-8ee7ddf36a83,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-4e97a884-dd2f-41aa-a4b0-66b95db66996,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-4d7d2c8e-ead2-4adb-831b-7a8b9bd76c68,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-8636edaf-21dd-49b4-9821-8d0987547d86,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-67f634c0-5fb6-4113-b0b2-08ff1c534980,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-4c87d7f2-7e58-4523-9d39-a17001c0d36b,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-d7044a20-c4ef-44c7-85d9-154e0b4c8cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-17a3edf5-19e1-4fca-96ef-3625acc9997d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135743576-172.17.0.19-1598370736748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38694,DS-f4c8cc56-31f6-41d2-987b-4e6b38ba1781,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-c1450de5-2456-461b-a234-021d6cb79a26,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-c05b3137-f128-4f0c-b3a9-9daefe02a8da,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-688ac54f-95e6-49ab-9c75-59aa5f658cef,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-1192f8c3-a35a-4148-b80a-79d13301bad7,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-1e5d7a84-d024-4816-b9f1-add5283de00d,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-5e3fb39b-f9c8-4882-b4e4-05d17de772f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-248b0343-fff6-4521-92de-6a99d4662dd9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135743576-172.17.0.19-1598370736748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38694,DS-f4c8cc56-31f6-41d2-987b-4e6b38ba1781,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-c1450de5-2456-461b-a234-021d6cb79a26,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-c05b3137-f128-4f0c-b3a9-9daefe02a8da,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-688ac54f-95e6-49ab-9c75-59aa5f658cef,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-1192f8c3-a35a-4148-b80a-79d13301bad7,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-1e5d7a84-d024-4816-b9f1-add5283de00d,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-5e3fb39b-f9c8-4882-b4e4-05d17de772f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-248b0343-fff6-4521-92de-6a99d4662dd9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673876818-172.17.0.19-1598370807514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44685,DS-77ee0e63-0b61-463d-b20c-a22015f7f193,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-21b7c7f6-adc2-4d39-8586-6e98271d979c,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-248da887-2d60-484f-9599-01a528f3f20c,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-d407bd1d-6f43-4ae5-89e0-47f06ab57d39,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-55abadb2-1ac6-47e0-8c1c-a0b9ddb1c90b,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-aa79f7f3-b4f1-4e80-9e89-3714a1e79484,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-2baf3c02-face-436a-aedc-006401bf020e,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-4e063b07-c96d-4fc6-95f5-267358da1651,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673876818-172.17.0.19-1598370807514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44685,DS-77ee0e63-0b61-463d-b20c-a22015f7f193,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-21b7c7f6-adc2-4d39-8586-6e98271d979c,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-248da887-2d60-484f-9599-01a528f3f20c,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-d407bd1d-6f43-4ae5-89e0-47f06ab57d39,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-55abadb2-1ac6-47e0-8c1c-a0b9ddb1c90b,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-aa79f7f3-b4f1-4e80-9e89-3714a1e79484,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-2baf3c02-face-436a-aedc-006401bf020e,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-4e063b07-c96d-4fc6-95f5-267358da1651,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027176406-172.17.0.19-1598371319661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45294,DS-4ce0d0e9-94a8-484e-8cd7-d6fc5c00052c,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-7d27d1ba-80d3-48d1-a8d4-c0a5a8fd9524,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-033de88a-a3be-479f-b3f9-c60bc7bb7d96,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-6867041f-20af-434f-97e5-4729de28bcff,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-b2d380bc-c7da-44c1-8c71-7dd374165de4,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-f48cb9cb-71eb-4077-9820-4eaa4705bcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-3f120bae-00ff-4d55-bbd9-461c19c2579a,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-df64fe85-7cf9-4f52-a227-b0fdaf819282,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027176406-172.17.0.19-1598371319661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45294,DS-4ce0d0e9-94a8-484e-8cd7-d6fc5c00052c,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-7d27d1ba-80d3-48d1-a8d4-c0a5a8fd9524,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-033de88a-a3be-479f-b3f9-c60bc7bb7d96,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-6867041f-20af-434f-97e5-4729de28bcff,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-b2d380bc-c7da-44c1-8c71-7dd374165de4,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-f48cb9cb-71eb-4077-9820-4eaa4705bcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-3f120bae-00ff-4d55-bbd9-461c19c2579a,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-df64fe85-7cf9-4f52-a227-b0fdaf819282,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101599766-172.17.0.19-1598371498927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38228,DS-37989ee2-6ea7-4cb1-ae56-5a358a3a2f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-5d14f911-a425-497d-86e8-db01353e9b19,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-5bfa3533-3921-42bb-adae-cb60512748db,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-97dd4c57-6ca9-42d8-8532-829084b1f9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-434892ac-3f8b-4475-9a61-20773c294b70,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-54853291-6bab-4f91-b43f-ade81f1a1bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-f00f97b9-f4dc-4490-88a3-ef6fa25893eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-5dc3a155-2349-45e3-bdf1-269ac4427054,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101599766-172.17.0.19-1598371498927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38228,DS-37989ee2-6ea7-4cb1-ae56-5a358a3a2f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-5d14f911-a425-497d-86e8-db01353e9b19,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-5bfa3533-3921-42bb-adae-cb60512748db,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-97dd4c57-6ca9-42d8-8532-829084b1f9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-434892ac-3f8b-4475-9a61-20773c294b70,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-54853291-6bab-4f91-b43f-ade81f1a1bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-f00f97b9-f4dc-4490-88a3-ef6fa25893eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-5dc3a155-2349-45e3-bdf1-269ac4427054,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386444552-172.17.0.19-1598371581648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41400,DS-a6aab0ef-b1b8-4633-a0d2-602ed01d4c98,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-d98650ad-05ee-4226-9f9c-04732eb8ff01,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-4d813a43-84aa-4782-92f9-e55ec5e4dcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-3361c147-c222-4637-a95b-4869805a8f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-b8bc0991-3c9f-434c-98e3-d28ca334276f,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-65730d8f-bd13-489d-9067-db8fc4be2ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-ec571519-fb73-4785-af47-321c4f6af448,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-615219f4-faee-47ac-a832-620d30ea97f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386444552-172.17.0.19-1598371581648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41400,DS-a6aab0ef-b1b8-4633-a0d2-602ed01d4c98,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-d98650ad-05ee-4226-9f9c-04732eb8ff01,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-4d813a43-84aa-4782-92f9-e55ec5e4dcf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-3361c147-c222-4637-a95b-4869805a8f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-b8bc0991-3c9f-434c-98e3-d28ca334276f,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-65730d8f-bd13-489d-9067-db8fc4be2ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-ec571519-fb73-4785-af47-321c4f6af448,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-615219f4-faee-47ac-a832-620d30ea97f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520785280-172.17.0.19-1598371805077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41263,DS-227c49e7-8881-4f20-abcf-6346c45f52d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-a089dd27-36c2-48b8-be3e-38bf86e65c89,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-148cfd03-3c32-4ba6-886c-295f89c9e814,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-a9613747-6267-4ad7-82d2-257ce5ffa50d,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-a26c9ce7-3c5f-480b-a26f-7faff04d7d73,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-5d677738-6a1d-4d14-a138-2330ae527db7,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-ec975458-f72a-457a-ae45-960fe8f18404,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-8d001646-7a83-4ac7-acae-71f9e9f69ce7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520785280-172.17.0.19-1598371805077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41263,DS-227c49e7-8881-4f20-abcf-6346c45f52d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-a089dd27-36c2-48b8-be3e-38bf86e65c89,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-148cfd03-3c32-4ba6-886c-295f89c9e814,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-a9613747-6267-4ad7-82d2-257ce5ffa50d,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-a26c9ce7-3c5f-480b-a26f-7faff04d7d73,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-5d677738-6a1d-4d14-a138-2330ae527db7,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-ec975458-f72a-457a-ae45-960fe8f18404,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-8d001646-7a83-4ac7-acae-71f9e9f69ce7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993856905-172.17.0.19-1598372206327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33221,DS-c8c9fd41-7990-43a2-a31a-149216d5788d,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-5a6eba3a-bae9-4745-8fbb-0986c6fb946b,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-6bd1cee7-9416-41ff-84cd-97f9650d1a14,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-cec1475d-efb0-4475-8536-fb3a2acd9abd,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-e887717a-fb83-44a8-9364-82fdd9dfc0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-8fbee2ba-92a7-41b1-99bf-1c83434409cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-6a55bf34-f96c-4851-b384-00caeacf23f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-220c13aa-77c6-4fa8-8418-cc11edbd2c20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993856905-172.17.0.19-1598372206327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33221,DS-c8c9fd41-7990-43a2-a31a-149216d5788d,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-5a6eba3a-bae9-4745-8fbb-0986c6fb946b,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-6bd1cee7-9416-41ff-84cd-97f9650d1a14,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-cec1475d-efb0-4475-8536-fb3a2acd9abd,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-e887717a-fb83-44a8-9364-82fdd9dfc0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-8fbee2ba-92a7-41b1-99bf-1c83434409cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-6a55bf34-f96c-4851-b384-00caeacf23f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-220c13aa-77c6-4fa8-8418-cc11edbd2c20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271940897-172.17.0.19-1598372279369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34462,DS-5c82ed5e-817c-4b70-84d6-bf76c731f396,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-4342dc81-905c-4bf0-94bf-12fe3d321d41,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-70c949c2-3875-4d3b-aac2-dce81a60bba8,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-a932956c-8da9-4627-a668-35be843665f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-d32da1e5-561a-444f-93e5-e39d4dcd4c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-a117906a-76d8-4717-b4dd-c888fe178da3,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-5658ad71-802b-4c10-8cbb-952508dc7ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-4b99d49d-c0d1-49a8-a157-c7a022343ef6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271940897-172.17.0.19-1598372279369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34462,DS-5c82ed5e-817c-4b70-84d6-bf76c731f396,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-4342dc81-905c-4bf0-94bf-12fe3d321d41,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-70c949c2-3875-4d3b-aac2-dce81a60bba8,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-a932956c-8da9-4627-a668-35be843665f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-d32da1e5-561a-444f-93e5-e39d4dcd4c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-a117906a-76d8-4717-b4dd-c888fe178da3,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-5658ad71-802b-4c10-8cbb-952508dc7ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-4b99d49d-c0d1-49a8-a157-c7a022343ef6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921812702-172.17.0.19-1598372436598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33463,DS-147fad27-968b-4f55-8a5c-d1b917d4bbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-d122ec96-87c3-4fe1-816e-9776ad5a22dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-688ae534-6b6d-4e2f-9d09-8f6a5191ede1,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-835591ba-cd9b-42bb-a70d-496af9dd50de,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-29a8b919-1f66-41ad-817c-49da58e0ed0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-fadbc851-b0fe-435d-95d1-9a2747fb8586,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-a70c7576-e075-4f7e-b002-3fa010610219,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-03264f02-0184-46cb-a82b-aa93dbfa03e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921812702-172.17.0.19-1598372436598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33463,DS-147fad27-968b-4f55-8a5c-d1b917d4bbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-d122ec96-87c3-4fe1-816e-9776ad5a22dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-688ae534-6b6d-4e2f-9d09-8f6a5191ede1,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-835591ba-cd9b-42bb-a70d-496af9dd50de,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-29a8b919-1f66-41ad-817c-49da58e0ed0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-fadbc851-b0fe-435d-95d1-9a2747fb8586,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-a70c7576-e075-4f7e-b002-3fa010610219,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-03264f02-0184-46cb-a82b-aa93dbfa03e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818871454-172.17.0.19-1598372475667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42871,DS-06a60ec9-2c77-4663-b069-df7c18a72b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-1d86cc67-b8d0-46d5-a16f-5ad574d77ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-0898b4d7-8a9d-4dc2-bf73-43009cf52b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-11a17f2e-b486-4950-a046-55e52c16c47b,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-3aa375cf-cdff-4f0f-9a0a-0e2668886720,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-caac1e6d-b779-4e7c-a937-bf8bb603953b,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-a9aee51f-0fb2-4251-b511-572eb7d25150,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-006b1484-b937-4fdf-9fa2-f202cd9af642,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818871454-172.17.0.19-1598372475667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42871,DS-06a60ec9-2c77-4663-b069-df7c18a72b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-1d86cc67-b8d0-46d5-a16f-5ad574d77ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-0898b4d7-8a9d-4dc2-bf73-43009cf52b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-11a17f2e-b486-4950-a046-55e52c16c47b,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-3aa375cf-cdff-4f0f-9a0a-0e2668886720,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-caac1e6d-b779-4e7c-a937-bf8bb603953b,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-a9aee51f-0fb2-4251-b511-572eb7d25150,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-006b1484-b937-4fdf-9fa2-f202cd9af642,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1262750549-172.17.0.19-1598372591443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42368,DS-954a02e4-5dee-4b15-8774-669a01c69943,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-3bfe32fc-d3a5-4870-8aaf-aff615350e68,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-04030275-765d-4428-85bf-cd6fef7ca405,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-b812c890-2ae4-41e1-8759-2eb911aeedd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-499d52cd-7872-47f2-b89a-cb8a4a22f65c,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-ff4e52e4-9110-48bb-aee8-d82ea6340358,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-2ba0477a-1357-45d9-ab54-ea243410a782,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-e0e4e054-6c3b-47e3-aa7f-26cfd6e78778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1262750549-172.17.0.19-1598372591443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42368,DS-954a02e4-5dee-4b15-8774-669a01c69943,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-3bfe32fc-d3a5-4870-8aaf-aff615350e68,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-04030275-765d-4428-85bf-cd6fef7ca405,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-b812c890-2ae4-41e1-8759-2eb911aeedd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-499d52cd-7872-47f2-b89a-cb8a4a22f65c,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-ff4e52e4-9110-48bb-aee8-d82ea6340358,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-2ba0477a-1357-45d9-ab54-ea243410a782,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-e0e4e054-6c3b-47e3-aa7f-26cfd6e78778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427801727-172.17.0.19-1598372707619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37148,DS-cdd0e41a-2c5f-4e06-af67-ab59b4ecbd55,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-1fe79be9-0d6d-4c48-a60f-5962aad569dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-236f336c-68f5-4f26-8e7a-b9da9011be2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-efecc7c4-f41c-4f19-b0d7-6e84393377c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-8d1d917b-e0d3-44b7-82c4-93071c1a33d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-58cefe32-5732-4315-bf8b-e608f8120aec,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-71fe6e4f-8404-4bbf-9073-193a38c26ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-cbaaa749-5763-47f0-842f-3e9ca3c2092b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427801727-172.17.0.19-1598372707619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37148,DS-cdd0e41a-2c5f-4e06-af67-ab59b4ecbd55,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-1fe79be9-0d6d-4c48-a60f-5962aad569dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-236f336c-68f5-4f26-8e7a-b9da9011be2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-efecc7c4-f41c-4f19-b0d7-6e84393377c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-8d1d917b-e0d3-44b7-82c4-93071c1a33d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-58cefe32-5732-4315-bf8b-e608f8120aec,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-71fe6e4f-8404-4bbf-9073-193a38c26ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-cbaaa749-5763-47f0-842f-3e9ca3c2092b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939942732-172.17.0.19-1598372752093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37551,DS-51542f13-b190-489b-ad19-931bdacfbc01,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-22ff5753-c0b9-4343-ba14-c7bf1cf424a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-5940692f-c0e9-4df8-a537-8ba6ba989ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-448e3984-3b9e-42b3-afbb-c3ee2828a6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-0b0c338e-f8f5-41e2-9972-0eee0ff3ef32,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-a7d07685-2132-4e9e-bc75-f9aa6952c6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-6638b9d2-8b24-4cac-a728-48c6c922b481,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-da0ffa4c-d843-4597-b288-edf45dd5d34e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939942732-172.17.0.19-1598372752093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37551,DS-51542f13-b190-489b-ad19-931bdacfbc01,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-22ff5753-c0b9-4343-ba14-c7bf1cf424a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-5940692f-c0e9-4df8-a537-8ba6ba989ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-448e3984-3b9e-42b3-afbb-c3ee2828a6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-0b0c338e-f8f5-41e2-9972-0eee0ff3ef32,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-a7d07685-2132-4e9e-bc75-f9aa6952c6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-6638b9d2-8b24-4cac-a728-48c6c922b481,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-da0ffa4c-d843-4597-b288-edf45dd5d34e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297373661-172.17.0.19-1598373145680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-2ec2859f-4178-4683-983f-c914b7d6e889,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-2c1eae26-23b5-4f47-82e8-af523a77afad,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-3def7f40-ae97-4e43-9b62-fd2b3f746084,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-03178796-aebf-471d-9980-6972c4d9e187,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-fefdd5bc-a798-4e7b-9d5e-161ceb694465,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-2c0e984b-fb7f-4ca8-8649-2274bf63c249,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-dd8a1d6a-f831-427c-9e14-43801e1a32b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-a7780723-90eb-4bf5-8541-ecf1f7ae1f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297373661-172.17.0.19-1598373145680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-2ec2859f-4178-4683-983f-c914b7d6e889,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-2c1eae26-23b5-4f47-82e8-af523a77afad,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-3def7f40-ae97-4e43-9b62-fd2b3f746084,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-03178796-aebf-471d-9980-6972c4d9e187,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-fefdd5bc-a798-4e7b-9d5e-161ceb694465,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-2c0e984b-fb7f-4ca8-8649-2274bf63c249,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-dd8a1d6a-f831-427c-9e14-43801e1a32b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-a7780723-90eb-4bf5-8541-ecf1f7ae1f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056464024-172.17.0.19-1598373346258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42173,DS-b05b9f01-0ae0-47e7-90ee-ead43438fca3,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-e1801883-3223-42f8-ba24-0aa3b8adc2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-1661cc31-2c0e-4ca3-8bb1-236dcafcc567,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-f4951b3a-4787-419d-b469-e254af4d7294,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-35388a94-68f9-4c68-920e-fae1c5775c95,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-c52beada-3964-40c0-8240-f5c62b929540,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-bf532aa1-7fd4-47be-958d-c016421ed485,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-1f4b9539-2dfc-4fe0-9342-113589ee1631,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056464024-172.17.0.19-1598373346258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42173,DS-b05b9f01-0ae0-47e7-90ee-ead43438fca3,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-e1801883-3223-42f8-ba24-0aa3b8adc2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-1661cc31-2c0e-4ca3-8bb1-236dcafcc567,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-f4951b3a-4787-419d-b469-e254af4d7294,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-35388a94-68f9-4c68-920e-fae1c5775c95,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-c52beada-3964-40c0-8240-f5c62b929540,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-bf532aa1-7fd4-47be-958d-c016421ed485,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-1f4b9539-2dfc-4fe0-9342-113589ee1631,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945974939-172.17.0.19-1598373422093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43127,DS-26709a1a-51a3-4699-abfe-1da012b86f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-c4cfbab4-686e-47e7-aaa9-88f0eadf1ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-9737c09a-ab89-4c68-b2cf-fbac7118c33f,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-722c56b3-332d-43b3-ac2a-823131662688,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-292e143d-21c4-4d5e-8fde-75ecaba1f8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-cf7ce280-eb17-4240-b973-93d77d217bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-cd79f535-dc22-4511-ab59-c18be4e9ce08,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-52e9b371-c602-48be-a557-2d57c2c44152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945974939-172.17.0.19-1598373422093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43127,DS-26709a1a-51a3-4699-abfe-1da012b86f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-c4cfbab4-686e-47e7-aaa9-88f0eadf1ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-9737c09a-ab89-4c68-b2cf-fbac7118c33f,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-722c56b3-332d-43b3-ac2a-823131662688,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-292e143d-21c4-4d5e-8fde-75ecaba1f8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-cf7ce280-eb17-4240-b973-93d77d217bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-cd79f535-dc22-4511-ab59-c18be4e9ce08,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-52e9b371-c602-48be-a557-2d57c2c44152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487438103-172.17.0.19-1598373503649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43373,DS-6eb12485-09b9-427d-8563-448493ebd6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-d792d738-5151-441d-be5b-5bb287108fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-3d443096-a054-486c-8e11-d856f90ee9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-2068388a-a9cd-4dc1-b6e3-cf9846ae4c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-6c4b0cb3-b18e-471b-83e8-c10005682d42,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-42d7fbf2-12d5-443c-8ae8-5574f6f3ae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-9bcbcca1-a162-472d-9b11-2a4b21795d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-2d3668e7-aaff-42b7-94ae-22ac3c4ed593,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487438103-172.17.0.19-1598373503649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43373,DS-6eb12485-09b9-427d-8563-448493ebd6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-d792d738-5151-441d-be5b-5bb287108fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-3d443096-a054-486c-8e11-d856f90ee9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-2068388a-a9cd-4dc1-b6e3-cf9846ae4c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-6c4b0cb3-b18e-471b-83e8-c10005682d42,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-42d7fbf2-12d5-443c-8ae8-5574f6f3ae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-9bcbcca1-a162-472d-9b11-2a4b21795d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-2d3668e7-aaff-42b7-94ae-22ac3c4ed593,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541388292-172.17.0.19-1598373651867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42840,DS-d2872c74-9ff9-481b-9270-541122dd34e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-1b227a2c-ed88-4877-b3c7-e3dd1c7b2865,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-3eb36dc5-4b71-4980-a2ab-2ca62045b3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-d9ccfd90-9330-44a4-a12d-b11cd238fc85,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-8fffd710-6927-4847-ac89-21754dbd08a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-984e3974-ba0c-430f-a9d9-54fd396345b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-d19c966e-c5aa-4b35-b49c-994437239911,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-253f87bb-5dc9-467e-93c7-ce86a6564872,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541388292-172.17.0.19-1598373651867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42840,DS-d2872c74-9ff9-481b-9270-541122dd34e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-1b227a2c-ed88-4877-b3c7-e3dd1c7b2865,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-3eb36dc5-4b71-4980-a2ab-2ca62045b3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-d9ccfd90-9330-44a4-a12d-b11cd238fc85,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-8fffd710-6927-4847-ac89-21754dbd08a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-984e3974-ba0c-430f-a9d9-54fd396345b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-d19c966e-c5aa-4b35-b49c-994437239911,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-253f87bb-5dc9-467e-93c7-ce86a6564872,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1513884484-172.17.0.19-1598373730782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46749,DS-02a23466-8100-4d05-bbfe-cd0dad286c70,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-7af37445-2e60-47e4-9fd6-b5e2590f33b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-8a04d37e-d3fc-47d9-bbe8-cf27350f5097,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-f52848f3-6a8b-4426-b156-23f2b15e6471,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-d288f76f-1391-4978-9507-f77d8a34e179,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-4bf33f2c-4cc4-435c-8793-b2d49ab4f3da,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-887a49ed-04c3-405b-9ec3-b8003ca609de,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-79a6c2c4-3b1b-4471-a4a6-a35d0d5df923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1513884484-172.17.0.19-1598373730782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46749,DS-02a23466-8100-4d05-bbfe-cd0dad286c70,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-7af37445-2e60-47e4-9fd6-b5e2590f33b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-8a04d37e-d3fc-47d9-bbe8-cf27350f5097,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-f52848f3-6a8b-4426-b156-23f2b15e6471,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-d288f76f-1391-4978-9507-f77d8a34e179,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-4bf33f2c-4cc4-435c-8793-b2d49ab4f3da,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-887a49ed-04c3-405b-9ec3-b8003ca609de,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-79a6c2c4-3b1b-4471-a4a6-a35d0d5df923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759625505-172.17.0.19-1598373769874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41922,DS-6d183372-5a6a-448c-aeac-d94b06922a18,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-659b8f78-73f0-4763-9f48-219b82a3e3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-fb89fad5-efa6-4428-815f-1a33f5f7bbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-78768504-4abc-41eb-8c29-a203844eef93,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-1f372d47-059a-457b-b755-b35e35ac352c,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-2122eb61-6231-496c-98d8-791f3ab72a04,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-9392045f-dd00-4770-9b5f-da82949183d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-20c8d665-9760-4a47-831f-5f611462f5de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759625505-172.17.0.19-1598373769874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41922,DS-6d183372-5a6a-448c-aeac-d94b06922a18,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-659b8f78-73f0-4763-9f48-219b82a3e3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-fb89fad5-efa6-4428-815f-1a33f5f7bbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-78768504-4abc-41eb-8c29-a203844eef93,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-1f372d47-059a-457b-b755-b35e35ac352c,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-2122eb61-6231-496c-98d8-791f3ab72a04,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-9392045f-dd00-4770-9b5f-da82949183d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-20c8d665-9760-4a47-831f-5f611462f5de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103587454-172.17.0.19-1598373805534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33954,DS-49c078d2-936b-4ab9-b5f9-5fed3c211c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-d85bc8f1-51bb-4972-8e36-befe6e0b38e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-bda787f2-e424-4c43-a6fa-4b42786d8d72,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-0bddd457-aa84-4a87-9bdb-970a5286272b,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-e91f43a0-85cb-47d0-8f61-49e7959b50b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-34674655-3e5d-42ae-8a1d-c170e67af154,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-aaeb76bb-3172-46b9-8f36-10c5a374bae3,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-a8a852d8-d6a2-477b-ae43-00339a33db1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103587454-172.17.0.19-1598373805534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33954,DS-49c078d2-936b-4ab9-b5f9-5fed3c211c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-d85bc8f1-51bb-4972-8e36-befe6e0b38e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-bda787f2-e424-4c43-a6fa-4b42786d8d72,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-0bddd457-aa84-4a87-9bdb-970a5286272b,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-e91f43a0-85cb-47d0-8f61-49e7959b50b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-34674655-3e5d-42ae-8a1d-c170e67af154,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-aaeb76bb-3172-46b9-8f36-10c5a374bae3,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-a8a852d8-d6a2-477b-ae43-00339a33db1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585330539-172.17.0.19-1598373885750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42606,DS-93ba962b-6332-42a6-922f-908ff3b672eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-ff389ae0-7d93-48ac-bc15-07d33d0d7a03,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-b0793343-c23c-4e34-94ad-f0c0ca8ecef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-5a8e4f9a-60ff-4025-9f0c-254741ec9eee,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-6c341919-91f8-47aa-a418-99a5f120196b,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-de42ba59-ded4-4399-9338-44170726f127,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-c3649376-1715-417f-b344-f83a3d8aa167,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-3a0a77c5-a769-48e5-adbb-c90f5126d72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585330539-172.17.0.19-1598373885750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42606,DS-93ba962b-6332-42a6-922f-908ff3b672eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-ff389ae0-7d93-48ac-bc15-07d33d0d7a03,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-b0793343-c23c-4e34-94ad-f0c0ca8ecef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-5a8e4f9a-60ff-4025-9f0c-254741ec9eee,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-6c341919-91f8-47aa-a418-99a5f120196b,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-de42ba59-ded4-4399-9338-44170726f127,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-c3649376-1715-417f-b344-f83a3d8aa167,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-3a0a77c5-a769-48e5-adbb-c90f5126d72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846945784-172.17.0.19-1598373927547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35679,DS-08344cca-baf9-486b-a1fa-99a6fde5fd91,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-45fac09a-3855-4ed3-ba09-4e22f3d20822,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-cb965049-511f-4f4c-82fc-45773ace6507,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-be9f6a33-3ca1-4eed-ad12-8ec98828d981,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-be6ea184-23ad-4df8-9118-07d7a62666a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-cd88a03a-9802-4f7f-a430-ef448baace9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-23768ef7-f55e-4793-90c0-7fe6ef0c74e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-421c3f95-48f2-4cb5-a908-04c0d20b9e34,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846945784-172.17.0.19-1598373927547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35679,DS-08344cca-baf9-486b-a1fa-99a6fde5fd91,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-45fac09a-3855-4ed3-ba09-4e22f3d20822,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-cb965049-511f-4f4c-82fc-45773ace6507,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-be9f6a33-3ca1-4eed-ad12-8ec98828d981,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-be6ea184-23ad-4df8-9118-07d7a62666a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-cd88a03a-9802-4f7f-a430-ef448baace9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-23768ef7-f55e-4793-90c0-7fe6ef0c74e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-421c3f95-48f2-4cb5-a908-04c0d20b9e34,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132606456-172.17.0.19-1598374004613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46398,DS-e26cce2e-4f33-42ca-8656-572771e782c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-37c9e29a-7630-421d-a6c4-06fb5ead000a,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-edefd98f-0b46-4055-b957-e7f66488bb41,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-e3c34651-b91e-48ca-b39c-37b696a9aac0,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-2d95a817-104a-4b30-873e-43a42913e886,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-5e711594-2242-4011-a6f7-e979b4b92a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-c4ba619a-08e9-496a-99f1-8480583cf396,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-4f7f8b1b-7260-43ad-a1bc-260a663b3a38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132606456-172.17.0.19-1598374004613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46398,DS-e26cce2e-4f33-42ca-8656-572771e782c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-37c9e29a-7630-421d-a6c4-06fb5ead000a,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-edefd98f-0b46-4055-b957-e7f66488bb41,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-e3c34651-b91e-48ca-b39c-37b696a9aac0,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-2d95a817-104a-4b30-873e-43a42913e886,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-5e711594-2242-4011-a6f7-e979b4b92a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-c4ba619a-08e9-496a-99f1-8480583cf396,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-4f7f8b1b-7260-43ad-a1bc-260a663b3a38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487208334-172.17.0.19-1598374041753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34866,DS-f9538d19-2ae2-4245-b1fc-1ee228ad4025,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-2e3551ac-89e7-49e7-8c10-c125ed0b063c,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-a7b1fde1-8a8f-4c87-a62f-c424b0a6ff1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-44edf595-a873-412f-bc34-28d711c0b855,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-09f2de60-4781-4c0f-bf47-edb07c6aa1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-d007e8a2-89c3-4376-9e9a-bc996c868e05,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-3c384ef1-e60c-43b8-878a-7f9f0ea7a04f,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-5cab5790-79b3-46d1-8d3b-f99d9dcbb0f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487208334-172.17.0.19-1598374041753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34866,DS-f9538d19-2ae2-4245-b1fc-1ee228ad4025,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-2e3551ac-89e7-49e7-8c10-c125ed0b063c,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-a7b1fde1-8a8f-4c87-a62f-c424b0a6ff1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-44edf595-a873-412f-bc34-28d711c0b855,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-09f2de60-4781-4c0f-bf47-edb07c6aa1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-d007e8a2-89c3-4376-9e9a-bc996c868e05,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-3c384ef1-e60c-43b8-878a-7f9f0ea7a04f,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-5cab5790-79b3-46d1-8d3b-f99d9dcbb0f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558682131-172.17.0.19-1598374081346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36212,DS-e19b4a06-dda3-4f1c-9008-32252100d99d,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-5e8b1601-af54-4ce9-9699-709c64ad9f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-bbd4bd78-5bbf-46ad-adda-f57ec135df74,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-f698bf00-75b8-48b7-b869-41449cf269c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-34817f44-43f4-4b6e-b025-568097a3137f,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-a8d0f8d4-7139-4d9c-be1a-700ac0034321,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-756ccd96-f17c-4de2-aa5e-d33028f437fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-900ba98d-228b-4efb-8d62-0233b66fd229,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558682131-172.17.0.19-1598374081346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36212,DS-e19b4a06-dda3-4f1c-9008-32252100d99d,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-5e8b1601-af54-4ce9-9699-709c64ad9f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-bbd4bd78-5bbf-46ad-adda-f57ec135df74,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-f698bf00-75b8-48b7-b869-41449cf269c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-34817f44-43f4-4b6e-b025-568097a3137f,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-a8d0f8d4-7139-4d9c-be1a-700ac0034321,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-756ccd96-f17c-4de2-aa5e-d33028f437fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-900ba98d-228b-4efb-8d62-0233b66fd229,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337216470-172.17.0.19-1598374472316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35400,DS-ad4b9466-d828-44a4-be10-d1e391a2d206,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-9506e8c2-af93-44e4-a5c7-9ae067368292,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-ebc59210-eac6-4bb3-bbe5-e964b3d64230,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-0971c8a4-c62a-4ac0-8eec-1be3d6643664,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-e274b68a-ae2f-4e8f-8a78-02fbc8edb031,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-7854cdb9-3c63-4d25-bd96-bbf94e7ee191,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-4b410d75-03ff-4b7b-a99f-f3fe4462f909,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-09c1281b-0c4d-4bc0-a047-6920ba88a4c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337216470-172.17.0.19-1598374472316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35400,DS-ad4b9466-d828-44a4-be10-d1e391a2d206,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-9506e8c2-af93-44e4-a5c7-9ae067368292,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-ebc59210-eac6-4bb3-bbe5-e964b3d64230,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-0971c8a4-c62a-4ac0-8eec-1be3d6643664,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-e274b68a-ae2f-4e8f-8a78-02fbc8edb031,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-7854cdb9-3c63-4d25-bd96-bbf94e7ee191,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-4b410d75-03ff-4b7b-a99f-f3fe4462f909,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-09c1281b-0c4d-4bc0-a047-6920ba88a4c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638582855-172.17.0.19-1598374677670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34740,DS-261a650b-37d6-4b63-90ac-6547af6b1267,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-6fcb9919-dbe5-423e-938f-aef7f66a76d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-8a5ecf97-2fdf-48e4-b2f9-2a1e8cf7dc77,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-db05343f-daf0-4a20-8c12-97c8d36ebc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-70e86a0c-186a-4fe5-be59-60687d0e81a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-6a983279-2cfc-49ec-bc8f-284f5447ef44,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-6baaa5e4-498a-4784-900b-a4e3334f7f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-ae3963f8-f259-41f7-9aa2-1b8e37765b9a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638582855-172.17.0.19-1598374677670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34740,DS-261a650b-37d6-4b63-90ac-6547af6b1267,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-6fcb9919-dbe5-423e-938f-aef7f66a76d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-8a5ecf97-2fdf-48e4-b2f9-2a1e8cf7dc77,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-db05343f-daf0-4a20-8c12-97c8d36ebc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-70e86a0c-186a-4fe5-be59-60687d0e81a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-6a983279-2cfc-49ec-bc8f-284f5447ef44,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-6baaa5e4-498a-4784-900b-a4e3334f7f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-ae3963f8-f259-41f7-9aa2-1b8e37765b9a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1794156580-172.17.0.19-1598374817459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42165,DS-2af8d319-c2fe-488e-ad78-ecc4836dd481,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-ede78746-0a5f-4acb-a1ac-cbe61e29b6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-d0d1446f-2cdc-4a92-b30a-fda39a59194a,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-181eb7bc-7968-400b-8e34-ff6093f707f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-e2d0a3ed-c08a-4986-ab93-d69849df4ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-54ca8478-f165-4c46-81d8-c102a98743e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-1e4f9369-2a1b-4440-8f96-11ba71af172e,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-4cea8abd-25ad-49e7-ba0d-52da7bc0ebe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1794156580-172.17.0.19-1598374817459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42165,DS-2af8d319-c2fe-488e-ad78-ecc4836dd481,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-ede78746-0a5f-4acb-a1ac-cbe61e29b6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-d0d1446f-2cdc-4a92-b30a-fda39a59194a,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-181eb7bc-7968-400b-8e34-ff6093f707f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-e2d0a3ed-c08a-4986-ab93-d69849df4ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-54ca8478-f165-4c46-81d8-c102a98743e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-1e4f9369-2a1b-4440-8f96-11ba71af172e,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-4cea8abd-25ad-49e7-ba0d-52da7bc0ebe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63731400-172.17.0.19-1598375027261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38930,DS-a4260305-ccde-46db-8bad-2c9fcc6f0491,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-b5c3da5f-f264-4f64-a620-db5d7e64f5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-4bd5f162-b67f-4d9d-a20f-f7eda38ef063,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-d5e91877-84b9-46e3-bdfb-8cbbed3e7527,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-6e2fa15a-c955-4b1c-b733-b1bcdd3bd896,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-2121d9a9-8153-47ec-ab22-43e986250744,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-48cd9333-a8b6-43ea-acd2-56b789b67c32,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-f55b7289-c43a-4907-bbc8-d127e1176563,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63731400-172.17.0.19-1598375027261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38930,DS-a4260305-ccde-46db-8bad-2c9fcc6f0491,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-b5c3da5f-f264-4f64-a620-db5d7e64f5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-4bd5f162-b67f-4d9d-a20f-f7eda38ef063,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-d5e91877-84b9-46e3-bdfb-8cbbed3e7527,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-6e2fa15a-c955-4b1c-b733-b1bcdd3bd896,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-2121d9a9-8153-47ec-ab22-43e986250744,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-48cd9333-a8b6-43ea-acd2-56b789b67c32,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-f55b7289-c43a-4907-bbc8-d127e1176563,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5604
