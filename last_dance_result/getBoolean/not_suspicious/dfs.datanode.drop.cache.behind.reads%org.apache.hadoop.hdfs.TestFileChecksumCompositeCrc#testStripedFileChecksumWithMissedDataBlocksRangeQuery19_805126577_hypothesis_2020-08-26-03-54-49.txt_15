reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327188084-172.17.0.2-1598414243534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33246,DS-77329541-679e-40db-a33f-1773edc72289,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-acc25b67-face-4ef4-992a-f2622f54ddf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-920171d5-e42c-4378-90db-399a2d1d88bc,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-7eb7ba47-1f69-46ae-b345-ea8bc1d48d69,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-ff225776-f4d0-4014-a0a3-79ab85e6a8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-77ef70a6-a787-4e44-90ed-bb4540792f85,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-960aab5a-9024-4f19-96e7-2e0eec885a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-8b8b2c7f-bfc0-457f-9851-a54a13d094dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327188084-172.17.0.2-1598414243534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33246,DS-77329541-679e-40db-a33f-1773edc72289,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-acc25b67-face-4ef4-992a-f2622f54ddf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-920171d5-e42c-4378-90db-399a2d1d88bc,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-7eb7ba47-1f69-46ae-b345-ea8bc1d48d69,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-ff225776-f4d0-4014-a0a3-79ab85e6a8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-77ef70a6-a787-4e44-90ed-bb4540792f85,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-960aab5a-9024-4f19-96e7-2e0eec885a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-8b8b2c7f-bfc0-457f-9851-a54a13d094dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770269610-172.17.0.2-1598414521895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40235,DS-18bcadd1-6405-4589-b13f-89fb0c2c41dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-5e59b645-d04d-417f-b468-349aa288f0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-fd32e18e-c3b8-47e9-8e86-ff3e066d57f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-c98dc1d8-e9ba-4119-a4e1-4e51e69a29bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-a5d41a41-ad41-44bf-bfde-c5a8b1af5372,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-a7c8296e-7a86-4f2b-aa44-c99714dbac08,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-d1ded7d6-faff-4084-bcf8-8d4bec0ed6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-fb5a1b46-a764-4674-9606-e89318307e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770269610-172.17.0.2-1598414521895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40235,DS-18bcadd1-6405-4589-b13f-89fb0c2c41dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-5e59b645-d04d-417f-b468-349aa288f0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-fd32e18e-c3b8-47e9-8e86-ff3e066d57f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-c98dc1d8-e9ba-4119-a4e1-4e51e69a29bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-a5d41a41-ad41-44bf-bfde-c5a8b1af5372,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-a7c8296e-7a86-4f2b-aa44-c99714dbac08,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-d1ded7d6-faff-4084-bcf8-8d4bec0ed6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-fb5a1b46-a764-4674-9606-e89318307e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918242471-172.17.0.2-1598415014110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36148,DS-b408bd65-4d3b-4d71-88cf-87664f0dccdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-b9097d44-a674-4eac-a1cf-ca88b32a0772,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-52a1230d-7d76-4846-bbc0-5901f3720301,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-f0bfe695-d3a9-4b2d-825e-29380574ae91,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-499a763d-eaea-42ac-8205-0ad6b8708a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-7b79fc52-efcd-40c1-8dcf-480bb74f33e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-662e81d7-b866-4921-8872-5367eeecf8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-23b93061-10b7-4e77-af31-ca49396f72f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918242471-172.17.0.2-1598415014110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36148,DS-b408bd65-4d3b-4d71-88cf-87664f0dccdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-b9097d44-a674-4eac-a1cf-ca88b32a0772,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-52a1230d-7d76-4846-bbc0-5901f3720301,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-f0bfe695-d3a9-4b2d-825e-29380574ae91,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-499a763d-eaea-42ac-8205-0ad6b8708a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-7b79fc52-efcd-40c1-8dcf-480bb74f33e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-662e81d7-b866-4921-8872-5367eeecf8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-23b93061-10b7-4e77-af31-ca49396f72f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158501776-172.17.0.2-1598415077832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39027,DS-66a9c924-0e73-464b-a68d-3e9834b57011,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-8dd1488a-8e4e-4d74-8e15-3329c4997ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-ff83ac4a-48cd-45b7-8ff0-d5b25de5ba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-a4c310c0-0065-49e4-9def-9144fa7e69ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-bcd4b1bb-1170-4099-b9ce-d35adea601a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-89dd11a1-c4cd-44be-bb07-137f0aa97caa,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-5fd39d2f-5f93-4715-acac-fdf16c1f8367,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-c24449cd-9b7e-4120-af23-7f7e677a5a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158501776-172.17.0.2-1598415077832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39027,DS-66a9c924-0e73-464b-a68d-3e9834b57011,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-8dd1488a-8e4e-4d74-8e15-3329c4997ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-ff83ac4a-48cd-45b7-8ff0-d5b25de5ba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-a4c310c0-0065-49e4-9def-9144fa7e69ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-bcd4b1bb-1170-4099-b9ce-d35adea601a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-89dd11a1-c4cd-44be-bb07-137f0aa97caa,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-5fd39d2f-5f93-4715-acac-fdf16c1f8367,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-c24449cd-9b7e-4120-af23-7f7e677a5a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1071460187-172.17.0.2-1598415241576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43745,DS-05df6361-4067-4d0e-9e4d-3b645aa13b81,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-935f7496-b45b-4a2b-92f6-63c141837da1,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-4e94667b-fb13-4d8f-94a5-4b3ce47af20f,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-abe7e32b-f707-4ef9-9c43-741fe85d0e67,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-570076b0-e598-41f6-9ee8-3b9aeda8041f,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-aa0a8925-082e-485a-a75c-60e600858219,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-446a6e4e-9aa6-41b8-9901-e4c4565c78f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-b59e9410-4e88-4f7a-b976-599a47abb8ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1071460187-172.17.0.2-1598415241576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43745,DS-05df6361-4067-4d0e-9e4d-3b645aa13b81,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-935f7496-b45b-4a2b-92f6-63c141837da1,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-4e94667b-fb13-4d8f-94a5-4b3ce47af20f,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-abe7e32b-f707-4ef9-9c43-741fe85d0e67,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-570076b0-e598-41f6-9ee8-3b9aeda8041f,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-aa0a8925-082e-485a-a75c-60e600858219,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-446a6e4e-9aa6-41b8-9901-e4c4565c78f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-b59e9410-4e88-4f7a-b976-599a47abb8ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610274595-172.17.0.2-1598415412064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43095,DS-9c0eef25-3c14-4058-acd9-ec27fdcf4a79,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-c8281bc7-19ac-490e-a156-8d8adf7da245,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-b6b6da39-fe65-4e23-a398-3b501c36075a,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-f516d563-52f1-4ed8-98fa-c56d91a256a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-f4d91948-48ce-4605-ba84-bc42f6f8e33d,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-abb4be3a-bd00-4b71-9ab9-8f9aff17c001,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-40646562-cf0d-4c3b-83b5-5997c2a2fd08,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-0c8d12a4-94f9-4fa3-bb9b-5712e5cb6149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610274595-172.17.0.2-1598415412064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43095,DS-9c0eef25-3c14-4058-acd9-ec27fdcf4a79,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-c8281bc7-19ac-490e-a156-8d8adf7da245,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-b6b6da39-fe65-4e23-a398-3b501c36075a,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-f516d563-52f1-4ed8-98fa-c56d91a256a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-f4d91948-48ce-4605-ba84-bc42f6f8e33d,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-abb4be3a-bd00-4b71-9ab9-8f9aff17c001,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-40646562-cf0d-4c3b-83b5-5997c2a2fd08,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-0c8d12a4-94f9-4fa3-bb9b-5712e5cb6149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-343861970-172.17.0.2-1598415513794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39647,DS-4ecd85ac-1c5d-4f4d-bfc9-2f372ff4dc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-012b71ba-bed1-4ec6-9e5c-e36de052ffd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-01d972d6-9438-446f-86ea-f5b383bae06f,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-17b25e6f-2ce7-46df-95e4-68749b994140,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-ee52da85-c11a-4864-8799-5b6b814ed072,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-7f9ac4c9-b4b3-4411-b65b-48eaa6e886d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-403a56a6-bed3-438e-bda5-40d651e10ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-b603c4fe-48ca-4fb8-82ef-ff24c2f10059,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-343861970-172.17.0.2-1598415513794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39647,DS-4ecd85ac-1c5d-4f4d-bfc9-2f372ff4dc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-012b71ba-bed1-4ec6-9e5c-e36de052ffd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-01d972d6-9438-446f-86ea-f5b383bae06f,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-17b25e6f-2ce7-46df-95e4-68749b994140,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-ee52da85-c11a-4864-8799-5b6b814ed072,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-7f9ac4c9-b4b3-4411-b65b-48eaa6e886d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-403a56a6-bed3-438e-bda5-40d651e10ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-b603c4fe-48ca-4fb8-82ef-ff24c2f10059,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990968350-172.17.0.2-1598415673927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42308,DS-5d494dfc-6183-438b-8f88-86de486f77f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-8b3737e3-58ed-4f4f-8fb4-0d35bb1a2d61,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-84ad427a-2fb1-475c-9047-6d8c8f0ee44c,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-520ee300-fdce-4d0e-8310-7087fd29bfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-5203c1a2-c371-4137-a888-8010ba92766d,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-e38b226a-8808-406c-87ee-7f25c0708203,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-ade01a63-abb9-4907-aa6e-af013917f47f,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-ff6ae05a-6641-4881-90ca-2a0597a3d01c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990968350-172.17.0.2-1598415673927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42308,DS-5d494dfc-6183-438b-8f88-86de486f77f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-8b3737e3-58ed-4f4f-8fb4-0d35bb1a2d61,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-84ad427a-2fb1-475c-9047-6d8c8f0ee44c,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-520ee300-fdce-4d0e-8310-7087fd29bfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-5203c1a2-c371-4137-a888-8010ba92766d,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-e38b226a-8808-406c-87ee-7f25c0708203,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-ade01a63-abb9-4907-aa6e-af013917f47f,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-ff6ae05a-6641-4881-90ca-2a0597a3d01c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758877963-172.17.0.2-1598416116607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42812,DS-4136974b-6f91-44a5-a68d-f58fdcd51fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-bb438257-f069-42f9-a020-fd5f69ba735d,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-2e9eba04-d950-4487-aacc-cc73ce22af91,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-9e28aa03-9660-4b4f-ba7a-eef7ce27b5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-4661c4d2-711f-43a1-bb52-3029c4da5907,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-1fad2430-b78b-4d59-9c20-c5853b67c6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-b4238362-400e-4f6b-89ce-6f1b2976c05d,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-c69bc47a-9da7-49ac-9619-a9a7dac7cfa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758877963-172.17.0.2-1598416116607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42812,DS-4136974b-6f91-44a5-a68d-f58fdcd51fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-bb438257-f069-42f9-a020-fd5f69ba735d,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-2e9eba04-d950-4487-aacc-cc73ce22af91,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-9e28aa03-9660-4b4f-ba7a-eef7ce27b5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-4661c4d2-711f-43a1-bb52-3029c4da5907,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-1fad2430-b78b-4d59-9c20-c5853b67c6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-b4238362-400e-4f6b-89ce-6f1b2976c05d,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-c69bc47a-9da7-49ac-9619-a9a7dac7cfa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382124340-172.17.0.2-1598416526704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34129,DS-9d3983c4-5785-4d9c-bf9d-105d7709a708,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-fb709704-6002-438a-80a1-88bbece5cd18,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-5d9a5af7-cc2f-4f71-b662-64ed0ab9dd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-9bebe326-7d95-4760-b051-ac9ed0642d78,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-b828e0c0-7a88-40bf-a2e1-8aa1207d5030,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-690f2f8a-fcae-46c4-81df-542506ff45e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-d9241ee5-1c61-4fac-a216-eacd2dd101da,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-4e7a7131-3cca-493d-86fb-c2efd46195e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382124340-172.17.0.2-1598416526704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34129,DS-9d3983c4-5785-4d9c-bf9d-105d7709a708,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-fb709704-6002-438a-80a1-88bbece5cd18,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-5d9a5af7-cc2f-4f71-b662-64ed0ab9dd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-9bebe326-7d95-4760-b051-ac9ed0642d78,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-b828e0c0-7a88-40bf-a2e1-8aa1207d5030,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-690f2f8a-fcae-46c4-81df-542506ff45e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-d9241ee5-1c61-4fac-a216-eacd2dd101da,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-4e7a7131-3cca-493d-86fb-c2efd46195e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340281914-172.17.0.2-1598416602208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43645,DS-45680e3e-2bad-43f9-97ad-351e42e779ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-d92f694a-3043-4ec9-821b-44c24ed9e41a,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-912a1fb4-5d07-42bf-9b3c-cec6cefeff55,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-1e5aac74-a68b-4445-8a0a-9f50854962aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-e4dbf8f4-9784-42fe-b820-9b697e22dda6,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-d07ca21c-6b9d-42a5-8f6b-6b8391528d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-282f8f9c-a9bb-44fa-8342-beb19864afb7,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-66344480-c4ff-485d-8536-7a93934dccd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340281914-172.17.0.2-1598416602208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43645,DS-45680e3e-2bad-43f9-97ad-351e42e779ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-d92f694a-3043-4ec9-821b-44c24ed9e41a,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-912a1fb4-5d07-42bf-9b3c-cec6cefeff55,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-1e5aac74-a68b-4445-8a0a-9f50854962aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-e4dbf8f4-9784-42fe-b820-9b697e22dda6,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-d07ca21c-6b9d-42a5-8f6b-6b8391528d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-282f8f9c-a9bb-44fa-8342-beb19864afb7,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-66344480-c4ff-485d-8536-7a93934dccd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812241448-172.17.0.2-1598416808752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37968,DS-6d24b8a6-1e75-48a1-83ea-f33257726781,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-1e57a403-571c-469a-9a23-cd256a2e1c53,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-ba9de904-df78-4e3d-9caa-7681e730ba5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-5f7c9e54-f58a-4258-ba46-deb194763ece,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-ce06f9aa-00a6-43f4-8095-5e49e59f8763,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-364f1be9-5580-4905-9c6d-1f63ebb072d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-ece2290c-eec8-4610-95ef-fc93057e36c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-770c9504-227e-47a3-8e4e-557e49f9e28d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812241448-172.17.0.2-1598416808752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37968,DS-6d24b8a6-1e75-48a1-83ea-f33257726781,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-1e57a403-571c-469a-9a23-cd256a2e1c53,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-ba9de904-df78-4e3d-9caa-7681e730ba5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-5f7c9e54-f58a-4258-ba46-deb194763ece,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-ce06f9aa-00a6-43f4-8095-5e49e59f8763,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-364f1be9-5580-4905-9c6d-1f63ebb072d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-ece2290c-eec8-4610-95ef-fc93057e36c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-770c9504-227e-47a3-8e4e-557e49f9e28d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-499200271-172.17.0.2-1598416970252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34002,DS-03c19b91-3e91-49f0-9918-4d73197de205,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-2cd0b4f9-5bac-4f28-add5-7c77f21d3f22,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-a43d7429-f7c9-4f7f-a29e-b9ae0750d474,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-a3f41d55-f9cf-4cfc-ae2e-4b727f3c6905,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-a531d1c2-12cf-45eb-bc2d-221f180d5554,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-057edfa6-e9d6-40eb-bd2b-91fb773555a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-36802938-7a78-4cb6-a56f-026b8d9619e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-8c53cd5a-ae15-4f44-a6bd-a7b679079404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-499200271-172.17.0.2-1598416970252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34002,DS-03c19b91-3e91-49f0-9918-4d73197de205,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-2cd0b4f9-5bac-4f28-add5-7c77f21d3f22,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-a43d7429-f7c9-4f7f-a29e-b9ae0750d474,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-a3f41d55-f9cf-4cfc-ae2e-4b727f3c6905,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-a531d1c2-12cf-45eb-bc2d-221f180d5554,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-057edfa6-e9d6-40eb-bd2b-91fb773555a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-36802938-7a78-4cb6-a56f-026b8d9619e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-8c53cd5a-ae15-4f44-a6bd-a7b679079404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369237227-172.17.0.2-1598417305941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33755,DS-44e08375-c855-4400-8d73-67d579e3a4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-d8190fbb-20d5-4be8-83ff-0ac1a1874356,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-ff57ab04-fc11-4d50-8b6b-7b8f26f9fd67,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-3876f6b0-1dd2-4e99-98fc-03e69f063d82,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-d4a187e7-f504-4a50-ac9a-aa727020a757,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-9e7caa4a-a1aa-486d-96f8-898cdd2db341,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-0d6c8c7a-b0aa-4ead-8710-04107260a2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-66473c5a-cd4a-4ed8-8f35-982927aab1e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369237227-172.17.0.2-1598417305941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33755,DS-44e08375-c855-4400-8d73-67d579e3a4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-d8190fbb-20d5-4be8-83ff-0ac1a1874356,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-ff57ab04-fc11-4d50-8b6b-7b8f26f9fd67,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-3876f6b0-1dd2-4e99-98fc-03e69f063d82,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-d4a187e7-f504-4a50-ac9a-aa727020a757,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-9e7caa4a-a1aa-486d-96f8-898cdd2db341,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-0d6c8c7a-b0aa-4ead-8710-04107260a2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-66473c5a-cd4a-4ed8-8f35-982927aab1e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-819504186-172.17.0.2-1598418122634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41683,DS-f92216bf-642f-433d-aaf8-aee0d60f9893,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-d6f3d570-ef56-406f-bdc0-6dd01ecc0b69,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-023aa69a-aec6-43a2-84b2-ed2aa7063dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-024eb16c-f53e-42d6-9a45-56c873f72732,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-ef1f0ed1-0525-44b4-9347-1f923a6a67c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-a7512eaf-6ebe-4b89-91ca-a09c52f300d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-3da455f8-7b7c-47a1-b6e2-7311f50c3bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-86bd62c5-acf8-477e-ac60-42fa9330a92d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-819504186-172.17.0.2-1598418122634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41683,DS-f92216bf-642f-433d-aaf8-aee0d60f9893,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-d6f3d570-ef56-406f-bdc0-6dd01ecc0b69,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-023aa69a-aec6-43a2-84b2-ed2aa7063dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-024eb16c-f53e-42d6-9a45-56c873f72732,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-ef1f0ed1-0525-44b4-9347-1f923a6a67c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-a7512eaf-6ebe-4b89-91ca-a09c52f300d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-3da455f8-7b7c-47a1-b6e2-7311f50c3bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-86bd62c5-acf8-477e-ac60-42fa9330a92d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-927897501-172.17.0.2-1598418804669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41628,DS-ee6306c7-6072-4d52-b6ac-84c999df95e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-0236322a-0749-424e-8fc6-5795dcf6f818,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-639025b4-dd35-463d-8348-dee28974fbec,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-aa4b47cf-d0f6-413e-a3f7-201178835b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-41c1b3f7-9f29-435a-a0b1-e5962f74b4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-50b51fa5-06d1-4725-8bc6-b19f79da6d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-3b9b48e5-a164-45d1-a202-83a60d5ea2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-83d47987-bf9d-4e81-ba43-ec8ef4559022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-927897501-172.17.0.2-1598418804669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41628,DS-ee6306c7-6072-4d52-b6ac-84c999df95e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-0236322a-0749-424e-8fc6-5795dcf6f818,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-639025b4-dd35-463d-8348-dee28974fbec,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-aa4b47cf-d0f6-413e-a3f7-201178835b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-41c1b3f7-9f29-435a-a0b1-e5962f74b4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-50b51fa5-06d1-4725-8bc6-b19f79da6d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-3b9b48e5-a164-45d1-a202-83a60d5ea2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-83d47987-bf9d-4e81-ba43-ec8ef4559022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732472556-172.17.0.2-1598418842149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36083,DS-e5888f5f-23b4-4284-be48-3a3544ab2ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-fe3bdf9e-bf61-40cb-b3fa-d3ab4ce202d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-5f6059f2-2320-48bd-8da5-b6e5ea8f4192,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-e254751f-cdf6-456e-ac1e-9b5bdc4650eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-8ce28cfd-f379-4595-8bbe-5270de5a6332,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-4d5cec47-cee2-4a2e-a0f3-5d000fcec4db,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-b1f491a2-29b9-43a4-8dd5-44c59dbe827c,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-302e4ec9-57a4-4c6c-9dad-d7423e80bbf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732472556-172.17.0.2-1598418842149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36083,DS-e5888f5f-23b4-4284-be48-3a3544ab2ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-fe3bdf9e-bf61-40cb-b3fa-d3ab4ce202d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-5f6059f2-2320-48bd-8da5-b6e5ea8f4192,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-e254751f-cdf6-456e-ac1e-9b5bdc4650eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-8ce28cfd-f379-4595-8bbe-5270de5a6332,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-4d5cec47-cee2-4a2e-a0f3-5d000fcec4db,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-b1f491a2-29b9-43a4-8dd5-44c59dbe827c,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-302e4ec9-57a4-4c6c-9dad-d7423e80bbf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1679708290-172.17.0.2-1598419056711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35070,DS-7fe06594-0f1e-4895-8977-3f7fa3f84a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-3825f264-c91a-4687-90a4-aace5ec1c1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-0bfe5412-97a1-451e-904e-c1c8f48b9705,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-12c123cc-65e1-4b1e-b92a-6054cb5263e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-8974a24d-2cb5-4d8b-992d-d732b6e822cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-a16b2a64-3d1f-4fa6-ba65-c14396fbfce3,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-2547121d-e6cd-464e-84dc-256d1362eea9,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-9eabbcea-0007-462e-91b0-836b19948429,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1679708290-172.17.0.2-1598419056711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35070,DS-7fe06594-0f1e-4895-8977-3f7fa3f84a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-3825f264-c91a-4687-90a4-aace5ec1c1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-0bfe5412-97a1-451e-904e-c1c8f48b9705,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-12c123cc-65e1-4b1e-b92a-6054cb5263e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-8974a24d-2cb5-4d8b-992d-d732b6e822cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-a16b2a64-3d1f-4fa6-ba65-c14396fbfce3,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-2547121d-e6cd-464e-84dc-256d1362eea9,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-9eabbcea-0007-462e-91b0-836b19948429,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-966085956-172.17.0.2-1598419196028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36802,DS-175455bd-dc91-45dd-9746-d57cc42165e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-d632d9f1-5c14-4fb5-8abd-26f64fbd63e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-379d1adf-fd0b-4461-9b59-de078edb3639,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-52b7aa68-e480-4f49-8b1e-62181b1a0907,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-d94a3681-22e7-4b55-b3d6-a856c2ac7cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-4de6cf54-869e-42f3-b3fd-fbe7b6cf3f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-79ac4328-24f6-4eb9-9236-a8683baf4024,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-23103976-095f-4b03-a831-f918a430ac58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-966085956-172.17.0.2-1598419196028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36802,DS-175455bd-dc91-45dd-9746-d57cc42165e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-d632d9f1-5c14-4fb5-8abd-26f64fbd63e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-379d1adf-fd0b-4461-9b59-de078edb3639,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-52b7aa68-e480-4f49-8b1e-62181b1a0907,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-d94a3681-22e7-4b55-b3d6-a856c2ac7cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-4de6cf54-869e-42f3-b3fd-fbe7b6cf3f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-79ac4328-24f6-4eb9-9236-a8683baf4024,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-23103976-095f-4b03-a831-f918a430ac58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5231
