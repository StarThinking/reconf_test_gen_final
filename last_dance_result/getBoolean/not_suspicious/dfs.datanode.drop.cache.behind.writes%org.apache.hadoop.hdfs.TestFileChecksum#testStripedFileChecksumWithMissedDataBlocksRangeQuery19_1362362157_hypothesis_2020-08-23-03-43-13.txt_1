reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435958599-172.17.0.7-1598154529704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46064,DS-a77f8142-6e6e-4d34-8c7b-039f97fdd25c,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-1391f98b-d28d-4b3a-9019-00bd16cd4226,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-280a76de-db60-4eef-afc2-ee84d8688045,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-e7102b16-e7fe-4ca0-ac40-3d309d040cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-7988b626-9841-4de5-9eed-81c66472e0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-6a145133-4ba4-4d3f-94df-08c12b642e72,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-91758803-e05e-41e7-8f86-fc13df30cdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-dbe94d2d-042e-47d6-a38d-9cfc6a2ec325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435958599-172.17.0.7-1598154529704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46064,DS-a77f8142-6e6e-4d34-8c7b-039f97fdd25c,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-1391f98b-d28d-4b3a-9019-00bd16cd4226,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-280a76de-db60-4eef-afc2-ee84d8688045,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-e7102b16-e7fe-4ca0-ac40-3d309d040cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-7988b626-9841-4de5-9eed-81c66472e0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-6a145133-4ba4-4d3f-94df-08c12b642e72,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-91758803-e05e-41e7-8f86-fc13df30cdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-dbe94d2d-042e-47d6-a38d-9cfc6a2ec325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504308751-172.17.0.7-1598154644996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45368,DS-e39b9763-649c-4514-a332-81eff0b99b67,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-1f63480e-a10d-46d8-869c-1d9c5525bc70,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-258c0ed2-018f-4929-996d-0388a8e299f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-12367cfb-480a-4c49-92bf-6e912501de07,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-7e354457-5388-492f-bccf-95897de2aa68,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-ad30998e-4b0d-4f35-a979-eb341a56b043,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-2b0e67ba-833f-49ec-bcef-ac73952f993a,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-71de0f2f-cd04-488b-8c70-de0f04c7b293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504308751-172.17.0.7-1598154644996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45368,DS-e39b9763-649c-4514-a332-81eff0b99b67,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-1f63480e-a10d-46d8-869c-1d9c5525bc70,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-258c0ed2-018f-4929-996d-0388a8e299f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-12367cfb-480a-4c49-92bf-6e912501de07,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-7e354457-5388-492f-bccf-95897de2aa68,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-ad30998e-4b0d-4f35-a979-eb341a56b043,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-2b0e67ba-833f-49ec-bcef-ac73952f993a,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-71de0f2f-cd04-488b-8c70-de0f04c7b293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014887802-172.17.0.7-1598154681995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44629,DS-d34e490f-7116-45dc-b3c3-115838913956,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-2861e8c8-2d0e-4ff7-9fc9-87bd93cfd54d,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-a3f3cd09-302d-4da4-a7b9-478432874794,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-aafaeac3-d94f-48ba-bd0f-32206b12cd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-6677c11e-926d-45c2-ac83-4da85fffde75,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-bba2244d-eecb-475b-9504-e8e833f80127,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-39b73650-b3e5-44c6-96f9-a9600e71caba,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-bca4782e-aabe-4028-b54c-e7022eda7094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014887802-172.17.0.7-1598154681995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44629,DS-d34e490f-7116-45dc-b3c3-115838913956,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-2861e8c8-2d0e-4ff7-9fc9-87bd93cfd54d,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-a3f3cd09-302d-4da4-a7b9-478432874794,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-aafaeac3-d94f-48ba-bd0f-32206b12cd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-6677c11e-926d-45c2-ac83-4da85fffde75,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-bba2244d-eecb-475b-9504-e8e833f80127,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-39b73650-b3e5-44c6-96f9-a9600e71caba,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-bca4782e-aabe-4028-b54c-e7022eda7094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72749570-172.17.0.7-1598155149654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45216,DS-de0af846-cd26-44e3-8267-6379a2218d37,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-b77c4832-52d9-4af2-a6de-3354ce88c847,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-3a6ef27a-8540-4438-959c-9f64c30300f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-48b31d0c-e04b-4dfe-b295-514c6e3bee41,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-3e61f086-9c38-4563-9c3c-ab99c4460199,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-1f67e67e-c5c9-4c79-bd9b-026c4ac0ffe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-2246299c-507c-4f2d-af76-709c82ce6f95,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-6d8e890b-7b88-41e1-9ed9-5781ffe6b67c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72749570-172.17.0.7-1598155149654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45216,DS-de0af846-cd26-44e3-8267-6379a2218d37,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-b77c4832-52d9-4af2-a6de-3354ce88c847,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-3a6ef27a-8540-4438-959c-9f64c30300f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-48b31d0c-e04b-4dfe-b295-514c6e3bee41,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-3e61f086-9c38-4563-9c3c-ab99c4460199,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-1f67e67e-c5c9-4c79-bd9b-026c4ac0ffe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-2246299c-507c-4f2d-af76-709c82ce6f95,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-6d8e890b-7b88-41e1-9ed9-5781ffe6b67c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377240288-172.17.0.7-1598155569096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44044,DS-9e26232c-ebb8-4124-ab7f-f7dfea69890e,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-6f860870-329d-4eec-8d44-5d5d7727f34a,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-9aa5e18a-5a0b-4798-a5f5-24598572fbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-7c4550a6-a021-441f-9729-bf895ae60eef,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-2b0c8651-28ca-4958-9428-bb71b016efe4,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-a3aa3ccb-32d2-4fb2-9435-c3bc7fe40cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-cfc4cb69-cc89-4505-b190-5de3d119f7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-2ffb9415-aa74-4791-81ca-0439de0adc07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377240288-172.17.0.7-1598155569096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44044,DS-9e26232c-ebb8-4124-ab7f-f7dfea69890e,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-6f860870-329d-4eec-8d44-5d5d7727f34a,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-9aa5e18a-5a0b-4798-a5f5-24598572fbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-7c4550a6-a021-441f-9729-bf895ae60eef,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-2b0c8651-28ca-4958-9428-bb71b016efe4,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-a3aa3ccb-32d2-4fb2-9435-c3bc7fe40cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-cfc4cb69-cc89-4505-b190-5de3d119f7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-2ffb9415-aa74-4791-81ca-0439de0adc07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1935476029-172.17.0.7-1598155728775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46272,DS-53c8bd9f-410e-4556-a7fd-e8547183295a,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-2d40228c-70f6-4e00-9d15-0685ef77f6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-b5e42879-4a39-4737-8e3f-296b03b4e33f,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-4e007fe5-df32-4a1c-869d-f216fb429b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-4c9cefee-f335-47e2-9442-d60744333dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-a98d11ee-ebd9-4d43-800d-11f24619df39,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-ccbfc4aa-a3c5-49bf-8c00-a05c4e166042,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-e556967e-8a1b-4377-bebd-8349e50fb819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1935476029-172.17.0.7-1598155728775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46272,DS-53c8bd9f-410e-4556-a7fd-e8547183295a,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-2d40228c-70f6-4e00-9d15-0685ef77f6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-b5e42879-4a39-4737-8e3f-296b03b4e33f,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-4e007fe5-df32-4a1c-869d-f216fb429b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-4c9cefee-f335-47e2-9442-d60744333dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-a98d11ee-ebd9-4d43-800d-11f24619df39,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-ccbfc4aa-a3c5-49bf-8c00-a05c4e166042,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-e556967e-8a1b-4377-bebd-8349e50fb819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722164071-172.17.0.7-1598155788737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46403,DS-d5adf79c-4ae9-45ad-a103-30a6a69fa5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-17bd19a2-47bd-4dcd-9afd-4ad57f68eb13,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-63421ce7-6a20-46f4-9919-2cd5d86101f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-32411a51-b444-4ca8-a80a-2932973777c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-dc64a36d-0dba-4da2-b2cf-0cd5cb449280,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-f98133c2-6917-412d-9b5b-0ecce0cfd336,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-0555c2e6-fa61-459d-8a6b-a4f1889a396b,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-bb07382b-101e-4c60-8864-9d145c0e4886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722164071-172.17.0.7-1598155788737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46403,DS-d5adf79c-4ae9-45ad-a103-30a6a69fa5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-17bd19a2-47bd-4dcd-9afd-4ad57f68eb13,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-63421ce7-6a20-46f4-9919-2cd5d86101f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-32411a51-b444-4ca8-a80a-2932973777c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-dc64a36d-0dba-4da2-b2cf-0cd5cb449280,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-f98133c2-6917-412d-9b5b-0ecce0cfd336,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-0555c2e6-fa61-459d-8a6b-a4f1889a396b,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-bb07382b-101e-4c60-8864-9d145c0e4886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308612022-172.17.0.7-1598156306774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43932,DS-b8907d57-d49f-42ed-ba62-914e7c7405b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-1056756b-68b2-4300-9f9a-b9d8c2440400,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-fe7d6a9e-4fdc-460b-a77a-468c3c6d8215,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-0c344d8e-9c10-4a3b-b8e2-6fb58fb60576,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-8d4ea1ec-3dc1-4303-a41c-7ec7fd24167a,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-7dff6a7e-6aed-4df1-aa0e-d5410f9f4cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-c165fa9b-b4cb-4681-9ec3-787ff61c8d49,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-f9b69a6e-e64a-4441-944a-46ed5a3b7747,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308612022-172.17.0.7-1598156306774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43932,DS-b8907d57-d49f-42ed-ba62-914e7c7405b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-1056756b-68b2-4300-9f9a-b9d8c2440400,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-fe7d6a9e-4fdc-460b-a77a-468c3c6d8215,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-0c344d8e-9c10-4a3b-b8e2-6fb58fb60576,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-8d4ea1ec-3dc1-4303-a41c-7ec7fd24167a,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-7dff6a7e-6aed-4df1-aa0e-d5410f9f4cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-c165fa9b-b4cb-4681-9ec3-787ff61c8d49,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-f9b69a6e-e64a-4441-944a-46ed5a3b7747,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523747024-172.17.0.7-1598156425906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46015,DS-7b153092-349b-4682-9c7e-ec7b5a8cd558,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-1a0760c7-56b9-4c57-a05e-a9a5ea6c97d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-4cf164b1-37db-431f-85d7-510c9923c1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-3c1a0479-a618-407b-b0cd-bd38d54737dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-be064c22-2cfe-4064-b73c-e6679d813676,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-0ee65a2f-5076-4e19-9578-e1283a2464e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-6b12c655-8d67-4ddb-a505-4e4d804e9d61,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-cabb8729-ca91-4b70-a11b-e1bd74ed5cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523747024-172.17.0.7-1598156425906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46015,DS-7b153092-349b-4682-9c7e-ec7b5a8cd558,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-1a0760c7-56b9-4c57-a05e-a9a5ea6c97d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-4cf164b1-37db-431f-85d7-510c9923c1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-3c1a0479-a618-407b-b0cd-bd38d54737dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-be064c22-2cfe-4064-b73c-e6679d813676,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-0ee65a2f-5076-4e19-9578-e1283a2464e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-6b12c655-8d67-4ddb-a505-4e4d804e9d61,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-cabb8729-ca91-4b70-a11b-e1bd74ed5cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439353371-172.17.0.7-1598157009281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46335,DS-686c2750-f927-4110-b383-578c8730ba64,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-5556a412-2bbd-4f74-822d-1c97e07409be,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-dd8ac380-6e9b-4ae5-a0a3-a967c5ce6b39,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-71b5e5b8-68ab-4c45-8802-5f2998194579,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-eeb84d89-6295-476b-b6ad-9444f69b963e,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-03eb1425-a27d-4c91-93ac-4514418546e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-5f8507dc-81fc-459b-80ef-3e827a2b7e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-8fc9d146-173b-4741-a2f6-a7872fa9a7e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439353371-172.17.0.7-1598157009281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46335,DS-686c2750-f927-4110-b383-578c8730ba64,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-5556a412-2bbd-4f74-822d-1c97e07409be,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-dd8ac380-6e9b-4ae5-a0a3-a967c5ce6b39,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-71b5e5b8-68ab-4c45-8802-5f2998194579,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-eeb84d89-6295-476b-b6ad-9444f69b963e,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-03eb1425-a27d-4c91-93ac-4514418546e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-5f8507dc-81fc-459b-80ef-3e827a2b7e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-8fc9d146-173b-4741-a2f6-a7872fa9a7e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-53470970-172.17.0.7-1598157072879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38563,DS-559137e7-e91f-48b6-8216-c986dca9c283,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-6ddd6f3c-8454-466a-9420-8a931b6e9acd,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-219a152d-b6e5-4291-ac3d-b13631d95665,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-1f120024-aa9b-4cd7-ac5b-51c3f6a47feb,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-3439e27a-933f-4a61-a17e-2754bc2b1d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-00db9fa4-2302-4df2-84e8-50fe75ce1e33,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-db2cb8f4-c455-4b53-95ed-e03c5b431f87,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-ef0ec786-c8ad-4e53-afdf-aff30e0406ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-53470970-172.17.0.7-1598157072879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38563,DS-559137e7-e91f-48b6-8216-c986dca9c283,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-6ddd6f3c-8454-466a-9420-8a931b6e9acd,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-219a152d-b6e5-4291-ac3d-b13631d95665,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-1f120024-aa9b-4cd7-ac5b-51c3f6a47feb,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-3439e27a-933f-4a61-a17e-2754bc2b1d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-00db9fa4-2302-4df2-84e8-50fe75ce1e33,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-db2cb8f4-c455-4b53-95ed-e03c5b431f87,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-ef0ec786-c8ad-4e53-afdf-aff30e0406ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-499907016-172.17.0.7-1598157252655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36646,DS-2207b04e-f247-4e34-bd1d-2a3e9821d002,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-eb44b30e-8ec1-4be5-a4c0-392ab70717c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-7fcc1e6b-8ca4-4141-9e58-db8d1bda860e,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-72101cad-2769-4628-8f87-d182c3a648c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-15511992-0974-4372-afa4-877cc0c47f66,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-0b2006c8-31b1-45ab-9de5-d3ef7a41db97,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-15956dda-52e6-4e11-9061-8d660dd6c0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-74d10d9a-b460-468a-8a29-dbfb9a5a7242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-499907016-172.17.0.7-1598157252655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36646,DS-2207b04e-f247-4e34-bd1d-2a3e9821d002,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-eb44b30e-8ec1-4be5-a4c0-392ab70717c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-7fcc1e6b-8ca4-4141-9e58-db8d1bda860e,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-72101cad-2769-4628-8f87-d182c3a648c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-15511992-0974-4372-afa4-877cc0c47f66,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-0b2006c8-31b1-45ab-9de5-d3ef7a41db97,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-15956dda-52e6-4e11-9061-8d660dd6c0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-74d10d9a-b460-468a-8a29-dbfb9a5a7242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-270312461-172.17.0.7-1598157699472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33139,DS-000f51cf-aca8-4a3f-9421-29405362f961,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-fd36a17c-24c9-4fe6-b353-3b703ca3e3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-14023472-1ab0-4d93-84ba-4488c7d20252,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-02f43ada-f358-48d0-99c9-add30248ca6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-00769c06-7593-4f47-8fae-fed53ad975ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-55d85664-83a0-4b46-a531-60f7b021edb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-5cf9142a-9cb6-402f-9252-608c69a59c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-14116252-07ac-47fd-9fd7-f90043dac086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-270312461-172.17.0.7-1598157699472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33139,DS-000f51cf-aca8-4a3f-9421-29405362f961,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-fd36a17c-24c9-4fe6-b353-3b703ca3e3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-14023472-1ab0-4d93-84ba-4488c7d20252,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-02f43ada-f358-48d0-99c9-add30248ca6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-00769c06-7593-4f47-8fae-fed53ad975ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-55d85664-83a0-4b46-a531-60f7b021edb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-5cf9142a-9cb6-402f-9252-608c69a59c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-14116252-07ac-47fd-9fd7-f90043dac086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312931743-172.17.0.7-1598158503062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-60c1e10b-6bf5-431b-a7a5-e4bf86b650fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-799f4d59-b79f-4712-bbd0-147346388803,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-1e83e982-f3b4-445e-957f-c42c28331631,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-16df7307-0aa7-428b-818c-ca098d94feab,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-ba8f9caa-1609-4aa2-a0c3-6d2d5c0b9618,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-1c9f7663-66ed-4fa2-a46a-ae0294ac8f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-877074ab-2299-49ee-8c8c-32f26ef29333,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-c34344af-c4ea-41f0-b52e-d53c70ee4006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312931743-172.17.0.7-1598158503062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-60c1e10b-6bf5-431b-a7a5-e4bf86b650fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-799f4d59-b79f-4712-bbd0-147346388803,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-1e83e982-f3b4-445e-957f-c42c28331631,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-16df7307-0aa7-428b-818c-ca098d94feab,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-ba8f9caa-1609-4aa2-a0c3-6d2d5c0b9618,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-1c9f7663-66ed-4fa2-a46a-ae0294ac8f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-877074ab-2299-49ee-8c8c-32f26ef29333,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-c34344af-c4ea-41f0-b52e-d53c70ee4006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-875749672-172.17.0.7-1598159088270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44966,DS-c1455594-acb5-4bdf-bc61-3e509187f69f,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-deba479b-c031-4612-8807-fb8c241f89eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-b717dfe9-5958-4134-b7cf-e6b479747d93,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-1a5a1111-1b56-47b6-84fb-be64c75d0d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-77a901ef-f856-44c0-a05a-b2454e93eaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-3de422b6-e177-4e4c-8a67-a5766d87999c,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-4d19dad6-aeb7-4a4b-bf1f-128df4def121,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-a66c3c76-6e0c-45d4-8f96-8baf6e1e0dba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-875749672-172.17.0.7-1598159088270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44966,DS-c1455594-acb5-4bdf-bc61-3e509187f69f,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-deba479b-c031-4612-8807-fb8c241f89eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-b717dfe9-5958-4134-b7cf-e6b479747d93,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-1a5a1111-1b56-47b6-84fb-be64c75d0d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-77a901ef-f856-44c0-a05a-b2454e93eaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-3de422b6-e177-4e4c-8a67-a5766d87999c,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-4d19dad6-aeb7-4a4b-bf1f-128df4def121,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-a66c3c76-6e0c-45d4-8f96-8baf6e1e0dba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5209
