reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602453463-172.17.0.21-1598439766200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40034,DS-bf00c4ab-18e5-48cc-b4e1-0b00ad9510b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-aab12f21-aca9-44d1-8ba0-be2c4e311057,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-22f7e8f5-5cce-4174-8a71-01213a0fcb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-d6930819-7086-4bdb-b972-83d475a7ab90,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-fce9d8e9-0abb-4280-a985-b87a0510cdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-123976e8-0597-4b94-be3d-dfe8dc9db6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-b05c47c1-eb23-4909-ae95-245fcb85004b,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-03287539-06dd-4d25-8ec6-429017e3b88a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602453463-172.17.0.21-1598439766200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40034,DS-bf00c4ab-18e5-48cc-b4e1-0b00ad9510b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-aab12f21-aca9-44d1-8ba0-be2c4e311057,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-22f7e8f5-5cce-4174-8a71-01213a0fcb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-d6930819-7086-4bdb-b972-83d475a7ab90,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-fce9d8e9-0abb-4280-a985-b87a0510cdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-123976e8-0597-4b94-be3d-dfe8dc9db6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-b05c47c1-eb23-4909-ae95-245fcb85004b,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-03287539-06dd-4d25-8ec6-429017e3b88a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382227213-172.17.0.21-1598439900618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35546,DS-fdf91f7b-16c1-4ea9-bc22-8455c256e68e,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-2b3ae48c-a8bb-4651-9edb-f20537b6f3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-9565ac6f-edd7-4b00-b18e-163c93eafd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-84622c7c-826d-4fd1-85a2-b1c1320c37db,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-2e0876c0-22d7-4f82-8973-88aef838e1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-347af494-29d5-4983-aeab-346b19bd6f57,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-db162113-7d20-4a67-9c00-3296d857b7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-a74e723a-7ab4-4457-be3b-4244e84bb1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382227213-172.17.0.21-1598439900618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35546,DS-fdf91f7b-16c1-4ea9-bc22-8455c256e68e,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-2b3ae48c-a8bb-4651-9edb-f20537b6f3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-9565ac6f-edd7-4b00-b18e-163c93eafd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-84622c7c-826d-4fd1-85a2-b1c1320c37db,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-2e0876c0-22d7-4f82-8973-88aef838e1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-347af494-29d5-4983-aeab-346b19bd6f57,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-db162113-7d20-4a67-9c00-3296d857b7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-a74e723a-7ab4-4457-be3b-4244e84bb1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685809516-172.17.0.21-1598440471426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41873,DS-46d1bc71-337b-49b5-8e61-020d771896df,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-7472e5ff-3030-4b9b-94e1-05d946eb50f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-3cbbfab8-de17-441e-8985-a0e4c07152de,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-70020789-7746-4e0b-aa68-ca328dc290f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-80cf2562-0e86-4b17-ac1a-a8946d671bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-2bb02b98-fbbc-4bfa-893d-0f20a734221f,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-fa85b110-0171-491c-9081-b4fe2daa9018,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-73a1b1db-1a0a-4713-b5e5-d0cb14b2e1ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685809516-172.17.0.21-1598440471426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41873,DS-46d1bc71-337b-49b5-8e61-020d771896df,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-7472e5ff-3030-4b9b-94e1-05d946eb50f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-3cbbfab8-de17-441e-8985-a0e4c07152de,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-70020789-7746-4e0b-aa68-ca328dc290f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-80cf2562-0e86-4b17-ac1a-a8946d671bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-2bb02b98-fbbc-4bfa-893d-0f20a734221f,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-fa85b110-0171-491c-9081-b4fe2daa9018,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-73a1b1db-1a0a-4713-b5e5-d0cb14b2e1ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068465343-172.17.0.21-1598440502825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33581,DS-88d61eaa-8863-471e-b7eb-a077e7c9e08f,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-8941b88e-7a17-477f-991c-2d7b2f4201ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-ed10946a-8bc7-4dc4-b7cf-0e38f71061f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-7309f114-82df-472e-9f81-fb90859c7cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-1154a39c-c938-4404-b6bd-1b41712c0446,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-d71c2103-b5c7-4c5a-9e62-8eb756b0f348,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-84e5bb6d-9a0a-4a65-b73b-d72eb318dac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-4fdd25eb-1cdf-4be2-a682-a4ed87785256,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068465343-172.17.0.21-1598440502825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33581,DS-88d61eaa-8863-471e-b7eb-a077e7c9e08f,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-8941b88e-7a17-477f-991c-2d7b2f4201ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-ed10946a-8bc7-4dc4-b7cf-0e38f71061f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-7309f114-82df-472e-9f81-fb90859c7cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-1154a39c-c938-4404-b6bd-1b41712c0446,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-d71c2103-b5c7-4c5a-9e62-8eb756b0f348,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-84e5bb6d-9a0a-4a65-b73b-d72eb318dac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-4fdd25eb-1cdf-4be2-a682-a4ed87785256,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499666831-172.17.0.21-1598440657553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36142,DS-bfb28597-919e-4e1c-879c-524073ad1aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-8c16e799-ff4c-405a-a81a-d9426fbd30ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-d377c4e5-2e2a-4c12-8b2a-8c353ef3bc22,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-d08a960e-2f1e-4350-a31b-8f3bf28ed62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-430042ad-d52f-4021-8bd5-290342dabc34,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-c5ccb9df-9285-4305-b909-9533f2c12745,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-b63a6056-9caf-4bb3-9fe4-06b456bd267e,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-0a948cc6-62eb-4e87-922f-fca997e2bffb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499666831-172.17.0.21-1598440657553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36142,DS-bfb28597-919e-4e1c-879c-524073ad1aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-8c16e799-ff4c-405a-a81a-d9426fbd30ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-d377c4e5-2e2a-4c12-8b2a-8c353ef3bc22,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-d08a960e-2f1e-4350-a31b-8f3bf28ed62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-430042ad-d52f-4021-8bd5-290342dabc34,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-c5ccb9df-9285-4305-b909-9533f2c12745,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-b63a6056-9caf-4bb3-9fe4-06b456bd267e,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-0a948cc6-62eb-4e87-922f-fca997e2bffb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551359157-172.17.0.21-1598441650565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34215,DS-09748fdb-3343-4c40-ad6f-77c13c86e199,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-4bf3b0d9-976e-4aa8-ad61-4c20b590f694,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-0907e776-39b5-45c6-a875-94d61c734811,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-8b3bd4cc-da28-48c7-b5db-53a1959dfc99,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-5038769b-ff28-4586-93e6-86f3d771ff53,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-8bff239a-ce66-428f-acee-2effde566334,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-26052d55-a5f0-40d5-acc8-084e0551caa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-970f45c5-4498-43e8-956c-bfb03681c45d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551359157-172.17.0.21-1598441650565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34215,DS-09748fdb-3343-4c40-ad6f-77c13c86e199,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-4bf3b0d9-976e-4aa8-ad61-4c20b590f694,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-0907e776-39b5-45c6-a875-94d61c734811,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-8b3bd4cc-da28-48c7-b5db-53a1959dfc99,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-5038769b-ff28-4586-93e6-86f3d771ff53,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-8bff239a-ce66-428f-acee-2effde566334,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-26052d55-a5f0-40d5-acc8-084e0551caa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-970f45c5-4498-43e8-956c-bfb03681c45d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642918191-172.17.0.21-1598442034276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39940,DS-feb21a38-4b4a-4980-942e-bc7bb0aa4db1,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-8bd187b9-61ab-49fe-97e1-39bb539f8451,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-f83dabbd-5c3f-4fb2-b2b0-c931f88e98db,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-3057cb36-543c-4503-9569-21c82aa5aa62,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-b1e3db6c-753c-4d11-9583-f9d2012d9c75,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-26353bc3-c27e-4036-8ca4-e7af1bc63925,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-ffe697a3-36ba-4002-b355-20dadab44319,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-6174bf7a-8a59-4cef-82ec-0613575971c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642918191-172.17.0.21-1598442034276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39940,DS-feb21a38-4b4a-4980-942e-bc7bb0aa4db1,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-8bd187b9-61ab-49fe-97e1-39bb539f8451,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-f83dabbd-5c3f-4fb2-b2b0-c931f88e98db,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-3057cb36-543c-4503-9569-21c82aa5aa62,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-b1e3db6c-753c-4d11-9583-f9d2012d9c75,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-26353bc3-c27e-4036-8ca4-e7af1bc63925,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-ffe697a3-36ba-4002-b355-20dadab44319,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-6174bf7a-8a59-4cef-82ec-0613575971c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111839297-172.17.0.21-1598442112736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36671,DS-8cde35ba-25bb-434c-b05a-1c4cdccc9a25,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-f3da22e0-ba44-4ba0-a332-265e5c28c88b,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-5bd53841-7edd-4ceb-b873-6c981d93a7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-6b4432e3-dea8-481d-8721-5a5c90b4f3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-536eedb9-360e-4060-9059-2dbe5b4083a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-ad175772-1d9a-481b-8b36-c83fe50dafc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-fcd124df-3d1f-425f-b6e8-2a2abdbdacd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-a111ba12-ef77-4de3-a632-5626ee9f554d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111839297-172.17.0.21-1598442112736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36671,DS-8cde35ba-25bb-434c-b05a-1c4cdccc9a25,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-f3da22e0-ba44-4ba0-a332-265e5c28c88b,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-5bd53841-7edd-4ceb-b873-6c981d93a7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-6b4432e3-dea8-481d-8721-5a5c90b4f3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-536eedb9-360e-4060-9059-2dbe5b4083a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-ad175772-1d9a-481b-8b36-c83fe50dafc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-fcd124df-3d1f-425f-b6e8-2a2abdbdacd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-a111ba12-ef77-4de3-a632-5626ee9f554d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859976210-172.17.0.21-1598442372508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35894,DS-30fe9e99-35f2-4cfd-ac45-244542d4c43e,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-2e764c7e-fec3-4460-a6ff-18dc40f09ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-e4225a44-80e1-4e20-92ef-f2301ec1b96c,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-37a3952f-21cd-40a2-825b-02c51cb963c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-e087aa9e-553a-410f-8370-413903c351b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-b1be294a-17b2-4cce-9234-9def1dccb72c,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-3a4dc1d1-c473-4f58-994e-7175732bd186,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-9422b165-0647-4134-abb4-ca3f69ee23f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859976210-172.17.0.21-1598442372508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35894,DS-30fe9e99-35f2-4cfd-ac45-244542d4c43e,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-2e764c7e-fec3-4460-a6ff-18dc40f09ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-e4225a44-80e1-4e20-92ef-f2301ec1b96c,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-37a3952f-21cd-40a2-825b-02c51cb963c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-e087aa9e-553a-410f-8370-413903c351b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-b1be294a-17b2-4cce-9234-9def1dccb72c,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-3a4dc1d1-c473-4f58-994e-7175732bd186,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-9422b165-0647-4134-abb4-ca3f69ee23f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710873284-172.17.0.21-1598442735044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43784,DS-c0bddd10-d884-437b-b107-2ffdb34d123b,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-ced8fcc2-7f81-472d-b48e-a671306f271b,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-af18a093-48df-4ada-97ec-a43b67380194,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-03763ccc-ea17-401e-81ff-b96cecb4f3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-e1578f0e-6a89-47d1-82fc-42eb169445e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-38f01cd0-bd5b-4782-b73a-8d74f0f797cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-7fb69f67-602c-4be6-806b-1909d1f40877,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-8dfde653-92d6-40d4-9785-4e19bf3d516f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710873284-172.17.0.21-1598442735044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43784,DS-c0bddd10-d884-437b-b107-2ffdb34d123b,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-ced8fcc2-7f81-472d-b48e-a671306f271b,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-af18a093-48df-4ada-97ec-a43b67380194,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-03763ccc-ea17-401e-81ff-b96cecb4f3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-e1578f0e-6a89-47d1-82fc-42eb169445e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-38f01cd0-bd5b-4782-b73a-8d74f0f797cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-7fb69f67-602c-4be6-806b-1909d1f40877,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-8dfde653-92d6-40d4-9785-4e19bf3d516f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157909717-172.17.0.21-1598443085642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39168,DS-1633cf2f-81a3-43ed-a87c-20ffcfa96ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-82804912-cf4d-495a-b82b-e76348a2b228,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-4bf2cbcf-5626-44d4-bea9-33cd8067c11b,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-554f80e9-0ca8-4d58-8df6-f8ecb8604ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-f1608a74-dfba-4938-a3a7-9578e0077cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-a347bec7-8a40-4d9f-9c47-fed3569c56bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-0eee1db4-27e3-48aa-8389-b957e9ba1bae,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-089dc503-28e0-4f7c-a53a-b017c96d5e87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157909717-172.17.0.21-1598443085642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39168,DS-1633cf2f-81a3-43ed-a87c-20ffcfa96ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-82804912-cf4d-495a-b82b-e76348a2b228,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-4bf2cbcf-5626-44d4-bea9-33cd8067c11b,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-554f80e9-0ca8-4d58-8df6-f8ecb8604ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-f1608a74-dfba-4938-a3a7-9578e0077cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-a347bec7-8a40-4d9f-9c47-fed3569c56bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-0eee1db4-27e3-48aa-8389-b957e9ba1bae,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-089dc503-28e0-4f7c-a53a-b017c96d5e87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686476925-172.17.0.21-1598443221079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36573,DS-b9094aea-9ec6-442c-b7eb-d81ae16491bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-4bb15214-496d-4863-9e4b-88cfc3c84507,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-54a2320e-1730-45dc-8e65-e570ee2bfe0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-4e484cec-c4c5-4987-969a-e719d6e2b591,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-d43101aa-c1f6-447a-a99e-7fa670d4e7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-f4eb595e-8763-4afd-9449-45d221dc837e,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-de3b08b2-1b11-41df-ad0c-e8052f1661e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-b8639196-0842-4e56-99a8-f262946357aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686476925-172.17.0.21-1598443221079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36573,DS-b9094aea-9ec6-442c-b7eb-d81ae16491bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-4bb15214-496d-4863-9e4b-88cfc3c84507,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-54a2320e-1730-45dc-8e65-e570ee2bfe0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-4e484cec-c4c5-4987-969a-e719d6e2b591,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-d43101aa-c1f6-447a-a99e-7fa670d4e7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-f4eb595e-8763-4afd-9449-45d221dc837e,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-de3b08b2-1b11-41df-ad0c-e8052f1661e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-b8639196-0842-4e56-99a8-f262946357aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030931083-172.17.0.21-1598443344767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42260,DS-2ba2e3da-e8be-4785-a141-78d3040595f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-23c2284e-d9a4-433f-8195-ce7c8b152beb,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-d8e589a1-40c6-4751-9d35-f82d302e4506,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-9e1ef5f6-f8c8-467b-ac90-3073fcc9d029,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-3ff24cc6-9aba-44d1-ab67-7231b75d76b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-3ad3986c-e105-4813-8057-4660559ca13c,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-e3a37f06-c625-4177-b1e1-6a37cf94deba,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-c90172bc-c334-40ff-95dd-eb002377e62e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030931083-172.17.0.21-1598443344767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42260,DS-2ba2e3da-e8be-4785-a141-78d3040595f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-23c2284e-d9a4-433f-8195-ce7c8b152beb,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-d8e589a1-40c6-4751-9d35-f82d302e4506,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-9e1ef5f6-f8c8-467b-ac90-3073fcc9d029,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-3ff24cc6-9aba-44d1-ab67-7231b75d76b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-3ad3986c-e105-4813-8057-4660559ca13c,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-e3a37f06-c625-4177-b1e1-6a37cf94deba,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-c90172bc-c334-40ff-95dd-eb002377e62e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403613555-172.17.0.21-1598443373051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36023,DS-54be1574-fa16-450f-b89b-2068266ec6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-85a060e1-d7f7-4c9c-a1fa-4a37c864bd42,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-1ff32a77-a4f5-4d3b-95e5-848d3d617ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-afc28709-1972-47a4-b9d5-a0cda2b20626,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-03835ca6-c3a4-4063-93b2-24891c6195f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-bcc02031-0bd5-4989-a316-c194d358840d,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-64751b7d-fd54-4c66-a02c-be1e6c667c72,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-52423983-9974-402c-93aa-86d2e7ceb009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403613555-172.17.0.21-1598443373051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36023,DS-54be1574-fa16-450f-b89b-2068266ec6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-85a060e1-d7f7-4c9c-a1fa-4a37c864bd42,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-1ff32a77-a4f5-4d3b-95e5-848d3d617ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-afc28709-1972-47a4-b9d5-a0cda2b20626,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-03835ca6-c3a4-4063-93b2-24891c6195f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-bcc02031-0bd5-4989-a316-c194d358840d,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-64751b7d-fd54-4c66-a02c-be1e6c667c72,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-52423983-9974-402c-93aa-86d2e7ceb009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1312104462-172.17.0.21-1598443481548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42716,DS-7ecd318a-7555-4530-8f3c-d3ee8c995154,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-305c4f28-601e-441e-8d0a-893ca88c5bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-57ab3e2a-1154-4816-8a4d-565a0890af9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-ce3a205b-3758-41b6-b304-2e246b0d5b53,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-c225b168-579c-4b38-85ae-828deac53f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-774c479d-30e1-4dfb-a881-beba0beccdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-51f7585e-ab03-4e17-a26b-0dc5d59f36df,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-60ae8805-95f7-4f0c-91a7-53b085657042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1312104462-172.17.0.21-1598443481548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42716,DS-7ecd318a-7555-4530-8f3c-d3ee8c995154,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-305c4f28-601e-441e-8d0a-893ca88c5bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-57ab3e2a-1154-4816-8a4d-565a0890af9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-ce3a205b-3758-41b6-b304-2e246b0d5b53,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-c225b168-579c-4b38-85ae-828deac53f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-774c479d-30e1-4dfb-a881-beba0beccdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-51f7585e-ab03-4e17-a26b-0dc5d59f36df,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-60ae8805-95f7-4f0c-91a7-53b085657042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221710078-172.17.0.21-1598443988586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37912,DS-41113d23-918f-4f7d-89b6-962e44305b85,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-ee360693-9a8e-4b62-b875-705651635012,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-1aac0e07-d73f-4a1c-875d-e5cf64e93c52,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-0a70bfca-bd5d-4e08-8c4a-99412d8179eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-99173460-a1a1-4274-9fd1-9eb942a87daf,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-dc67d6b6-acdd-4713-a081-d7e4ea2833e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-f602baf0-1b57-4a8f-967c-5cd5bddc899d,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-d17b6732-dee3-4220-b11c-cbac65ac9fe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221710078-172.17.0.21-1598443988586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37912,DS-41113d23-918f-4f7d-89b6-962e44305b85,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-ee360693-9a8e-4b62-b875-705651635012,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-1aac0e07-d73f-4a1c-875d-e5cf64e93c52,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-0a70bfca-bd5d-4e08-8c4a-99412d8179eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-99173460-a1a1-4274-9fd1-9eb942a87daf,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-dc67d6b6-acdd-4713-a081-d7e4ea2833e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-f602baf0-1b57-4a8f-967c-5cd5bddc899d,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-d17b6732-dee3-4220-b11c-cbac65ac9fe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846198093-172.17.0.21-1598444056729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38436,DS-9572504c-1748-4a39-add1-d1e6e1a9b755,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-8f7ae829-1806-4eb3-8247-36150fce42cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-ade53a1f-5bc1-4633-99dc-e76111f9d3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-af2b8dd9-76e0-45fa-ab35-7328ccbadbab,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-a79d249f-0a2e-4832-bf17-21a63dafab1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-7e7ef3b8-3225-424f-811a-a97f0702d054,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-12ff25c2-c4ee-4444-ab30-3012c62398e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-ce89dd05-8c25-4e71-b142-b765229ca73e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846198093-172.17.0.21-1598444056729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38436,DS-9572504c-1748-4a39-add1-d1e6e1a9b755,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-8f7ae829-1806-4eb3-8247-36150fce42cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-ade53a1f-5bc1-4633-99dc-e76111f9d3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-af2b8dd9-76e0-45fa-ab35-7328ccbadbab,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-a79d249f-0a2e-4832-bf17-21a63dafab1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-7e7ef3b8-3225-424f-811a-a97f0702d054,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-12ff25c2-c4ee-4444-ab30-3012c62398e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-ce89dd05-8c25-4e71-b142-b765229ca73e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800387280-172.17.0.21-1598444093468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40645,DS-2253e37b-0313-4731-aaab-3f1e46cd4946,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-813cbbac-21a4-49a9-866f-41c4aad81c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-128df09f-4930-427e-9f97-ad6224f25ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-a7d4b2b6-f511-4c89-818b-7a8c743728ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-9f7a4908-b949-48c7-b713-90023fe8f30d,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-103f0d37-401e-4b1b-8d32-4872c5f191a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-174f2900-ae7b-409b-a396-87de46674252,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-0e816a88-a9e1-44a0-bab9-fb058316cbca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800387280-172.17.0.21-1598444093468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40645,DS-2253e37b-0313-4731-aaab-3f1e46cd4946,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-813cbbac-21a4-49a9-866f-41c4aad81c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-128df09f-4930-427e-9f97-ad6224f25ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-a7d4b2b6-f511-4c89-818b-7a8c743728ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-9f7a4908-b949-48c7-b713-90023fe8f30d,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-103f0d37-401e-4b1b-8d32-4872c5f191a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-174f2900-ae7b-409b-a396-87de46674252,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-0e816a88-a9e1-44a0-bab9-fb058316cbca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5209
