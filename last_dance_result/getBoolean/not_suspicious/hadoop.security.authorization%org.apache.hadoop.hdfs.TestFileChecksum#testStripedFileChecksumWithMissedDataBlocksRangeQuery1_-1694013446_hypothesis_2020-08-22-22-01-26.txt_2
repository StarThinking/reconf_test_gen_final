reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108827401-172.17.0.10-1598133736602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41676,DS-b68e60b3-c8d9-459a-8756-e63039ade3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-22687606-39d5-4968-8e63-78ecbc141589,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-1bf2a703-f345-4e46-a45c-6c6eb221b242,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-b5325dd9-7bff-4b81-88d0-1098e1fb6443,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-b0d09399-0f66-4729-acd6-400beec6f90d,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-c083fd3a-faf9-4f74-956f-c1d64fb11562,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-7bbb1d8f-407f-4148-b2e3-8ac0faab7bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-4e6d8e7e-8ffc-4667-8f87-2592c7ce8fcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108827401-172.17.0.10-1598133736602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41676,DS-b68e60b3-c8d9-459a-8756-e63039ade3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-22687606-39d5-4968-8e63-78ecbc141589,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-1bf2a703-f345-4e46-a45c-6c6eb221b242,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-b5325dd9-7bff-4b81-88d0-1098e1fb6443,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-b0d09399-0f66-4729-acd6-400beec6f90d,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-c083fd3a-faf9-4f74-956f-c1d64fb11562,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-7bbb1d8f-407f-4148-b2e3-8ac0faab7bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-4e6d8e7e-8ffc-4667-8f87-2592c7ce8fcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571669183-172.17.0.10-1598133955787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37228,DS-4364d9fe-64a8-490e-a1f5-eac8adefd468,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-9ce51494-3354-4350-83d7-b2b71850b135,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-b53512d1-9c8a-4535-9856-1f1661185218,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-12940b4e-adca-4f60-94b2-38eb0fe18c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-69d94f88-a96f-4f03-9aff-079976b2896f,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-2b0b626f-9b90-411a-8d8c-e2a722eb6058,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-d2b926e2-a025-46cf-8def-304bb98db07f,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-a3557e31-b495-482f-b3a4-de9331de43f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571669183-172.17.0.10-1598133955787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37228,DS-4364d9fe-64a8-490e-a1f5-eac8adefd468,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-9ce51494-3354-4350-83d7-b2b71850b135,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-b53512d1-9c8a-4535-9856-1f1661185218,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-12940b4e-adca-4f60-94b2-38eb0fe18c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-69d94f88-a96f-4f03-9aff-079976b2896f,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-2b0b626f-9b90-411a-8d8c-e2a722eb6058,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-d2b926e2-a025-46cf-8def-304bb98db07f,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-a3557e31-b495-482f-b3a4-de9331de43f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117004128-172.17.0.10-1598134610830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-327f042e-24be-4c16-a9d0-94fc0c2f272f,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-aaae30f5-bfc5-4df6-b496-2f0df49f2162,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-dac524d1-d9e2-4524-94bb-e4b7c565da85,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-4746a646-b9ea-44ec-a64a-dca6bc798994,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-93f885e5-105e-4b1b-8ed8-e9cc25251a71,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-c30e8d5b-3a16-4151-ad4d-08e02cfb45c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-1dd84c8f-45e7-49bc-a052-119159528e71,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-f3728577-5b95-4716-9d9c-c9df8ab80850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117004128-172.17.0.10-1598134610830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-327f042e-24be-4c16-a9d0-94fc0c2f272f,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-aaae30f5-bfc5-4df6-b496-2f0df49f2162,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-dac524d1-d9e2-4524-94bb-e4b7c565da85,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-4746a646-b9ea-44ec-a64a-dca6bc798994,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-93f885e5-105e-4b1b-8ed8-e9cc25251a71,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-c30e8d5b-3a16-4151-ad4d-08e02cfb45c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-1dd84c8f-45e7-49bc-a052-119159528e71,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-f3728577-5b95-4716-9d9c-c9df8ab80850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033015484-172.17.0.10-1598134902666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36172,DS-d9300ef3-8977-4a3f-a66b-4a1f38feef9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-c71e5011-0e7e-4eb3-a7d8-731eaa03b270,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-b14bfa2a-f528-495b-885d-4440167ce304,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-65d726db-8e6d-48bd-a828-2a15dd714b89,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-5151dd25-07ea-42ca-b473-63f61c1aea2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-6007f470-0329-4f72-be02-81f9f605dd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-6cfd6333-b71c-4ea2-8665-a0ef6c6e08bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-63a7acb6-2bc8-40fb-89b3-af1211e3672e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033015484-172.17.0.10-1598134902666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36172,DS-d9300ef3-8977-4a3f-a66b-4a1f38feef9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-c71e5011-0e7e-4eb3-a7d8-731eaa03b270,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-b14bfa2a-f528-495b-885d-4440167ce304,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-65d726db-8e6d-48bd-a828-2a15dd714b89,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-5151dd25-07ea-42ca-b473-63f61c1aea2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-6007f470-0329-4f72-be02-81f9f605dd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-6cfd6333-b71c-4ea2-8665-a0ef6c6e08bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-63a7acb6-2bc8-40fb-89b3-af1211e3672e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674352215-172.17.0.10-1598135586915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36075,DS-f4353c79-3b05-42b3-9f2d-4d839aef11e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-a1186a62-e696-45b8-b71f-287ad9e1e777,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-648657ee-c900-445c-952a-ccbbf1dec3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-b989668c-97c3-4c12-91b4-f7be309e32fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-b3616593-01eb-4159-8646-a910a3db325c,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-a2444592-6461-4787-96e5-9380e30a2d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-2753ecd1-2ffe-45bd-b920-ffc83ea44d25,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-15d01632-7555-41af-b042-2a66e9c4765d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674352215-172.17.0.10-1598135586915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36075,DS-f4353c79-3b05-42b3-9f2d-4d839aef11e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-a1186a62-e696-45b8-b71f-287ad9e1e777,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-648657ee-c900-445c-952a-ccbbf1dec3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-b989668c-97c3-4c12-91b4-f7be309e32fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-b3616593-01eb-4159-8646-a910a3db325c,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-a2444592-6461-4787-96e5-9380e30a2d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-2753ecd1-2ffe-45bd-b920-ffc83ea44d25,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-15d01632-7555-41af-b042-2a66e9c4765d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803285661-172.17.0.10-1598135979232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37087,DS-fda3da11-f2bf-4eef-804c-9687f985e70b,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-a72b5968-0675-48be-aa7c-a03a637320bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-a9af189f-82ce-4f60-96e6-6d4ebfac37b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-ec2df74e-d42d-42fa-a159-b23c36de5fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-e4180772-5120-4274-922e-491a6c5ef4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-1bc84746-78b6-416c-a81c-aa72796490b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-a6c1e0c8-782c-4b80-b0c2-057bbb825e35,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-0fc24a5f-fc23-41b8-8eb1-bf42b6cc25da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803285661-172.17.0.10-1598135979232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37087,DS-fda3da11-f2bf-4eef-804c-9687f985e70b,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-a72b5968-0675-48be-aa7c-a03a637320bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-a9af189f-82ce-4f60-96e6-6d4ebfac37b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-ec2df74e-d42d-42fa-a159-b23c36de5fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-e4180772-5120-4274-922e-491a6c5ef4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-1bc84746-78b6-416c-a81c-aa72796490b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-a6c1e0c8-782c-4b80-b0c2-057bbb825e35,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-0fc24a5f-fc23-41b8-8eb1-bf42b6cc25da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1392429433-172.17.0.10-1598136887495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32908,DS-a2d5e0fe-7d6f-4379-9501-9aab850b7955,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-ace83e8c-722a-459b-b103-37bd41362e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-b30f70b5-252a-486a-9767-75a24fa88cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-119dee06-a17e-4e20-a9df-9186195e702c,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-439af4c6-1abd-482e-a84e-599a151a7db2,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-4090c558-6cac-4886-9d1b-be998e8058bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-41deb66c-1b13-4ba5-867c-ce0d920487d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-80f3f74f-5f47-472a-be2f-30fc751b45f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1392429433-172.17.0.10-1598136887495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32908,DS-a2d5e0fe-7d6f-4379-9501-9aab850b7955,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-ace83e8c-722a-459b-b103-37bd41362e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-b30f70b5-252a-486a-9767-75a24fa88cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-119dee06-a17e-4e20-a9df-9186195e702c,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-439af4c6-1abd-482e-a84e-599a151a7db2,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-4090c558-6cac-4886-9d1b-be998e8058bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-41deb66c-1b13-4ba5-867c-ce0d920487d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-80f3f74f-5f47-472a-be2f-30fc751b45f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753317149-172.17.0.10-1598136923527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36325,DS-022ce22c-0128-47aa-af53-64f2c248fc96,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-f863b076-d444-4544-8134-87baf3cf25c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-974390fa-8a57-41de-9e0e-db23cd57225b,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-b66e4269-9577-4d78-8886-4789acd18155,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-69ce84f4-9a64-414c-994b-254f60986caf,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-d12c1bc8-8a43-413e-9d27-11607252a047,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-147bf205-513b-4a66-86bf-5da375103529,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-d2d5cf23-56ed-45eb-a701-ceffcd814e0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753317149-172.17.0.10-1598136923527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36325,DS-022ce22c-0128-47aa-af53-64f2c248fc96,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-f863b076-d444-4544-8134-87baf3cf25c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-974390fa-8a57-41de-9e0e-db23cd57225b,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-b66e4269-9577-4d78-8886-4789acd18155,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-69ce84f4-9a64-414c-994b-254f60986caf,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-d12c1bc8-8a43-413e-9d27-11607252a047,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-147bf205-513b-4a66-86bf-5da375103529,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-d2d5cf23-56ed-45eb-a701-ceffcd814e0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963210271-172.17.0.10-1598137034621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41135,DS-99077e9f-451a-4843-a77d-f92d83fcd7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-f80b55f9-6bfe-45dc-b870-90c2fdcf05cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-b2c7f444-5171-4050-9f53-3dd2774f003d,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-236a38fc-83a4-46b3-85a8-48f149adb334,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-70dcdb65-6bf6-46b3-8102-83b07d8c1bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-f1f3ef8a-fe09-475b-b12b-722e8717a525,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-e2a87f2b-923a-4ad6-816e-904831280e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-fe0b3b2e-d127-4a64-af2d-583a8d805db5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963210271-172.17.0.10-1598137034621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41135,DS-99077e9f-451a-4843-a77d-f92d83fcd7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-f80b55f9-6bfe-45dc-b870-90c2fdcf05cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-b2c7f444-5171-4050-9f53-3dd2774f003d,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-236a38fc-83a4-46b3-85a8-48f149adb334,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-70dcdb65-6bf6-46b3-8102-83b07d8c1bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-f1f3ef8a-fe09-475b-b12b-722e8717a525,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-e2a87f2b-923a-4ad6-816e-904831280e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-fe0b3b2e-d127-4a64-af2d-583a8d805db5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374026047-172.17.0.10-1598137334703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-e13d56ed-6f27-4831-b4fe-687dbf9f8c61,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-9d7d3923-dc35-4ffc-a3fe-d25f2d9e82df,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-e1ddb6a2-9ee8-4f36-b121-8b3afdd633c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-28ef3f16-3b79-4011-88ff-a7dcb80cc03c,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-97bf8218-b0fd-428a-bc83-fbb7f368ee48,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-f29acc1e-91b2-4d3d-a16b-eca7bc13dc88,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-af44ca32-7a86-4f74-99d4-9ca08ec6c35d,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-3eec858b-18f1-48f4-a748-41de1cc6bec2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374026047-172.17.0.10-1598137334703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38023,DS-e13d56ed-6f27-4831-b4fe-687dbf9f8c61,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-9d7d3923-dc35-4ffc-a3fe-d25f2d9e82df,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-e1ddb6a2-9ee8-4f36-b121-8b3afdd633c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-28ef3f16-3b79-4011-88ff-a7dcb80cc03c,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-97bf8218-b0fd-428a-bc83-fbb7f368ee48,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-f29acc1e-91b2-4d3d-a16b-eca7bc13dc88,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-af44ca32-7a86-4f74-99d4-9ca08ec6c35d,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-3eec858b-18f1-48f4-a748-41de1cc6bec2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25063438-172.17.0.10-1598137615174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40811,DS-95b7c147-909a-4e25-aee2-354672d8b599,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-f3c59f28-c705-49b5-ba5e-5e3af30e2765,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-381eda8a-fd59-4c35-909e-5869c759c4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-e25a0354-5b03-42cd-99af-fe8ad0648022,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-63e6cb6b-d44b-4527-bc2c-6bd0e5933415,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-d5046e0d-9438-427a-a408-33fb63744d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-d02ca673-1553-4bf4-8c35-4ba9ae172f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-b15ddfa2-a9b4-4bcb-87c4-ae8d356975f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25063438-172.17.0.10-1598137615174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40811,DS-95b7c147-909a-4e25-aee2-354672d8b599,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-f3c59f28-c705-49b5-ba5e-5e3af30e2765,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-381eda8a-fd59-4c35-909e-5869c759c4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-e25a0354-5b03-42cd-99af-fe8ad0648022,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-63e6cb6b-d44b-4527-bc2c-6bd0e5933415,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-d5046e0d-9438-427a-a408-33fb63744d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-d02ca673-1553-4bf4-8c35-4ba9ae172f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-b15ddfa2-a9b4-4bcb-87c4-ae8d356975f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237248096-172.17.0.10-1598137795698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34458,DS-ea321728-4ab2-4b42-a1e5-cab45b4b5dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-63f3576c-8fbc-49b9-8302-857b15fa276a,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-84ea8c42-4dd9-4fa5-8b2b-9e243408e47b,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-287c4558-7296-4cbb-b782-2d0c77584437,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-9f9ffaae-714f-4395-bf57-68fcee71ae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-93ce1ea4-b5c9-47c8-97a9-c259644fa1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-b1c401d5-ea64-4d90-bc04-98f4ea1e0533,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-2485598e-9c98-4692-a51c-88765159db10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237248096-172.17.0.10-1598137795698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34458,DS-ea321728-4ab2-4b42-a1e5-cab45b4b5dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-63f3576c-8fbc-49b9-8302-857b15fa276a,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-84ea8c42-4dd9-4fa5-8b2b-9e243408e47b,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-287c4558-7296-4cbb-b782-2d0c77584437,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-9f9ffaae-714f-4395-bf57-68fcee71ae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-93ce1ea4-b5c9-47c8-97a9-c259644fa1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-b1c401d5-ea64-4d90-bc04-98f4ea1e0533,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-2485598e-9c98-4692-a51c-88765159db10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076710060-172.17.0.10-1598137835409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37832,DS-8fe100c9-752c-45df-8ec1-8203965e9f81,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-a8b2d1e2-23d4-4d49-b780-2b88e38dfeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-30065f28-9862-4ead-98db-e27ffef4459a,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-422cf456-1cfb-4019-8010-3c0bdb5af24d,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-2cfc215b-f890-4a8a-8615-46b9eeb30336,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-9a951ab1-5201-4d30-b440-a4a8b4d5bcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-5de272ff-de03-4fce-9282-aa5560f0bb81,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-59f7843c-55da-4abe-aa3c-f62f8bfa08e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076710060-172.17.0.10-1598137835409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37832,DS-8fe100c9-752c-45df-8ec1-8203965e9f81,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-a8b2d1e2-23d4-4d49-b780-2b88e38dfeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-30065f28-9862-4ead-98db-e27ffef4459a,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-422cf456-1cfb-4019-8010-3c0bdb5af24d,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-2cfc215b-f890-4a8a-8615-46b9eeb30336,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-9a951ab1-5201-4d30-b440-a4a8b4d5bcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-5de272ff-de03-4fce-9282-aa5560f0bb81,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-59f7843c-55da-4abe-aa3c-f62f8bfa08e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439206588-172.17.0.10-1598138126290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43503,DS-4e7d411c-bfd7-45a3-ac9b-d89a270e0b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-03272ab0-7337-4a84-a2f3-655a8d82b064,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-899edf08-c9d9-4b65-b4c6-bd6f909bef55,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-b261cdee-e139-4656-96b7-3ab0fe2abc98,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-9a31449d-3c3e-44e0-bfe1-4533d50359d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-b4eec0fd-ce35-435b-a6cd-d9f5f88097a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-347334df-7367-415a-8bf7-e826284ec174,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-7622f7dd-aca8-4d80-a87c-8eff96463913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439206588-172.17.0.10-1598138126290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43503,DS-4e7d411c-bfd7-45a3-ac9b-d89a270e0b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-03272ab0-7337-4a84-a2f3-655a8d82b064,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-899edf08-c9d9-4b65-b4c6-bd6f909bef55,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-b261cdee-e139-4656-96b7-3ab0fe2abc98,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-9a31449d-3c3e-44e0-bfe1-4533d50359d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-b4eec0fd-ce35-435b-a6cd-d9f5f88097a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-347334df-7367-415a-8bf7-e826284ec174,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-7622f7dd-aca8-4d80-a87c-8eff96463913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123950048-172.17.0.10-1598138456184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45352,DS-c537c54f-2db1-4d0d-8eb7-175ef50c3206,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-ce49cb4f-9d1f-4f8e-bc7f-883155c567da,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-fb5aef99-36ce-49ed-85e2-6ca88754773b,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-c5d3ec37-3209-4678-8289-c741281b6b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-9d06b515-2660-46fc-9179-1ea1a37d6bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-85a07957-ae54-449c-b6a3-6699b1d77589,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-988dc6d5-7df7-4cae-a3d4-fcab4842bba4,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-18df4c4b-d45c-4025-8e06-2742ef5f438a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123950048-172.17.0.10-1598138456184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45352,DS-c537c54f-2db1-4d0d-8eb7-175ef50c3206,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-ce49cb4f-9d1f-4f8e-bc7f-883155c567da,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-fb5aef99-36ce-49ed-85e2-6ca88754773b,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-c5d3ec37-3209-4678-8289-c741281b6b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-9d06b515-2660-46fc-9179-1ea1a37d6bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-85a07957-ae54-449c-b6a3-6699b1d77589,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-988dc6d5-7df7-4cae-a3d4-fcab4842bba4,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-18df4c4b-d45c-4025-8e06-2742ef5f438a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5285
