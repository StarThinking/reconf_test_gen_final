reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886734189-172.17.0.7-1598109382514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38150,DS-0775fa9f-281d-4d8f-929f-b3f3eeda4c86,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-42bce06a-2803-4a7c-a4ee-29d2db782b53,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-ffeff2e0-780a-4bfe-814b-4f885528abe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-645b416c-9ac7-47d6-804f-d756d78dad85,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-4a88b190-67ce-4421-8fc4-4bbb755f2ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-2064b5c7-6c30-4333-99b2-80c8bfc0d4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-43d442c2-5699-4cc5-b737-4ecd683eac69,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-95ac2bb1-326e-4d8a-b3ed-9e343e615298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886734189-172.17.0.7-1598109382514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38150,DS-0775fa9f-281d-4d8f-929f-b3f3eeda4c86,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-42bce06a-2803-4a7c-a4ee-29d2db782b53,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-ffeff2e0-780a-4bfe-814b-4f885528abe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-645b416c-9ac7-47d6-804f-d756d78dad85,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-4a88b190-67ce-4421-8fc4-4bbb755f2ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-2064b5c7-6c30-4333-99b2-80c8bfc0d4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-43d442c2-5699-4cc5-b737-4ecd683eac69,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-95ac2bb1-326e-4d8a-b3ed-9e343e615298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036591892-172.17.0.7-1598109449104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38617,DS-d80cd5f5-c653-43ea-9b8a-524d389c5112,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-23c04e9a-1b31-463f-9405-857d8390b23b,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-5079dc07-320e-46bb-8d90-c038386485e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-4ddab788-934d-4c4f-985f-f0351cd4fe80,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-1cde6170-cb27-4844-87b2-9f3649e9ac46,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-c6831ca2-50c4-4b5d-bd65-703e860389b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-2da91d41-5382-4528-aadf-77e399126b28,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-96d921bb-8def-45a2-ad78-35542e4372c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036591892-172.17.0.7-1598109449104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38617,DS-d80cd5f5-c653-43ea-9b8a-524d389c5112,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-23c04e9a-1b31-463f-9405-857d8390b23b,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-5079dc07-320e-46bb-8d90-c038386485e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-4ddab788-934d-4c4f-985f-f0351cd4fe80,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-1cde6170-cb27-4844-87b2-9f3649e9ac46,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-c6831ca2-50c4-4b5d-bd65-703e860389b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-2da91d41-5382-4528-aadf-77e399126b28,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-96d921bb-8def-45a2-ad78-35542e4372c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977893409-172.17.0.7-1598109484193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33736,DS-d8507133-e9fb-4197-9881-fa30387de861,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-6d99d4d7-9621-4768-8d10-ed93bc28f7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-53c8de31-3b3f-469b-a234-f4df4dfac208,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-13abef47-0ebf-4815-b822-2f7129828bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-0165e955-f2a5-4f25-bdea-6cec4e7aeede,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-0ef7a1f7-0784-447e-a0d9-18078fc13188,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-7de7aea5-b440-46ea-be8d-5f3820056458,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-4242a109-5360-433e-8d83-b189ab617d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977893409-172.17.0.7-1598109484193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33736,DS-d8507133-e9fb-4197-9881-fa30387de861,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-6d99d4d7-9621-4768-8d10-ed93bc28f7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-53c8de31-3b3f-469b-a234-f4df4dfac208,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-13abef47-0ebf-4815-b822-2f7129828bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-0165e955-f2a5-4f25-bdea-6cec4e7aeede,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-0ef7a1f7-0784-447e-a0d9-18078fc13188,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-7de7aea5-b440-46ea-be8d-5f3820056458,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-4242a109-5360-433e-8d83-b189ab617d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128448738-172.17.0.7-1598109586244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35750,DS-c461f6ae-bae3-44b3-ba34-31cf0366b373,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-aa25ee13-0f7b-4e74-bcbb-dc7a8e9b753e,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-f9474f9d-a339-4180-a283-33cdbcb8aeef,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-ac892afb-dd19-42ab-9905-21575fcb01a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-20d2b8ca-720a-4fec-8ebc-ecccc52c7f38,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-9486b1f5-d558-45ca-8d9a-4c44cb7cf55c,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-2adbe5a3-692b-4761-b09c-9d5d13e3bcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-4e7ae3f0-c816-4cbf-946a-5f79ed8ed981,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128448738-172.17.0.7-1598109586244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35750,DS-c461f6ae-bae3-44b3-ba34-31cf0366b373,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-aa25ee13-0f7b-4e74-bcbb-dc7a8e9b753e,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-f9474f9d-a339-4180-a283-33cdbcb8aeef,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-ac892afb-dd19-42ab-9905-21575fcb01a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-20d2b8ca-720a-4fec-8ebc-ecccc52c7f38,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-9486b1f5-d558-45ca-8d9a-4c44cb7cf55c,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-2adbe5a3-692b-4761-b09c-9d5d13e3bcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-4e7ae3f0-c816-4cbf-946a-5f79ed8ed981,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095609043-172.17.0.7-1598109765434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41433,DS-a8de1b6f-a29c-4893-9943-3f5c47617975,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-202ae9c6-a243-4d75-8285-e17270486c33,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-e6fb896e-6b0f-4d15-9dc5-d90a7d66b65b,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-378f07fa-01dc-4e7c-816b-942909119e28,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-c13332b0-ca26-4afc-a5b6-a679e667bf99,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-0ed2b070-4f91-4460-a84f-b114162731ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-edb2d651-7a77-4183-8dbc-1f9b02be836d,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-99cdf89f-22ee-4230-8991-cc4ac4beb612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095609043-172.17.0.7-1598109765434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41433,DS-a8de1b6f-a29c-4893-9943-3f5c47617975,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-202ae9c6-a243-4d75-8285-e17270486c33,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-e6fb896e-6b0f-4d15-9dc5-d90a7d66b65b,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-378f07fa-01dc-4e7c-816b-942909119e28,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-c13332b0-ca26-4afc-a5b6-a679e667bf99,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-0ed2b070-4f91-4460-a84f-b114162731ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-edb2d651-7a77-4183-8dbc-1f9b02be836d,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-99cdf89f-22ee-4230-8991-cc4ac4beb612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887869371-172.17.0.7-1598110713426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38858,DS-6c94990c-4e4b-4859-8cf9-e25c56fe04fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-c36b7934-6a79-4499-95c3-8d980c5037d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-5ed8ffe9-82b3-4dc0-b2f9-17c0696c578c,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-76b135ed-fe5a-43ce-a315-337299023dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-c9ec3055-4607-45fd-a768-ea1620f42d33,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-1eaf746b-d80f-4989-8ced-81c820d58464,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-bc70d03d-87aa-4d6f-bec2-793be4a3f7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-52d41e65-2712-4d12-b933-1ffae4bf6e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887869371-172.17.0.7-1598110713426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38858,DS-6c94990c-4e4b-4859-8cf9-e25c56fe04fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-c36b7934-6a79-4499-95c3-8d980c5037d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-5ed8ffe9-82b3-4dc0-b2f9-17c0696c578c,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-76b135ed-fe5a-43ce-a315-337299023dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-c9ec3055-4607-45fd-a768-ea1620f42d33,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-1eaf746b-d80f-4989-8ced-81c820d58464,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-bc70d03d-87aa-4d6f-bec2-793be4a3f7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-52d41e65-2712-4d12-b933-1ffae4bf6e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648757745-172.17.0.7-1598110821052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45931,DS-a7061d39-4f5d-4806-aa52-2d5cf275f269,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-cfc3b10b-9ea7-4a3f-9c91-ded2764d8336,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-d94c003f-5c2f-41fd-a5dc-9aba0f338be4,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-35f58c5f-3d0a-4232-b5f6-6d14fc8fcdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-b56d83f4-6090-49ca-b568-4e429164b9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-21d72f96-b04a-473d-b679-c59ba3421dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-fcd43b64-3b86-4e31-9696-9546f7b5e757,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-e5b5b4b4-ae60-43cb-8e18-a093b025c201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648757745-172.17.0.7-1598110821052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45931,DS-a7061d39-4f5d-4806-aa52-2d5cf275f269,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-cfc3b10b-9ea7-4a3f-9c91-ded2764d8336,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-d94c003f-5c2f-41fd-a5dc-9aba0f338be4,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-35f58c5f-3d0a-4232-b5f6-6d14fc8fcdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-b56d83f4-6090-49ca-b568-4e429164b9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-21d72f96-b04a-473d-b679-c59ba3421dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-fcd43b64-3b86-4e31-9696-9546f7b5e757,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-e5b5b4b4-ae60-43cb-8e18-a093b025c201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152114787-172.17.0.7-1598110901352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42949,DS-c777c8b6-8010-469a-bbdc-91f10ec00ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-15e12231-bd4f-46c1-a59c-2543ee9e693c,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-0fb7ea79-af0e-424d-8d02-c0a36643daa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-72acb893-62a3-4045-aaa8-8f0e6613cc87,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-37c7542a-05b2-4650-9570-5cba239fdf62,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-fce3513e-7126-4397-9d60-ae7c274cb13f,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-8125e2ec-6494-4bd0-aa3d-bbc4dd297562,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-101a0d1e-9635-451e-b9fd-973c53a53900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152114787-172.17.0.7-1598110901352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42949,DS-c777c8b6-8010-469a-bbdc-91f10ec00ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-15e12231-bd4f-46c1-a59c-2543ee9e693c,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-0fb7ea79-af0e-424d-8d02-c0a36643daa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-72acb893-62a3-4045-aaa8-8f0e6613cc87,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-37c7542a-05b2-4650-9570-5cba239fdf62,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-fce3513e-7126-4397-9d60-ae7c274cb13f,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-8125e2ec-6494-4bd0-aa3d-bbc4dd297562,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-101a0d1e-9635-451e-b9fd-973c53a53900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789925644-172.17.0.7-1598112086285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40416,DS-a3732b0a-8554-4094-be30-84e514a0fc47,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-8f883e9a-aaef-4be8-b171-1a710ed0404b,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-31536edb-89f6-4bc2-95ef-59d30d22d72e,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-8808577e-58a8-476c-9678-ab66f606b7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-97a0bfb1-f10f-4c08-b927-3bdcd35d80f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-8d6e5a69-aa6f-496d-b066-2fc9f27deb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-6d11dde8-98d5-41b4-867b-365265abe996,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-dacca086-944c-44ae-9bd9-9d4e37ce6deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789925644-172.17.0.7-1598112086285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40416,DS-a3732b0a-8554-4094-be30-84e514a0fc47,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-8f883e9a-aaef-4be8-b171-1a710ed0404b,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-31536edb-89f6-4bc2-95ef-59d30d22d72e,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-8808577e-58a8-476c-9678-ab66f606b7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-97a0bfb1-f10f-4c08-b927-3bdcd35d80f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-8d6e5a69-aa6f-496d-b066-2fc9f27deb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-6d11dde8-98d5-41b4-867b-365265abe996,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-dacca086-944c-44ae-9bd9-9d4e37ce6deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239311817-172.17.0.7-1598112119547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45466,DS-4aabb166-c62a-442a-b0e0-f9fcda21bb94,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-80f678e4-4811-462b-a6e8-fe2078bc2b78,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-840e1725-681a-4cea-bd68-6a7bc458ede3,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-b0baf696-daf1-41e4-8b8a-4700c6e286d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-6f3f65b3-90d2-4763-9b67-e10fbf8fdecb,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-a3808bc1-3bf9-471e-bb30-2691e9604932,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-cf0a38f2-8acf-4ce4-a928-8197eb81ecc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-62dd0df1-21a4-43b6-9e93-771637958156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239311817-172.17.0.7-1598112119547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45466,DS-4aabb166-c62a-442a-b0e0-f9fcda21bb94,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-80f678e4-4811-462b-a6e8-fe2078bc2b78,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-840e1725-681a-4cea-bd68-6a7bc458ede3,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-b0baf696-daf1-41e4-8b8a-4700c6e286d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-6f3f65b3-90d2-4763-9b67-e10fbf8fdecb,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-a3808bc1-3bf9-471e-bb30-2691e9604932,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-cf0a38f2-8acf-4ce4-a928-8197eb81ecc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-62dd0df1-21a4-43b6-9e93-771637958156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783993488-172.17.0.7-1598112718098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33120,DS-e3f64e64-6115-46c2-8593-a755d95b9efa,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-39ff5f8b-9cc3-497e-b109-c1fbdfaeaa8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-b90817ce-08d0-48ad-bf5d-0ce3a856545c,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-6b06afc7-d4cc-4a55-a2b9-073f0aab7d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-57a7a310-8c90-4d5a-a486-1bc771716a16,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-0706cc44-9755-4f30-9698-596fc35f63c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-528e9558-8297-4255-81f0-157b1415aea6,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-5e0d15ee-856b-4230-9e5d-378e5179eee4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783993488-172.17.0.7-1598112718098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33120,DS-e3f64e64-6115-46c2-8593-a755d95b9efa,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-39ff5f8b-9cc3-497e-b109-c1fbdfaeaa8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-b90817ce-08d0-48ad-bf5d-0ce3a856545c,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-6b06afc7-d4cc-4a55-a2b9-073f0aab7d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-57a7a310-8c90-4d5a-a486-1bc771716a16,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-0706cc44-9755-4f30-9698-596fc35f63c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-528e9558-8297-4255-81f0-157b1415aea6,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-5e0d15ee-856b-4230-9e5d-378e5179eee4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-146941108-172.17.0.7-1598113524354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-a1b0efb9-79ef-4e0d-b39f-563391161f69,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-0b80c6fb-3d41-4f9a-84b5-66cd7975d2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-e5d7373f-9583-4125-b259-57e94511886b,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-8f7edf9a-2b9b-4e02-aeef-4874b041a6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-40f5aced-8839-45c1-8994-3cc0a5d8a91e,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-293d0cef-8cdd-4fcc-b0dc-50acc92f5528,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-98e0fd96-ea10-4c2d-a8c5-9ae61d0221ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-d918dd69-0c49-475f-8b17-d0f835ae794f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-146941108-172.17.0.7-1598113524354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-a1b0efb9-79ef-4e0d-b39f-563391161f69,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-0b80c6fb-3d41-4f9a-84b5-66cd7975d2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-e5d7373f-9583-4125-b259-57e94511886b,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-8f7edf9a-2b9b-4e02-aeef-4874b041a6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-40f5aced-8839-45c1-8994-3cc0a5d8a91e,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-293d0cef-8cdd-4fcc-b0dc-50acc92f5528,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-98e0fd96-ea10-4c2d-a8c5-9ae61d0221ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-d918dd69-0c49-475f-8b17-d0f835ae794f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469079506-172.17.0.7-1598113997683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40927,DS-0d69fa4a-52a6-4a38-9fb0-b729541319e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-4ea94b6b-1bae-45a6-9bc6-aa87c81bbf83,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-55972d58-f269-4f26-abed-834f95d847e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-22a00441-fb9c-4fcb-b826-ddb1d4e42fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-6b26efaa-3b9c-4512-ae30-c43f0d250032,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-1d254abf-a9a1-460e-bb33-07ca7dfbe80e,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-e1b7ab4e-c786-45a7-af77-f88b2c5a03d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-c4926d22-1586-4842-bfae-d9854a5c0567,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469079506-172.17.0.7-1598113997683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40927,DS-0d69fa4a-52a6-4a38-9fb0-b729541319e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-4ea94b6b-1bae-45a6-9bc6-aa87c81bbf83,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-55972d58-f269-4f26-abed-834f95d847e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-22a00441-fb9c-4fcb-b826-ddb1d4e42fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-6b26efaa-3b9c-4512-ae30-c43f0d250032,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-1d254abf-a9a1-460e-bb33-07ca7dfbe80e,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-e1b7ab4e-c786-45a7-af77-f88b2c5a03d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-c4926d22-1586-4842-bfae-d9854a5c0567,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624202723-172.17.0.7-1598114415285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40388,DS-c6dfb332-7f87-4c4e-b1c9-a9ca13e34a50,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-4b7d9ebf-4ca1-4c06-8099-addd31953e12,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-ace6b45b-3dc9-4414-8d40-50b6bb275f43,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-fc0bfc5a-c0c2-43e9-8ff3-26aec81317d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-db38c414-b996-41ae-9194-3b5354df9024,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-3fa37586-8650-4e34-98e9-928eb80c18e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-9d4cae60-8296-4d5d-96b2-fa840102b087,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-a78036c7-b2e2-437b-8357-c5e202afad92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624202723-172.17.0.7-1598114415285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40388,DS-c6dfb332-7f87-4c4e-b1c9-a9ca13e34a50,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-4b7d9ebf-4ca1-4c06-8099-addd31953e12,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-ace6b45b-3dc9-4414-8d40-50b6bb275f43,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-fc0bfc5a-c0c2-43e9-8ff3-26aec81317d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-db38c414-b996-41ae-9194-3b5354df9024,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-3fa37586-8650-4e34-98e9-928eb80c18e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-9d4cae60-8296-4d5d-96b2-fa840102b087,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-a78036c7-b2e2-437b-8357-c5e202afad92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941025791-172.17.0.7-1598114472169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41542,DS-6fe23fa6-c651-4bca-ae20-cf3e47c6883e,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-d61eba49-6f49-413f-b3a2-317ca298a248,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-bac26d07-648b-497b-91df-b8dc7fad81ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-d58a9571-2770-4e48-adaa-ad97cb1cd937,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-7542c016-2ae7-4473-8d0c-6146dd3ee0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-84e7cf95-5e7d-4dac-b097-ec556e43394e,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-dfb40f3f-08fc-476d-b459-0343fd68fbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-31adb212-c892-448d-a6bb-72d0e3bb148a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941025791-172.17.0.7-1598114472169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41542,DS-6fe23fa6-c651-4bca-ae20-cf3e47c6883e,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-d61eba49-6f49-413f-b3a2-317ca298a248,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-bac26d07-648b-497b-91df-b8dc7fad81ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-d58a9571-2770-4e48-adaa-ad97cb1cd937,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-7542c016-2ae7-4473-8d0c-6146dd3ee0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-84e7cf95-5e7d-4dac-b097-ec556e43394e,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-dfb40f3f-08fc-476d-b459-0343fd68fbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-31adb212-c892-448d-a6bb-72d0e3bb148a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5558
