reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60349124-172.17.0.16-1598402127538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43280,DS-bfd4915f-ad19-441e-8660-fb5c5b3c4fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-7bedf5ef-5c4f-4473-b0e2-24162ffe463f,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-a331d458-43e8-446c-8d1d-681d47543d85,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-10d13a95-0569-44fb-acee-556bf6484c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-fb5c2a16-4f5f-4db6-b4e2-5f2c410625bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-35e3523b-fc9a-49c5-ba14-5b4f30de50a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-b425f26b-dbba-4e65-8d57-2381c09b174e,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-128fdfab-a295-48ae-9481-a0568ebd3343,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60349124-172.17.0.16-1598402127538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43280,DS-bfd4915f-ad19-441e-8660-fb5c5b3c4fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-7bedf5ef-5c4f-4473-b0e2-24162ffe463f,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-a331d458-43e8-446c-8d1d-681d47543d85,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-10d13a95-0569-44fb-acee-556bf6484c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-fb5c2a16-4f5f-4db6-b4e2-5f2c410625bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-35e3523b-fc9a-49c5-ba14-5b4f30de50a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-b425f26b-dbba-4e65-8d57-2381c09b174e,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-128fdfab-a295-48ae-9481-a0568ebd3343,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524380827-172.17.0.16-1598402487713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45078,DS-21169f17-59e8-4299-b12d-e283a1f814b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-e246b406-1636-48c7-9bd4-b212f06569c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-8433fcbf-85db-4eef-9838-f6d61d0d4823,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-78bc9e5c-6272-418a-a65a-e237c9cedd85,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-43e8c65a-c196-4400-99ab-b29831d454d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-d9b3dc4d-9d49-47d0-81bf-4899033c85e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-353c9a8b-b1d9-41b1-90d6-23ed4b7b8c79,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-32a665f8-6258-48e6-9c8a-96fd352cc53d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524380827-172.17.0.16-1598402487713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45078,DS-21169f17-59e8-4299-b12d-e283a1f814b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-e246b406-1636-48c7-9bd4-b212f06569c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-8433fcbf-85db-4eef-9838-f6d61d0d4823,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-78bc9e5c-6272-418a-a65a-e237c9cedd85,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-43e8c65a-c196-4400-99ab-b29831d454d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-d9b3dc4d-9d49-47d0-81bf-4899033c85e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-353c9a8b-b1d9-41b1-90d6-23ed4b7b8c79,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-32a665f8-6258-48e6-9c8a-96fd352cc53d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312821844-172.17.0.16-1598402763119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35847,DS-5b9d65fc-4dec-40c6-9825-1a48d0cde6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-46be4c62-2166-429a-8c57-dda97d646c00,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-42d354fa-d3d0-4739-ba95-6cfc710ed05d,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-66768db2-4852-4b3d-a6fb-e9d3f3ade9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-87e722c2-2665-44bf-aa16-85d4e1a3bbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-aabe9784-8a7b-4665-9c3a-1adc0c6d49a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-b097e8a4-475f-432b-9b99-ccac930330f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-31a5a157-ad35-4a5f-a9d4-1dba0130d5b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312821844-172.17.0.16-1598402763119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35847,DS-5b9d65fc-4dec-40c6-9825-1a48d0cde6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-46be4c62-2166-429a-8c57-dda97d646c00,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-42d354fa-d3d0-4739-ba95-6cfc710ed05d,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-66768db2-4852-4b3d-a6fb-e9d3f3ade9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-87e722c2-2665-44bf-aa16-85d4e1a3bbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-aabe9784-8a7b-4665-9c3a-1adc0c6d49a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-b097e8a4-475f-432b-9b99-ccac930330f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-31a5a157-ad35-4a5f-a9d4-1dba0130d5b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834198535-172.17.0.16-1598402901704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34071,DS-5b5b7029-e5d9-425f-a37f-cf1276478d04,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-643fc18e-d208-4720-9269-7c12443eb561,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-f53f395e-1c8a-47fd-aa97-34e243c14506,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-411b91ee-de69-4b9e-a33b-bc95fc5e1526,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-9680a597-d70e-4ecd-818f-af776d0b2f31,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-f5bff2b4-200b-47be-923f-a0d34c3a4335,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-3fd43182-47cd-4e9c-8e22-3aae72cebb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-c34ad1a3-e92c-4db2-b356-9713b3fd202f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834198535-172.17.0.16-1598402901704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34071,DS-5b5b7029-e5d9-425f-a37f-cf1276478d04,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-643fc18e-d208-4720-9269-7c12443eb561,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-f53f395e-1c8a-47fd-aa97-34e243c14506,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-411b91ee-de69-4b9e-a33b-bc95fc5e1526,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-9680a597-d70e-4ecd-818f-af776d0b2f31,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-f5bff2b4-200b-47be-923f-a0d34c3a4335,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-3fd43182-47cd-4e9c-8e22-3aae72cebb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-c34ad1a3-e92c-4db2-b356-9713b3fd202f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1324157419-172.17.0.16-1598403083010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41199,DS-a3da1764-beb4-4e52-b76f-f71ddf062878,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-8d635d9e-37e8-4a08-a605-85a5f1e2a3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-dc45c500-a3ef-4717-bbd6-4a2ee517b812,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-c1aa2d07-6a9f-401a-a272-b0380fbf3451,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-35e9dd9b-da11-49c5-a59b-adbc53dd8e35,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-b25c615a-50fe-4ccb-828d-2e7d68e7bfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-3ea77d8a-501d-44ba-a14c-e12bc1b5dc72,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-c01cc2f7-a622-467c-bb02-bf6697301c26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1324157419-172.17.0.16-1598403083010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41199,DS-a3da1764-beb4-4e52-b76f-f71ddf062878,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-8d635d9e-37e8-4a08-a605-85a5f1e2a3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-dc45c500-a3ef-4717-bbd6-4a2ee517b812,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-c1aa2d07-6a9f-401a-a272-b0380fbf3451,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-35e9dd9b-da11-49c5-a59b-adbc53dd8e35,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-b25c615a-50fe-4ccb-828d-2e7d68e7bfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-3ea77d8a-501d-44ba-a14c-e12bc1b5dc72,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-c01cc2f7-a622-467c-bb02-bf6697301c26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203527475-172.17.0.16-1598403114461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38135,DS-92c269d2-f2fc-447b-b9e3-532528e4b43b,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-e52a0c4e-00c1-4fa1-b1c5-2c2fb6f3bd51,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-983d0ce6-2e01-45b8-b3ad-f65b20f14281,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-97ad5f1c-55a5-43fb-b41f-b9876f61d699,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-b52fa9d4-b6fe-4047-a75b-5c59eabefe6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-b4017ee7-a967-4f06-8591-e7be57eef086,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-22972e49-23ab-43cb-a669-2f4c1a94bb04,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-5ae662df-2da2-4228-b3d4-949a6668578b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203527475-172.17.0.16-1598403114461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38135,DS-92c269d2-f2fc-447b-b9e3-532528e4b43b,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-e52a0c4e-00c1-4fa1-b1c5-2c2fb6f3bd51,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-983d0ce6-2e01-45b8-b3ad-f65b20f14281,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-97ad5f1c-55a5-43fb-b41f-b9876f61d699,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-b52fa9d4-b6fe-4047-a75b-5c59eabefe6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-b4017ee7-a967-4f06-8591-e7be57eef086,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-22972e49-23ab-43cb-a669-2f4c1a94bb04,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-5ae662df-2da2-4228-b3d4-949a6668578b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822794118-172.17.0.16-1598403566433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46748,DS-d90c09a5-d1fb-467d-b435-b506b810d768,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-f4a73044-9de1-4a5d-912c-b31034fd3e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-ce434de9-13b1-4a7b-9ae5-6f30ea3ec2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-14d8b52e-ecf6-4f21-a844-ebd29619df57,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-c9fcb8ea-75ae-43bf-8b53-efae8fd21b95,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-a151a25e-10a1-4723-9494-cc695462079d,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-9e20a81a-8277-402e-8806-b2eaefab8fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-0a51bc76-1f84-476c-b4d7-a10db9f47f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822794118-172.17.0.16-1598403566433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46748,DS-d90c09a5-d1fb-467d-b435-b506b810d768,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-f4a73044-9de1-4a5d-912c-b31034fd3e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-ce434de9-13b1-4a7b-9ae5-6f30ea3ec2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-14d8b52e-ecf6-4f21-a844-ebd29619df57,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-c9fcb8ea-75ae-43bf-8b53-efae8fd21b95,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-a151a25e-10a1-4723-9494-cc695462079d,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-9e20a81a-8277-402e-8806-b2eaefab8fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-0a51bc76-1f84-476c-b4d7-a10db9f47f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529074972-172.17.0.16-1598403897531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37845,DS-f1be957a-ecf9-4913-90ae-05109db64e31,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-30a02669-9385-4886-b05d-9dbf4add4155,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-e0d502cb-c8fe-45ff-a1e1-aed21cbeaff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-4f2bcba8-cb54-4663-b775-403068ee989f,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-f5164631-614e-4492-ae05-c4b1a16f48ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-0ab0258e-2d39-4e9a-965d-a80718e4c14b,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-b78188ed-50fd-46cc-901b-448b082b0c02,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-f360a77f-f776-444b-9632-a2dd460c1715,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529074972-172.17.0.16-1598403897531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37845,DS-f1be957a-ecf9-4913-90ae-05109db64e31,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-30a02669-9385-4886-b05d-9dbf4add4155,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-e0d502cb-c8fe-45ff-a1e1-aed21cbeaff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-4f2bcba8-cb54-4663-b775-403068ee989f,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-f5164631-614e-4492-ae05-c4b1a16f48ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-0ab0258e-2d39-4e9a-965d-a80718e4c14b,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-b78188ed-50fd-46cc-901b-448b082b0c02,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-f360a77f-f776-444b-9632-a2dd460c1715,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558757800-172.17.0.16-1598403928046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33467,DS-d980d4e5-c49d-4d05-a59d-6ee3820b7fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-c491b9e0-5f4f-4749-8592-ef4449cf39e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-fce86bb1-005f-4a25-bb85-ea4ba8b52dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-c3539a0f-1970-4405-9603-0f0edd9b833b,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-abd23ff1-4b05-445d-802b-642462b24696,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-1d6bbd4c-44e3-453e-a1d8-b365c6685291,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-d9a230fc-0d2c-48f5-8f2c-3ec913f08007,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-7296e441-0018-4ca4-9176-ec7bdd9e9e7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558757800-172.17.0.16-1598403928046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33467,DS-d980d4e5-c49d-4d05-a59d-6ee3820b7fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-c491b9e0-5f4f-4749-8592-ef4449cf39e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-fce86bb1-005f-4a25-bb85-ea4ba8b52dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-c3539a0f-1970-4405-9603-0f0edd9b833b,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-abd23ff1-4b05-445d-802b-642462b24696,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-1d6bbd4c-44e3-453e-a1d8-b365c6685291,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-d9a230fc-0d2c-48f5-8f2c-3ec913f08007,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-7296e441-0018-4ca4-9176-ec7bdd9e9e7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476949589-172.17.0.16-1598404099136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46452,DS-c33817c8-99de-4750-b779-e5053ee9a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-32ff3623-3ae0-4a8e-94e6-8b7cfbff9a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-221b6774-b0f8-4985-8d15-2100ca41583f,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-2eefb5f6-6e11-4160-9e0a-5c9c88f85b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-6c359f14-38d5-4a69-a46d-04b779154edc,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-3c43a1ae-ee24-4f0d-9793-680e40c82bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-785ea8fe-6e4e-47af-9002-7eab4ad0c20a,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-0830a735-7a1f-48b5-904a-8c1d3f557e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476949589-172.17.0.16-1598404099136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46452,DS-c33817c8-99de-4750-b779-e5053ee9a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-32ff3623-3ae0-4a8e-94e6-8b7cfbff9a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-221b6774-b0f8-4985-8d15-2100ca41583f,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-2eefb5f6-6e11-4160-9e0a-5c9c88f85b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-6c359f14-38d5-4a69-a46d-04b779154edc,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-3c43a1ae-ee24-4f0d-9793-680e40c82bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-785ea8fe-6e4e-47af-9002-7eab4ad0c20a,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-0830a735-7a1f-48b5-904a-8c1d3f557e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880505220-172.17.0.16-1598404643420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39511,DS-40758f0e-a41b-4d8b-9658-773fa506cefe,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-72ada168-80de-4351-9bdf-f77cf174e0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-2f25459b-b15f-43a1-a55d-fa7b4c605b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-d7c805ad-6d9a-4be8-8835-d247083aeac4,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-e3ec7bc9-2915-4a77-ab16-a2b00007e210,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-bbab21f2-3447-4238-ab0d-4f77e1134849,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-40366872-68f1-4af2-b42c-9409c17aafb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-5aeff549-9033-49a0-9687-e3543691946e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880505220-172.17.0.16-1598404643420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39511,DS-40758f0e-a41b-4d8b-9658-773fa506cefe,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-72ada168-80de-4351-9bdf-f77cf174e0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-2f25459b-b15f-43a1-a55d-fa7b4c605b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-d7c805ad-6d9a-4be8-8835-d247083aeac4,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-e3ec7bc9-2915-4a77-ab16-a2b00007e210,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-bbab21f2-3447-4238-ab0d-4f77e1134849,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-40366872-68f1-4af2-b42c-9409c17aafb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-5aeff549-9033-49a0-9687-e3543691946e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045966945-172.17.0.16-1598404849073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43093,DS-e58b90df-2a50-42af-9121-5a2152f05510,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-0719c8b4-172d-4af9-a7da-aad9a386f91d,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-a6a100cb-72d8-4230-81ab-48e77c07af38,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-f48b0f32-a0ba-4c94-9149-57efcb3015b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-97c96bde-c384-460d-bd6e-ceb12e9febaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-72f5bf4d-f9d8-4d0f-9bed-ef699a143967,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-0d53a5b7-d1d7-4e55-a680-577a7b8e8f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-1942d43d-4d5e-470f-96a4-0c1374dd729a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045966945-172.17.0.16-1598404849073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43093,DS-e58b90df-2a50-42af-9121-5a2152f05510,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-0719c8b4-172d-4af9-a7da-aad9a386f91d,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-a6a100cb-72d8-4230-81ab-48e77c07af38,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-f48b0f32-a0ba-4c94-9149-57efcb3015b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-97c96bde-c384-460d-bd6e-ceb12e9febaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-72f5bf4d-f9d8-4d0f-9bed-ef699a143967,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-0d53a5b7-d1d7-4e55-a680-577a7b8e8f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-1942d43d-4d5e-470f-96a4-0c1374dd729a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920569409-172.17.0.16-1598405055800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37229,DS-33e5aad5-8198-407b-9b66-6b2b17241467,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-07ffc6cd-7008-4c9d-87fe-72833aab7e51,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-c6eac2e3-d202-4fd6-afac-3c94c4277a90,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-f959926b-7827-419f-8aad-2213277084ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-90f91a1e-04ee-43ca-905d-b1065004c26e,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-3d525871-1cf1-4fd0-b4a2-8041f93fac12,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-13a8b249-0189-484a-8a7d-433648bafc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-cfbbc2b2-957a-4482-8de2-39782b04c5d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920569409-172.17.0.16-1598405055800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37229,DS-33e5aad5-8198-407b-9b66-6b2b17241467,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-07ffc6cd-7008-4c9d-87fe-72833aab7e51,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-c6eac2e3-d202-4fd6-afac-3c94c4277a90,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-f959926b-7827-419f-8aad-2213277084ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-90f91a1e-04ee-43ca-905d-b1065004c26e,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-3d525871-1cf1-4fd0-b4a2-8041f93fac12,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-13a8b249-0189-484a-8a7d-433648bafc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-cfbbc2b2-957a-4482-8de2-39782b04c5d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019544471-172.17.0.16-1598405742050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41839,DS-79aa0531-ccec-4780-82aa-464bc0d16444,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-596d609c-5c5d-40ea-ae88-dbed6e6c5099,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-ec0a7ebb-1df8-440f-b470-773f119ecd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-74ca9a6d-f3eb-4ea0-915a-459e7da3030f,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-d4f8f74f-3ba6-4a6b-9585-13332c7dc5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-060c4c91-7d66-48ed-a527-dd5173bb78c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-e8809d3f-0976-4482-bba3-6c15b837ce1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-7501e14e-981e-4f15-8461-5b88bdd6e2f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019544471-172.17.0.16-1598405742050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41839,DS-79aa0531-ccec-4780-82aa-464bc0d16444,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-596d609c-5c5d-40ea-ae88-dbed6e6c5099,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-ec0a7ebb-1df8-440f-b470-773f119ecd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-74ca9a6d-f3eb-4ea0-915a-459e7da3030f,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-d4f8f74f-3ba6-4a6b-9585-13332c7dc5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-060c4c91-7d66-48ed-a527-dd5173bb78c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-e8809d3f-0976-4482-bba3-6c15b837ce1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-7501e14e-981e-4f15-8461-5b88bdd6e2f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595733738-172.17.0.16-1598405924514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40583,DS-457c2aff-22c1-49a3-b11e-c2e752db57e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-2ae84af9-c6b3-4438-9f45-7230c28bb380,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-23911a70-f8a5-4bf3-a3f1-9ed1450cd9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-def9c02e-2075-41b4-9ea3-6eaf723c7fef,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-509120f5-a64d-4d6f-b0fd-d7cb50de08fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-6ecc5ae3-8820-44a3-9ccc-e8a34f656696,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-1cea4ab8-b646-4c69-a876-74c10c4e810d,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-f9dac2e9-72c9-42f1-9d99-6cb689cb2363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595733738-172.17.0.16-1598405924514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40583,DS-457c2aff-22c1-49a3-b11e-c2e752db57e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-2ae84af9-c6b3-4438-9f45-7230c28bb380,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-23911a70-f8a5-4bf3-a3f1-9ed1450cd9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-def9c02e-2075-41b4-9ea3-6eaf723c7fef,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-509120f5-a64d-4d6f-b0fd-d7cb50de08fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-6ecc5ae3-8820-44a3-9ccc-e8a34f656696,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-1cea4ab8-b646-4c69-a876-74c10c4e810d,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-f9dac2e9-72c9-42f1-9d99-6cb689cb2363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621850085-172.17.0.16-1598406116125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45713,DS-1a06aaa0-017b-4706-beef-e27f5ff60dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-ca046dff-c3a2-49d0-804d-f1925d65e470,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-096406c1-3121-4fb1-9a0a-b250cbe6ca42,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-19ed6161-a41a-4a83-93ab-b6617913beb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-5fe49f12-deb3-42cb-9aae-1acea3e15460,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-5ad67d97-a46a-4016-bc76-8fbf72ca6c39,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-d2c0334e-4228-465d-9926-f9a4aa6267ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-9e854b52-1aeb-4941-9b20-45f29122c43f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621850085-172.17.0.16-1598406116125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45713,DS-1a06aaa0-017b-4706-beef-e27f5ff60dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-ca046dff-c3a2-49d0-804d-f1925d65e470,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-096406c1-3121-4fb1-9a0a-b250cbe6ca42,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-19ed6161-a41a-4a83-93ab-b6617913beb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-5fe49f12-deb3-42cb-9aae-1acea3e15460,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-5ad67d97-a46a-4016-bc76-8fbf72ca6c39,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-d2c0334e-4228-465d-9926-f9a4aa6267ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-9e854b52-1aeb-4941-9b20-45f29122c43f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781258165-172.17.0.16-1598406190410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42771,DS-b5d4d470-ac96-45af-a12c-b0bf914e6a70,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-65c4b0eb-dc19-4aa4-b184-4d05e0eed607,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-a7421c38-ed7e-4843-90b6-281469e5380f,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-5c4f0998-91cc-4915-9339-2a472893d36d,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-9ab83333-5260-460b-b0d7-90a10a1c9e60,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-cc95c148-f027-4055-a3c6-db9f87932c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-47c4ddd2-0ae6-432d-8597-d3895fe9e99f,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-1921f077-e7ab-404b-bdda-8c71a240b3b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781258165-172.17.0.16-1598406190410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42771,DS-b5d4d470-ac96-45af-a12c-b0bf914e6a70,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-65c4b0eb-dc19-4aa4-b184-4d05e0eed607,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-a7421c38-ed7e-4843-90b6-281469e5380f,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-5c4f0998-91cc-4915-9339-2a472893d36d,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-9ab83333-5260-460b-b0d7-90a10a1c9e60,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-cc95c148-f027-4055-a3c6-db9f87932c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-47c4ddd2-0ae6-432d-8597-d3895fe9e99f,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-1921f077-e7ab-404b-bdda-8c71a240b3b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105207611-172.17.0.16-1598406857110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43630,DS-4f538923-3463-47d9-8489-bd4cae3b522c,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-ee48f495-5cde-411e-b195-8df60eb59312,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-ee4c33c6-b1f7-4003-806d-053eeb4a7aea,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-9463c44f-f655-4e0f-b35e-dc9bc63e13e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-cb2ff468-d27f-403e-9448-90ba625a8663,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-387e49f4-f11c-4c09-b476-409b98f188e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-1ba5cceb-463e-424b-89a5-080926ca2de8,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-e9c21698-aab1-4fad-9db1-06eb2ddc131d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105207611-172.17.0.16-1598406857110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43630,DS-4f538923-3463-47d9-8489-bd4cae3b522c,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-ee48f495-5cde-411e-b195-8df60eb59312,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-ee4c33c6-b1f7-4003-806d-053eeb4a7aea,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-9463c44f-f655-4e0f-b35e-dc9bc63e13e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-cb2ff468-d27f-403e-9448-90ba625a8663,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-387e49f4-f11c-4c09-b476-409b98f188e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-1ba5cceb-463e-424b-89a5-080926ca2de8,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-e9c21698-aab1-4fad-9db1-06eb2ddc131d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5337
