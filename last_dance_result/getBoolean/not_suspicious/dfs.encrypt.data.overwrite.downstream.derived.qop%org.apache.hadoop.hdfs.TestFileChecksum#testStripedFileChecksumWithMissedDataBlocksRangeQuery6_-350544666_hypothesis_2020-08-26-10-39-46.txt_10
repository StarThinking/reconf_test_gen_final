reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624114439-172.17.0.12-1598438433857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43792,DS-bbd63124-d63b-44cc-bf1f-6ce67b693b28,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-a4d6b383-bb0a-4920-8b0c-d58eeb7f495a,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-0b056362-cfb5-4f0b-92ed-69828fe378d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-b35d48ca-4a10-44ca-9dbc-9f385acb86a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-02f8ec18-569a-4f99-a585-2213b30b7a17,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-2cb25b94-6026-45dd-bb93-122ffe438cae,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-d88b4f7c-f679-4bb4-83d6-c50da9094bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-aae98ee7-a69e-4c60-bc6f-c72e68f5a2fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624114439-172.17.0.12-1598438433857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43792,DS-bbd63124-d63b-44cc-bf1f-6ce67b693b28,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-a4d6b383-bb0a-4920-8b0c-d58eeb7f495a,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-0b056362-cfb5-4f0b-92ed-69828fe378d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-b35d48ca-4a10-44ca-9dbc-9f385acb86a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-02f8ec18-569a-4f99-a585-2213b30b7a17,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-2cb25b94-6026-45dd-bb93-122ffe438cae,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-d88b4f7c-f679-4bb4-83d6-c50da9094bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-aae98ee7-a69e-4c60-bc6f-c72e68f5a2fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655838294-172.17.0.12-1598438469880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34746,DS-a9d5c850-0069-4231-8fe5-20731b146328,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-a8206ec0-6fa8-4c23-83e0-9a81991edee5,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-a906a07a-7370-4b70-8bdf-928abe63c1df,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-b3c7bde9-dd8f-419f-846f-8e68a3f62df3,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-7241daea-9cbc-4535-bbae-f74c42ef028c,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-76f87d44-9e77-4204-83a7-6c5c0692bde3,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-96eb3d59-806e-4999-957f-4696c83e80a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-50ff85a2-aeb9-47ec-963c-bc7592eb6cca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655838294-172.17.0.12-1598438469880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34746,DS-a9d5c850-0069-4231-8fe5-20731b146328,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-a8206ec0-6fa8-4c23-83e0-9a81991edee5,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-a906a07a-7370-4b70-8bdf-928abe63c1df,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-b3c7bde9-dd8f-419f-846f-8e68a3f62df3,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-7241daea-9cbc-4535-bbae-f74c42ef028c,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-76f87d44-9e77-4204-83a7-6c5c0692bde3,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-96eb3d59-806e-4999-957f-4696c83e80a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-50ff85a2-aeb9-47ec-963c-bc7592eb6cca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504417054-172.17.0.12-1598438838064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42803,DS-a640099f-ef94-476a-ace4-95b43f5f3dde,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-bdcc2155-abed-47a8-835b-9c49a450eea1,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-c274b7e0-d627-49b2-b294-8baffccfa34c,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-7be43688-002b-4c2b-85f8-c57251c06c26,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-4cd19015-4fd2-422a-ad51-a4394ba01fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-27536589-081f-4726-b075-bd04d3928abb,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-e8ecac4e-df16-4d39-ae57-f77f2688c141,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-f4f90114-ff78-42a8-8b17-6a7bc9573dd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504417054-172.17.0.12-1598438838064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42803,DS-a640099f-ef94-476a-ace4-95b43f5f3dde,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-bdcc2155-abed-47a8-835b-9c49a450eea1,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-c274b7e0-d627-49b2-b294-8baffccfa34c,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-7be43688-002b-4c2b-85f8-c57251c06c26,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-4cd19015-4fd2-422a-ad51-a4394ba01fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-27536589-081f-4726-b075-bd04d3928abb,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-e8ecac4e-df16-4d39-ae57-f77f2688c141,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-f4f90114-ff78-42a8-8b17-6a7bc9573dd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445572039-172.17.0.12-1598439025753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34696,DS-11342621-9ee9-4742-9cb6-a942a2d28d85,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-6908c4ea-ed9d-4cd5-be51-0d84fc9ebe95,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-40b67489-56fe-4401-bc94-d7289bb172e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-422dd3f8-fcf4-4593-858f-ec36865ef4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-7294f0f7-20b0-4b91-951a-0e30d3e2a2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-b19ba7a0-75b7-4813-92f3-58692dfd6ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-9205b05b-5a23-4a0d-976e-ba0384aed304,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-5f9f806c-350b-4e7f-933d-a586f721dd59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445572039-172.17.0.12-1598439025753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34696,DS-11342621-9ee9-4742-9cb6-a942a2d28d85,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-6908c4ea-ed9d-4cd5-be51-0d84fc9ebe95,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-40b67489-56fe-4401-bc94-d7289bb172e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-422dd3f8-fcf4-4593-858f-ec36865ef4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-7294f0f7-20b0-4b91-951a-0e30d3e2a2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-b19ba7a0-75b7-4813-92f3-58692dfd6ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-9205b05b-5a23-4a0d-976e-ba0384aed304,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-5f9f806c-350b-4e7f-933d-a586f721dd59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913000182-172.17.0.12-1598439064840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37892,DS-f5e9fd2b-b84e-4ca5-8930-434b17df66c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-04c6b4ba-f504-4fa8-b93b-7f10c0c8d1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-783ba1d4-de5c-478a-904c-d0f497d90bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-e6356b46-580c-4ffd-a7c2-6dd647e32a61,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-b47f4a90-909f-4bac-8232-e1adb611d64b,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-b99d772a-118f-4dbb-a3ad-07473b8562db,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-1199bf61-2817-4931-a9f3-c8e534919e57,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-1b5d0f4a-d3ef-4a4c-956f-f7d52ab3d3c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913000182-172.17.0.12-1598439064840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37892,DS-f5e9fd2b-b84e-4ca5-8930-434b17df66c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-04c6b4ba-f504-4fa8-b93b-7f10c0c8d1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-783ba1d4-de5c-478a-904c-d0f497d90bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-e6356b46-580c-4ffd-a7c2-6dd647e32a61,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-b47f4a90-909f-4bac-8232-e1adb611d64b,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-b99d772a-118f-4dbb-a3ad-07473b8562db,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-1199bf61-2817-4931-a9f3-c8e534919e57,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-1b5d0f4a-d3ef-4a4c-956f-f7d52ab3d3c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802999609-172.17.0.12-1598439140420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46303,DS-ccea121e-17aa-4d49-9b79-0ebb53152602,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-964e4556-0cb8-43f7-bfb1-5ca56012aa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-ae3c3173-0610-4a5c-95e4-06b1e8fcab0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-97572e3f-db47-4b93-b847-f54dd738df4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-615ac489-3f30-4269-956b-12a17ffda0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-8e0d23df-d8d4-48cb-8d09-a883b7f554cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-aa6a0f6a-07ab-4bff-a6e7-7bc0744d2b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-97bba9d5-ec17-48ae-89ab-4d2dbfe7df4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802999609-172.17.0.12-1598439140420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46303,DS-ccea121e-17aa-4d49-9b79-0ebb53152602,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-964e4556-0cb8-43f7-bfb1-5ca56012aa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-ae3c3173-0610-4a5c-95e4-06b1e8fcab0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-97572e3f-db47-4b93-b847-f54dd738df4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-615ac489-3f30-4269-956b-12a17ffda0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-8e0d23df-d8d4-48cb-8d09-a883b7f554cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-aa6a0f6a-07ab-4bff-a6e7-7bc0744d2b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-97bba9d5-ec17-48ae-89ab-4d2dbfe7df4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625631962-172.17.0.12-1598439295409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43601,DS-79a8b317-7a51-4481-b2db-74eb79c0bf83,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-f2dcbd5f-2de0-4b3e-baea-e943770e8371,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-477b7dfe-8544-4966-a2a7-b69f59973ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-4793800c-c406-41d2-8689-145e49c846c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-22731d37-1168-4699-a21b-8cd7175833c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-1d3197a5-13bb-4692-adfd-425a8162cde6,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-6d91b3a6-059f-462d-976e-7b1b9e1dac30,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-984ea7f2-892c-4417-ac28-2bc73e97d084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625631962-172.17.0.12-1598439295409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43601,DS-79a8b317-7a51-4481-b2db-74eb79c0bf83,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-f2dcbd5f-2de0-4b3e-baea-e943770e8371,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-477b7dfe-8544-4966-a2a7-b69f59973ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-4793800c-c406-41d2-8689-145e49c846c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-22731d37-1168-4699-a21b-8cd7175833c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-1d3197a5-13bb-4692-adfd-425a8162cde6,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-6d91b3a6-059f-462d-976e-7b1b9e1dac30,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-984ea7f2-892c-4417-ac28-2bc73e97d084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130331732-172.17.0.12-1598439479528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36521,DS-05e0887d-dcc5-447e-85f5-782d81996471,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-41101daf-8b5f-4e11-b3fd-6e5b3968a2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-91bbb2ea-78d3-42b7-a7e0-3c38bc98103c,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-284ec36c-2240-484e-8a11-566cccbad2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-f5f7c737-a449-4cde-a861-145e4400f45a,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-6378a78a-d3c6-4369-ba67-1354632bcbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-e0158404-6e51-437f-b9ce-ef6d9f58581f,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-9137e480-531d-4c82-99e5-0fda13d967d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130331732-172.17.0.12-1598439479528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36521,DS-05e0887d-dcc5-447e-85f5-782d81996471,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-41101daf-8b5f-4e11-b3fd-6e5b3968a2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-91bbb2ea-78d3-42b7-a7e0-3c38bc98103c,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-284ec36c-2240-484e-8a11-566cccbad2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-f5f7c737-a449-4cde-a861-145e4400f45a,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-6378a78a-d3c6-4369-ba67-1354632bcbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-e0158404-6e51-437f-b9ce-ef6d9f58581f,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-9137e480-531d-4c82-99e5-0fda13d967d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817652598-172.17.0.12-1598439521242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42776,DS-6c428280-6200-48a6-a707-cf568ec1a1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-0bc40491-b5cf-4e5c-af1a-018f15fb3dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-21a5ba5e-e90a-4864-a7a8-f0f6169ce3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-5be5ffc3-3896-44eb-a48b-6ac9e244d95a,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-8590b044-3d82-427b-a2a8-1acc8265f630,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-8d356e65-ecd5-4958-afb8-357c53e2d421,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-2c2e766e-3153-4b22-a2a9-5f121904c5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-d0eaf78e-8662-4c62-92db-31b860659fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817652598-172.17.0.12-1598439521242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42776,DS-6c428280-6200-48a6-a707-cf568ec1a1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-0bc40491-b5cf-4e5c-af1a-018f15fb3dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-21a5ba5e-e90a-4864-a7a8-f0f6169ce3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-5be5ffc3-3896-44eb-a48b-6ac9e244d95a,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-8590b044-3d82-427b-a2a8-1acc8265f630,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-8d356e65-ecd5-4958-afb8-357c53e2d421,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-2c2e766e-3153-4b22-a2a9-5f121904c5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-d0eaf78e-8662-4c62-92db-31b860659fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464598201-172.17.0.12-1598439634097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33925,DS-98a32faf-b91f-41ab-9ed2-edd57a91c591,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-7008f048-78da-46d6-8d24-442687bf3417,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-3c82dc5e-a96c-4c14-9ff8-cca23c5383e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-5da6b168-eae7-4323-8986-2e2bab8e50be,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-8577678c-0a80-4e17-ab31-adb18ae196e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-44b14cde-dd83-4135-b01b-5a56144e809d,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-3a73882f-0198-4dbf-ab8a-2b6920addd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-48d60850-7afa-49fd-947d-b8f1842e5f5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464598201-172.17.0.12-1598439634097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33925,DS-98a32faf-b91f-41ab-9ed2-edd57a91c591,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-7008f048-78da-46d6-8d24-442687bf3417,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-3c82dc5e-a96c-4c14-9ff8-cca23c5383e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-5da6b168-eae7-4323-8986-2e2bab8e50be,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-8577678c-0a80-4e17-ab31-adb18ae196e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-44b14cde-dd83-4135-b01b-5a56144e809d,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-3a73882f-0198-4dbf-ab8a-2b6920addd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-48d60850-7afa-49fd-947d-b8f1842e5f5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592623582-172.17.0.12-1598439906466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35191,DS-9cbcb344-5553-41eb-8a6c-42e9f917762e,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-ecdaf3c0-b699-4285-93e0-b528c6a7f44d,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-70b08311-3b67-4522-afae-be131ff5adc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-7f283d5c-d50e-4fd1-b0c5-d0eddefd6bea,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-0aa1acd6-7192-45db-96c8-0eefdc55331a,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-ed561327-596c-419a-b35b-4b295aad045a,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-441cb379-a98f-40c5-a03b-ae45ae2169a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-231b9f9f-e07f-4e9d-b599-f4ab420195ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592623582-172.17.0.12-1598439906466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35191,DS-9cbcb344-5553-41eb-8a6c-42e9f917762e,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-ecdaf3c0-b699-4285-93e0-b528c6a7f44d,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-70b08311-3b67-4522-afae-be131ff5adc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-7f283d5c-d50e-4fd1-b0c5-d0eddefd6bea,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-0aa1acd6-7192-45db-96c8-0eefdc55331a,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-ed561327-596c-419a-b35b-4b295aad045a,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-441cb379-a98f-40c5-a03b-ae45ae2169a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-231b9f9f-e07f-4e9d-b599-f4ab420195ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369240773-172.17.0.12-1598440094330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33521,DS-c63b409c-9361-4c6e-bc04-1f7dfb1b1d08,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-1e5dba06-a5bd-4816-b485-1aa117c482f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-a3fa4b6a-c5bf-4634-94f6-74bae8f08eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-bfd49844-874f-4b0a-9f12-c5f02238d612,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-1d0bcc9a-ce2f-4efb-b247-a1c1f6c8d5be,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-49f0d3e1-9104-4ac8-9a0f-59997ed0c110,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-0dd4e932-f5f6-4596-a116-5e5a15ce00c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-2bbfd22a-d994-4d4b-bd67-317caf527e49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369240773-172.17.0.12-1598440094330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33521,DS-c63b409c-9361-4c6e-bc04-1f7dfb1b1d08,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-1e5dba06-a5bd-4816-b485-1aa117c482f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-a3fa4b6a-c5bf-4634-94f6-74bae8f08eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-bfd49844-874f-4b0a-9f12-c5f02238d612,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-1d0bcc9a-ce2f-4efb-b247-a1c1f6c8d5be,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-49f0d3e1-9104-4ac8-9a0f-59997ed0c110,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-0dd4e932-f5f6-4596-a116-5e5a15ce00c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-2bbfd22a-d994-4d4b-bd67-317caf527e49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441764501-172.17.0.12-1598440167903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-7a577ef8-3ba1-45e1-a4c5-30944a44342c,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-2a82400b-3b4b-4780-a44b-570fbcfcb434,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-6e3481a9-d12c-4bb2-aa65-26203d746542,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-48807949-c257-4965-99d2-e37992d934bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-ec630a21-75e4-404a-99d5-3405f45dc045,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-fde78721-acf1-4f61-87f0-9331409dee94,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-89325259-3431-455d-8405-b458895bbeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-f2037e9a-c2ff-4c5c-8468-05d267d42f1e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441764501-172.17.0.12-1598440167903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-7a577ef8-3ba1-45e1-a4c5-30944a44342c,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-2a82400b-3b4b-4780-a44b-570fbcfcb434,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-6e3481a9-d12c-4bb2-aa65-26203d746542,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-48807949-c257-4965-99d2-e37992d934bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-ec630a21-75e4-404a-99d5-3405f45dc045,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-fde78721-acf1-4f61-87f0-9331409dee94,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-89325259-3431-455d-8405-b458895bbeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-f2037e9a-c2ff-4c5c-8468-05d267d42f1e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722075446-172.17.0.12-1598440239535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46837,DS-d665c4f3-c7f7-4619-bdb7-fcfdd93a4d83,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-65a0ad54-ecf6-4211-8717-75a3fffe9183,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-e8209a68-dfd5-4f68-bf3a-d1b60697a98d,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-2ced7171-251c-4457-8c95-40c99e7297dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-bb7beab9-5a56-4a1e-b71d-e3ea6dc3285a,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-bdd06ad7-10ef-4de7-acd3-bb218cd3c2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-2313ba13-b4b8-4ae3-8b5d-99a679bff67f,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-32edaffc-20c5-44d6-af4f-25c528ef99d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722075446-172.17.0.12-1598440239535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46837,DS-d665c4f3-c7f7-4619-bdb7-fcfdd93a4d83,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-65a0ad54-ecf6-4211-8717-75a3fffe9183,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-e8209a68-dfd5-4f68-bf3a-d1b60697a98d,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-2ced7171-251c-4457-8c95-40c99e7297dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-bb7beab9-5a56-4a1e-b71d-e3ea6dc3285a,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-bdd06ad7-10ef-4de7-acd3-bb218cd3c2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-2313ba13-b4b8-4ae3-8b5d-99a679bff67f,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-32edaffc-20c5-44d6-af4f-25c528ef99d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238044156-172.17.0.12-1598440392449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34449,DS-484834ca-f6f1-49b5-9823-b86755cbf849,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-30cd1226-345e-4728-b498-5cba794295e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-ec89dfd8-6340-4d01-b1f9-da52e75b6afb,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-655de0eb-87a4-4d81-bac4-71952cb339ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-ddb63873-c414-4cd2-856e-6d57adc1a66d,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-09cff217-db9e-4bd9-b340-5adf81b3e61d,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-47d3f546-d798-4e11-8e44-9fda9246b9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-b4e3928e-110f-4d46-9d20-5d066dfe05c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238044156-172.17.0.12-1598440392449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34449,DS-484834ca-f6f1-49b5-9823-b86755cbf849,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-30cd1226-345e-4728-b498-5cba794295e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-ec89dfd8-6340-4d01-b1f9-da52e75b6afb,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-655de0eb-87a4-4d81-bac4-71952cb339ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-ddb63873-c414-4cd2-856e-6d57adc1a66d,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-09cff217-db9e-4bd9-b340-5adf81b3e61d,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-47d3f546-d798-4e11-8e44-9fda9246b9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-b4e3928e-110f-4d46-9d20-5d066dfe05c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648697254-172.17.0.12-1598440519221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44858,DS-63ab89d9-c16e-48a6-b204-33fcb3346698,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-aeb5093d-8490-443d-8089-58defafb07e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-e01c35e8-c47c-4b70-b71a-78baf7181ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-a9478c21-d898-4802-8ec7-f5ef3157be30,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-6176d5ba-6bd6-4c8f-981f-6b35870cbf02,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-156b67a9-4bc6-4f64-9f94-e68b688e4e28,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-b3bd1532-f778-45e2-9853-d2f2fb46e6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-a86439dd-9420-4303-b670-da5a8f41630d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648697254-172.17.0.12-1598440519221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44858,DS-63ab89d9-c16e-48a6-b204-33fcb3346698,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-aeb5093d-8490-443d-8089-58defafb07e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-e01c35e8-c47c-4b70-b71a-78baf7181ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-a9478c21-d898-4802-8ec7-f5ef3157be30,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-6176d5ba-6bd6-4c8f-981f-6b35870cbf02,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-156b67a9-4bc6-4f64-9f94-e68b688e4e28,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-b3bd1532-f778-45e2-9853-d2f2fb46e6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-a86439dd-9420-4303-b670-da5a8f41630d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606514615-172.17.0.12-1598440684236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35977,DS-fc0ce8d4-ec75-4179-a325-c37c4b347e96,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-b7d36d01-50a3-4e08-b993-effbfc483a04,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-621277f2-0a76-42ff-9865-83c919652eac,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-be33a4ab-79ae-46e1-a3b7-8e37aad78c24,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-7ae7ef8f-61bf-487b-98b9-65ce547c3f65,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-28a37dfa-f68e-4672-9b4f-80db0305c799,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-6d4309ed-070f-4c75-a4a7-f5cd9bcc522d,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-d4062d80-e88f-4220-b1b7-f7d1cd421700,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606514615-172.17.0.12-1598440684236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35977,DS-fc0ce8d4-ec75-4179-a325-c37c4b347e96,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-b7d36d01-50a3-4e08-b993-effbfc483a04,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-621277f2-0a76-42ff-9865-83c919652eac,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-be33a4ab-79ae-46e1-a3b7-8e37aad78c24,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-7ae7ef8f-61bf-487b-98b9-65ce547c3f65,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-28a37dfa-f68e-4672-9b4f-80db0305c799,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-6d4309ed-070f-4c75-a4a7-f5cd9bcc522d,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-d4062d80-e88f-4220-b1b7-f7d1cd421700,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673253548-172.17.0.12-1598440903035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36606,DS-369804a6-0656-450c-a28e-45900feb61a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-cf823ba1-f317-40b1-8524-43ec5b94ccd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-ef1b02dd-b077-4f54-8d17-c2fba1c57fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-a5144b59-4042-4a3a-bb8d-8c1735c5b0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-5e546a08-9b67-4e15-a9f1-e349510284dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-a1595a08-afd1-4d22-b910-a01a6dd1a83b,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-c443a9d4-b77d-434a-acfb-680a5864f6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-4d165599-a563-40e2-835b-48c39f521992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673253548-172.17.0.12-1598440903035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36606,DS-369804a6-0656-450c-a28e-45900feb61a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-cf823ba1-f317-40b1-8524-43ec5b94ccd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-ef1b02dd-b077-4f54-8d17-c2fba1c57fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-a5144b59-4042-4a3a-bb8d-8c1735c5b0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-5e546a08-9b67-4e15-a9f1-e349510284dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-a1595a08-afd1-4d22-b910-a01a6dd1a83b,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-c443a9d4-b77d-434a-acfb-680a5864f6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-4d165599-a563-40e2-835b-48c39f521992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158520977-172.17.0.12-1598440937638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35926,DS-a1d6c3b3-a93d-40f7-b3d4-0b93a3347d42,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-837d4b8d-b772-4a97-b28f-f2cae31f4171,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-c56bd101-c53e-441c-8041-94d510610517,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-5127fcf1-b223-488b-bf52-3289c6bdaa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-b6f06ee4-4cae-41fe-9c67-1e606b6b3a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-99cd42ce-774d-4fff-b43e-6e60b35a7aba,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-3ad00da2-382e-4104-bc92-b06c26092caa,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-f00745bf-2e2b-44c1-812b-624fa91e0eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158520977-172.17.0.12-1598440937638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35926,DS-a1d6c3b3-a93d-40f7-b3d4-0b93a3347d42,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-837d4b8d-b772-4a97-b28f-f2cae31f4171,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-c56bd101-c53e-441c-8041-94d510610517,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-5127fcf1-b223-488b-bf52-3289c6bdaa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-b6f06ee4-4cae-41fe-9c67-1e606b6b3a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-99cd42ce-774d-4fff-b43e-6e60b35a7aba,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-3ad00da2-382e-4104-bc92-b06c26092caa,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-f00745bf-2e2b-44c1-812b-624fa91e0eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096803008-172.17.0.12-1598441153095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38723,DS-a17f0474-afa7-4ae0-bd94-04b6f1d9d835,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-4cb8a7a8-2faa-406f-8c80-3ff8b7c409ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-9a31e3cd-37de-4006-a253-f6473c4141f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-abe5586d-4db8-4a48-94dc-58838ba34dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-088c3f53-3841-4e5a-848d-3c0fa0ff92c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-4e3d1e02-16e4-454b-a25e-748ed8bf4950,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-157d7ce1-59c0-424b-87f7-6863d85666b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-33a27de5-0fcc-45f2-8e29-a501e9dc5d79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096803008-172.17.0.12-1598441153095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38723,DS-a17f0474-afa7-4ae0-bd94-04b6f1d9d835,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-4cb8a7a8-2faa-406f-8c80-3ff8b7c409ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-9a31e3cd-37de-4006-a253-f6473c4141f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-abe5586d-4db8-4a48-94dc-58838ba34dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-088c3f53-3841-4e5a-848d-3c0fa0ff92c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-4e3d1e02-16e4-454b-a25e-748ed8bf4950,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-157d7ce1-59c0-424b-87f7-6863d85666b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-33a27de5-0fcc-45f2-8e29-a501e9dc5d79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172883591-172.17.0.12-1598441397347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37712,DS-a90da90f-5ba9-4d71-b970-ea40b53fb346,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-7befc41c-6280-40ef-98a9-08788cb5ae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-34cd6f82-f787-4b10-98f4-bade5b4903d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-ee5fec22-6020-4d03-8f67-78b2ab619f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-79e9bba1-0a79-4d9d-a6f1-ed3676cf128f,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-17cf5961-402a-417a-b136-fbdcdb39a63a,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-5c065b5d-dbb9-4ee3-a806-615857035ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-b25f5ccf-6ea9-4c25-9874-f9c8bcd3949d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172883591-172.17.0.12-1598441397347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37712,DS-a90da90f-5ba9-4d71-b970-ea40b53fb346,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-7befc41c-6280-40ef-98a9-08788cb5ae8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-34cd6f82-f787-4b10-98f4-bade5b4903d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-ee5fec22-6020-4d03-8f67-78b2ab619f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-79e9bba1-0a79-4d9d-a6f1-ed3676cf128f,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-17cf5961-402a-417a-b136-fbdcdb39a63a,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-5c065b5d-dbb9-4ee3-a806-615857035ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-b25f5ccf-6ea9-4c25-9874-f9c8bcd3949d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-431631921-172.17.0.12-1598441512090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45686,DS-5c99fa6a-434c-465d-bdda-0ddd78e02a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-9852840a-64af-47c3-9ff3-3ba67e95ecf6,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-a9f31bb1-d00f-4f65-8b85-0c8e6c06683d,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-c8e3a39e-7c55-46d4-b50a-7260ee0fd430,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-fe93ef47-e798-4108-b136-b3c8733d43cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-a4e09ff3-d460-4251-a742-618e086ea52c,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-0452e3c7-9df7-4662-bba1-ce49ac146e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-15ab2aee-79ea-41f6-a5c9-373b16f22dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-431631921-172.17.0.12-1598441512090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45686,DS-5c99fa6a-434c-465d-bdda-0ddd78e02a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-9852840a-64af-47c3-9ff3-3ba67e95ecf6,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-a9f31bb1-d00f-4f65-8b85-0c8e6c06683d,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-c8e3a39e-7c55-46d4-b50a-7260ee0fd430,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-fe93ef47-e798-4108-b136-b3c8733d43cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-a4e09ff3-d460-4251-a742-618e086ea52c,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-0452e3c7-9df7-4662-bba1-ce49ac146e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-15ab2aee-79ea-41f6-a5c9-373b16f22dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155800499-172.17.0.12-1598441701847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40143,DS-ad6085b9-6c78-4196-97c5-a23a0a693fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-4380586c-6a80-434a-9a32-aa4704f724cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-879a3233-b138-4d51-8b63-bd28da5162f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-61457129-21a7-4fee-babd-a70e8671d9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-eaec7cea-14ca-4da0-af05-a0167170d263,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-949a93ca-4786-4024-8ff1-015de0ae1442,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-d1b9b970-cc43-47ba-9b1c-6413e72c36ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-c42c3b7c-c34b-451f-8ad6-27d86ff2b905,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155800499-172.17.0.12-1598441701847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40143,DS-ad6085b9-6c78-4196-97c5-a23a0a693fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-4380586c-6a80-434a-9a32-aa4704f724cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-879a3233-b138-4d51-8b63-bd28da5162f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-61457129-21a7-4fee-babd-a70e8671d9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-eaec7cea-14ca-4da0-af05-a0167170d263,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-949a93ca-4786-4024-8ff1-015de0ae1442,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-d1b9b970-cc43-47ba-9b1c-6413e72c36ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-c42c3b7c-c34b-451f-8ad6-27d86ff2b905,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239624395-172.17.0.12-1598441772659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35260,DS-b4ead011-e006-4783-bf25-d34b130b51de,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-76177ad0-cdf2-4892-824f-e773ec7a65c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-bde2353a-2b82-4bf0-a0b8-c9859b5b9345,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-b23be79c-ccee-42cc-a5df-01bce0b7ef25,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-db4faf0f-7149-439a-9cef-264ded4c2309,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-84c95d90-af4a-42e3-acee-2a8da9a3df9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-8f2ebe86-9300-4164-91d2-46b46ac794de,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-08143dcc-004b-4279-8d7f-506d2b255498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239624395-172.17.0.12-1598441772659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35260,DS-b4ead011-e006-4783-bf25-d34b130b51de,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-76177ad0-cdf2-4892-824f-e773ec7a65c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-bde2353a-2b82-4bf0-a0b8-c9859b5b9345,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-b23be79c-ccee-42cc-a5df-01bce0b7ef25,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-db4faf0f-7149-439a-9cef-264ded4c2309,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-84c95d90-af4a-42e3-acee-2a8da9a3df9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-8f2ebe86-9300-4164-91d2-46b46ac794de,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-08143dcc-004b-4279-8d7f-506d2b255498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615601290-172.17.0.12-1598442166986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37372,DS-c91a5f6b-0610-40d4-b6a7-e13aced132a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-0f0ff805-0832-436a-84e3-38d69964f98e,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-7710d0c2-f448-4062-8285-abf6f16a059d,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-b5875cb5-c7a1-42e4-8642-3711aba46a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-904e9488-c6f6-4db2-b023-3a81454ede5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-07b01f04-5b33-4dcf-ab30-36308ce7d1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-ca617f2a-1cdd-40c7-a1ba-0cfe1eae9cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-89651985-f4e6-47d8-89c2-d865f33cdb3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615601290-172.17.0.12-1598442166986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37372,DS-c91a5f6b-0610-40d4-b6a7-e13aced132a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-0f0ff805-0832-436a-84e3-38d69964f98e,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-7710d0c2-f448-4062-8285-abf6f16a059d,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-b5875cb5-c7a1-42e4-8642-3711aba46a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-904e9488-c6f6-4db2-b023-3a81454ede5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-07b01f04-5b33-4dcf-ab30-36308ce7d1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-ca617f2a-1cdd-40c7-a1ba-0cfe1eae9cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-89651985-f4e6-47d8-89c2-d865f33cdb3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875093381-172.17.0.12-1598442584431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32966,DS-9b03ee16-8144-4f72-99f8-2b63d02fabc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-db2754be-4b28-4eaa-a037-173a8a7d0611,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-b6b2b594-b3d7-4f9e-9c21-60fa26b00822,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-dd6cbef9-8404-4555-95a0-65c952ee9347,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-5a109b2d-8b90-405f-998f-1683b0914327,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-43f7ae00-b435-48ce-876f-d31189e042f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-6626888f-02b8-402a-8607-22e74a0170a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-395e3565-a25e-4b1a-b642-67901cd93726,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875093381-172.17.0.12-1598442584431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32966,DS-9b03ee16-8144-4f72-99f8-2b63d02fabc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-db2754be-4b28-4eaa-a037-173a8a7d0611,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-b6b2b594-b3d7-4f9e-9c21-60fa26b00822,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-dd6cbef9-8404-4555-95a0-65c952ee9347,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-5a109b2d-8b90-405f-998f-1683b0914327,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-43f7ae00-b435-48ce-876f-d31189e042f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-6626888f-02b8-402a-8607-22e74a0170a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-395e3565-a25e-4b1a-b642-67901cd93726,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874179492-172.17.0.12-1598442976305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42349,DS-0a6d0f0a-7400-487b-8fdb-72fbcc2e66c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-17ecb1b3-6e30-45f7-af4e-97addbdfa90b,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-0114edf3-9ed1-4782-8b0d-46daf849626e,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-450848ab-f13c-4c2f-95f5-01688fd7346c,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-8e9569f7-3433-4be0-989a-7bb6b3d717c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-6bf4b046-2059-4be4-8ee2-f9bb1750c098,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-40dd3993-71d9-4b73-a109-a9751056b6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-dddc0984-8ba4-4639-ad3b-49fd28452e07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874179492-172.17.0.12-1598442976305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42349,DS-0a6d0f0a-7400-487b-8fdb-72fbcc2e66c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-17ecb1b3-6e30-45f7-af4e-97addbdfa90b,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-0114edf3-9ed1-4782-8b0d-46daf849626e,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-450848ab-f13c-4c2f-95f5-01688fd7346c,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-8e9569f7-3433-4be0-989a-7bb6b3d717c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-6bf4b046-2059-4be4-8ee2-f9bb1750c098,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-40dd3993-71d9-4b73-a109-a9751056b6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-dddc0984-8ba4-4639-ad3b-49fd28452e07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120761521-172.17.0.12-1598443371554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43850,DS-7858f841-d1ba-4f2f-b888-3ae26718051d,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-ec0d1f17-a314-4229-af0b-fe97b54a1189,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-3806380b-c2ad-4105-ab61-77089789c3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-4853c543-8a88-4a62-9584-ad1e7d6e0d83,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-e94cc426-09b1-4b34-bf65-d7493edef1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-6352f853-5302-4077-b450-8cad46161255,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-304e61b3-b7a5-4b53-bc5d-3007494fa5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-19ffacf4-0d22-403e-8e19-1da3dcb91ec5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120761521-172.17.0.12-1598443371554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43850,DS-7858f841-d1ba-4f2f-b888-3ae26718051d,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-ec0d1f17-a314-4229-af0b-fe97b54a1189,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-3806380b-c2ad-4105-ab61-77089789c3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-4853c543-8a88-4a62-9584-ad1e7d6e0d83,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-e94cc426-09b1-4b34-bf65-d7493edef1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-6352f853-5302-4077-b450-8cad46161255,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-304e61b3-b7a5-4b53-bc5d-3007494fa5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-19ffacf4-0d22-403e-8e19-1da3dcb91ec5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5560
