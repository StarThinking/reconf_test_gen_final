reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195932720-172.17.0.11-1598435415906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44298,DS-db9eb4f8-2d6b-4c7f-a246-b55abac3382d,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-db39a89d-f642-4c6b-9fe7-21e62de3c937,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-33f4e664-1620-4d2d-b586-56a6cf833000,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-6b2fd487-5d86-4e4c-9355-c603bda4a4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-f8d55857-4559-4c65-b222-249f5150eacd,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-13c691a1-9ac2-4613-b70a-337186e2e5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-514850b2-abea-42f4-9d72-2f90f6f80ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-119e198e-0627-4d16-b84c-65606c150f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-195932720-172.17.0.11-1598435415906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44298,DS-db9eb4f8-2d6b-4c7f-a246-b55abac3382d,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-db39a89d-f642-4c6b-9fe7-21e62de3c937,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-33f4e664-1620-4d2d-b586-56a6cf833000,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-6b2fd487-5d86-4e4c-9355-c603bda4a4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-f8d55857-4559-4c65-b222-249f5150eacd,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-13c691a1-9ac2-4613-b70a-337186e2e5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-514850b2-abea-42f4-9d72-2f90f6f80ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-119e198e-0627-4d16-b84c-65606c150f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335639057-172.17.0.11-1598435447566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43169,DS-17365769-d0bc-43dd-967e-d736bb1c8d40,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-56a4026c-318a-45d0-b3dc-1ca0918d8740,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-ec7cb653-c6fa-4dd6-8613-8f23005db6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-d8cb1e46-6c72-47d7-8d5f-1d6a9d1ba6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-774c4dbc-72f1-44c7-8a00-b1002ce40fce,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-564033e3-683f-4c36-a146-4e0e12625d97,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-fc5605df-a2a4-4dae-bf43-49bc9ba17f64,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-870c652e-bc8b-45f8-83c9-9f8b97eb8e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335639057-172.17.0.11-1598435447566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43169,DS-17365769-d0bc-43dd-967e-d736bb1c8d40,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-56a4026c-318a-45d0-b3dc-1ca0918d8740,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-ec7cb653-c6fa-4dd6-8613-8f23005db6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-d8cb1e46-6c72-47d7-8d5f-1d6a9d1ba6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-774c4dbc-72f1-44c7-8a00-b1002ce40fce,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-564033e3-683f-4c36-a146-4e0e12625d97,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-fc5605df-a2a4-4dae-bf43-49bc9ba17f64,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-870c652e-bc8b-45f8-83c9-9f8b97eb8e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1149073157-172.17.0.11-1598435797287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40909,DS-b19c6e0e-18b5-48e8-8ca9-8c40b2ae95af,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-e5ebe475-4b01-4e67-8d97-bcc262433248,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-aa95728c-7463-48d0-aa33-b6aa92b9193d,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-b387fcdc-3588-4b54-9fe6-0e3e1588681a,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-796d9ece-53a5-476e-93ec-ec17131d1f84,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-feb115a2-1ae6-45e1-b67b-b17f3aba0a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-ebba03e5-dee7-4eef-b567-d111748204b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-76166a5b-0cd9-4de3-bd1d-d36e90eee917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1149073157-172.17.0.11-1598435797287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40909,DS-b19c6e0e-18b5-48e8-8ca9-8c40b2ae95af,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-e5ebe475-4b01-4e67-8d97-bcc262433248,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-aa95728c-7463-48d0-aa33-b6aa92b9193d,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-b387fcdc-3588-4b54-9fe6-0e3e1588681a,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-796d9ece-53a5-476e-93ec-ec17131d1f84,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-feb115a2-1ae6-45e1-b67b-b17f3aba0a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-ebba03e5-dee7-4eef-b567-d111748204b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-76166a5b-0cd9-4de3-bd1d-d36e90eee917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249924357-172.17.0.11-1598435828784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46872,DS-ac07e68e-8ced-4ab5-9dc6-7e57ee35ddea,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-e50cd8fa-2c2e-423f-8284-4d6efedf95cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-cd3310a7-ef14-4c85-9be7-02d978775a59,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-ad8fcb4c-a597-4eec-9f40-fa37eafb2989,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-50585a0d-fc18-43ac-a9a1-c6b8a6039e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-2b898dff-af07-46c1-b422-dea9ea4018e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-ac94d79b-c0cd-4d3b-997e-54a1e329b80c,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-62f9dca5-df29-41d1-96b9-a3a5071580fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249924357-172.17.0.11-1598435828784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46872,DS-ac07e68e-8ced-4ab5-9dc6-7e57ee35ddea,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-e50cd8fa-2c2e-423f-8284-4d6efedf95cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-cd3310a7-ef14-4c85-9be7-02d978775a59,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-ad8fcb4c-a597-4eec-9f40-fa37eafb2989,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-50585a0d-fc18-43ac-a9a1-c6b8a6039e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-2b898dff-af07-46c1-b422-dea9ea4018e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-ac94d79b-c0cd-4d3b-997e-54a1e329b80c,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-62f9dca5-df29-41d1-96b9-a3a5071580fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380371409-172.17.0.11-1598436128507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42308,DS-745706ed-adaa-4058-aaae-00898b637f55,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-3d08b380-cc96-406a-a21c-76053452fa55,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-28a52e1e-f4a6-41ad-a6e7-c4569989d005,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-8c408eb2-fafc-4a90-bbeb-068789c33188,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-b45aded7-8de0-429b-802f-1cb6fe863265,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-b5472d09-8e15-4318-bb98-db0b988d2e46,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-6df2d200-0666-41f3-93f9-ef91fa31ea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-22792453-c373-4a26-9c4e-b9986cb7ecd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380371409-172.17.0.11-1598436128507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42308,DS-745706ed-adaa-4058-aaae-00898b637f55,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-3d08b380-cc96-406a-a21c-76053452fa55,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-28a52e1e-f4a6-41ad-a6e7-c4569989d005,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-8c408eb2-fafc-4a90-bbeb-068789c33188,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-b45aded7-8de0-429b-802f-1cb6fe863265,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-b5472d09-8e15-4318-bb98-db0b988d2e46,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-6df2d200-0666-41f3-93f9-ef91fa31ea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-22792453-c373-4a26-9c4e-b9986cb7ecd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774069133-172.17.0.11-1598436407737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33122,DS-449b56f1-6f39-436e-a09b-fc590ce8cc06,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-2098ae1b-c68d-4f61-86c3-213708a99b21,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-a4fd3b6d-0e86-4dcb-86e6-5e858b487312,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-038ca784-d092-4b9a-b3e9-ab76180536cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-51bfbf7b-90a2-4d68-9c03-787964bc0348,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-fcc97763-3f6c-49a1-9333-6c395ec6c3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-52d71cea-ed7d-4e8d-9ea1-3269da8eecca,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-c61649b6-7218-4b5a-82ee-65384f28e92e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774069133-172.17.0.11-1598436407737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33122,DS-449b56f1-6f39-436e-a09b-fc590ce8cc06,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-2098ae1b-c68d-4f61-86c3-213708a99b21,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-a4fd3b6d-0e86-4dcb-86e6-5e858b487312,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-038ca784-d092-4b9a-b3e9-ab76180536cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-51bfbf7b-90a2-4d68-9c03-787964bc0348,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-fcc97763-3f6c-49a1-9333-6c395ec6c3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-52d71cea-ed7d-4e8d-9ea1-3269da8eecca,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-c61649b6-7218-4b5a-82ee-65384f28e92e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567510114-172.17.0.11-1598436653305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36352,DS-7747d86e-e8d9-4ce9-9a14-ebe17363f92a,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-0cb2ca0f-fdb6-4013-9231-5e731a516ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-e2712201-3bfa-4122-b91c-bfecfc16d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-c9fa62bd-90ed-4ea3-b973-1ea29013a651,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-68a2b919-212e-4480-ae81-2fa2ce3f7df0,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-c9e21bde-e9af-4c98-ba2a-f4ca868312c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-ab95fa23-e82a-4bb3-b261-49dadc7e2353,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-8d6b725f-f3e0-447c-81d3-529c650825b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567510114-172.17.0.11-1598436653305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36352,DS-7747d86e-e8d9-4ce9-9a14-ebe17363f92a,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-0cb2ca0f-fdb6-4013-9231-5e731a516ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-e2712201-3bfa-4122-b91c-bfecfc16d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-c9fa62bd-90ed-4ea3-b973-1ea29013a651,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-68a2b919-212e-4480-ae81-2fa2ce3f7df0,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-c9e21bde-e9af-4c98-ba2a-f4ca868312c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-ab95fa23-e82a-4bb3-b261-49dadc7e2353,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-8d6b725f-f3e0-447c-81d3-529c650825b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77815151-172.17.0.11-1598436716858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38758,DS-530517c0-e3b4-4ff0-81ec-1cc7647b4716,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-acc789b1-2a78-45e1-bef4-7c721369a44a,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-1d5f6805-7eb1-4478-92b1-a0b0f586a720,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-6da47875-bfa4-4675-bda0-62120d652e40,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-ed1de11d-0a91-4559-8238-b92bc82717bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-1adbedaa-5d44-4140-a11c-6daa7518e483,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-d5cefc50-10f2-4dd1-b452-3081535267c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-4ae3eddf-38f1-49d0-8ae1-32c20df21460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77815151-172.17.0.11-1598436716858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38758,DS-530517c0-e3b4-4ff0-81ec-1cc7647b4716,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-acc789b1-2a78-45e1-bef4-7c721369a44a,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-1d5f6805-7eb1-4478-92b1-a0b0f586a720,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-6da47875-bfa4-4675-bda0-62120d652e40,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-ed1de11d-0a91-4559-8238-b92bc82717bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-1adbedaa-5d44-4140-a11c-6daa7518e483,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-d5cefc50-10f2-4dd1-b452-3081535267c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-4ae3eddf-38f1-49d0-8ae1-32c20df21460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228808729-172.17.0.11-1598436909852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33443,DS-feb53797-c0c0-4643-b327-cf64ac687058,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-66f68917-7799-4e83-90a2-d7803cf19f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-599da86e-8291-4193-9020-659ae6e5a0be,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-1f191181-f448-4df1-98f5-6b0b5bbf8b04,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-64534ea3-ffcd-41fa-bd3c-830848d7b7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-b5d54288-8ad4-4fdb-8771-9a359dba2d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-f43864b0-eaee-444e-bc6f-41ed7c655962,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-cdde7854-9911-4bd4-a07a-e6e20aaa7949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228808729-172.17.0.11-1598436909852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33443,DS-feb53797-c0c0-4643-b327-cf64ac687058,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-66f68917-7799-4e83-90a2-d7803cf19f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-599da86e-8291-4193-9020-659ae6e5a0be,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-1f191181-f448-4df1-98f5-6b0b5bbf8b04,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-64534ea3-ffcd-41fa-bd3c-830848d7b7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-b5d54288-8ad4-4fdb-8771-9a359dba2d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-f43864b0-eaee-444e-bc6f-41ed7c655962,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-cdde7854-9911-4bd4-a07a-e6e20aaa7949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41473728-172.17.0.11-1598437048258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39650,DS-2b5d4e57-2369-40c6-ac43-4f80b76de01c,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-1fbf971c-4f24-4d3a-b8b9-6773067ff1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-b899115d-8be3-47e1-b430-9256a2499b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-2b2ff3db-0ec5-4a81-8f29-7bc9f7962d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-c3ae3372-9882-45e7-9c47-fa36e642eade,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-2a3c99f0-9c1c-4a96-8b24-46876177a38d,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-48a292c4-cabc-4fda-a289-bced1c5d2bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-02eedf9e-1d29-4aef-a489-e6853621acf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41473728-172.17.0.11-1598437048258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39650,DS-2b5d4e57-2369-40c6-ac43-4f80b76de01c,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-1fbf971c-4f24-4d3a-b8b9-6773067ff1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-b899115d-8be3-47e1-b430-9256a2499b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-2b2ff3db-0ec5-4a81-8f29-7bc9f7962d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-c3ae3372-9882-45e7-9c47-fa36e642eade,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-2a3c99f0-9c1c-4a96-8b24-46876177a38d,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-48a292c4-cabc-4fda-a289-bced1c5d2bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-02eedf9e-1d29-4aef-a489-e6853621acf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364263653-172.17.0.11-1598437125857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43585,DS-b20a4721-ddf1-4e6e-885f-e21f85552c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-21d8158e-20b6-4873-b4d0-39459843bd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-d7806524-2881-4d99-afb2-5c930a44ebc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-28b2c60a-42ed-4652-bcb7-fc6cc8071f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-7351cfe5-dda4-4158-b3d1-85e065cf40ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-e50d9018-a125-4d5a-aa51-4142a16758cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-c0593fd0-5cb5-4f73-a221-8ed9e854a6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-a371d7a4-775c-4215-b73e-5942ff6710e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364263653-172.17.0.11-1598437125857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43585,DS-b20a4721-ddf1-4e6e-885f-e21f85552c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-21d8158e-20b6-4873-b4d0-39459843bd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-d7806524-2881-4d99-afb2-5c930a44ebc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-28b2c60a-42ed-4652-bcb7-fc6cc8071f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-7351cfe5-dda4-4158-b3d1-85e065cf40ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-e50d9018-a125-4d5a-aa51-4142a16758cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-c0593fd0-5cb5-4f73-a221-8ed9e854a6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-a371d7a4-775c-4215-b73e-5942ff6710e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841460120-172.17.0.11-1598437228126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39821,DS-9efae1c7-9722-4eec-b7c5-f57311215c47,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-0031f5c1-0077-47d1-94f3-d06430a79eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-892cd0d0-21ad-4bfd-ba8f-93dc1789ae48,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-77d7ead7-00ba-4830-aa18-7a61945cea61,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-3a407cc7-05b0-40fb-b276-70fc9dbb3532,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-eb034101-df72-4774-9ec8-5be2f535870c,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-6cb34718-ccf8-4f82-a182-031155227758,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-0cac80fc-db51-478d-8938-1ca81b42ec46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841460120-172.17.0.11-1598437228126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39821,DS-9efae1c7-9722-4eec-b7c5-f57311215c47,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-0031f5c1-0077-47d1-94f3-d06430a79eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-892cd0d0-21ad-4bfd-ba8f-93dc1789ae48,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-77d7ead7-00ba-4830-aa18-7a61945cea61,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-3a407cc7-05b0-40fb-b276-70fc9dbb3532,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-eb034101-df72-4774-9ec8-5be2f535870c,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-6cb34718-ccf8-4f82-a182-031155227758,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-0cac80fc-db51-478d-8938-1ca81b42ec46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890851509-172.17.0.11-1598437409232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35734,DS-adf1d456-af54-42c0-86bc-19f5564d7e76,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-5cb24e54-c0b3-4c03-9904-4245d417313a,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-dec69fc3-2268-4a39-aad1-c43ab36f6b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-8850a216-0a5c-413c-af55-c1d9a66cfe06,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-8a4f00de-da7e-47fe-9e90-ad95127b7fde,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-58e0044c-cf74-48a8-9926-3869f7143f36,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-0da0625f-6a96-4834-bd9f-a5bf70eca5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-70ee3d90-4d8b-4fbe-92e3-7a3140ff8d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890851509-172.17.0.11-1598437409232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35734,DS-adf1d456-af54-42c0-86bc-19f5564d7e76,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-5cb24e54-c0b3-4c03-9904-4245d417313a,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-dec69fc3-2268-4a39-aad1-c43ab36f6b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-8850a216-0a5c-413c-af55-c1d9a66cfe06,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-8a4f00de-da7e-47fe-9e90-ad95127b7fde,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-58e0044c-cf74-48a8-9926-3869f7143f36,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-0da0625f-6a96-4834-bd9f-a5bf70eca5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-70ee3d90-4d8b-4fbe-92e3-7a3140ff8d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080363467-172.17.0.11-1598437513506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42315,DS-554ad4b1-6b8a-4bfa-8918-fe92e2c1156c,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-001ffffd-a9b3-48f4-ad5f-add95f090a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-373f827e-4508-4dbb-8d50-bb7b334fe9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-e0924e24-b398-41c7-91cd-553125194dca,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-0a94d153-1106-4767-98d2-24d7dd72c196,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-39527059-91bf-42a3-9529-48a56984c62a,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-9a6ac489-67db-4aa9-9203-374378815970,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-03f1865c-37b2-4589-a4ce-f6c6fb9d84cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080363467-172.17.0.11-1598437513506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42315,DS-554ad4b1-6b8a-4bfa-8918-fe92e2c1156c,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-001ffffd-a9b3-48f4-ad5f-add95f090a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-373f827e-4508-4dbb-8d50-bb7b334fe9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-e0924e24-b398-41c7-91cd-553125194dca,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-0a94d153-1106-4767-98d2-24d7dd72c196,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-39527059-91bf-42a3-9529-48a56984c62a,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-9a6ac489-67db-4aa9-9203-374378815970,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-03f1865c-37b2-4589-a4ce-f6c6fb9d84cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943468416-172.17.0.11-1598437548550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45956,DS-d18b6318-7b49-4af3-82f4-b286ddc01b00,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-041d5b31-6e96-4248-bbdc-f1500de9764d,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-85b2391e-b1f9-477f-9703-4d7d92875087,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-27eca098-e7ff-47a3-98d8-435ec75b9497,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-1a649459-3f8d-424d-99ec-922a84bab22c,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-b107aa3b-5273-4153-94d6-20331b5c2f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-704cc4ae-26f9-4c54-8673-610c161d9b83,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-02cdecbb-80bb-4967-b0aa-709eaa0468f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943468416-172.17.0.11-1598437548550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45956,DS-d18b6318-7b49-4af3-82f4-b286ddc01b00,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-041d5b31-6e96-4248-bbdc-f1500de9764d,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-85b2391e-b1f9-477f-9703-4d7d92875087,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-27eca098-e7ff-47a3-98d8-435ec75b9497,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-1a649459-3f8d-424d-99ec-922a84bab22c,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-b107aa3b-5273-4153-94d6-20331b5c2f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-704cc4ae-26f9-4c54-8673-610c161d9b83,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-02cdecbb-80bb-4967-b0aa-709eaa0468f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518113955-172.17.0.11-1598438066146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35915,DS-9f757f34-91e7-4e7a-9ac2-1f0a1b4fab3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-f179a842-9209-4adf-b5a1-7fd478f02914,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-366c7e8f-b152-4dad-aa63-cff90bc6dd42,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-a4c3bf03-7b78-468a-a442-a190c8cb67f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-bf2aefbe-3a40-4298-ab6f-f6064a97d752,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-84a75d05-697d-460a-a439-c1ee57ab564c,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-1090dc6c-6255-4019-8575-8f8539433ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-e6e9e3c6-b0f4-4e6b-82d9-aebb2386d0e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518113955-172.17.0.11-1598438066146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35915,DS-9f757f34-91e7-4e7a-9ac2-1f0a1b4fab3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-f179a842-9209-4adf-b5a1-7fd478f02914,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-366c7e8f-b152-4dad-aa63-cff90bc6dd42,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-a4c3bf03-7b78-468a-a442-a190c8cb67f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-bf2aefbe-3a40-4298-ab6f-f6064a97d752,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-84a75d05-697d-460a-a439-c1ee57ab564c,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-1090dc6c-6255-4019-8575-8f8539433ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-e6e9e3c6-b0f4-4e6b-82d9-aebb2386d0e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729135797-172.17.0.11-1598438276663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35025,DS-4475e595-79db-47dc-86b5-1a34cf079714,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-6302f9b9-9c06-41ee-841e-bb67cf8cd403,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-ed601f31-cf3b-46f8-aea9-4c5a5995d941,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-8841e066-652f-4938-a2d0-90195b58da75,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-281e4a45-cbdb-4125-92a6-e333fa1d69b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-165189e2-8e40-482e-b7b7-75ff162f3ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-ebf86e35-3773-411f-bb74-638d37aeaf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-81d2bcd3-27b3-4848-95d9-5dbc3ac60e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729135797-172.17.0.11-1598438276663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35025,DS-4475e595-79db-47dc-86b5-1a34cf079714,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-6302f9b9-9c06-41ee-841e-bb67cf8cd403,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-ed601f31-cf3b-46f8-aea9-4c5a5995d941,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-8841e066-652f-4938-a2d0-90195b58da75,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-281e4a45-cbdb-4125-92a6-e333fa1d69b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-165189e2-8e40-482e-b7b7-75ff162f3ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-ebf86e35-3773-411f-bb74-638d37aeaf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-81d2bcd3-27b3-4848-95d9-5dbc3ac60e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930517697-172.17.0.11-1598438334905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-e132b8a0-d95a-4de5-a1aa-57d821bfabc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-ffb946de-d2bc-48a1-b69f-fd96591aa2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-df9fca4a-17a9-4bac-ac60-5c35ff549888,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-b0036e89-f6cb-4aa9-81bf-95abceb99aec,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-b7d41258-2b4d-4429-a4d5-10920af71b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-5815e0bd-1a45-49c3-8e45-ef38932ffaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-afb08edd-2afe-4ee4-a3d6-0b49427157eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-5831b097-1bd6-4dcb-8f4b-3bd71021f303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930517697-172.17.0.11-1598438334905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-e132b8a0-d95a-4de5-a1aa-57d821bfabc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-ffb946de-d2bc-48a1-b69f-fd96591aa2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-df9fca4a-17a9-4bac-ac60-5c35ff549888,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-b0036e89-f6cb-4aa9-81bf-95abceb99aec,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-b7d41258-2b4d-4429-a4d5-10920af71b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-5815e0bd-1a45-49c3-8e45-ef38932ffaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-afb08edd-2afe-4ee4-a3d6-0b49427157eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-5831b097-1bd6-4dcb-8f4b-3bd71021f303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767093716-172.17.0.11-1598438473037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41122,DS-df3fc935-6407-488c-a668-bbfaeae5bcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-0a60b92f-f526-4600-9893-282828861b70,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-99233e12-9e27-449e-a092-8435807cab88,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-e3f4cceb-76d8-43db-a0d0-34ecb950b505,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-3d424f26-c881-497f-bc03-f37b880581d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-dcec366b-2cd9-4b39-ae4a-019efda79acd,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-05cf9e64-2c18-48ad-87a9-31f3b29bc1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-a3ab0cfc-323a-489b-93c8-d0102a20b613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767093716-172.17.0.11-1598438473037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41122,DS-df3fc935-6407-488c-a668-bbfaeae5bcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-0a60b92f-f526-4600-9893-282828861b70,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-99233e12-9e27-449e-a092-8435807cab88,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-e3f4cceb-76d8-43db-a0d0-34ecb950b505,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-3d424f26-c881-497f-bc03-f37b880581d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-dcec366b-2cd9-4b39-ae4a-019efda79acd,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-05cf9e64-2c18-48ad-87a9-31f3b29bc1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-a3ab0cfc-323a-489b-93c8-d0102a20b613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385157018-172.17.0.11-1598438506639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38825,DS-962c1995-791c-4b79-9de9-86cdb8cf7874,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-48945006-a791-4049-af91-c8ba1b12e6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-1b5f094e-85c7-4c92-8c19-661e000f0c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-33024b33-dcb1-4615-b554-6593bdd32870,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-25128dbd-d14e-4ddf-a294-224bd60d5c35,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-0b75fb11-94eb-46e1-9a76-76178efdc84a,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-8c96b6fb-14b5-41d9-bb02-cbc0241b2058,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-954a3988-36ac-41b1-bd44-601c7b48dc29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385157018-172.17.0.11-1598438506639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38825,DS-962c1995-791c-4b79-9de9-86cdb8cf7874,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-48945006-a791-4049-af91-c8ba1b12e6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-1b5f094e-85c7-4c92-8c19-661e000f0c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-33024b33-dcb1-4615-b554-6593bdd32870,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-25128dbd-d14e-4ddf-a294-224bd60d5c35,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-0b75fb11-94eb-46e1-9a76-76178efdc84a,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-8c96b6fb-14b5-41d9-bb02-cbc0241b2058,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-954a3988-36ac-41b1-bd44-601c7b48dc29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618143782-172.17.0.11-1598438543878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46883,DS-c552d0b3-d180-45bd-977f-b6c1c25adee4,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-84469c40-5dbd-4811-8431-ce2ce01751ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-48ce9c2c-1ce4-4de5-9d28-aba8131c3ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-b2f394e7-83db-43ee-b196-acc9521fdefc,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-186b3ff2-b1bb-4567-bc4b-212774b9110e,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-e3395716-661d-491d-843b-1a5fe0c3b4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-33352669-dfa5-4637-86a8-cf077aaf0eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-d8fea865-ee3c-463f-a052-7cf4e1d4a1ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618143782-172.17.0.11-1598438543878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46883,DS-c552d0b3-d180-45bd-977f-b6c1c25adee4,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-84469c40-5dbd-4811-8431-ce2ce01751ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-48ce9c2c-1ce4-4de5-9d28-aba8131c3ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-b2f394e7-83db-43ee-b196-acc9521fdefc,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-186b3ff2-b1bb-4567-bc4b-212774b9110e,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-e3395716-661d-491d-843b-1a5fe0c3b4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-33352669-dfa5-4637-86a8-cf077aaf0eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-d8fea865-ee3c-463f-a052-7cf4e1d4a1ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653914701-172.17.0.11-1598438968890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45413,DS-99650c68-28a6-41e3-865a-39ffb3727768,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-dc1c2990-96f7-4abb-bbb2-f6464f46845a,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-99bbe341-0a6b-4ab5-ad5b-e7e1fbdff896,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-bc0e134d-2298-475c-b50b-201386b74e02,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-7bc5be36-376d-4697-8200-81e998882598,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-6626926f-9685-47c9-af0b-56045c22486b,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-69e387cb-844e-448f-96ba-3523b2095589,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-fcb23fc2-0c25-4eb5-90d5-6651a9437187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653914701-172.17.0.11-1598438968890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45413,DS-99650c68-28a6-41e3-865a-39ffb3727768,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-dc1c2990-96f7-4abb-bbb2-f6464f46845a,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-99bbe341-0a6b-4ab5-ad5b-e7e1fbdff896,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-bc0e134d-2298-475c-b50b-201386b74e02,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-7bc5be36-376d-4697-8200-81e998882598,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-6626926f-9685-47c9-af0b-56045c22486b,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-69e387cb-844e-448f-96ba-3523b2095589,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-fcb23fc2-0c25-4eb5-90d5-6651a9437187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682990039-172.17.0.11-1598439042778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36736,DS-71ee2947-4df8-413c-9692-4169b0a70615,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-9bd331aa-f2e8-4303-ac4f-df53096b4ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-eba1a7d5-6b09-4301-938b-371ef0dfb891,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-4f2324d1-c3a4-462d-8125-8240d3d3b454,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-b0636b05-4033-482a-a753-d8b7b68a9647,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-2392a1e6-11fc-4297-b691-f02ba4388749,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-be06dde4-06d0-4452-9997-880f8bc2d234,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-6f6bd62e-7949-48c4-a725-a7045f79ab5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682990039-172.17.0.11-1598439042778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36736,DS-71ee2947-4df8-413c-9692-4169b0a70615,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-9bd331aa-f2e8-4303-ac4f-df53096b4ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-eba1a7d5-6b09-4301-938b-371ef0dfb891,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-4f2324d1-c3a4-462d-8125-8240d3d3b454,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-b0636b05-4033-482a-a753-d8b7b68a9647,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-2392a1e6-11fc-4297-b691-f02ba4388749,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-be06dde4-06d0-4452-9997-880f8bc2d234,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-6f6bd62e-7949-48c4-a725-a7045f79ab5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410002351-172.17.0.11-1598439189550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38800,DS-9e565bc4-128f-41ae-a0f9-f8c0431951fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-d49aa3aa-e24c-4dae-a439-206e8fb35698,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-9a2d8819-ba95-4ba5-8cf7-60210289079c,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-319ab033-8376-443e-8eed-a2e839bbec11,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-7667a0b4-dfa5-4690-9726-a19a6a42dd08,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-c4eac355-be66-4c49-9593-264c4732c24e,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-67608e4c-7ad8-4d9c-bf9b-1e3eca7fe629,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-6e80434f-bb0f-428a-b90c-fcb8e1649466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410002351-172.17.0.11-1598439189550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38800,DS-9e565bc4-128f-41ae-a0f9-f8c0431951fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-d49aa3aa-e24c-4dae-a439-206e8fb35698,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-9a2d8819-ba95-4ba5-8cf7-60210289079c,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-319ab033-8376-443e-8eed-a2e839bbec11,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-7667a0b4-dfa5-4690-9726-a19a6a42dd08,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-c4eac355-be66-4c49-9593-264c4732c24e,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-67608e4c-7ad8-4d9c-bf9b-1e3eca7fe629,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-6e80434f-bb0f-428a-b90c-fcb8e1649466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390789937-172.17.0.11-1598439417673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46219,DS-dc5bfc9d-48db-44f4-b367-1823dd00bfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-4d002666-8779-4568-81ff-3a9e9fff0a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-5f2254df-5ae9-4954-8a5b-2e235382b689,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-1f06d1c7-b0d9-4792-8e2a-1215b248ac1d,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-8ef33b6c-5930-4a3c-89e1-0d40ed99610c,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-984f1adc-c8c1-4050-8ca8-c2a838863aed,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-aea5d647-b2ad-406d-b863-f163d989fa88,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-f3bdf09b-222c-4ed5-add4-0ba60049da13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390789937-172.17.0.11-1598439417673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46219,DS-dc5bfc9d-48db-44f4-b367-1823dd00bfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-4d002666-8779-4568-81ff-3a9e9fff0a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-5f2254df-5ae9-4954-8a5b-2e235382b689,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-1f06d1c7-b0d9-4792-8e2a-1215b248ac1d,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-8ef33b6c-5930-4a3c-89e1-0d40ed99610c,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-984f1adc-c8c1-4050-8ca8-c2a838863aed,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-aea5d647-b2ad-406d-b863-f163d989fa88,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-f3bdf09b-222c-4ed5-add4-0ba60049da13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013754796-172.17.0.11-1598439790807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43020,DS-3f091c39-b28d-42f8-bd07-2b8f2800f126,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-be3c98e5-3b96-437b-9742-1d0ea9e0b380,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-96fbe82c-a1e3-4251-bc2a-160cfd320387,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-464681b2-6485-49d7-9256-bc6628007dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-17bd2804-a594-4e0c-9aa1-cf20af76d2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-5223200e-ab21-4521-8378-c715ff2b5cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-688b6511-76ad-4718-a37e-36905a63c037,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-d974b75e-5627-4b19-aedc-1732526edfb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1013754796-172.17.0.11-1598439790807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43020,DS-3f091c39-b28d-42f8-bd07-2b8f2800f126,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-be3c98e5-3b96-437b-9742-1d0ea9e0b380,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-96fbe82c-a1e3-4251-bc2a-160cfd320387,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-464681b2-6485-49d7-9256-bc6628007dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-17bd2804-a594-4e0c-9aa1-cf20af76d2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-5223200e-ab21-4521-8378-c715ff2b5cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-688b6511-76ad-4718-a37e-36905a63c037,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-d974b75e-5627-4b19-aedc-1732526edfb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5189
