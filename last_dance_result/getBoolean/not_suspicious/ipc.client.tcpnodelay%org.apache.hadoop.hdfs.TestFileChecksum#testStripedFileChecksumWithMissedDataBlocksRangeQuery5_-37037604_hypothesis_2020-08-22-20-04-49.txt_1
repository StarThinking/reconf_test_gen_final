reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784799847-172.17.0.21-1598126913926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45104,DS-ca376aba-009e-46d2-b129-60bf2f6b8893,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-63223d06-419c-483f-9011-b4e8fb2ee3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-12745a29-e5ee-4302-a92a-501cb318cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-238f8642-a9bf-4994-b06b-13cd44035b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-ce3ba9b9-91aa-4068-9de9-58b3ce67b84d,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-7ff59baa-56f2-4523-a039-465fbac83942,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-0e5a7337-e201-4148-b11a-d85778968a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-e4e2a6f2-28ed-4420-a3e4-17cde472e2d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784799847-172.17.0.21-1598126913926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45104,DS-ca376aba-009e-46d2-b129-60bf2f6b8893,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-63223d06-419c-483f-9011-b4e8fb2ee3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-12745a29-e5ee-4302-a92a-501cb318cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-238f8642-a9bf-4994-b06b-13cd44035b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-ce3ba9b9-91aa-4068-9de9-58b3ce67b84d,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-7ff59baa-56f2-4523-a039-465fbac83942,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-0e5a7337-e201-4148-b11a-d85778968a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-e4e2a6f2-28ed-4420-a3e4-17cde472e2d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132416027-172.17.0.21-1598127342309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35240,DS-692b3054-207d-47d8-bfe1-7db42f97aa97,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-dea6444d-d5f7-4ab8-9d86-a84fc95fd06c,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-b8ecbad6-aebc-4604-8f04-d079ea8dbbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-0fff7e91-1e1e-47d8-a417-c6ba3c8ee824,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-88f34b7c-f66c-40e7-8533-8d0dd4389e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-f2937651-c8ca-489c-8f21-eaa894a326db,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-05824e6e-37d7-4849-b32a-a11f8a0565d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-863dc24c-b353-44ec-8f36-e621e73494de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132416027-172.17.0.21-1598127342309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35240,DS-692b3054-207d-47d8-bfe1-7db42f97aa97,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-dea6444d-d5f7-4ab8-9d86-a84fc95fd06c,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-b8ecbad6-aebc-4604-8f04-d079ea8dbbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-0fff7e91-1e1e-47d8-a417-c6ba3c8ee824,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-88f34b7c-f66c-40e7-8533-8d0dd4389e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-f2937651-c8ca-489c-8f21-eaa894a326db,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-05824e6e-37d7-4849-b32a-a11f8a0565d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-863dc24c-b353-44ec-8f36-e621e73494de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808972921-172.17.0.21-1598127538158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43331,DS-e7a5df37-4de9-45fe-8df4-c33f50a549eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-61ea5ffd-a7d3-44d7-a511-9719743eae48,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-2a723f5f-43f5-4db6-bb8c-8e7450229c07,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-64f3c435-e7e4-42a7-8514-173dae92b73c,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-bc96b878-e16d-4a18-aa6c-ec20a082e279,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-01ad6262-edf0-414e-8f33-666a4dacea59,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-ba3c26df-89be-4767-8996-f1345470a626,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-522b0441-e74b-48dd-9e23-55598ea9696e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808972921-172.17.0.21-1598127538158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43331,DS-e7a5df37-4de9-45fe-8df4-c33f50a549eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-61ea5ffd-a7d3-44d7-a511-9719743eae48,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-2a723f5f-43f5-4db6-bb8c-8e7450229c07,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-64f3c435-e7e4-42a7-8514-173dae92b73c,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-bc96b878-e16d-4a18-aa6c-ec20a082e279,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-01ad6262-edf0-414e-8f33-666a4dacea59,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-ba3c26df-89be-4767-8996-f1345470a626,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-522b0441-e74b-48dd-9e23-55598ea9696e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-14080252-172.17.0.21-1598128400702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42019,DS-6219d449-4392-4ea9-9ff8-9e098f724e00,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-8d739a68-7e67-4c74-b780-cad1ba04d6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-44f5b7c2-53b6-4ea5-a336-911cccdbaad2,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-65ab45ac-af10-4ed7-99e4-e8251123d6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-1ae32c15-e2c1-4818-a886-bb996d31067b,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-15dcaeb9-3ed7-4e67-9854-fef82066dd57,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-80eab75e-a3f8-48ac-9438-1e26eed7c1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-9c819dd3-2379-444b-9276-65fd73401fb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-14080252-172.17.0.21-1598128400702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42019,DS-6219d449-4392-4ea9-9ff8-9e098f724e00,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-8d739a68-7e67-4c74-b780-cad1ba04d6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-44f5b7c2-53b6-4ea5-a336-911cccdbaad2,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-65ab45ac-af10-4ed7-99e4-e8251123d6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-1ae32c15-e2c1-4818-a886-bb996d31067b,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-15dcaeb9-3ed7-4e67-9854-fef82066dd57,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-80eab75e-a3f8-48ac-9438-1e26eed7c1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-9c819dd3-2379-444b-9276-65fd73401fb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963703767-172.17.0.21-1598129416908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36313,DS-6e031150-ec3e-40d3-8225-c46a70053644,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-67a337e6-1aa7-40ac-8ca8-329355cc47df,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-3279fcab-09df-49f9-986d-17a85c170cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-29e4d492-eece-4a6a-b00e-218c84be48ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-ba65968a-391a-4044-836a-de278b9d32bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-8782f9b0-9cb6-49f5-8fca-6ee1ed69f073,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-3ea0f0e5-0b5d-45aa-9e52-65487805b6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-7a2303aa-25c9-483f-b08a-47d446c4be17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963703767-172.17.0.21-1598129416908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36313,DS-6e031150-ec3e-40d3-8225-c46a70053644,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-67a337e6-1aa7-40ac-8ca8-329355cc47df,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-3279fcab-09df-49f9-986d-17a85c170cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-29e4d492-eece-4a6a-b00e-218c84be48ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-ba65968a-391a-4044-836a-de278b9d32bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-8782f9b0-9cb6-49f5-8fca-6ee1ed69f073,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-3ea0f0e5-0b5d-45aa-9e52-65487805b6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-7a2303aa-25c9-483f-b08a-47d446c4be17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235917134-172.17.0.21-1598130843973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35322,DS-ab3fb69e-6865-4f35-92fb-6047b572b906,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-3afcb90e-6a73-4f88-aad1-86b012df2e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-23813c31-0109-43b1-ac02-fafa9903d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-ce3e8768-a082-4c42-b030-587e276bfc26,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-a7a8ffaa-6ee9-4021-a164-ed3bf6858a76,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-f6c61375-2bd0-4576-9fb7-e2fd536161c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-e1430a85-717e-4ad8-9d5d-c7d3d5981765,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-2e44be35-6bb2-4223-83e1-75c84ce9281d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235917134-172.17.0.21-1598130843973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35322,DS-ab3fb69e-6865-4f35-92fb-6047b572b906,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-3afcb90e-6a73-4f88-aad1-86b012df2e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-23813c31-0109-43b1-ac02-fafa9903d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-ce3e8768-a082-4c42-b030-587e276bfc26,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-a7a8ffaa-6ee9-4021-a164-ed3bf6858a76,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-f6c61375-2bd0-4576-9fb7-e2fd536161c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-e1430a85-717e-4ad8-9d5d-c7d3d5981765,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-2e44be35-6bb2-4223-83e1-75c84ce9281d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016167833-172.17.0.21-1598131412767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44600,DS-718a3fca-aca1-4b72-bdcc-fcb898a8a577,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-e96d01e2-bbb4-492f-af16-f3d09ffe30ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-a73a89e9-e000-4703-9f39-a98f933ce200,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-81ba55d3-1623-49b7-909b-04f2a8b392b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-de028207-99c1-44d3-b56e-524402290e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-50195d98-b61f-46f5-a48b-5ca36d7c611d,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-bcdfc5d6-0ef6-47f2-8e8e-46407281b858,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-9e9d8a96-92f8-48c8-bd46-ae5fc4fa9a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016167833-172.17.0.21-1598131412767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44600,DS-718a3fca-aca1-4b72-bdcc-fcb898a8a577,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-e96d01e2-bbb4-492f-af16-f3d09ffe30ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-a73a89e9-e000-4703-9f39-a98f933ce200,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-81ba55d3-1623-49b7-909b-04f2a8b392b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-de028207-99c1-44d3-b56e-524402290e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-50195d98-b61f-46f5-a48b-5ca36d7c611d,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-bcdfc5d6-0ef6-47f2-8e8e-46407281b858,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-9e9d8a96-92f8-48c8-bd46-ae5fc4fa9a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432586039-172.17.0.21-1598131444443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41237,DS-36e7a031-ce33-4532-9469-eb0e64c02b04,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-373bec6b-27a8-4996-a02a-abac9a6cea4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-e376c207-3652-433b-8809-315ac138863b,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-b229e680-1eb6-4e96-bf0c-65c23686b105,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-213abbaa-1492-4323-8eb9-e111af2066d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-2b5d07fc-d709-40c4-81b2-fde8a948bd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-dee2f27c-65db-4613-b39a-212430fca638,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-14c062e0-0df4-4949-ac96-8ce3bff08402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432586039-172.17.0.21-1598131444443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41237,DS-36e7a031-ce33-4532-9469-eb0e64c02b04,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-373bec6b-27a8-4996-a02a-abac9a6cea4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-e376c207-3652-433b-8809-315ac138863b,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-b229e680-1eb6-4e96-bf0c-65c23686b105,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-213abbaa-1492-4323-8eb9-e111af2066d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-2b5d07fc-d709-40c4-81b2-fde8a948bd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-dee2f27c-65db-4613-b39a-212430fca638,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-14c062e0-0df4-4949-ac96-8ce3bff08402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 5454
