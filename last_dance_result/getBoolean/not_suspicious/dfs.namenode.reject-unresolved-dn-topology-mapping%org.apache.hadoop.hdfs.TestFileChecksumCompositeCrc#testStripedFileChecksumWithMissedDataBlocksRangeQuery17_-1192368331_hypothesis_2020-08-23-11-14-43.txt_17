reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1161381327-172.17.0.17-1598181603521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35762,DS-5f11f8cd-fcc0-49e3-be9d-bce8be1daaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-154172d2-5621-45ce-8656-7c57c6923c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-dcf408a8-d324-44c5-a5f9-2d1881d3e60e,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-c1a2002d-226d-4c82-a225-ce07b83ac7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-7fbaf95d-a6fa-4ef4-92e7-4c4838c95b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-2bb0064c-cc37-4e82-8145-6ee053b3a0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-3ab4ea77-ba1e-487b-911c-5314b09bc463,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-db9d5953-0cf0-488d-9713-451d19d5eaf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1161381327-172.17.0.17-1598181603521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35762,DS-5f11f8cd-fcc0-49e3-be9d-bce8be1daaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-154172d2-5621-45ce-8656-7c57c6923c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-dcf408a8-d324-44c5-a5f9-2d1881d3e60e,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-c1a2002d-226d-4c82-a225-ce07b83ac7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-7fbaf95d-a6fa-4ef4-92e7-4c4838c95b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-2bb0064c-cc37-4e82-8145-6ee053b3a0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-3ab4ea77-ba1e-487b-911c-5314b09bc463,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-db9d5953-0cf0-488d-9713-451d19d5eaf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-450251378-172.17.0.17-1598181888610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39901,DS-5dd02915-0756-4c5e-8310-3991d9083a20,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-ac751371-5455-4a63-a965-19b4f16ea776,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-b2026e15-d56b-42fe-93d2-f404fce24127,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-ea0a3650-cf29-4182-97ec-f9ef8af2fbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-0c473632-16c4-4fd4-b32d-e2203b1ef48b,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-5a234298-b69b-47de-b085-3063e018f146,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-6c4efa00-e9ce-4587-9015-f2ddcbcc34a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-12ab890e-6f3f-41b1-ae2c-bc23dd97f2ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-450251378-172.17.0.17-1598181888610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39901,DS-5dd02915-0756-4c5e-8310-3991d9083a20,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-ac751371-5455-4a63-a965-19b4f16ea776,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-b2026e15-d56b-42fe-93d2-f404fce24127,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-ea0a3650-cf29-4182-97ec-f9ef8af2fbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-0c473632-16c4-4fd4-b32d-e2203b1ef48b,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-5a234298-b69b-47de-b085-3063e018f146,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-6c4efa00-e9ce-4587-9015-f2ddcbcc34a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-12ab890e-6f3f-41b1-ae2c-bc23dd97f2ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242114352-172.17.0.17-1598182694506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32999,DS-63b7a0c4-12be-49bc-a5bd-2c2702a276e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-c7a5d131-b990-4ef0-84a5-391acf5a106f,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-d987ab2b-5957-4308-83f6-1539951a41ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-10fdc4a2-f3bc-4b98-97e2-97468941e4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-6d114fb7-2859-465f-8d48-9518f93f9d32,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-4321c1a5-8f0d-40a5-b000-1fafb97392fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-08af11bd-fb78-430f-bbbb-5de7d85ddb31,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-669bbbb7-0abb-4fc5-8242-8bc0ba1ce12a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242114352-172.17.0.17-1598182694506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32999,DS-63b7a0c4-12be-49bc-a5bd-2c2702a276e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-c7a5d131-b990-4ef0-84a5-391acf5a106f,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-d987ab2b-5957-4308-83f6-1539951a41ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-10fdc4a2-f3bc-4b98-97e2-97468941e4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-6d114fb7-2859-465f-8d48-9518f93f9d32,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-4321c1a5-8f0d-40a5-b000-1fafb97392fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-08af11bd-fb78-430f-bbbb-5de7d85ddb31,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-669bbbb7-0abb-4fc5-8242-8bc0ba1ce12a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-5196865-172.17.0.17-1598182954336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44574,DS-73d26127-59c0-43cc-bdda-529cebff79d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-f50490ec-3756-4802-b518-49d2298b732e,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-bf6fd5c2-95db-43dc-9ecf-03bf94241ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-e2837a0b-235a-416b-a5eb-665bd1791f05,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-6ce1dde4-c79f-471f-b6b9-7f70c221b5df,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-13c360ab-3b39-4fb6-ba4a-abe8b9d0762c,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-e18feeba-37e6-40a4-865e-2a76a66d6c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-74dc9f8b-a000-4f63-bde6-f482e2e43202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-5196865-172.17.0.17-1598182954336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44574,DS-73d26127-59c0-43cc-bdda-529cebff79d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-f50490ec-3756-4802-b518-49d2298b732e,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-bf6fd5c2-95db-43dc-9ecf-03bf94241ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-e2837a0b-235a-416b-a5eb-665bd1791f05,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-6ce1dde4-c79f-471f-b6b9-7f70c221b5df,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-13c360ab-3b39-4fb6-ba4a-abe8b9d0762c,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-e18feeba-37e6-40a4-865e-2a76a66d6c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-74dc9f8b-a000-4f63-bde6-f482e2e43202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222583857-172.17.0.17-1598183001134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36338,DS-96f521d0-807e-4303-b7fa-6d7d375a2cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-0f7f8a1c-1b55-4c7a-b047-df3d6dcdca6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-de23053b-f6d7-4e9e-a705-0eeea85f7cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-6d67ee94-dc7e-4484-abd2-06d4ab5aa1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-9aa2ccc2-ed39-4b8e-9a21-34b8d983c11b,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-d4b17153-1841-4989-b1ef-4621e89dd929,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-36c89057-9fa4-4de2-b6ff-49aa7e5c3e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-1c112e5a-6a4d-4140-89ba-43fe07823bbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222583857-172.17.0.17-1598183001134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36338,DS-96f521d0-807e-4303-b7fa-6d7d375a2cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-0f7f8a1c-1b55-4c7a-b047-df3d6dcdca6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-de23053b-f6d7-4e9e-a705-0eeea85f7cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-6d67ee94-dc7e-4484-abd2-06d4ab5aa1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-9aa2ccc2-ed39-4b8e-9a21-34b8d983c11b,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-d4b17153-1841-4989-b1ef-4621e89dd929,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-36c89057-9fa4-4de2-b6ff-49aa7e5c3e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-1c112e5a-6a4d-4140-89ba-43fe07823bbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-837686979-172.17.0.17-1598183077665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44910,DS-46a0e837-8338-4f93-ae61-6eeaf910ea5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-d31f5974-2330-4350-8a07-192e2648d63f,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-5d700076-5a06-4aff-bd0a-34324cf3ef12,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-5ea4da05-2199-4570-b9fd-531288478f51,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-814d34fa-0951-4040-9871-0832d990e4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-3e703087-e07d-4650-b778-281f4682b9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-8602187b-4ac0-485b-a364-d6d10ee35320,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-c739dc13-2fcc-47f2-83d0-b445c79433f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-837686979-172.17.0.17-1598183077665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44910,DS-46a0e837-8338-4f93-ae61-6eeaf910ea5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-d31f5974-2330-4350-8a07-192e2648d63f,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-5d700076-5a06-4aff-bd0a-34324cf3ef12,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-5ea4da05-2199-4570-b9fd-531288478f51,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-814d34fa-0951-4040-9871-0832d990e4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-3e703087-e07d-4650-b778-281f4682b9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-8602187b-4ac0-485b-a364-d6d10ee35320,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-c739dc13-2fcc-47f2-83d0-b445c79433f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-923025155-172.17.0.17-1598184680274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39004,DS-3f0f63b2-8702-4f6b-9a5d-2898662ef5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-f5fe6484-d284-4db7-abc0-259c1894fa2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-9ce8d559-1799-423a-b07b-fc5f8136f3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-9ebb5b94-3741-4302-bc53-55c12e7789a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-bf7be738-849f-418b-9721-ac0113d60b40,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-5e6e594c-2143-43a3-924c-9700cafe991d,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-fbc71d4b-006b-442b-9291-e59129e8b0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-178bc244-5db5-4ec7-9755-85303a9a68ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-923025155-172.17.0.17-1598184680274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39004,DS-3f0f63b2-8702-4f6b-9a5d-2898662ef5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-f5fe6484-d284-4db7-abc0-259c1894fa2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-9ce8d559-1799-423a-b07b-fc5f8136f3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-9ebb5b94-3741-4302-bc53-55c12e7789a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-bf7be738-849f-418b-9721-ac0113d60b40,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-5e6e594c-2143-43a3-924c-9700cafe991d,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-fbc71d4b-006b-442b-9291-e59129e8b0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-178bc244-5db5-4ec7-9755-85303a9a68ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635233290-172.17.0.17-1598185314338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46137,DS-4de57f5a-3fa8-45a0-ae49-928e6cf0d846,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-622d6d30-dc1f-4f81-a75b-49d66ff1b9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-fe005cc6-2073-4615-a94f-0fbacc467b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-19059812-b63c-4581-953e-2d2b5c5c671b,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-14dd4e3b-39bf-44f2-ab5f-eb65a3e7c993,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-36a480a7-beae-477a-ac65-baf8a3c65216,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-3be18c51-ec52-474c-9778-a9a09112f75b,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-6e2d986b-4f5d-47eb-9c54-9663c2ceca1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635233290-172.17.0.17-1598185314338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46137,DS-4de57f5a-3fa8-45a0-ae49-928e6cf0d846,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-622d6d30-dc1f-4f81-a75b-49d66ff1b9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-fe005cc6-2073-4615-a94f-0fbacc467b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-19059812-b63c-4581-953e-2d2b5c5c671b,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-14dd4e3b-39bf-44f2-ab5f-eb65a3e7c993,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-36a480a7-beae-477a-ac65-baf8a3c65216,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-3be18c51-ec52-474c-9778-a9a09112f75b,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-6e2d986b-4f5d-47eb-9c54-9663c2ceca1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793803898-172.17.0.17-1598185339560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45445,DS-a3325e04-8217-4012-b568-d679aab18837,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-d49891ac-7398-4828-80a4-11a7175958c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-05b2b22d-da43-4a78-af72-3a5f40ced91f,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-5eea3db4-f8f9-472c-95f6-7095b77275f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-c2a658e6-e01c-4eb0-8b4e-56319e2e773b,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-04f7fc11-a086-4e74-8621-9f3d5ccbb2db,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-0aff14b7-4db5-4a77-85f0-ab849c08a06e,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-be0f81ee-961c-430e-9d59-e1a5d682e643,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793803898-172.17.0.17-1598185339560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45445,DS-a3325e04-8217-4012-b568-d679aab18837,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-d49891ac-7398-4828-80a4-11a7175958c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-05b2b22d-da43-4a78-af72-3a5f40ced91f,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-5eea3db4-f8f9-472c-95f6-7095b77275f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-c2a658e6-e01c-4eb0-8b4e-56319e2e773b,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-04f7fc11-a086-4e74-8621-9f3d5ccbb2db,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-0aff14b7-4db5-4a77-85f0-ab849c08a06e,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-be0f81ee-961c-430e-9d59-e1a5d682e643,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542450937-172.17.0.17-1598185956605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39399,DS-90215a35-3148-4be1-986c-e18d62b6e0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-b0bf316b-7867-496e-bb41-b9115edcb49b,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-d2677949-900e-4d96-874c-cffe7224220e,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-6d1db574-b9b5-4757-9d37-95ba6c345dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-72fa8e06-bf60-4080-a733-33595042e5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-44377393-846e-4e4e-a31d-87aaa1f9ebb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-7c302ad2-ade0-4215-9ec0-b52012d1c2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-6a550860-aac3-43a1-afb9-7741c8780cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542450937-172.17.0.17-1598185956605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39399,DS-90215a35-3148-4be1-986c-e18d62b6e0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-b0bf316b-7867-496e-bb41-b9115edcb49b,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-d2677949-900e-4d96-874c-cffe7224220e,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-6d1db574-b9b5-4757-9d37-95ba6c345dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-72fa8e06-bf60-4080-a733-33595042e5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-44377393-846e-4e4e-a31d-87aaa1f9ebb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-7c302ad2-ade0-4215-9ec0-b52012d1c2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-6a550860-aac3-43a1-afb9-7741c8780cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5362
