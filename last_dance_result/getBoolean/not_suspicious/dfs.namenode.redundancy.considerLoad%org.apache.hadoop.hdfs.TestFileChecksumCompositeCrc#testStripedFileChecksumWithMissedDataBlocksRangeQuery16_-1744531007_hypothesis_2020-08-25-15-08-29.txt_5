reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085288595-172.17.0.6-1598368493841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40895,DS-54932491-ed00-48cf-ae40-8a6dc8b8dbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-4dd4d90a-12e7-4b2b-b8cf-2b940cf5838b,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-38f8d569-1efa-408b-9369-db3329559fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-5cdc71f3-b552-4f1c-a621-9c58e90e3d13,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-81550f1e-155b-4a9f-9cf9-bc1a5dceb67b,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-da891db2-d924-4ab0-9c85-08ab9cfee244,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-97a2de7c-74c4-4e0e-ae5f-0be1d07cb9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-0260919a-884e-4d6a-bffd-2c128f3d0734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085288595-172.17.0.6-1598368493841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40895,DS-54932491-ed00-48cf-ae40-8a6dc8b8dbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-4dd4d90a-12e7-4b2b-b8cf-2b940cf5838b,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-38f8d569-1efa-408b-9369-db3329559fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-5cdc71f3-b552-4f1c-a621-9c58e90e3d13,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-81550f1e-155b-4a9f-9cf9-bc1a5dceb67b,DISK], DatanodeInfoWithStorage[127.0.0.1:34839,DS-da891db2-d924-4ab0-9c85-08ab9cfee244,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-97a2de7c-74c4-4e0e-ae5f-0be1d07cb9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-0260919a-884e-4d6a-bffd-2c128f3d0734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615969938-172.17.0.6-1598368604716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40269,DS-e36a126b-6dac-42f6-9b03-209633765e68,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-4a5239a5-03ff-4c92-850a-ed1b1b089eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-5a350b37-7d6b-43bb-a9a6-2f9b3bf01007,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-98bf79e1-9fca-40b1-bbaa-ef3cb7c138e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-22757246-28b4-45db-ad77-40f5140ef55f,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-416d80fc-b4c9-4729-80a4-499d83a13f45,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-fef31f9c-9dba-4419-9403-c1ae9cbabe65,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-d547fa0b-1712-4c7c-9dc5-bd5beb35806e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615969938-172.17.0.6-1598368604716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40269,DS-e36a126b-6dac-42f6-9b03-209633765e68,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-4a5239a5-03ff-4c92-850a-ed1b1b089eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-5a350b37-7d6b-43bb-a9a6-2f9b3bf01007,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-98bf79e1-9fca-40b1-bbaa-ef3cb7c138e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-22757246-28b4-45db-ad77-40f5140ef55f,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-416d80fc-b4c9-4729-80a4-499d83a13f45,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-fef31f9c-9dba-4419-9403-c1ae9cbabe65,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-d547fa0b-1712-4c7c-9dc5-bd5beb35806e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984221772-172.17.0.6-1598368732806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33178,DS-d2659b13-1d0b-4797-86fd-fa8a00871816,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-911f7eca-c0c1-4ee7-a52c-74557a7bd82a,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-64ce8014-e546-4f26-b5dd-28bb9fa57060,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-a5218007-7394-4c24-98f0-63bee7ca57cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-de5601d7-d794-42a1-bd97-600b7bb3a58a,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-0039f09c-e5b1-406f-bc6e-9a7752bcadbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-a4820f1b-3872-4a96-9e1f-3d8ebe843573,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-5ee71b4c-e5ba-45a8-9e09-e8b1515ff49a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984221772-172.17.0.6-1598368732806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33178,DS-d2659b13-1d0b-4797-86fd-fa8a00871816,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-911f7eca-c0c1-4ee7-a52c-74557a7bd82a,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-64ce8014-e546-4f26-b5dd-28bb9fa57060,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-a5218007-7394-4c24-98f0-63bee7ca57cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-de5601d7-d794-42a1-bd97-600b7bb3a58a,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-0039f09c-e5b1-406f-bc6e-9a7752bcadbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-a4820f1b-3872-4a96-9e1f-3d8ebe843573,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-5ee71b4c-e5ba-45a8-9e09-e8b1515ff49a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1295120129-172.17.0.6-1598369028707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34018,DS-f60ca8b2-4ba2-481b-99d5-bda30ce3a489,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-73195aa6-ba0a-4e85-97ac-aae98fc31ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-18a58f32-f5bc-4680-a32a-505b815ff063,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-8c58f45a-31c6-45bd-8e58-d5f84b383b91,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-d2a4ef8d-ea70-48d6-a132-ffba410ccddc,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-0cd238a6-7a81-4a3a-970c-d29fa8137bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-93fbaf1d-4762-41b1-b305-58d538d4e3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-734db0d1-10a8-4385-b63c-0ecba5f3d2a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1295120129-172.17.0.6-1598369028707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34018,DS-f60ca8b2-4ba2-481b-99d5-bda30ce3a489,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-73195aa6-ba0a-4e85-97ac-aae98fc31ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-18a58f32-f5bc-4680-a32a-505b815ff063,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-8c58f45a-31c6-45bd-8e58-d5f84b383b91,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-d2a4ef8d-ea70-48d6-a132-ffba410ccddc,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-0cd238a6-7a81-4a3a-970c-d29fa8137bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-93fbaf1d-4762-41b1-b305-58d538d4e3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-734db0d1-10a8-4385-b63c-0ecba5f3d2a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-35096685-172.17.0.6-1598369095334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43111,DS-88b1647b-4f1c-49fc-9b07-8a581f694011,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-11d10a0b-b925-4204-a3c5-679051a94f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-6bcc8759-ef3e-4dd8-8987-bf8772c722c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-76a18973-dc61-403c-8a45-6c8d3a9b5f50,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-8d87a950-da8b-4e98-8de8-078437190d55,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-cc9b1b06-8be7-4356-9d33-2e78da3d9868,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-b2b464ef-1b85-46b0-b5b3-e9fb54dfe574,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-6730d350-83e9-4f9f-b891-173eeb319f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-35096685-172.17.0.6-1598369095334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43111,DS-88b1647b-4f1c-49fc-9b07-8a581f694011,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-11d10a0b-b925-4204-a3c5-679051a94f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-6bcc8759-ef3e-4dd8-8987-bf8772c722c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-76a18973-dc61-403c-8a45-6c8d3a9b5f50,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-8d87a950-da8b-4e98-8de8-078437190d55,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-cc9b1b06-8be7-4356-9d33-2e78da3d9868,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-b2b464ef-1b85-46b0-b5b3-e9fb54dfe574,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-6730d350-83e9-4f9f-b891-173eeb319f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638231548-172.17.0.6-1598369407403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43049,DS-ecf87d3e-b19a-42aa-b251-50fc627ca320,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-cc35e8a3-e61f-4657-bff5-df08cc5d8468,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-8caf6d9a-de7f-4c86-9ad8-622de3d36fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-3aa31eb1-45d8-4e24-a345-8f7697efb26d,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-3dc90068-b764-42ab-8c8c-1d177a8a46dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-92c0f7b3-e4a7-43f2-b403-75a6893f4b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-29c1dd7a-49ee-4aa0-b5de-53094b49fdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-ffec4371-167e-4018-9dd7-d6d6a6036648,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638231548-172.17.0.6-1598369407403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43049,DS-ecf87d3e-b19a-42aa-b251-50fc627ca320,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-cc35e8a3-e61f-4657-bff5-df08cc5d8468,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-8caf6d9a-de7f-4c86-9ad8-622de3d36fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-3aa31eb1-45d8-4e24-a345-8f7697efb26d,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-3dc90068-b764-42ab-8c8c-1d177a8a46dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-92c0f7b3-e4a7-43f2-b403-75a6893f4b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-29c1dd7a-49ee-4aa0-b5de-53094b49fdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-ffec4371-167e-4018-9dd7-d6d6a6036648,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186764428-172.17.0.6-1598369588286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45020,DS-190a972a-4cf4-4a00-a1a9-c1f900547fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-86f83044-2ca7-4223-8d5f-734d284255f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-ee90cc26-b4bc-4763-b714-a72d381bb320,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-c8e360f0-78bf-45c4-bdec-1d7cac2d65dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-87785666-501e-486c-a7eb-b6a313e76414,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-d1df2c2c-1a59-47a6-9b77-e4ce268b77ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-ab56eba6-a567-4947-afa4-87280fa064e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-49dab7b5-3c3b-4001-a08f-455ca247b26a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186764428-172.17.0.6-1598369588286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45020,DS-190a972a-4cf4-4a00-a1a9-c1f900547fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-86f83044-2ca7-4223-8d5f-734d284255f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-ee90cc26-b4bc-4763-b714-a72d381bb320,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-c8e360f0-78bf-45c4-bdec-1d7cac2d65dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-87785666-501e-486c-a7eb-b6a313e76414,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-d1df2c2c-1a59-47a6-9b77-e4ce268b77ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-ab56eba6-a567-4947-afa4-87280fa064e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-49dab7b5-3c3b-4001-a08f-455ca247b26a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-824507917-172.17.0.6-1598369622238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41122,DS-3da51345-2269-4ffe-87ec-88c8ade69cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-4de3993f-c8bd-435b-a486-f01e54c0b283,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-ceab8864-d5d6-42be-84ea-9c399441183d,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-62414a30-caf5-4e82-ab60-8c2c2d0d0851,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-ce3fcf58-bcb8-4516-b7d2-1c15102f8b70,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-519473aa-c4d1-4bd5-9945-b3082e52ad09,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-503dcd54-8a71-46c9-95cd-e0b238800529,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-1f4f75af-f79f-40c8-a055-1cfcbadd3fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-824507917-172.17.0.6-1598369622238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41122,DS-3da51345-2269-4ffe-87ec-88c8ade69cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-4de3993f-c8bd-435b-a486-f01e54c0b283,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-ceab8864-d5d6-42be-84ea-9c399441183d,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-62414a30-caf5-4e82-ab60-8c2c2d0d0851,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-ce3fcf58-bcb8-4516-b7d2-1c15102f8b70,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-519473aa-c4d1-4bd5-9945-b3082e52ad09,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-503dcd54-8a71-46c9-95cd-e0b238800529,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-1f4f75af-f79f-40c8-a055-1cfcbadd3fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1376623647-172.17.0.6-1598369701851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42793,DS-29a63f5a-6302-499c-a02d-769161be314b,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-372dd125-97ae-4bef-948b-64cb715cdd46,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-61d452b5-8716-4154-92cb-0f6c90995adc,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-db9bbb34-43b9-439a-9cff-65f582d29850,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-0b455b9b-d292-4b14-8561-696c44e540d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-f7c65b50-041a-4436-90ad-51c1c4120116,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-471a7cca-6b03-461a-9c87-057855bbd9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-55674ad6-9290-4fe8-882d-b03611fae4a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1376623647-172.17.0.6-1598369701851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42793,DS-29a63f5a-6302-499c-a02d-769161be314b,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-372dd125-97ae-4bef-948b-64cb715cdd46,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-61d452b5-8716-4154-92cb-0f6c90995adc,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-db9bbb34-43b9-439a-9cff-65f582d29850,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-0b455b9b-d292-4b14-8561-696c44e540d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-f7c65b50-041a-4436-90ad-51c1c4120116,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-471a7cca-6b03-461a-9c87-057855bbd9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-55674ad6-9290-4fe8-882d-b03611fae4a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1258672113-172.17.0.6-1598369880659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36602,DS-c275a980-12c6-4df2-85d0-8b32307192ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-7f447579-d39e-421c-b7bb-2b436c95db2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-d9fc6fd0-766f-4b90-93ad-c96c5c8a31e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-bec28d8e-d9ea-410f-83b2-ea3495962609,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-b18a7ca2-228f-460f-9f73-73df0aa06374,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-9367b443-6a39-490a-9f55-6dd4720d2d45,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-947d0a47-bd56-48ca-af67-0e3b7b947252,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-dc7f4361-6815-4bce-b29f-53d536e82556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1258672113-172.17.0.6-1598369880659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36602,DS-c275a980-12c6-4df2-85d0-8b32307192ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-7f447579-d39e-421c-b7bb-2b436c95db2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-d9fc6fd0-766f-4b90-93ad-c96c5c8a31e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-bec28d8e-d9ea-410f-83b2-ea3495962609,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-b18a7ca2-228f-460f-9f73-73df0aa06374,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-9367b443-6a39-490a-9f55-6dd4720d2d45,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-947d0a47-bd56-48ca-af67-0e3b7b947252,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-dc7f4361-6815-4bce-b29f-53d536e82556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645275057-172.17.0.6-1598369993032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32807,DS-7a518c07-c62d-4939-858d-26b0b717f3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-19a1b630-c8e4-4b3b-9843-c6a2a5187f66,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-f585353f-ad4d-4a01-85e8-be476c9a560e,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-2944c5c8-450d-4a3d-8ea8-0e165308aaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-125fa377-7667-425f-8a53-8ad6bbb23bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-e7ef66f0-7c89-4f8e-ae8a-73bf5bcc8c37,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-c8df2c4b-cdef-45cb-9eba-886ecb02ee24,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-32eace8f-be9c-4124-b287-bb111107b11e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645275057-172.17.0.6-1598369993032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32807,DS-7a518c07-c62d-4939-858d-26b0b717f3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-19a1b630-c8e4-4b3b-9843-c6a2a5187f66,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-f585353f-ad4d-4a01-85e8-be476c9a560e,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-2944c5c8-450d-4a3d-8ea8-0e165308aaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-125fa377-7667-425f-8a53-8ad6bbb23bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-e7ef66f0-7c89-4f8e-ae8a-73bf5bcc8c37,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-c8df2c4b-cdef-45cb-9eba-886ecb02ee24,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-32eace8f-be9c-4124-b287-bb111107b11e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100600037-172.17.0.6-1598370637922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46012,DS-a69d6321-b11e-4f91-a21e-31b2c87975a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-4cc6dff7-6e13-4158-ba5a-f8de7f61a332,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-0db94eee-2cca-4f12-85b4-fa1b3c0c3801,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-9896eb73-484e-475f-9e55-788ad575141c,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-36ecd8e3-61d6-423b-a696-03c8e4aea643,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-3ed622e8-73da-4b69-ad46-7b5bad868195,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-6f9b1130-8b79-4992-8a9f-e419e65e5fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-ec1449d6-4299-4785-a465-c14f27462a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100600037-172.17.0.6-1598370637922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46012,DS-a69d6321-b11e-4f91-a21e-31b2c87975a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-4cc6dff7-6e13-4158-ba5a-f8de7f61a332,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-0db94eee-2cca-4f12-85b4-fa1b3c0c3801,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-9896eb73-484e-475f-9e55-788ad575141c,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-36ecd8e3-61d6-423b-a696-03c8e4aea643,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-3ed622e8-73da-4b69-ad46-7b5bad868195,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-6f9b1130-8b79-4992-8a9f-e419e65e5fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-ec1449d6-4299-4785-a465-c14f27462a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1390007059-172.17.0.6-1598370905571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40649,DS-17c1c7d4-ffbe-4f13-9fff-f107984e44bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-ac58a0de-2425-4bc6-bb7c-a6205b67888d,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-af494af0-1e08-4b82-a511-b2dd4ed17781,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-f9eea666-5f1e-471f-ae92-410b8a3f23c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-d8806189-d949-4226-9bb0-9f3d98bfc104,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-20c37c85-833c-4d20-9ead-47a69015cfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-70122fe0-ee15-48f9-9924-af5de201748a,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-d51b7ba6-de2c-4f6d-98cf-10aad7596af2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1390007059-172.17.0.6-1598370905571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40649,DS-17c1c7d4-ffbe-4f13-9fff-f107984e44bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-ac58a0de-2425-4bc6-bb7c-a6205b67888d,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-af494af0-1e08-4b82-a511-b2dd4ed17781,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-f9eea666-5f1e-471f-ae92-410b8a3f23c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-d8806189-d949-4226-9bb0-9f3d98bfc104,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-20c37c85-833c-4d20-9ead-47a69015cfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-70122fe0-ee15-48f9-9924-af5de201748a,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-d51b7ba6-de2c-4f6d-98cf-10aad7596af2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972445669-172.17.0.6-1598370987672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41775,DS-b7e276cf-5db9-4255-9ceb-aa5f5ca4c30f,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-048a03e1-355e-4096-9430-8f678067ee81,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-6abc7e85-4afb-4619-9461-7e2a5b8e5bce,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-3f9d3888-9760-4a56-9d46-e52a7d1619c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-6264c176-bd2c-425f-b4cb-002275736c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-553d3c06-72d4-41cb-8024-7d95140cea8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-24ca0953-b5a5-4983-a6b5-2bdce8f81b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-358d0b7a-ee79-48a4-b4b3-1aa8caea3410,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972445669-172.17.0.6-1598370987672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41775,DS-b7e276cf-5db9-4255-9ceb-aa5f5ca4c30f,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-048a03e1-355e-4096-9430-8f678067ee81,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-6abc7e85-4afb-4619-9461-7e2a5b8e5bce,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-3f9d3888-9760-4a56-9d46-e52a7d1619c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-6264c176-bd2c-425f-b4cb-002275736c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-553d3c06-72d4-41cb-8024-7d95140cea8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-24ca0953-b5a5-4983-a6b5-2bdce8f81b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-358d0b7a-ee79-48a4-b4b3-1aa8caea3410,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033897874-172.17.0.6-1598371161744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37662,DS-d338e913-a74a-4167-a90f-abfea1e520b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-cfa58562-40ea-4191-81b9-a62dd48cf9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-2389c3ce-4135-4789-b0e1-2bb90326e756,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-002f2782-1e50-463a-825e-1596453cc0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-b4afff7b-62a1-4e67-8018-07561586dda6,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-db905706-3b58-42de-8cf5-d60295d10d31,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-d13e9ff1-afdb-4400-a3d9-5b9d55987dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-a8a5b06f-3fa5-4e0b-9a81-8b7625d756a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033897874-172.17.0.6-1598371161744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37662,DS-d338e913-a74a-4167-a90f-abfea1e520b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-cfa58562-40ea-4191-81b9-a62dd48cf9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-2389c3ce-4135-4789-b0e1-2bb90326e756,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-002f2782-1e50-463a-825e-1596453cc0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-b4afff7b-62a1-4e67-8018-07561586dda6,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-db905706-3b58-42de-8cf5-d60295d10d31,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-d13e9ff1-afdb-4400-a3d9-5b9d55987dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-a8a5b06f-3fa5-4e0b-9a81-8b7625d756a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-38745097-172.17.0.6-1598371701347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41793,DS-ddd6114d-a951-49df-b0d4-30d72394a56e,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-556cce07-f2f1-4675-8962-7d665d8fb05d,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-a6b77790-7081-4c5e-b9ed-4faa0dd2179b,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-383d4967-79bb-4532-845b-235d73854cea,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-35732fb2-2a7b-4818-b038-870b65135810,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-72dd9465-c6c2-417f-9be7-6fd8d81124a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-c6540ec2-327f-4dc8-8fee-cc9db5d043f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-915ddd34-e84a-4ef7-b59e-7682364cd261,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-38745097-172.17.0.6-1598371701347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41793,DS-ddd6114d-a951-49df-b0d4-30d72394a56e,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-556cce07-f2f1-4675-8962-7d665d8fb05d,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-a6b77790-7081-4c5e-b9ed-4faa0dd2179b,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-383d4967-79bb-4532-845b-235d73854cea,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-35732fb2-2a7b-4818-b038-870b65135810,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-72dd9465-c6c2-417f-9be7-6fd8d81124a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-c6540ec2-327f-4dc8-8fee-cc9db5d043f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-915ddd34-e84a-4ef7-b59e-7682364cd261,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783297317-172.17.0.6-1598372050647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-41e8bcc6-bb77-4fff-a517-47db92bcd297,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-0f677005-e581-4f42-abfc-3ae432095dca,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-a4777750-2b99-43b3-9632-ede8e7a4df1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-4741fcc2-558d-4b48-b252-6e180d88e493,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-a9e55cc9-5f35-4f1d-8d62-329633da17ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-39e0dbed-31e6-45cb-af37-1902c87b626d,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-d45e8639-e987-4961-9071-37c5224234cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-12c916da-ea05-45e0-aab6-8d89e5b20e97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783297317-172.17.0.6-1598372050647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-41e8bcc6-bb77-4fff-a517-47db92bcd297,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-0f677005-e581-4f42-abfc-3ae432095dca,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-a4777750-2b99-43b3-9632-ede8e7a4df1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-4741fcc2-558d-4b48-b252-6e180d88e493,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-a9e55cc9-5f35-4f1d-8d62-329633da17ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-39e0dbed-31e6-45cb-af37-1902c87b626d,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-d45e8639-e987-4961-9071-37c5224234cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-12c916da-ea05-45e0-aab6-8d89e5b20e97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858317526-172.17.0.6-1598372112282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-c91e6cfb-52bd-4975-9a73-d7bede6c68ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-250f26a6-5d76-48e6-8247-94277813cd47,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-29770f38-a6df-469a-9068-2802faeb2764,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-09dcbf6b-b218-438a-9da8-7aa8b39ed8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-3838b1f0-78e1-4f89-be23-8f764f4e2bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-43814cba-5605-4476-a300-51acadbbcc58,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-5e3cef43-5a0a-48c3-b4cc-37c7b15372b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-d6de8866-1296-46b2-aa13-09dd0fdd45c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858317526-172.17.0.6-1598372112282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-c91e6cfb-52bd-4975-9a73-d7bede6c68ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-250f26a6-5d76-48e6-8247-94277813cd47,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-29770f38-a6df-469a-9068-2802faeb2764,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-09dcbf6b-b218-438a-9da8-7aa8b39ed8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-3838b1f0-78e1-4f89-be23-8f764f4e2bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-43814cba-5605-4476-a300-51acadbbcc58,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-5e3cef43-5a0a-48c3-b4cc-37c7b15372b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-d6de8866-1296-46b2-aa13-09dd0fdd45c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-330912753-172.17.0.6-1598372290621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35098,DS-5cbfc3b2-73b8-4aee-a83e-23cf32eef601,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-62cdbd04-1c2a-4571-9bac-6e1d5a2e091f,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-ee2cdd15-e0c8-4198-87aa-136b8c4006ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-3ad1ee13-7fbd-43b4-9230-9e615c40d45e,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-d5bcf94a-3583-4ba0-824e-f9bcedc5ffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-9471e1e7-1879-49af-8fbb-ae89f659eb18,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-044e8aa0-3a60-42a1-9201-c3924a3d8dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-26bd3d46-65ca-44d2-80fe-2df8e5934808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-330912753-172.17.0.6-1598372290621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35098,DS-5cbfc3b2-73b8-4aee-a83e-23cf32eef601,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-62cdbd04-1c2a-4571-9bac-6e1d5a2e091f,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-ee2cdd15-e0c8-4198-87aa-136b8c4006ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-3ad1ee13-7fbd-43b4-9230-9e615c40d45e,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-d5bcf94a-3583-4ba0-824e-f9bcedc5ffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-9471e1e7-1879-49af-8fbb-ae89f659eb18,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-044e8aa0-3a60-42a1-9201-c3924a3d8dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-26bd3d46-65ca-44d2-80fe-2df8e5934808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1663985852-172.17.0.6-1598372394785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35366,DS-2f44360e-0910-4683-80b2-25d13d32282c,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-837e566e-44e6-4f78-87fd-6a973a1675bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-1e7cc957-9508-4f27-98b4-bad63eea0ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-a6d0d743-0527-4cbf-89d7-422b1add151b,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-9540a0db-62f4-42c3-a9f8-7f5538cf9f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-8ac4438f-c84f-4013-bcb2-6f8fb70c6074,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-f2878572-c887-46bd-a8da-fc15cc80bf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-ab625249-8cbd-425b-b670-23baa22c4ee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1663985852-172.17.0.6-1598372394785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35366,DS-2f44360e-0910-4683-80b2-25d13d32282c,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-837e566e-44e6-4f78-87fd-6a973a1675bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-1e7cc957-9508-4f27-98b4-bad63eea0ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-a6d0d743-0527-4cbf-89d7-422b1add151b,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-9540a0db-62f4-42c3-a9f8-7f5538cf9f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-8ac4438f-c84f-4013-bcb2-6f8fb70c6074,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-f2878572-c887-46bd-a8da-fc15cc80bf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-ab625249-8cbd-425b-b670-23baa22c4ee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1892398402-172.17.0.6-1598372547625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36089,DS-edd37ab3-159a-4005-8292-17d8509e395d,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-a319bbec-59a4-40ec-8825-e935d6368258,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-1b93e241-8996-4bb8-8410-82b7e32656ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-4758a342-2be1-4391-bd82-6ebf73e1694e,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-0af998ad-0d39-4deb-be7d-271ea0260a38,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-62e58d0a-7d9b-471c-a596-790c467995c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-c5e39caa-0f3b-43f0-9beb-8ce17f01b840,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-07c4d9ea-8870-403d-b410-b0f62bb009f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1892398402-172.17.0.6-1598372547625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36089,DS-edd37ab3-159a-4005-8292-17d8509e395d,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-a319bbec-59a4-40ec-8825-e935d6368258,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-1b93e241-8996-4bb8-8410-82b7e32656ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-4758a342-2be1-4391-bd82-6ebf73e1694e,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-0af998ad-0d39-4deb-be7d-271ea0260a38,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-62e58d0a-7d9b-471c-a596-790c467995c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-c5e39caa-0f3b-43f0-9beb-8ce17f01b840,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-07c4d9ea-8870-403d-b410-b0f62bb009f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612130151-172.17.0.6-1598372866150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46762,DS-db93e5e1-8608-40b0-86d8-629aadf005dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-36281ad3-d44f-4388-8e58-babf3e0fde7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-eb00a25e-0250-48a9-b85e-79b66841510a,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-e340265d-fff4-4f0a-b341-2b431a10ac7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-1ed7e486-e5e3-48eb-8367-b372d91a2067,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-3d58ed14-93df-4fea-8026-4cc28c810333,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-fc73ebc5-6ab4-41de-a4d6-a8594faf8e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-6f4992bd-71b2-40fa-9e1d-3e750ae60510,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612130151-172.17.0.6-1598372866150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46762,DS-db93e5e1-8608-40b0-86d8-629aadf005dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-36281ad3-d44f-4388-8e58-babf3e0fde7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-eb00a25e-0250-48a9-b85e-79b66841510a,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-e340265d-fff4-4f0a-b341-2b431a10ac7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-1ed7e486-e5e3-48eb-8367-b372d91a2067,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-3d58ed14-93df-4fea-8026-4cc28c810333,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-fc73ebc5-6ab4-41de-a4d6-a8594faf8e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-6f4992bd-71b2-40fa-9e1d-3e750ae60510,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5266
