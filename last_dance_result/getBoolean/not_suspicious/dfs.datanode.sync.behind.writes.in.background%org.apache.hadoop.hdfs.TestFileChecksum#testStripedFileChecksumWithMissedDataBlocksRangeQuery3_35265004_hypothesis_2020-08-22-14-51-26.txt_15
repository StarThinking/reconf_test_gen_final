reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387376788-172.17.0.7-1598107955701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40481,DS-117ac2ea-ffab-460a-9d54-4f5c3c126f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-c99d6b07-943f-47a3-b186-6678ed976a02,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-0945079f-bbda-48fe-bb0b-bc780e8dc9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-f7b4e4ec-2a82-4464-80ab-6c7633d84828,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-7b28f0d1-f359-49da-b194-309ee9bd362b,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-44ceec97-629d-449d-a2b3-16fd3ce6c070,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-ff19fda1-1d4e-47be-9792-991fa3447469,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-1b231be5-ba5c-464b-87c8-0b0a78c2a8fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387376788-172.17.0.7-1598107955701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40481,DS-117ac2ea-ffab-460a-9d54-4f5c3c126f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-c99d6b07-943f-47a3-b186-6678ed976a02,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-0945079f-bbda-48fe-bb0b-bc780e8dc9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-f7b4e4ec-2a82-4464-80ab-6c7633d84828,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-7b28f0d1-f359-49da-b194-309ee9bd362b,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-44ceec97-629d-449d-a2b3-16fd3ce6c070,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-ff19fda1-1d4e-47be-9792-991fa3447469,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-1b231be5-ba5c-464b-87c8-0b0a78c2a8fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215488938-172.17.0.7-1598108707046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34589,DS-007ec2f9-d5f7-4007-aae1-206b206123f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-098b692e-ddf2-430d-8e40-aba6d9764f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-250645eb-d151-4e53-b853-213af28b1087,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-5025bc7f-a9fe-4ad0-8a9d-6652e57ebdea,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-93d87fa8-0caf-4c0f-87ff-6128d655d697,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-7f00610f-09b5-4339-8eb5-5c73507289fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-1f896934-714d-4c03-a38e-fa67667756fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-f894b543-8048-47f0-832c-35e935b9636f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215488938-172.17.0.7-1598108707046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34589,DS-007ec2f9-d5f7-4007-aae1-206b206123f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-098b692e-ddf2-430d-8e40-aba6d9764f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-250645eb-d151-4e53-b853-213af28b1087,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-5025bc7f-a9fe-4ad0-8a9d-6652e57ebdea,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-93d87fa8-0caf-4c0f-87ff-6128d655d697,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-7f00610f-09b5-4339-8eb5-5c73507289fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-1f896934-714d-4c03-a38e-fa67667756fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-f894b543-8048-47f0-832c-35e935b9636f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725119125-172.17.0.7-1598108758541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41567,DS-c3809dab-3671-4329-b823-7fced71bfa04,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-f6fdf420-a47f-4496-adc2-9596ce47489f,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-331c9fc0-da90-489d-b4f2-dc30f36aead0,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-27fed0cf-492e-47b1-8b1d-19f024fa1ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-1cef3abf-9ced-4ba3-b13a-89fd561895cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-6cd5d0d2-8315-490f-9ef0-51540b0c9f04,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-1997c141-0497-4da2-b826-5c03ace6aefe,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-7c88b045-b6c2-4d17-ac2d-d9f2e3ccf31c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725119125-172.17.0.7-1598108758541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41567,DS-c3809dab-3671-4329-b823-7fced71bfa04,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-f6fdf420-a47f-4496-adc2-9596ce47489f,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-331c9fc0-da90-489d-b4f2-dc30f36aead0,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-27fed0cf-492e-47b1-8b1d-19f024fa1ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-1cef3abf-9ced-4ba3-b13a-89fd561895cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-6cd5d0d2-8315-490f-9ef0-51540b0c9f04,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-1997c141-0497-4da2-b826-5c03ace6aefe,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-7c88b045-b6c2-4d17-ac2d-d9f2e3ccf31c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533675245-172.17.0.7-1598109862674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45210,DS-ae029c35-60e5-4cef-9e14-8a3d36e5fcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-d3343cfa-df5e-4121-83f1-7d9f16b6163c,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-95d48479-60ed-4fec-bcf5-9a5afcb02788,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-43810194-3641-4128-bbb3-6a3bdabb1b04,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-7793fb07-f5dd-46e0-a5d0-f73db2c7eb90,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-56952772-b311-4eee-b7b1-f722a1fb68b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-71050eaf-de9c-4146-95e8-62fd8582775f,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-e92da5b5-a1ad-40ae-a53a-7b043103d573,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533675245-172.17.0.7-1598109862674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45210,DS-ae029c35-60e5-4cef-9e14-8a3d36e5fcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-d3343cfa-df5e-4121-83f1-7d9f16b6163c,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-95d48479-60ed-4fec-bcf5-9a5afcb02788,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-43810194-3641-4128-bbb3-6a3bdabb1b04,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-7793fb07-f5dd-46e0-a5d0-f73db2c7eb90,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-56952772-b311-4eee-b7b1-f722a1fb68b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-71050eaf-de9c-4146-95e8-62fd8582775f,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-e92da5b5-a1ad-40ae-a53a-7b043103d573,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031972351-172.17.0.7-1598110507693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40492,DS-52302c5b-7b69-4693-847e-ec233642b91c,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-490a0faa-00ad-4a69-805c-3cb8b45bb124,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-0f2758b2-c425-4f3e-a199-91bf69d79db3,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-6d370ae5-e238-4931-b680-95d05b985a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-ccf08adc-a586-4cc6-bcd1-04b09995ec64,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-4c2e3b01-f3d1-4533-9dc0-a3c8db22658b,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-8d2d342e-4a20-4359-b597-edabd2430449,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-ac87ec78-fb8f-42c4-8d2f-4369679be29f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031972351-172.17.0.7-1598110507693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40492,DS-52302c5b-7b69-4693-847e-ec233642b91c,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-490a0faa-00ad-4a69-805c-3cb8b45bb124,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-0f2758b2-c425-4f3e-a199-91bf69d79db3,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-6d370ae5-e238-4931-b680-95d05b985a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-ccf08adc-a586-4cc6-bcd1-04b09995ec64,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-4c2e3b01-f3d1-4533-9dc0-a3c8db22658b,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-8d2d342e-4a20-4359-b597-edabd2430449,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-ac87ec78-fb8f-42c4-8d2f-4369679be29f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824462918-172.17.0.7-1598111593159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44296,DS-81ac021a-381d-427e-8f6c-279150ae627e,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-0359d0fc-667e-4003-8365-8ac16777dd47,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-85eb7536-95c8-4bf2-b6da-c8193d5ee268,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-72ede561-ae52-4eb1-ab65-c83a5066f58d,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-33f53155-25cf-470e-8481-ec3241d728da,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-d59f0def-979f-4e98-8d42-1a1e851c03da,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-e82e0bd3-c1b9-4ae2-b365-2bcd9f796814,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-5220a230-ee22-4cda-81b4-09d150e9ebe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824462918-172.17.0.7-1598111593159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44296,DS-81ac021a-381d-427e-8f6c-279150ae627e,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-0359d0fc-667e-4003-8365-8ac16777dd47,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-85eb7536-95c8-4bf2-b6da-c8193d5ee268,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-72ede561-ae52-4eb1-ab65-c83a5066f58d,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-33f53155-25cf-470e-8481-ec3241d728da,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-d59f0def-979f-4e98-8d42-1a1e851c03da,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-e82e0bd3-c1b9-4ae2-b365-2bcd9f796814,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-5220a230-ee22-4cda-81b4-09d150e9ebe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451401340-172.17.0.7-1598111774066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35003,DS-352cfd98-8580-44a5-b41d-819b58ed57ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-aed69dce-e1a6-45f0-a7eb-88c2382e8d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-b5c613e6-b0f8-4a2a-917c-712a1f920f43,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-efb01a86-3718-4d74-9c8d-631c145a2673,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-81ed6805-739c-404b-a3cc-0e840586c944,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-3152d258-6bb1-4820-972d-556205f7bb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-dbb12c30-9d36-4745-a523-1c172e3acae2,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-b874bb33-e9ec-46dd-bd20-81aae1a1a2e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451401340-172.17.0.7-1598111774066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35003,DS-352cfd98-8580-44a5-b41d-819b58ed57ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-aed69dce-e1a6-45f0-a7eb-88c2382e8d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-b5c613e6-b0f8-4a2a-917c-712a1f920f43,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-efb01a86-3718-4d74-9c8d-631c145a2673,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-81ed6805-739c-404b-a3cc-0e840586c944,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-3152d258-6bb1-4820-972d-556205f7bb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-dbb12c30-9d36-4745-a523-1c172e3acae2,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-b874bb33-e9ec-46dd-bd20-81aae1a1a2e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380172090-172.17.0.7-1598111903830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45275,DS-b8b89494-a276-433b-999e-e0a1fb624dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-3221b57c-702f-4b69-8f63-2f35c90d1e05,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-f52bf5b6-6f53-420d-9cc9-2a0cb352dc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-cd5fa05b-8c9c-4548-951b-1a33a04c2717,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-b5fa81f1-b3b9-47ca-aa08-62bfbb6a6025,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-be3c90b7-b3f0-40c6-a478-e13c2f741312,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-d0697592-bd77-4bfb-8d63-021c60bbefc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-1a67467e-cf92-4919-b8da-e05d8e68c55b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380172090-172.17.0.7-1598111903830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45275,DS-b8b89494-a276-433b-999e-e0a1fb624dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-3221b57c-702f-4b69-8f63-2f35c90d1e05,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-f52bf5b6-6f53-420d-9cc9-2a0cb352dc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-cd5fa05b-8c9c-4548-951b-1a33a04c2717,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-b5fa81f1-b3b9-47ca-aa08-62bfbb6a6025,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-be3c90b7-b3f0-40c6-a478-e13c2f741312,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-d0697592-bd77-4bfb-8d63-021c60bbefc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-1a67467e-cf92-4919-b8da-e05d8e68c55b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302124693-172.17.0.7-1598112127438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35738,DS-5e0a4e87-6be8-48aa-8603-5a0863dbdf47,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-f4e7acc4-5480-481b-aeed-f04b782cc023,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-5e537fbb-8dd4-49d9-a71d-1b63383ceb06,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-4a8664f8-7332-464d-ac83-b5f56e8d2d79,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-b0237e24-8a6c-40e5-95b3-f8d6a714b651,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-7020b754-8bb6-47e9-81a9-932a7ed4c8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-ad93232a-f97e-42ef-a477-0be38619bfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-4f18da7e-cde3-4020-a0ec-2937db19dd9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302124693-172.17.0.7-1598112127438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35738,DS-5e0a4e87-6be8-48aa-8603-5a0863dbdf47,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-f4e7acc4-5480-481b-aeed-f04b782cc023,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-5e537fbb-8dd4-49d9-a71d-1b63383ceb06,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-4a8664f8-7332-464d-ac83-b5f56e8d2d79,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-b0237e24-8a6c-40e5-95b3-f8d6a714b651,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-7020b754-8bb6-47e9-81a9-932a7ed4c8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-ad93232a-f97e-42ef-a477-0be38619bfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-4f18da7e-cde3-4020-a0ec-2937db19dd9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589315518-172.17.0.7-1598112530546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44011,DS-6f2ee7ed-7fc7-4155-9982-11a94db7882f,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-096abe82-1bdf-46e2-aabe-b66035ae622b,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-6f38c655-89a6-41be-99b5-1de9b9840b33,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-ec3ad6d5-0a2b-46af-9f8b-e2f1629cd8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-d5196af5-abe2-4452-b055-71b42675dd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-e88a0907-fcaf-45ee-a5cd-6f0a3c177130,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-ab0c056e-fc90-4663-b178-0f8fe9c27afe,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-283272d7-c41c-47b8-b174-229c23f1f559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589315518-172.17.0.7-1598112530546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44011,DS-6f2ee7ed-7fc7-4155-9982-11a94db7882f,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-096abe82-1bdf-46e2-aabe-b66035ae622b,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-6f38c655-89a6-41be-99b5-1de9b9840b33,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-ec3ad6d5-0a2b-46af-9f8b-e2f1629cd8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-d5196af5-abe2-4452-b055-71b42675dd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-e88a0907-fcaf-45ee-a5cd-6f0a3c177130,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-ab0c056e-fc90-4663-b178-0f8fe9c27afe,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-283272d7-c41c-47b8-b174-229c23f1f559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056267162-172.17.0.7-1598112651572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33276,DS-f40b3104-8250-4a0b-b9bf-b5e3d1d589cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-aa2a5790-4852-424e-b5de-8d9166491b14,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-506095d3-3c5c-444d-85e2-ed299d8c03b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-15a365ff-4f76-4ab9-a426-b08165362387,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-538f02e9-efb9-44e5-bcf0-50816dd99803,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-05625b8b-bd1d-4399-9a4c-b4b2f72eea77,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-c2204746-459d-4a69-a52c-b99630b9ca86,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-3700f546-99e6-4a25-9378-457735c67d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056267162-172.17.0.7-1598112651572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33276,DS-f40b3104-8250-4a0b-b9bf-b5e3d1d589cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-aa2a5790-4852-424e-b5de-8d9166491b14,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-506095d3-3c5c-444d-85e2-ed299d8c03b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-15a365ff-4f76-4ab9-a426-b08165362387,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-538f02e9-efb9-44e5-bcf0-50816dd99803,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-05625b8b-bd1d-4399-9a4c-b4b2f72eea77,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-c2204746-459d-4a69-a52c-b99630b9ca86,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-3700f546-99e6-4a25-9378-457735c67d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793771580-172.17.0.7-1598112689676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-8fa4dbac-0c6f-4e2a-bafc-e5d21e0457f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-d29154e9-fb8b-4ced-aada-a31c0e16ae1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-1b4b1b64-bcf5-474a-a0b3-ca136838f30f,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-8e9fffea-8cbc-4eb7-97e1-9eb3af23d408,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-12ee0cba-8af7-44c7-a27c-fa1987541840,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-942e2876-7c45-4798-ba85-e5e8f9453210,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-29773f43-d626-4881-9761-b423e5de5831,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-02754aa2-67e2-4d7f-a76b-b5d7880b2083,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793771580-172.17.0.7-1598112689676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-8fa4dbac-0c6f-4e2a-bafc-e5d21e0457f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-d29154e9-fb8b-4ced-aada-a31c0e16ae1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-1b4b1b64-bcf5-474a-a0b3-ca136838f30f,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-8e9fffea-8cbc-4eb7-97e1-9eb3af23d408,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-12ee0cba-8af7-44c7-a27c-fa1987541840,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-942e2876-7c45-4798-ba85-e5e8f9453210,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-29773f43-d626-4881-9761-b423e5de5831,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-02754aa2-67e2-4d7f-a76b-b5d7880b2083,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461788223-172.17.0.7-1598112878480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43058,DS-172f5840-c192-4ba5-bc38-d20637667ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-ef6cfc7f-7318-42c3-9f39-338bc1b2b2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-14a800c7-4bd0-42cd-a3db-570a2735fe68,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-305dda4b-2fd3-40ec-92ef-c09ab1fe060b,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-ae500d01-dc22-4500-a969-5a6b369b2a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-ee2824a8-7365-476f-8d76-499c7c3600f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-9245d942-2424-43f6-96a1-fccc8ee7e8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-8c13b0f1-5bfb-4b66-a791-cf1e968b1b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461788223-172.17.0.7-1598112878480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43058,DS-172f5840-c192-4ba5-bc38-d20637667ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-ef6cfc7f-7318-42c3-9f39-338bc1b2b2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-14a800c7-4bd0-42cd-a3db-570a2735fe68,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-305dda4b-2fd3-40ec-92ef-c09ab1fe060b,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-ae500d01-dc22-4500-a969-5a6b369b2a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-ee2824a8-7365-476f-8d76-499c7c3600f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-9245d942-2424-43f6-96a1-fccc8ee7e8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-8c13b0f1-5bfb-4b66-a791-cf1e968b1b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450433594-172.17.0.7-1598113143524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43857,DS-e4d6120f-9d56-4f04-9309-f9a722ab92e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-addf093f-5205-4107-8ad1-3474c437244e,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-ea363501-39ca-47fd-af79-ff388c4a88f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-b209fb99-77ba-4326-9bf4-8ee28ac3fc38,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-4ee80da6-2010-489b-9b19-18167d7c7322,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-67d6be51-6656-4dd5-aff5-2bf4c904b75f,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-8286a49c-3a5f-4f8f-97af-b08b7297dd23,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-ad64ac06-ef28-46f5-a1cf-fd822f32543b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450433594-172.17.0.7-1598113143524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43857,DS-e4d6120f-9d56-4f04-9309-f9a722ab92e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-addf093f-5205-4107-8ad1-3474c437244e,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-ea363501-39ca-47fd-af79-ff388c4a88f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-b209fb99-77ba-4326-9bf4-8ee28ac3fc38,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-4ee80da6-2010-489b-9b19-18167d7c7322,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-67d6be51-6656-4dd5-aff5-2bf4c904b75f,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-8286a49c-3a5f-4f8f-97af-b08b7297dd23,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-ad64ac06-ef28-46f5-a1cf-fd822f32543b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938622719-172.17.0.7-1598113447243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-eaf3dbf5-f6ac-475a-9cda-33733cffae2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-29bbee2a-958f-49e2-967a-725109824ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-6a6e043d-ef58-47f7-9f8e-af7c4821d5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-6030bd18-fc9a-46fc-ace4-e900ed460f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-988af51a-97e3-4a3f-908c-346c5ec917ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-67e8a307-9f26-4c79-aed2-58a1c5ecb203,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-d278ffdf-e83a-42bd-8f87-fb0a9b679a19,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-a87a2cca-e851-4893-ba1e-670e5f0f5fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938622719-172.17.0.7-1598113447243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-eaf3dbf5-f6ac-475a-9cda-33733cffae2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-29bbee2a-958f-49e2-967a-725109824ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-6a6e043d-ef58-47f7-9f8e-af7c4821d5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-6030bd18-fc9a-46fc-ace4-e900ed460f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-988af51a-97e3-4a3f-908c-346c5ec917ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-67e8a307-9f26-4c79-aed2-58a1c5ecb203,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-d278ffdf-e83a-42bd-8f87-fb0a9b679a19,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-a87a2cca-e851-4893-ba1e-670e5f0f5fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412590311-172.17.0.7-1598114599769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41113,DS-1cbbc318-d429-4ec1-bf24-148e757e8b26,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-a80adff3-f1ec-4ccf-a090-32b5c22b1c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-9ea3030e-4165-4882-a041-a5111b6605c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-25173a20-c9f0-4dd7-bce3-4a3431c79ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-c61e095f-ebc6-4587-9238-defbb2bbceba,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-4afb319d-e99a-4d0c-a05d-f5f5d8e6cbec,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-a2390e33-bf1d-4609-8b36-bab43d3ac6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-c3ddb201-d147-4834-ba67-1fcbb8077deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412590311-172.17.0.7-1598114599769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41113,DS-1cbbc318-d429-4ec1-bf24-148e757e8b26,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-a80adff3-f1ec-4ccf-a090-32b5c22b1c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-9ea3030e-4165-4882-a041-a5111b6605c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-25173a20-c9f0-4dd7-bce3-4a3431c79ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-c61e095f-ebc6-4587-9238-defbb2bbceba,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-4afb319d-e99a-4d0c-a05d-f5f5d8e6cbec,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-a2390e33-bf1d-4609-8b36-bab43d3ac6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-c3ddb201-d147-4834-ba67-1fcbb8077deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6737
