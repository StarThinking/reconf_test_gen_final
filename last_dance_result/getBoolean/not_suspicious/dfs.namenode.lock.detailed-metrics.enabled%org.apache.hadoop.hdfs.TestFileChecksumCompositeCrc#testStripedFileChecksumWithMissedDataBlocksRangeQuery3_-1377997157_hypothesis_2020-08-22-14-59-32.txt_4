reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121730632-172.17.0.19-1598108850582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38740,DS-eddf143d-5908-43ea-bfe4-9e116229583f,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-c4f6c896-af61-466a-a2bd-ab22a48479ad,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-cebe1f45-660a-463a-8e9d-39455f7cc16e,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-796015c7-c3be-421b-ab9f-d378a1863928,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-f6ed7416-ca95-4e25-98c7-a3ad15a79770,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-df732d7d-cac7-4e6b-82cd-2725ef931afd,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-d90169f6-3888-437c-8488-f14744a45b01,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-f8701265-bc06-4191-a488-c6a7ce0cc902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121730632-172.17.0.19-1598108850582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38740,DS-eddf143d-5908-43ea-bfe4-9e116229583f,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-c4f6c896-af61-466a-a2bd-ab22a48479ad,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-cebe1f45-660a-463a-8e9d-39455f7cc16e,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-796015c7-c3be-421b-ab9f-d378a1863928,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-f6ed7416-ca95-4e25-98c7-a3ad15a79770,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-df732d7d-cac7-4e6b-82cd-2725ef931afd,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-d90169f6-3888-437c-8488-f14744a45b01,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-f8701265-bc06-4191-a488-c6a7ce0cc902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746143500-172.17.0.19-1598109440316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-323c133c-e91e-4e10-9647-711b5a4d52c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-2436be3a-c4bd-4462-a21c-dab545e54015,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-9c346daf-2ec4-4deb-94a5-46e1da38020c,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-81dad445-a179-491f-89d2-e295883babd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-12bbaf30-a40d-48cc-abb7-0add3c7eec5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-66051f15-8dc0-4344-98a3-0bd2643eb8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-c799f55f-cbfd-4e88-b414-8c7494c47ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-f82e4a44-c179-40a8-b38f-60c3be21973f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746143500-172.17.0.19-1598109440316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-323c133c-e91e-4e10-9647-711b5a4d52c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-2436be3a-c4bd-4462-a21c-dab545e54015,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-9c346daf-2ec4-4deb-94a5-46e1da38020c,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-81dad445-a179-491f-89d2-e295883babd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-12bbaf30-a40d-48cc-abb7-0add3c7eec5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-66051f15-8dc0-4344-98a3-0bd2643eb8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-c799f55f-cbfd-4e88-b414-8c7494c47ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-f82e4a44-c179-40a8-b38f-60c3be21973f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587149883-172.17.0.19-1598109476671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33886,DS-90e8216c-9743-4be1-8ee3-f57706290eca,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-3dca0fb6-b133-4dfe-aac3-c8de37938675,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-09f03d68-9303-4166-9a1d-f97bf249e647,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-8af7c494-790a-49e2-84b3-b0bc941da204,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-6baf8e81-a1a1-413e-b732-f5028db772cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-8315c783-1566-4a15-8dd5-3fcb15f323c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-789b472d-f838-4f64-ae00-691c213e10d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-83428c04-68cc-4ff6-ad49-75ce92b0ab46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587149883-172.17.0.19-1598109476671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33886,DS-90e8216c-9743-4be1-8ee3-f57706290eca,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-3dca0fb6-b133-4dfe-aac3-c8de37938675,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-09f03d68-9303-4166-9a1d-f97bf249e647,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-8af7c494-790a-49e2-84b3-b0bc941da204,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-6baf8e81-a1a1-413e-b732-f5028db772cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-8315c783-1566-4a15-8dd5-3fcb15f323c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-789b472d-f838-4f64-ae00-691c213e10d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-83428c04-68cc-4ff6-ad49-75ce92b0ab46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486812155-172.17.0.19-1598109693992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46422,DS-b1708e7f-0309-46c4-829d-3872ebc75add,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-770c6685-a35f-4dc3-bd5e-c65106407a92,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-5ef9e139-b6dd-4217-a8cd-67c016c4aa33,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-ed268d10-4b8b-416c-b937-aeb15047d0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-cc38b528-53a9-4c74-8301-d01be66a90d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-b6eb9272-c615-4b5c-b685-f8d3d4000be6,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-522c7c07-7faf-4955-a826-09957c88c128,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-cffa42c1-2e5d-4026-acae-4bd9347c5f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486812155-172.17.0.19-1598109693992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46422,DS-b1708e7f-0309-46c4-829d-3872ebc75add,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-770c6685-a35f-4dc3-bd5e-c65106407a92,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-5ef9e139-b6dd-4217-a8cd-67c016c4aa33,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-ed268d10-4b8b-416c-b937-aeb15047d0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-cc38b528-53a9-4c74-8301-d01be66a90d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-b6eb9272-c615-4b5c-b685-f8d3d4000be6,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-522c7c07-7faf-4955-a826-09957c88c128,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-cffa42c1-2e5d-4026-acae-4bd9347c5f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325191849-172.17.0.19-1598109764770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41100,DS-df5f9e54-d287-4e4c-9b1a-3a87988b8636,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-e020ff1f-b5cc-490b-a5a3-d710a5245af8,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-c472b9fc-2e09-4593-a956-0450f644a50a,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-31dc93df-c106-4e9b-8b89-d1136700c696,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-91a4ec7b-1055-488b-996e-1443df69a871,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-5e0aa486-6568-4ed6-9b91-266cf9caf0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-100e40e8-c372-4802-bb3b-165b437c8eac,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-3f2fee0f-1bdf-4fc6-a4b6-e784fea5efb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325191849-172.17.0.19-1598109764770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41100,DS-df5f9e54-d287-4e4c-9b1a-3a87988b8636,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-e020ff1f-b5cc-490b-a5a3-d710a5245af8,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-c472b9fc-2e09-4593-a956-0450f644a50a,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-31dc93df-c106-4e9b-8b89-d1136700c696,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-91a4ec7b-1055-488b-996e-1443df69a871,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-5e0aa486-6568-4ed6-9b91-266cf9caf0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-100e40e8-c372-4802-bb3b-165b437c8eac,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-3f2fee0f-1bdf-4fc6-a4b6-e784fea5efb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359277708-172.17.0.19-1598109939800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33019,DS-92897dc5-55e7-446d-a7e8-a77e41878226,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-a1e9abc1-5708-4643-8f42-eec6f922a1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-165f3fca-df3a-432b-b558-b194fd4935a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-6e1c4e3c-2440-415a-b284-b8175e263cae,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-69512780-7f6a-447e-8c6e-d8e5ec1daf36,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-6b8f6d1c-bdcc-4a96-b35c-4a8aefb3eba7,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-c8433ba7-4d51-42b8-8eb0-ef54f2e9edea,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-0ce84c97-7508-444f-ba58-1f694c039739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359277708-172.17.0.19-1598109939800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33019,DS-92897dc5-55e7-446d-a7e8-a77e41878226,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-a1e9abc1-5708-4643-8f42-eec6f922a1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-165f3fca-df3a-432b-b558-b194fd4935a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-6e1c4e3c-2440-415a-b284-b8175e263cae,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-69512780-7f6a-447e-8c6e-d8e5ec1daf36,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-6b8f6d1c-bdcc-4a96-b35c-4a8aefb3eba7,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-c8433ba7-4d51-42b8-8eb0-ef54f2e9edea,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-0ce84c97-7508-444f-ba58-1f694c039739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106703474-172.17.0.19-1598110734857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41790,DS-9ea3679c-e580-44ae-8210-b40fdf540240,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-4ddbf1c0-b4d9-40d2-916f-03bc5b4cf408,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-bbfb5f34-4635-4c22-bfd2-64cd91c320d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-20668e68-3720-4e26-a008-979b70a261eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-ba29bafa-0c5f-4349-b9a4-5bc7985dedb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-92cc8a09-b6a7-4c71-b60b-4e2c72bfbb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-7888333e-277a-49d9-9026-71397e23b8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-8dc43ae9-e394-470a-aa4c-b8185d1dd679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106703474-172.17.0.19-1598110734857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41790,DS-9ea3679c-e580-44ae-8210-b40fdf540240,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-4ddbf1c0-b4d9-40d2-916f-03bc5b4cf408,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-bbfb5f34-4635-4c22-bfd2-64cd91c320d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-20668e68-3720-4e26-a008-979b70a261eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-ba29bafa-0c5f-4349-b9a4-5bc7985dedb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-92cc8a09-b6a7-4c71-b60b-4e2c72bfbb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-7888333e-277a-49d9-9026-71397e23b8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-8dc43ae9-e394-470a-aa4c-b8185d1dd679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63883789-172.17.0.19-1598110842523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45846,DS-d941856e-6d77-48c2-9651-3f744f633ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-7736a97d-4fe1-4a43-90b1-9bfec489749a,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-a594fe4c-aa6f-4c41-a871-c1a74f81bb56,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-da292ecf-7993-4d3b-ad62-435f14f841ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-146849ed-4837-43d4-8a44-bb45621156d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-88f70c6a-c350-43dd-ba77-6cb6271012ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-99e2b44d-06ae-4f58-a4ee-865dd802dc90,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-79b89bd5-e7c7-495d-aff4-9bca883c878c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63883789-172.17.0.19-1598110842523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45846,DS-d941856e-6d77-48c2-9651-3f744f633ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-7736a97d-4fe1-4a43-90b1-9bfec489749a,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-a594fe4c-aa6f-4c41-a871-c1a74f81bb56,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-da292ecf-7993-4d3b-ad62-435f14f841ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-146849ed-4837-43d4-8a44-bb45621156d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-88f70c6a-c350-43dd-ba77-6cb6271012ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-99e2b44d-06ae-4f58-a4ee-865dd802dc90,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-79b89bd5-e7c7-495d-aff4-9bca883c878c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216484653-172.17.0.19-1598111134729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36435,DS-cbce6c5c-6e0e-43ea-b40e-da0b7c354987,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-0b69dd08-cb7c-44db-bc2e-44461a7aeded,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-42abfbc1-9678-49a7-8ee3-7ea3a1433489,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-da1adc73-3b2e-464b-b6a8-2c755cbac6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-f8ad819f-163f-42ff-8e4a-f7c5ef329653,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-99f8503f-18f5-4c41-9b16-f4d1aea19b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-09228d28-c1b8-4616-93aa-d1d692884276,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-65023ed5-6271-4f28-acac-ba947e2acfbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216484653-172.17.0.19-1598111134729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36435,DS-cbce6c5c-6e0e-43ea-b40e-da0b7c354987,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-0b69dd08-cb7c-44db-bc2e-44461a7aeded,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-42abfbc1-9678-49a7-8ee3-7ea3a1433489,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-da1adc73-3b2e-464b-b6a8-2c755cbac6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-f8ad819f-163f-42ff-8e4a-f7c5ef329653,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-99f8503f-18f5-4c41-9b16-f4d1aea19b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-09228d28-c1b8-4616-93aa-d1d692884276,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-65023ed5-6271-4f28-acac-ba947e2acfbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191512946-172.17.0.19-1598111683370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32775,DS-763c698b-6d68-46e8-b901-69cf0a59b133,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-7cff6cb5-02d9-415f-b859-1cd17d14adf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-35c56dae-8298-46f4-a035-0092d270d612,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-31831c09-3208-4bea-9eaf-8743ba37ec37,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-16177706-df0c-48a7-934e-140fe394776d,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-90c67568-7d83-4589-9be1-604905a8e95e,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-8c004c48-96cc-43d4-9dd5-ad8f79eb4746,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-84d030a0-8a2b-46cc-8470-b09d54d24362,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191512946-172.17.0.19-1598111683370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32775,DS-763c698b-6d68-46e8-b901-69cf0a59b133,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-7cff6cb5-02d9-415f-b859-1cd17d14adf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-35c56dae-8298-46f4-a035-0092d270d612,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-31831c09-3208-4bea-9eaf-8743ba37ec37,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-16177706-df0c-48a7-934e-140fe394776d,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-90c67568-7d83-4589-9be1-604905a8e95e,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-8c004c48-96cc-43d4-9dd5-ad8f79eb4746,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-84d030a0-8a2b-46cc-8470-b09d54d24362,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699194607-172.17.0.19-1598111886528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42668,DS-92b4221e-390f-478d-a5b2-a8176bbd75b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-63e861b5-8949-43a2-a020-1a2b191e1c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-bfc0e9d8-892c-425e-b3b8-40f6bf8a160b,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-24f8ed75-a09f-475e-87a4-71308b8f56f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-f33e4dfd-5408-4bf1-80fc-8f500b1bdfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-d39792b6-b666-431c-b951-f89c4572c595,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-dbbd87eb-3451-43ba-8bab-28b95f5ba13b,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-fe5f719c-8da3-4e09-b0f5-01b86856cfa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699194607-172.17.0.19-1598111886528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42668,DS-92b4221e-390f-478d-a5b2-a8176bbd75b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-63e861b5-8949-43a2-a020-1a2b191e1c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-bfc0e9d8-892c-425e-b3b8-40f6bf8a160b,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-24f8ed75-a09f-475e-87a4-71308b8f56f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-f33e4dfd-5408-4bf1-80fc-8f500b1bdfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-d39792b6-b666-431c-b951-f89c4572c595,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-dbbd87eb-3451-43ba-8bab-28b95f5ba13b,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-fe5f719c-8da3-4e09-b0f5-01b86856cfa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990124918-172.17.0.19-1598112141549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36267,DS-f21a6372-2df9-461d-8bc4-cbeed7ba6b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-2db2412f-ffca-40da-871f-12a974f718a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-8774fb18-777e-4df9-bb11-08014cc3ae84,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-d3c3b866-9323-4a43-af3a-4c8e19329e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-90e20021-6dff-438b-9245-5191c7f2ab47,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-f7971695-2a1c-46bf-8766-668c8f7876cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-6a84a593-ba18-4545-87d5-4cddaf25bd10,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-cb8d61c2-7c05-41cc-8453-45b9a3b7a99b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990124918-172.17.0.19-1598112141549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36267,DS-f21a6372-2df9-461d-8bc4-cbeed7ba6b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-2db2412f-ffca-40da-871f-12a974f718a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-8774fb18-777e-4df9-bb11-08014cc3ae84,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-d3c3b866-9323-4a43-af3a-4c8e19329e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-90e20021-6dff-438b-9245-5191c7f2ab47,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-f7971695-2a1c-46bf-8766-668c8f7876cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-6a84a593-ba18-4545-87d5-4cddaf25bd10,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-cb8d61c2-7c05-41cc-8453-45b9a3b7a99b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016792685-172.17.0.19-1598112408151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36074,DS-4a1ccbed-87f1-40a8-8158-3e740ff5fbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-de5098a1-3241-4a8c-97ae-74fde1076ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-d75c36bf-708b-4316-b637-62da3223de5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-4ef592a9-89b7-41b5-8b5d-b776378ff442,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-06ea5ac7-5abf-439a-a285-cd8d1d2541f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-bd61cf02-b074-4cb1-a901-1cafaef7c157,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-ff1bf63e-cb20-4a13-907b-1cae1bee18f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-9357b3a3-3f28-4a5b-937d-2949197d5ae1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016792685-172.17.0.19-1598112408151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36074,DS-4a1ccbed-87f1-40a8-8158-3e740ff5fbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-de5098a1-3241-4a8c-97ae-74fde1076ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-d75c36bf-708b-4316-b637-62da3223de5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-4ef592a9-89b7-41b5-8b5d-b776378ff442,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-06ea5ac7-5abf-439a-a285-cd8d1d2541f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-bd61cf02-b074-4cb1-a901-1cafaef7c157,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-ff1bf63e-cb20-4a13-907b-1cae1bee18f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-9357b3a3-3f28-4a5b-937d-2949197d5ae1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728839493-172.17.0.19-1598112554736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35827,DS-9326dd25-f2e0-484f-978f-bde53b6c45dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-e7068575-2bf7-492e-b773-84ec9d946d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-89942910-f09f-4af5-8697-fee2f5a59570,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-01af0d8e-7c10-4c17-a9ac-9f47a2691a16,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-6fc98218-75be-4bdb-b464-f97bfa3d14d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-949be571-84ec-4b38-915c-57d2d329224e,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-264868cf-1066-4e8b-9fa5-a9f70ff100a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-b1460618-b34f-403c-81a7-1fc5fdbbea79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728839493-172.17.0.19-1598112554736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35827,DS-9326dd25-f2e0-484f-978f-bde53b6c45dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-e7068575-2bf7-492e-b773-84ec9d946d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-89942910-f09f-4af5-8697-fee2f5a59570,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-01af0d8e-7c10-4c17-a9ac-9f47a2691a16,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-6fc98218-75be-4bdb-b464-f97bfa3d14d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-949be571-84ec-4b38-915c-57d2d329224e,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-264868cf-1066-4e8b-9fa5-a9f70ff100a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-b1460618-b34f-403c-81a7-1fc5fdbbea79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851382832-172.17.0.19-1598112627944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40309,DS-760ac692-0f8e-452e-b48c-75035cf4e647,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-3ecb3e72-8306-4105-a317-0888d02eebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-2b3e2057-5590-4eb2-9bc9-b7e39484a36d,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-af9ed37a-6e3c-4c29-943f-956f5d2a2adc,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-5fafe73c-f717-4e31-bc1e-184e2ac43555,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-3d759219-7813-43e0-ac0c-7f25885c7214,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-476a3b03-df71-4891-97ca-0772abde833a,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-e3b10626-c955-4085-bc93-7515b9fa719b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851382832-172.17.0.19-1598112627944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40309,DS-760ac692-0f8e-452e-b48c-75035cf4e647,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-3ecb3e72-8306-4105-a317-0888d02eebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-2b3e2057-5590-4eb2-9bc9-b7e39484a36d,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-af9ed37a-6e3c-4c29-943f-956f5d2a2adc,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-5fafe73c-f717-4e31-bc1e-184e2ac43555,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-3d759219-7813-43e0-ac0c-7f25885c7214,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-476a3b03-df71-4891-97ca-0772abde833a,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-e3b10626-c955-4085-bc93-7515b9fa719b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2094666233-172.17.0.19-1598112975434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34234,DS-0299877c-86db-4633-9ae9-f87bad2baaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-24132735-f28b-4c89-83d1-d25b5179b7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-162e2b84-cb64-44a9-9841-b7e6539abbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-59f54b35-0ce5-4ceb-a681-5d58a84343d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-d9583d0f-d645-46ea-b3e4-cee437df5865,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-4fa8fda3-1dcb-4c5c-a9ca-009fcb8c65a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-36abde5d-842a-4a55-a730-99e5aa83e261,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-ac73f9d1-9247-4e04-8342-18d5bbdda27c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2094666233-172.17.0.19-1598112975434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34234,DS-0299877c-86db-4633-9ae9-f87bad2baaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-24132735-f28b-4c89-83d1-d25b5179b7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-162e2b84-cb64-44a9-9841-b7e6539abbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-59f54b35-0ce5-4ceb-a681-5d58a84343d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-d9583d0f-d645-46ea-b3e4-cee437df5865,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-4fa8fda3-1dcb-4c5c-a9ca-009fcb8c65a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-36abde5d-842a-4a55-a730-99e5aa83e261,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-ac73f9d1-9247-4e04-8342-18d5bbdda27c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955878190-172.17.0.19-1598113158709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37659,DS-6f3dcdb5-6ae2-4093-9106-f7bb7a41d99a,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-1e44f3de-af8c-4710-a2de-d518161ede51,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-5b40cc8c-c314-4d45-8fe8-f57519e12571,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-8718346d-dfd7-4810-ae3a-9995ce6c2fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-52471d98-ac29-419d-ad3f-f4fcdc9f037f,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-714eee9c-f254-4b08-92b2-4f873ad1121f,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-d69f025a-db0b-40b8-8a42-e9728d92b4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-fb4fc07d-75c6-4bc4-8b3a-0c115df940f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955878190-172.17.0.19-1598113158709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37659,DS-6f3dcdb5-6ae2-4093-9106-f7bb7a41d99a,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-1e44f3de-af8c-4710-a2de-d518161ede51,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-5b40cc8c-c314-4d45-8fe8-f57519e12571,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-8718346d-dfd7-4810-ae3a-9995ce6c2fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-52471d98-ac29-419d-ad3f-f4fcdc9f037f,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-714eee9c-f254-4b08-92b2-4f873ad1121f,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-d69f025a-db0b-40b8-8a42-e9728d92b4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-fb4fc07d-75c6-4bc4-8b3a-0c115df940f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257864655-172.17.0.19-1598113305763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41948,DS-632f3451-5acf-4e46-ae18-df6dbd4e94fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-f62baafb-fee6-4f54-85e0-a97026d1d46e,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-d3d3ebd8-bd58-423a-8996-008f2e1d04c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-4628792c-ca0c-492a-b580-cfe0a8c95b64,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-7a5c84d7-618b-44a7-a2db-f2dc75f99656,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-79be623f-e00f-4c33-a2ce-b32d14d7b0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-c4ad9d01-80c4-4dbd-9e29-f030e9734b10,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-8b339930-280c-4846-b18a-c0089e8f4b92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257864655-172.17.0.19-1598113305763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41948,DS-632f3451-5acf-4e46-ae18-df6dbd4e94fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-f62baafb-fee6-4f54-85e0-a97026d1d46e,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-d3d3ebd8-bd58-423a-8996-008f2e1d04c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-4628792c-ca0c-492a-b580-cfe0a8c95b64,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-7a5c84d7-618b-44a7-a2db-f2dc75f99656,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-79be623f-e00f-4c33-a2ce-b32d14d7b0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-c4ad9d01-80c4-4dbd-9e29-f030e9734b10,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-8b339930-280c-4846-b18a-c0089e8f4b92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799346915-172.17.0.19-1598113585094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41224,DS-5c121e0b-7791-4423-8a79-6586c2c38340,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-51e01d95-56e6-47ce-84b0-0675d2e645ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-6a0aefa2-ccd2-4630-a669-44ae0f1cfa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-36a26cce-3b95-42bd-beec-b1420cb78e29,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-77e2d8fc-876f-4e46-a1f2-c061f260ba1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-d707cada-b160-4b59-83f6-7adc0c4ccaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-3069c635-384e-4632-8d14-e7c81ac3f342,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-b8f220b7-8b98-433f-9fba-9d9193a56d89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799346915-172.17.0.19-1598113585094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41224,DS-5c121e0b-7791-4423-8a79-6586c2c38340,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-51e01d95-56e6-47ce-84b0-0675d2e645ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-6a0aefa2-ccd2-4630-a669-44ae0f1cfa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-36a26cce-3b95-42bd-beec-b1420cb78e29,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-77e2d8fc-876f-4e46-a1f2-c061f260ba1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-d707cada-b160-4b59-83f6-7adc0c4ccaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-3069c635-384e-4632-8d14-e7c81ac3f342,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-b8f220b7-8b98-433f-9fba-9d9193a56d89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484664993-172.17.0.19-1598113816812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41381,DS-4674c8dc-2d78-4299-8938-0fb14075ebc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-ba96d402-35a4-425a-9577-341e779e910d,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-1fc7a72e-65a8-4492-bcab-5c87b4c71480,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-ac7dc36a-8cec-44c1-a52c-aecfb5a50a57,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-c5961450-4cf6-42e2-960f-bb938ea5a0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-e9bb4c8a-9e86-486d-ad40-2859ea23fbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-91f65028-6a60-4b7b-a251-3b0503bb8d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-6ce28eef-dd31-4d9f-a75f-b77c2419fc56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484664993-172.17.0.19-1598113816812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41381,DS-4674c8dc-2d78-4299-8938-0fb14075ebc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-ba96d402-35a4-425a-9577-341e779e910d,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-1fc7a72e-65a8-4492-bcab-5c87b4c71480,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-ac7dc36a-8cec-44c1-a52c-aecfb5a50a57,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-c5961450-4cf6-42e2-960f-bb938ea5a0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-e9bb4c8a-9e86-486d-ad40-2859ea23fbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-91f65028-6a60-4b7b-a251-3b0503bb8d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-6ce28eef-dd31-4d9f-a75f-b77c2419fc56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1139677445-172.17.0.19-1598113859487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46843,DS-9a949c8a-7613-44d0-bc7d-ea40188c9185,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-6b19e521-f3ca-430d-92c2-ca3f4e2830ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-8ad7b25e-a0e6-4d8a-a3ac-d319968f9702,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-2b9f4453-11c3-4a37-bd61-ee4a8f68aba7,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-7c558146-6918-4be5-a992-5fbe5798630d,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-d93b721a-da6d-43b3-bdf1-658fd0a65529,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-3d88024c-2fc0-41ad-a29c-f29d328cf0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-9f8c1278-b117-411c-9d8a-22a00eb13011,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1139677445-172.17.0.19-1598113859487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46843,DS-9a949c8a-7613-44d0-bc7d-ea40188c9185,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-6b19e521-f3ca-430d-92c2-ca3f4e2830ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-8ad7b25e-a0e6-4d8a-a3ac-d319968f9702,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-2b9f4453-11c3-4a37-bd61-ee4a8f68aba7,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-7c558146-6918-4be5-a992-5fbe5798630d,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-d93b721a-da6d-43b3-bdf1-658fd0a65529,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-3d88024c-2fc0-41ad-a29c-f29d328cf0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-9f8c1278-b117-411c-9d8a-22a00eb13011,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5558
