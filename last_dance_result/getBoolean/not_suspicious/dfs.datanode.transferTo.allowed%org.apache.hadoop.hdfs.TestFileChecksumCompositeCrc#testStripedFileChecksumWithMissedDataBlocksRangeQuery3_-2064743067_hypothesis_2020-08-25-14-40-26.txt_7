reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962845132-172.17.0.7-1598366965610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42844,DS-37dab1bc-fdf4-44e0-94b9-72e4b6b87767,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-03461fa5-e1fe-4927-9bd5-fbdaedc92a57,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-26b4b5ab-b0f8-4443-88b9-a70f3518a447,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-716ec9ec-4d6d-4974-a827-38f80b802b40,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-f8640769-ac1a-45cd-b368-b494b4e677c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-02d21285-fb38-4cf7-a40b-310de9ef1ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-d758cfd2-738d-4bc0-b96a-eece23d7d16d,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-1d69a83f-1070-41a8-bd9b-f6580039e346,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962845132-172.17.0.7-1598366965610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42844,DS-37dab1bc-fdf4-44e0-94b9-72e4b6b87767,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-03461fa5-e1fe-4927-9bd5-fbdaedc92a57,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-26b4b5ab-b0f8-4443-88b9-a70f3518a447,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-716ec9ec-4d6d-4974-a827-38f80b802b40,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-f8640769-ac1a-45cd-b368-b494b4e677c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-02d21285-fb38-4cf7-a40b-310de9ef1ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-d758cfd2-738d-4bc0-b96a-eece23d7d16d,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-1d69a83f-1070-41a8-bd9b-f6580039e346,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589120950-172.17.0.7-1598367621290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35100,DS-3326f56f-3541-4441-9317-0b8a9daea29e,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-922fc307-ce4d-4f55-bc71-bd7433020519,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-ed1fd297-4752-416e-8ce6-f5202a76888b,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-f6d5258e-e0b9-42b9-b8a8-33cd05e7522f,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-d9a29d41-9416-4c24-994f-5eaa0b4bda3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-aae66d9d-b6c9-4535-9235-6eefd6a7b896,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-fba93405-8b0b-430d-b664-bb28e8e2776f,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-bbe787fd-82c3-4449-9eae-148926b8ce5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589120950-172.17.0.7-1598367621290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35100,DS-3326f56f-3541-4441-9317-0b8a9daea29e,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-922fc307-ce4d-4f55-bc71-bd7433020519,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-ed1fd297-4752-416e-8ce6-f5202a76888b,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-f6d5258e-e0b9-42b9-b8a8-33cd05e7522f,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-d9a29d41-9416-4c24-994f-5eaa0b4bda3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-aae66d9d-b6c9-4535-9235-6eefd6a7b896,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-fba93405-8b0b-430d-b664-bb28e8e2776f,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-bbe787fd-82c3-4449-9eae-148926b8ce5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1795303252-172.17.0.7-1598368229575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43676,DS-b0ab1db1-731d-4ad3-bd71-8a0b9bad8027,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-9891df62-2490-4fc7-869d-099beb8ac560,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-ff1e8a42-5703-4f5b-92d8-46ecaa7ab208,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-d720fc0b-baa8-4ca4-a7f3-0aa7380343e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-ee79aacb-2302-4f79-95be-db2569ddc630,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-81c5b40e-0e12-45d8-8c63-2bfcdc225387,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-c5b7e14a-cabf-4267-8026-b217b951e0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-1ac99669-aabb-4eb0-87c8-8bb07ddea140,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1795303252-172.17.0.7-1598368229575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43676,DS-b0ab1db1-731d-4ad3-bd71-8a0b9bad8027,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-9891df62-2490-4fc7-869d-099beb8ac560,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-ff1e8a42-5703-4f5b-92d8-46ecaa7ab208,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-d720fc0b-baa8-4ca4-a7f3-0aa7380343e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-ee79aacb-2302-4f79-95be-db2569ddc630,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-81c5b40e-0e12-45d8-8c63-2bfcdc225387,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-c5b7e14a-cabf-4267-8026-b217b951e0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-1ac99669-aabb-4eb0-87c8-8bb07ddea140,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898200142-172.17.0.7-1598368470067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42073,DS-b7fc6872-1807-40e7-a1db-b9327b2f174c,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-f970012d-3c8d-432c-96e2-af22edf4ca61,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-d8b544e1-6977-4a36-959d-824f50279160,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-1c499c99-20a4-476f-91ac-a0960f5e81c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-1273fc76-5b8f-4eda-9a94-bf341aa6d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-02c66518-5aaa-498c-b71a-1b75a735ebfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-0eaab43a-fa98-4237-b3ae-ea1d2a5eda21,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-7212ff04-ca97-4fb7-abcc-79ca662aeacd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898200142-172.17.0.7-1598368470067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42073,DS-b7fc6872-1807-40e7-a1db-b9327b2f174c,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-f970012d-3c8d-432c-96e2-af22edf4ca61,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-d8b544e1-6977-4a36-959d-824f50279160,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-1c499c99-20a4-476f-91ac-a0960f5e81c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-1273fc76-5b8f-4eda-9a94-bf341aa6d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-02c66518-5aaa-498c-b71a-1b75a735ebfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-0eaab43a-fa98-4237-b3ae-ea1d2a5eda21,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-7212ff04-ca97-4fb7-abcc-79ca662aeacd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638524483-172.17.0.7-1598369016610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42461,DS-08e290a1-11b5-45ca-bfe7-23d1e2d9cdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-4cbf1f00-5bd0-4def-946c-297d894eb240,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-f6d8ecc1-b4d4-4afd-a57e-89e13f40e26f,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-4923d434-31f2-4e8e-8d46-2604b525e87a,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-6148f725-24e0-48c0-9b9a-98d9513757c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-a04a6c04-6341-4082-bec2-23b54ead4814,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-fc63971c-76d1-47ec-99ef-e9ee78a53472,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-92e0ed40-ee84-4c1c-be85-f7e9a1e88f25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638524483-172.17.0.7-1598369016610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42461,DS-08e290a1-11b5-45ca-bfe7-23d1e2d9cdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-4cbf1f00-5bd0-4def-946c-297d894eb240,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-f6d8ecc1-b4d4-4afd-a57e-89e13f40e26f,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-4923d434-31f2-4e8e-8d46-2604b525e87a,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-6148f725-24e0-48c0-9b9a-98d9513757c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-a04a6c04-6341-4082-bec2-23b54ead4814,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-fc63971c-76d1-47ec-99ef-e9ee78a53472,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-92e0ed40-ee84-4c1c-be85-f7e9a1e88f25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272830654-172.17.0.7-1598369125017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39947,DS-dc892a65-bdd4-437f-a717-a680825e978d,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-18b683df-1ae8-4356-84b6-7057fef8a74c,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-94049d78-9a5d-42f0-bec5-d325e977041b,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-a234893e-45f0-42c4-a900-7c1a9f8dda6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-cf7633b0-0749-41bf-8a8e-c3ef3c89aacd,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-74cfaa2b-f128-4097-91ad-c5d9148d37b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-7788c7d1-44e0-4730-a59c-ce76e6cd52e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-8726e094-a7a0-4359-8a8e-a521fa0055c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272830654-172.17.0.7-1598369125017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39947,DS-dc892a65-bdd4-437f-a717-a680825e978d,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-18b683df-1ae8-4356-84b6-7057fef8a74c,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-94049d78-9a5d-42f0-bec5-d325e977041b,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-a234893e-45f0-42c4-a900-7c1a9f8dda6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-cf7633b0-0749-41bf-8a8e-c3ef3c89aacd,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-74cfaa2b-f128-4097-91ad-c5d9148d37b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-7788c7d1-44e0-4730-a59c-ce76e6cd52e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-8726e094-a7a0-4359-8a8e-a521fa0055c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225755149-172.17.0.7-1598369520744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41990,DS-425d2b9e-0e99-49e2-b588-a9eb1b8bf80f,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-b3713d8a-b3de-4db4-a3dd-a345bca56556,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-00176af8-1aaf-446f-bc26-16a3a789bb34,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-4cb92935-024a-4a45-91b4-c9f21e7a372a,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-280950e1-e0aa-4fde-a61e-a44f23799b57,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-a572f1f7-a35f-4c33-b57e-c4b8f63cd012,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-cf4a5b53-5211-4fca-9cc3-da0fa615aa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-48c97911-ec8c-46ec-a9a0-ad83442d056a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225755149-172.17.0.7-1598369520744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41990,DS-425d2b9e-0e99-49e2-b588-a9eb1b8bf80f,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-b3713d8a-b3de-4db4-a3dd-a345bca56556,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-00176af8-1aaf-446f-bc26-16a3a789bb34,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-4cb92935-024a-4a45-91b4-c9f21e7a372a,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-280950e1-e0aa-4fde-a61e-a44f23799b57,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-a572f1f7-a35f-4c33-b57e-c4b8f63cd012,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-cf4a5b53-5211-4fca-9cc3-da0fa615aa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-48c97911-ec8c-46ec-a9a0-ad83442d056a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816778518-172.17.0.7-1598369964369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41725,DS-52b14d65-a48b-470e-9d97-4ea60eb727df,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-4161076d-6ade-4537-bd3c-79c7ec7c9070,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-e388117e-da7c-474d-aedb-86a7abd04340,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-7e4ce770-64d6-4d6e-b09f-988a5d0ac32d,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-45b18fa3-c286-4d29-8582-d706cd2fd1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-c7388706-a317-4034-a729-d65c148b5713,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-e76f9ac0-4a0b-41c8-b203-6f7c74f68619,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-32be7989-6b9b-484c-bd46-d3e6d6b599d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816778518-172.17.0.7-1598369964369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41725,DS-52b14d65-a48b-470e-9d97-4ea60eb727df,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-4161076d-6ade-4537-bd3c-79c7ec7c9070,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-e388117e-da7c-474d-aedb-86a7abd04340,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-7e4ce770-64d6-4d6e-b09f-988a5d0ac32d,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-45b18fa3-c286-4d29-8582-d706cd2fd1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-c7388706-a317-4034-a729-d65c148b5713,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-e76f9ac0-4a0b-41c8-b203-6f7c74f68619,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-32be7989-6b9b-484c-bd46-d3e6d6b599d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005588227-172.17.0.7-1598370548219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41193,DS-5a6a1cfa-56f3-4b62-a6b9-8dcffdee7806,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-0f4c7733-3824-485b-8376-a48d64661363,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-fdc0250a-0cb3-4ea6-a7cd-360e032ed5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-5b234456-6bbd-4409-8cfd-3acd3d5169f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-ac1f1784-ddc9-4176-aa26-3f1400eb0278,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-78b97978-6b09-4d02-aee5-47c4d70ab885,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-4191681d-c8ef-46d3-804f-5a1ada13e4de,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-cc65c7a2-0858-45d2-aa90-01d413febbba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005588227-172.17.0.7-1598370548219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41193,DS-5a6a1cfa-56f3-4b62-a6b9-8dcffdee7806,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-0f4c7733-3824-485b-8376-a48d64661363,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-fdc0250a-0cb3-4ea6-a7cd-360e032ed5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-5b234456-6bbd-4409-8cfd-3acd3d5169f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-ac1f1784-ddc9-4176-aa26-3f1400eb0278,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-78b97978-6b09-4d02-aee5-47c4d70ab885,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-4191681d-c8ef-46d3-804f-5a1ada13e4de,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-cc65c7a2-0858-45d2-aa90-01d413febbba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057828943-172.17.0.7-1598370804999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43202,DS-060e0063-1f6a-4739-8c9c-28c0f20a5fee,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-58496c70-b73e-433a-9f2e-a37883fd6ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-60e334db-4f00-4d34-9cad-f8b4f0def2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-b6077f5f-7582-4a6d-9494-475f0a223052,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-3c3e3d23-d7b2-47ed-88bf-22a22834ef41,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-7f01d6eb-6aaf-45be-ba43-16256c04f82c,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-7a1a2abd-e73b-4c9d-ad20-c7899b3666cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-ec8106fe-1cb4-4cf5-a0af-ccdb394a09cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057828943-172.17.0.7-1598370804999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43202,DS-060e0063-1f6a-4739-8c9c-28c0f20a5fee,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-58496c70-b73e-433a-9f2e-a37883fd6ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-60e334db-4f00-4d34-9cad-f8b4f0def2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-b6077f5f-7582-4a6d-9494-475f0a223052,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-3c3e3d23-d7b2-47ed-88bf-22a22834ef41,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-7f01d6eb-6aaf-45be-ba43-16256c04f82c,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-7a1a2abd-e73b-4c9d-ad20-c7899b3666cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-ec8106fe-1cb4-4cf5-a0af-ccdb394a09cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 0 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: v1v2 failure didn't occur
Total execution time in seconds : 5281
