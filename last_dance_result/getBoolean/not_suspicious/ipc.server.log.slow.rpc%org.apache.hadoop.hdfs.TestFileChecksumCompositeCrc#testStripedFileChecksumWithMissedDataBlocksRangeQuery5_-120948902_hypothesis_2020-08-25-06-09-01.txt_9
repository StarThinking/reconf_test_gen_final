reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126755534-172.17.0.5-1598336699517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35990,DS-7db7fe61-8429-46c8-b548-3696aed4f68d,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-64e971b3-9d55-4fdf-87d8-fbeae2aa7fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-ebac8ce0-74a1-4d8c-8e53-a0bf2681d0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-88d59c65-d3bd-409d-bccd-9bdd91d897b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-f22d38b9-6ce9-45fd-addc-2dffee9a5e58,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-41635f4e-dceb-4dab-b26a-1517e9c35f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-ccbfbbc1-b361-4596-b0f2-f52c7478c112,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-0da2c472-c452-4f64-9612-2a595fd10518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126755534-172.17.0.5-1598336699517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35990,DS-7db7fe61-8429-46c8-b548-3696aed4f68d,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-64e971b3-9d55-4fdf-87d8-fbeae2aa7fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-ebac8ce0-74a1-4d8c-8e53-a0bf2681d0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-88d59c65-d3bd-409d-bccd-9bdd91d897b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-f22d38b9-6ce9-45fd-addc-2dffee9a5e58,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-41635f4e-dceb-4dab-b26a-1517e9c35f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-ccbfbbc1-b361-4596-b0f2-f52c7478c112,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-0da2c472-c452-4f64-9612-2a595fd10518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444913102-172.17.0.5-1598336732249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34069,DS-4dedfa3f-4263-4eb6-8b69-510ef6f0d6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-8c87ba0a-f5f3-4fd2-8897-594fa11eae63,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-cccad000-ca67-4423-b87d-a60a71def78c,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-1eaa7ab5-ced5-4c14-88c1-7859336f4609,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-ec71ab04-bd16-44b3-9367-1f1885d944d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-8f72ae2e-9ddf-453f-a176-f5d2af1a5486,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-7f02e292-456b-4fbf-8ea5-a1351ba96e25,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-a5f39a63-58e0-4fcc-ac98-9af5a759148f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444913102-172.17.0.5-1598336732249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34069,DS-4dedfa3f-4263-4eb6-8b69-510ef6f0d6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-8c87ba0a-f5f3-4fd2-8897-594fa11eae63,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-cccad000-ca67-4423-b87d-a60a71def78c,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-1eaa7ab5-ced5-4c14-88c1-7859336f4609,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-ec71ab04-bd16-44b3-9367-1f1885d944d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-8f72ae2e-9ddf-453f-a176-f5d2af1a5486,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-7f02e292-456b-4fbf-8ea5-a1351ba96e25,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-a5f39a63-58e0-4fcc-ac98-9af5a759148f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654344329-172.17.0.5-1598337287069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41429,DS-38534c0b-786d-46f5-88a8-5538798ad39c,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-37feb1cf-196d-47b4-9ab3-d6b266432015,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-5abcc523-0056-4ac5-ada5-42e534e1ed16,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-e0795853-40ca-4486-9aae-9ab3d0e5ae4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-944c1132-7567-41a6-ab2d-4245a4f815c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-089074ec-979b-43ea-8440-bf88a7795e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-10e143d4-6839-45e7-ad72-0a558ce57037,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-94eb83d2-3277-4ede-8ea8-6227141df096,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654344329-172.17.0.5-1598337287069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41429,DS-38534c0b-786d-46f5-88a8-5538798ad39c,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-37feb1cf-196d-47b4-9ab3-d6b266432015,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-5abcc523-0056-4ac5-ada5-42e534e1ed16,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-e0795853-40ca-4486-9aae-9ab3d0e5ae4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-944c1132-7567-41a6-ab2d-4245a4f815c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-089074ec-979b-43ea-8440-bf88a7795e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-10e143d4-6839-45e7-ad72-0a558ce57037,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-94eb83d2-3277-4ede-8ea8-6227141df096,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1878806386-172.17.0.5-1598337521647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46184,DS-d920211b-58c6-4996-aaee-7fc72ca338ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-c004e4b2-b1e4-46a8-8d3b-a17fd07ccdae,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-470aae48-8b9d-4929-8341-ee71fd3e6eff,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-edbaa430-d3aa-4261-8e77-2a6a70af3c96,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-ec613fa2-fa99-45f5-9bf8-438f81fa19b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-682e14b5-b128-4508-b4f5-771ad3b9b6db,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-6c88493e-9ffd-4fdc-8f4f-8255a58cd509,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-38ea7821-6f18-4282-ba3e-cc303ee5f574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1878806386-172.17.0.5-1598337521647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46184,DS-d920211b-58c6-4996-aaee-7fc72ca338ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-c004e4b2-b1e4-46a8-8d3b-a17fd07ccdae,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-470aae48-8b9d-4929-8341-ee71fd3e6eff,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-edbaa430-d3aa-4261-8e77-2a6a70af3c96,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-ec613fa2-fa99-45f5-9bf8-438f81fa19b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-682e14b5-b128-4508-b4f5-771ad3b9b6db,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-6c88493e-9ffd-4fdc-8f4f-8255a58cd509,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-38ea7821-6f18-4282-ba3e-cc303ee5f574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515628837-172.17.0.5-1598338083084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39059,DS-d57e6fc6-b98c-494e-a10b-8cc11e538db6,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-376a1112-4ac6-44a6-a2d1-8718a4e60bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-942a2b12-97cd-4d0c-9e38-3e787158ffdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-01fceda7-6a12-4241-a902-3b099eae83bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-7bb9aab9-a399-4537-bdae-b5f4fee09966,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-5fd7746b-dbf1-4315-aa29-5b60b56501f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-24e7c543-e8c3-4534-b60a-b36b9fd7fa27,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-a7efc0dc-e0a0-4f0b-b372-67dc5f2e4448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515628837-172.17.0.5-1598338083084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39059,DS-d57e6fc6-b98c-494e-a10b-8cc11e538db6,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-376a1112-4ac6-44a6-a2d1-8718a4e60bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-942a2b12-97cd-4d0c-9e38-3e787158ffdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-01fceda7-6a12-4241-a902-3b099eae83bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-7bb9aab9-a399-4537-bdae-b5f4fee09966,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-5fd7746b-dbf1-4315-aa29-5b60b56501f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-24e7c543-e8c3-4534-b60a-b36b9fd7fa27,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-a7efc0dc-e0a0-4f0b-b372-67dc5f2e4448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256483834-172.17.0.5-1598338467816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43330,DS-4bb11bf5-f79d-40cd-b357-391973f79985,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-6c4a8181-6663-4b9d-b8f6-ee0e582ce3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-ed6f68e8-9c2f-4222-8783-509791fb980a,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-f91b308b-8a33-4eb8-a35c-4b5514801293,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-33d84d04-df1f-4db2-b9d0-0dea74aebdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-911b3683-90f5-4bd9-9536-a2728edebc15,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-2768f50d-928d-45bb-8fca-23995ec1e536,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-66e271db-f5ff-49b6-858f-b111aa8e852d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256483834-172.17.0.5-1598338467816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43330,DS-4bb11bf5-f79d-40cd-b357-391973f79985,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-6c4a8181-6663-4b9d-b8f6-ee0e582ce3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-ed6f68e8-9c2f-4222-8783-509791fb980a,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-f91b308b-8a33-4eb8-a35c-4b5514801293,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-33d84d04-df1f-4db2-b9d0-0dea74aebdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-911b3683-90f5-4bd9-9536-a2728edebc15,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-2768f50d-928d-45bb-8fca-23995ec1e536,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-66e271db-f5ff-49b6-858f-b111aa8e852d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278932012-172.17.0.5-1598338724293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39723,DS-b208975b-0a19-472f-9ebf-d158a89b642f,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-3a7d6af2-9d0f-4fe4-aa78-44cc0f531210,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-e622ac89-7575-438c-8572-cc257846ef7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-cb370ac0-5763-48be-b6c1-ddeff8cd09c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-c441975c-c942-4aa2-86f5-5e96f07debe2,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-79343b7b-f548-4904-a5a5-d07de5e8600e,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-37ded63f-0263-4a57-959a-22057804aebd,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-e04951f7-699b-415e-bfbb-019a56d4a3e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278932012-172.17.0.5-1598338724293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39723,DS-b208975b-0a19-472f-9ebf-d158a89b642f,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-3a7d6af2-9d0f-4fe4-aa78-44cc0f531210,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-e622ac89-7575-438c-8572-cc257846ef7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-cb370ac0-5763-48be-b6c1-ddeff8cd09c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-c441975c-c942-4aa2-86f5-5e96f07debe2,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-79343b7b-f548-4904-a5a5-d07de5e8600e,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-37ded63f-0263-4a57-959a-22057804aebd,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-e04951f7-699b-415e-bfbb-019a56d4a3e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941415238-172.17.0.5-1598338883408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42311,DS-1983137b-a3a1-4f6a-b509-3a2f8d7d4ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-68aee1af-d2d3-4eb7-9522-5c3d7def4f56,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-c69d3fae-8d84-4b3c-9439-ee18f790108a,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-8e1f149b-c8c5-4cf4-a720-6ba7258e0b17,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-773d523b-8e0a-47db-931c-a00ccb5386dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-d4fb05a3-33af-4f95-976d-4889599b0344,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-d1131615-2367-4074-83d9-6d13c154e744,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-1fde8b85-d799-4ce8-b6d4-bc7d57f86659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941415238-172.17.0.5-1598338883408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42311,DS-1983137b-a3a1-4f6a-b509-3a2f8d7d4ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-68aee1af-d2d3-4eb7-9522-5c3d7def4f56,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-c69d3fae-8d84-4b3c-9439-ee18f790108a,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-8e1f149b-c8c5-4cf4-a720-6ba7258e0b17,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-773d523b-8e0a-47db-931c-a00ccb5386dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-d4fb05a3-33af-4f95-976d-4889599b0344,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-d1131615-2367-4074-83d9-6d13c154e744,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-1fde8b85-d799-4ce8-b6d4-bc7d57f86659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355316367-172.17.0.5-1598339294645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40173,DS-265a5b5f-548f-4c21-9068-a698598d3c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-9577bb9f-e0f1-401d-b4e4-02fd0871a2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-629c0621-24a9-4832-ac96-b8c9e079b6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-7ace6796-f918-4101-adab-ec1f1296a309,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-5faaf5d1-0f1b-4cca-9e32-d845e6397a12,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-7dd316e0-d01b-4cf7-a165-b312db710427,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-4333b9c2-e45c-4773-82eb-082f34972356,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-b1511e9d-a418-4512-9972-6e29d4e25b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355316367-172.17.0.5-1598339294645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40173,DS-265a5b5f-548f-4c21-9068-a698598d3c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-9577bb9f-e0f1-401d-b4e4-02fd0871a2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-629c0621-24a9-4832-ac96-b8c9e079b6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-7ace6796-f918-4101-adab-ec1f1296a309,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-5faaf5d1-0f1b-4cca-9e32-d845e6397a12,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-7dd316e0-d01b-4cf7-a165-b312db710427,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-4333b9c2-e45c-4773-82eb-082f34972356,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-b1511e9d-a418-4512-9972-6e29d4e25b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401825618-172.17.0.5-1598339487122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38049,DS-1e58132d-6369-4391-b47d-9001d8672ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-aa045205-a7b9-4feb-82a8-a4c4e73bed8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-8c767c62-5a0c-433b-9f28-4651dcac2ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-517a906f-e7c4-40f4-967d-337e46509aae,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-55043e01-6c89-4f0b-9a77-7b07341bfccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-7ed9ef85-b721-4b61-ad41-915c95d38884,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-66bc0021-dc10-47be-9958-a0ecb6ce355f,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-40be1364-d384-4d2e-a3c0-4c83611987fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401825618-172.17.0.5-1598339487122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38049,DS-1e58132d-6369-4391-b47d-9001d8672ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-aa045205-a7b9-4feb-82a8-a4c4e73bed8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-8c767c62-5a0c-433b-9f28-4651dcac2ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-517a906f-e7c4-40f4-967d-337e46509aae,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-55043e01-6c89-4f0b-9a77-7b07341bfccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-7ed9ef85-b721-4b61-ad41-915c95d38884,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-66bc0021-dc10-47be-9958-a0ecb6ce355f,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-40be1364-d384-4d2e-a3c0-4c83611987fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254093394-172.17.0.5-1598339634366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35970,DS-595edecc-5640-4080-9627-7b8aabd94517,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-aeabf8f8-40d8-419b-bd73-0fb16e0ded05,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-8f17068a-7b37-4011-94d8-3e54c783b974,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-91d3783c-ed0b-475c-b17e-b7a4576d71c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-2a9f02d6-dcc9-44dd-9fc1-3d26e7c1691b,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-9b10a043-2136-40cf-8ec7-d95d61dd3973,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-2cffa9ed-8cab-4c93-b9f1-c8d7b9e121ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-d750f3df-c089-43a7-887a-3f2a09f860c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254093394-172.17.0.5-1598339634366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35970,DS-595edecc-5640-4080-9627-7b8aabd94517,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-aeabf8f8-40d8-419b-bd73-0fb16e0ded05,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-8f17068a-7b37-4011-94d8-3e54c783b974,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-91d3783c-ed0b-475c-b17e-b7a4576d71c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-2a9f02d6-dcc9-44dd-9fc1-3d26e7c1691b,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-9b10a043-2136-40cf-8ec7-d95d61dd3973,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-2cffa9ed-8cab-4c93-b9f1-c8d7b9e121ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-d750f3df-c089-43a7-887a-3f2a09f860c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-405769675-172.17.0.5-1598339777359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38890,DS-227f616f-8637-4ab1-ab2a-cdbe7d4f360d,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-90620cbf-136e-4eff-a34b-c1143a37a314,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-d78a40c2-6e8e-4b11-9a00-6d1a15841716,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-f57d4b73-4575-4787-b687-32ae512bb7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-4ddc3a18-e0e5-45ec-8cff-61d699f6646c,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-b4692c43-b8ae-4c98-8c10-ca2929aa4d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-f908ea3c-7297-4599-a214-6e5c43b2b550,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-4cec50ec-2c7c-4304-af38-a748ce04c89f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-405769675-172.17.0.5-1598339777359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38890,DS-227f616f-8637-4ab1-ab2a-cdbe7d4f360d,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-90620cbf-136e-4eff-a34b-c1143a37a314,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-d78a40c2-6e8e-4b11-9a00-6d1a15841716,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-f57d4b73-4575-4787-b687-32ae512bb7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-4ddc3a18-e0e5-45ec-8cff-61d699f6646c,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-b4692c43-b8ae-4c98-8c10-ca2929aa4d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-f908ea3c-7297-4599-a214-6e5c43b2b550,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-4cec50ec-2c7c-4304-af38-a748ce04c89f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294810060-172.17.0.5-1598339894650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45314,DS-37a10c67-7016-41dc-9cd9-f97f47381cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-8577108c-dc93-4a62-be90-d766deb03e51,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-5c72acf7-9495-4557-9771-d212f6139ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-b6f31a91-ce81-4ce6-8e3c-2bedc34125b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-8ba256ef-aea1-4232-ba82-8e88e07b7db0,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-8825dbf5-d900-47ce-b8f9-a6b1d90eb812,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-fcd107dc-c513-4dc7-8054-6974b739f277,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-3c0993f3-2029-4f68-a8fc-6629e4fd8f8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294810060-172.17.0.5-1598339894650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45314,DS-37a10c67-7016-41dc-9cd9-f97f47381cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-8577108c-dc93-4a62-be90-d766deb03e51,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-5c72acf7-9495-4557-9771-d212f6139ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-b6f31a91-ce81-4ce6-8e3c-2bedc34125b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-8ba256ef-aea1-4232-ba82-8e88e07b7db0,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-8825dbf5-d900-47ce-b8f9-a6b1d90eb812,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-fcd107dc-c513-4dc7-8054-6974b739f277,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-3c0993f3-2029-4f68-a8fc-6629e4fd8f8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886928822-172.17.0.5-1598340497904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34566,DS-e870d0f1-1e42-4c38-bf4f-8f54a91f210d,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-c51b5a15-157b-4559-9637-147eea73fb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-5f04bb4c-3cb0-415c-ad7d-d21070a7c0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-7b887b6c-b517-45d6-97e3-2119957a3558,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-b5e7c54e-56bf-45f0-b035-505a688facd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-bd12734a-c3c2-461e-b79a-4d10d1431595,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-419f9855-5568-474f-84c2-5953848c33fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-2eb58dcb-c646-48d5-aa6e-dcdf79f68eca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886928822-172.17.0.5-1598340497904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34566,DS-e870d0f1-1e42-4c38-bf4f-8f54a91f210d,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-c51b5a15-157b-4559-9637-147eea73fb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-5f04bb4c-3cb0-415c-ad7d-d21070a7c0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-7b887b6c-b517-45d6-97e3-2119957a3558,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-b5e7c54e-56bf-45f0-b035-505a688facd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-bd12734a-c3c2-461e-b79a-4d10d1431595,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-419f9855-5568-474f-84c2-5953848c33fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-2eb58dcb-c646-48d5-aa6e-dcdf79f68eca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777575004-172.17.0.5-1598340529247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38726,DS-7ad1cc77-a515-4cd7-a699-bf21443e4a63,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-5d558143-7267-4327-889e-93afd6536300,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-73d0c82f-b0e0-4910-ae84-2019bb647d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-b3241a07-17ff-4c18-9a66-d8cf0900a75e,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-174040c1-b38c-469e-bcf0-73c071ff57eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-f41ed9be-b4a9-43c5-a994-e7d98f2c094f,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-be3c3489-8ed2-43a3-9b58-f14a98784d69,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-289398aa-1d6a-436b-8aab-9d061f07f5af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777575004-172.17.0.5-1598340529247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38726,DS-7ad1cc77-a515-4cd7-a699-bf21443e4a63,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-5d558143-7267-4327-889e-93afd6536300,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-73d0c82f-b0e0-4910-ae84-2019bb647d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-b3241a07-17ff-4c18-9a66-d8cf0900a75e,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-174040c1-b38c-469e-bcf0-73c071ff57eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-f41ed9be-b4a9-43c5-a994-e7d98f2c094f,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-be3c3489-8ed2-43a3-9b58-f14a98784d69,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-289398aa-1d6a-436b-8aab-9d061f07f5af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5487
