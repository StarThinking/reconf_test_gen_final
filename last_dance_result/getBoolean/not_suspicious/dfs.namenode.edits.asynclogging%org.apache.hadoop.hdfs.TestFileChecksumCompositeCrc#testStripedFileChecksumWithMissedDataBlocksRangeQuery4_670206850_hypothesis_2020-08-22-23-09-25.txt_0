reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032445473-172.17.0.7-1598137845452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42062,DS-ff7525b0-0f49-46fc-bf4b-380315d4f988,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-2572ab93-95ca-4b08-be3b-61ae11f43f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-dfd0cc7d-02b1-4ecc-8f37-e272e9946370,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-e94d1713-2219-4f6f-ac44-81509864b14b,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-fba6c507-fd23-430d-9914-38a0880548f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-b43c372c-8571-4abf-8fcb-89712f05dd66,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-4bd15a3a-8d21-4464-a27f-395a775226b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-e5816b75-0ad0-4e92-9c45-67a0fd6f1df8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032445473-172.17.0.7-1598137845452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42062,DS-ff7525b0-0f49-46fc-bf4b-380315d4f988,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-2572ab93-95ca-4b08-be3b-61ae11f43f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-dfd0cc7d-02b1-4ecc-8f37-e272e9946370,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-e94d1713-2219-4f6f-ac44-81509864b14b,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-fba6c507-fd23-430d-9914-38a0880548f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-b43c372c-8571-4abf-8fcb-89712f05dd66,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-4bd15a3a-8d21-4464-a27f-395a775226b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-e5816b75-0ad0-4e92-9c45-67a0fd6f1df8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904288505-172.17.0.7-1598138138493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36134,DS-3cccbafc-dafa-484b-afce-91cc295b1297,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-7007cb50-e439-4656-8b34-e1b8169dba4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-9a624034-55e2-47b1-a445-7c041e93681f,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-11a54680-48e5-4dbf-bdc7-d05c7b5e1f17,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-88346917-72e7-435a-aaaf-e27ad9671911,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-d2e5db8d-0628-4fac-86fe-7fab7568966a,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-56f9fd92-9ed2-4d50-b18e-c2eca23fb292,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-a45e4d50-75a2-4537-bab7-a58fc5e7ace5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904288505-172.17.0.7-1598138138493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36134,DS-3cccbafc-dafa-484b-afce-91cc295b1297,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-7007cb50-e439-4656-8b34-e1b8169dba4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-9a624034-55e2-47b1-a445-7c041e93681f,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-11a54680-48e5-4dbf-bdc7-d05c7b5e1f17,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-88346917-72e7-435a-aaaf-e27ad9671911,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-d2e5db8d-0628-4fac-86fe-7fab7568966a,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-56f9fd92-9ed2-4d50-b18e-c2eca23fb292,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-a45e4d50-75a2-4537-bab7-a58fc5e7ace5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81138721-172.17.0.7-1598138407503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34109,DS-e5a347ed-8d7a-49cd-8273-7e1e032cea4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-7bddbdec-bb29-4c70-a37f-902701ee33f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-61ba4ae0-debe-4f47-9089-4261c375cc57,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-ea079bbc-248f-4913-94f7-ad57cf3a369b,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-462250c1-1063-4135-9eec-6d000055ba8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-b3cd3b99-380d-42be-abf4-d696366f656c,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-a27d04bb-5ef5-4be3-ac5b-d03a57c2c353,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-3902b628-02d7-43ca-9d2f-b7b91f103938,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81138721-172.17.0.7-1598138407503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34109,DS-e5a347ed-8d7a-49cd-8273-7e1e032cea4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-7bddbdec-bb29-4c70-a37f-902701ee33f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-61ba4ae0-debe-4f47-9089-4261c375cc57,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-ea079bbc-248f-4913-94f7-ad57cf3a369b,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-462250c1-1063-4135-9eec-6d000055ba8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-b3cd3b99-380d-42be-abf4-d696366f656c,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-a27d04bb-5ef5-4be3-ac5b-d03a57c2c353,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-3902b628-02d7-43ca-9d2f-b7b91f103938,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724808940-172.17.0.7-1598138606015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34161,DS-dd3bab72-2b39-4b4e-a28d-cc042554aed4,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-5e43296a-c4e4-408d-855e-7c5bb251545c,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-6bc07049-6b6a-47ef-a9af-d891dee83366,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-5a30d0d0-8db6-41a4-8318-a48fff3aecf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-f3a094de-1830-4eac-a119-a8ef78544623,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-79e31df3-9876-4870-865d-3f391b155f22,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-9fd76462-b431-47fd-a445-9f921c30e224,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-e7a97a02-47c6-4164-88f1-9a9f5a3b7a0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724808940-172.17.0.7-1598138606015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34161,DS-dd3bab72-2b39-4b4e-a28d-cc042554aed4,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-5e43296a-c4e4-408d-855e-7c5bb251545c,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-6bc07049-6b6a-47ef-a9af-d891dee83366,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-5a30d0d0-8db6-41a4-8318-a48fff3aecf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-f3a094de-1830-4eac-a119-a8ef78544623,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-79e31df3-9876-4870-865d-3f391b155f22,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-9fd76462-b431-47fd-a445-9f921c30e224,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-e7a97a02-47c6-4164-88f1-9a9f5a3b7a0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317272514-172.17.0.7-1598138677819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41501,DS-1da9f06d-d27a-4f03-a9e9-e333380f88be,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-5fd437ab-133f-40ff-975f-3c0ce3b0213a,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-74c55f55-8c9b-43c9-a089-c7513da5851d,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-64880149-2a5d-458c-9616-b8c9a2c50f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-2a1d6647-c0dd-4cf9-8749-ce28a0da1e25,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-0d461787-4836-4ab3-9b62-63a08284b3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-edc6cb79-eff7-4113-af77-8ecc770c03f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-31f2c4e6-1c7e-4525-8b7c-3d482ab4abeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317272514-172.17.0.7-1598138677819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41501,DS-1da9f06d-d27a-4f03-a9e9-e333380f88be,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-5fd437ab-133f-40ff-975f-3c0ce3b0213a,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-74c55f55-8c9b-43c9-a089-c7513da5851d,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-64880149-2a5d-458c-9616-b8c9a2c50f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-2a1d6647-c0dd-4cf9-8749-ce28a0da1e25,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-0d461787-4836-4ab3-9b62-63a08284b3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-edc6cb79-eff7-4113-af77-8ecc770c03f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-31f2c4e6-1c7e-4525-8b7c-3d482ab4abeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656431082-172.17.0.7-1598138950858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40913,DS-7b0f34fe-deae-4054-863f-875ea4a7a10f,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-28819f95-8105-471d-a515-0ce250dce3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-c014d074-b007-44eb-acc3-7d3d525e5fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-a9bd00e8-e9a0-43f6-af0b-54f1818e1f81,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-02e31778-32c9-48da-945a-61bcdf5b5248,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-3ea03d83-b3a8-4b9c-809c-6b7167d8ab98,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-eba569e7-6eec-482c-b28f-0d3e48b6a8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-5616e341-454f-49fa-8f56-45a2a6b701b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656431082-172.17.0.7-1598138950858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40913,DS-7b0f34fe-deae-4054-863f-875ea4a7a10f,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-28819f95-8105-471d-a515-0ce250dce3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-c014d074-b007-44eb-acc3-7d3d525e5fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-a9bd00e8-e9a0-43f6-af0b-54f1818e1f81,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-02e31778-32c9-48da-945a-61bcdf5b5248,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-3ea03d83-b3a8-4b9c-809c-6b7167d8ab98,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-eba569e7-6eec-482c-b28f-0d3e48b6a8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-5616e341-454f-49fa-8f56-45a2a6b701b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069369136-172.17.0.7-1598138981951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36137,DS-a46dc085-9f6b-4d87-b00c-bb22f6ac4e83,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-07ce9486-cb7e-42cf-91fd-7596f38a90c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-375f2a62-d6a1-4ac1-a89d-b40343b200c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-f27fbdd5-2cf0-462d-bb76-c3f60993b2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-e581174d-27e1-40cc-b4ba-25a9731b0ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-19b3c5f2-4337-4df4-b7fe-afbc6010a7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-7ba0b603-d7c0-4b39-a268-2732aac32679,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-c1fd7fb8-d4d7-4aa6-bba8-8f628f01aabb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069369136-172.17.0.7-1598138981951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36137,DS-a46dc085-9f6b-4d87-b00c-bb22f6ac4e83,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-07ce9486-cb7e-42cf-91fd-7596f38a90c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-375f2a62-d6a1-4ac1-a89d-b40343b200c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-f27fbdd5-2cf0-462d-bb76-c3f60993b2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-e581174d-27e1-40cc-b4ba-25a9731b0ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-19b3c5f2-4337-4df4-b7fe-afbc6010a7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-7ba0b603-d7c0-4b39-a268-2732aac32679,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-c1fd7fb8-d4d7-4aa6-bba8-8f628f01aabb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509742352-172.17.0.7-1598139083102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43916,DS-fe74414d-e6cb-4dad-b7fc-3f53740c9f42,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-e856b4cb-2cad-4183-8d5c-1209fa6e4324,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-130d25e4-b321-40d8-820d-8ef59ae19271,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-ed64c828-da4b-4a7f-a356-8207b3dec6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-7fc37074-27a2-4338-a497-0530a87c985f,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-1afa8fad-a69a-4a04-90e6-23eb6062f45b,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-98702e56-d2c1-49a0-8f99-9bdfce8fc378,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-406f1452-75af-4925-8b10-b53d22d0454b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509742352-172.17.0.7-1598139083102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43916,DS-fe74414d-e6cb-4dad-b7fc-3f53740c9f42,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-e856b4cb-2cad-4183-8d5c-1209fa6e4324,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-130d25e4-b321-40d8-820d-8ef59ae19271,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-ed64c828-da4b-4a7f-a356-8207b3dec6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-7fc37074-27a2-4338-a497-0530a87c985f,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-1afa8fad-a69a-4a04-90e6-23eb6062f45b,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-98702e56-d2c1-49a0-8f99-9bdfce8fc378,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-406f1452-75af-4925-8b10-b53d22d0454b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456674866-172.17.0.7-1598139159044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35821,DS-95a4bb74-bb23-4d77-bfe8-8cc773103cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-6070ff8e-0211-441d-b723-8c6e54047ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-da63e37c-0a99-46b4-94d0-78adeeb6ab5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-bde64ad4-0d48-43e6-8027-f813610defa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-a97e424d-00c5-4cb0-a735-4697f6fb542a,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-022d6f87-99b8-4e4d-a49d-0f45217d76ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-a4337225-b98e-437e-878e-be5ca6dfa159,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-e2e45bec-bcbc-4f8f-82e7-78b828bd6ce9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456674866-172.17.0.7-1598139159044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35821,DS-95a4bb74-bb23-4d77-bfe8-8cc773103cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-6070ff8e-0211-441d-b723-8c6e54047ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-da63e37c-0a99-46b4-94d0-78adeeb6ab5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-bde64ad4-0d48-43e6-8027-f813610defa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-a97e424d-00c5-4cb0-a735-4697f6fb542a,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-022d6f87-99b8-4e4d-a49d-0f45217d76ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-a4337225-b98e-437e-878e-be5ca6dfa159,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-e2e45bec-bcbc-4f8f-82e7-78b828bd6ce9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832806238-172.17.0.7-1598139786246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37708,DS-b35f9f1b-1e86-46fb-bd4c-598d73fcf07e,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-3756dddf-3a9b-43f0-8b91-5790c8c31ace,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-fde47d10-d3a7-47dd-9f0b-89891d5ba3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-8eccb2c1-3e1a-41c3-8b29-a3f40213ad99,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-3bedb142-cae6-4293-9ba3-7cb20ab8fe71,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-480bdaac-2188-4027-82a8-8ad4cb91917a,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-ddf02b59-5d46-4152-be9d-6bdcb36a1934,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-8d59add5-5ccd-4867-9d51-52efc5c3a199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832806238-172.17.0.7-1598139786246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37708,DS-b35f9f1b-1e86-46fb-bd4c-598d73fcf07e,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-3756dddf-3a9b-43f0-8b91-5790c8c31ace,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-fde47d10-d3a7-47dd-9f0b-89891d5ba3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-8eccb2c1-3e1a-41c3-8b29-a3f40213ad99,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-3bedb142-cae6-4293-9ba3-7cb20ab8fe71,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-480bdaac-2188-4027-82a8-8ad4cb91917a,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-ddf02b59-5d46-4152-be9d-6bdcb36a1934,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-8d59add5-5ccd-4867-9d51-52efc5c3a199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045101679-172.17.0.7-1598139891112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35465,DS-f6befdaf-f8f2-42c1-934e-b0f0d5e72faa,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-b93661f6-a1ce-47c5-9252-247ce6457af9,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-a5e48062-c8ef-4f14-bcb9-b90df40e0afa,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-dae50d5b-12cb-4978-a6c1-c2801f5c390f,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-a497edf9-d34e-4c37-8878-84dce13efa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-f19d5615-6aff-4e1e-9f41-a44f7eeb5b88,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-c3870082-0228-4bb5-b9bb-5e957a1ae41f,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-5cdf1381-0e24-49b3-a39e-55cf1a65f1de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045101679-172.17.0.7-1598139891112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35465,DS-f6befdaf-f8f2-42c1-934e-b0f0d5e72faa,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-b93661f6-a1ce-47c5-9252-247ce6457af9,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-a5e48062-c8ef-4f14-bcb9-b90df40e0afa,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-dae50d5b-12cb-4978-a6c1-c2801f5c390f,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-a497edf9-d34e-4c37-8878-84dce13efa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-f19d5615-6aff-4e1e-9f41-a44f7eeb5b88,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-c3870082-0228-4bb5-b9bb-5e957a1ae41f,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-5cdf1381-0e24-49b3-a39e-55cf1a65f1de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540005182-172.17.0.7-1598140077496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40419,DS-063cc427-0383-469e-b130-d73ba79ab0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-965e9f3c-4bfa-40e0-bfed-3b46f8f4becd,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-05836afe-c158-416a-b916-ab7a76d3dc18,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-b90844ce-f511-4ff7-9a3f-77ac2f255f03,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-38f2682b-c63b-4a89-b280-c0c033c23170,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-a79e6298-3228-4e7f-97c7-5b349559fbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-772d2ef6-4cd8-4271-925e-4931dac52410,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-20fc2c6e-cf5b-4af3-900c-8454e98b72ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540005182-172.17.0.7-1598140077496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40419,DS-063cc427-0383-469e-b130-d73ba79ab0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-965e9f3c-4bfa-40e0-bfed-3b46f8f4becd,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-05836afe-c158-416a-b916-ab7a76d3dc18,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-b90844ce-f511-4ff7-9a3f-77ac2f255f03,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-38f2682b-c63b-4a89-b280-c0c033c23170,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-a79e6298-3228-4e7f-97c7-5b349559fbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-772d2ef6-4cd8-4271-925e-4931dac52410,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-20fc2c6e-cf5b-4af3-900c-8454e98b72ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214847582-172.17.0.7-1598140294643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44623,DS-dec5ac42-07a5-41c7-b417-172da8b7f2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-ce4fcf66-e465-4409-9fb9-5be14a5442ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-86f9850a-90e3-4c59-840c-a1f5c0a7eb09,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-40b6d1d2-bfcd-4eb7-a7c1-44f442221ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-71b9118f-4f25-46cf-9f6f-b07e77e856f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-0b2d6063-1b55-4fcb-be58-d19374b0f82b,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-ad14ad0b-20d5-4706-b17c-ff5a09d96966,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-336d0b84-6c46-4488-ae11-053dffe13a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214847582-172.17.0.7-1598140294643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44623,DS-dec5ac42-07a5-41c7-b417-172da8b7f2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-ce4fcf66-e465-4409-9fb9-5be14a5442ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-86f9850a-90e3-4c59-840c-a1f5c0a7eb09,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-40b6d1d2-bfcd-4eb7-a7c1-44f442221ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-71b9118f-4f25-46cf-9f6f-b07e77e856f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-0b2d6063-1b55-4fcb-be58-d19374b0f82b,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-ad14ad0b-20d5-4706-b17c-ff5a09d96966,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-336d0b84-6c46-4488-ae11-053dffe13a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537152651-172.17.0.7-1598140582376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43973,DS-6ed853e3-1a26-40f3-b0e0-725bd286af4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-73156152-f242-49c3-a994-76ffb1c62de0,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-0c2918bd-df1a-4c45-be1d-5d19ffa4d086,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-61048386-e074-4266-ab6f-ec10f6fd5358,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-8a6052e3-a519-4b82-85e9-1bd5869e6188,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-695ca14a-c7c1-4a45-bb4f-c4b423865aba,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-eaad7621-3b66-4ea2-a1a6-24a211a74410,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-de24b360-b5f7-401d-8ad4-b1295783e2ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537152651-172.17.0.7-1598140582376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43973,DS-6ed853e3-1a26-40f3-b0e0-725bd286af4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-73156152-f242-49c3-a994-76ffb1c62de0,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-0c2918bd-df1a-4c45-be1d-5d19ffa4d086,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-61048386-e074-4266-ab6f-ec10f6fd5358,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-8a6052e3-a519-4b82-85e9-1bd5869e6188,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-695ca14a-c7c1-4a45-bb4f-c4b423865aba,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-eaad7621-3b66-4ea2-a1a6-24a211a74410,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-de24b360-b5f7-401d-8ad4-b1295783e2ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221181340-172.17.0.7-1598141382692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35760,DS-f28104c5-0029-490d-96fa-3a081042f383,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-ce34914d-a732-40f9-9408-cdb81d54e7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-1fd45ca4-6a9a-436f-a0ad-3c9800022716,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-91edfe16-e11d-4794-b737-b20abb2ef8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-8be37adf-3f3a-45e9-8cd8-40928bb64086,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-d3218f52-2d4b-4e86-bc03-c7bd3aebb5de,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-50c75fa8-3529-4bde-bd13-8f808b05d94a,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-b7a7cc15-d4ca-4a35-b9e3-151296794065,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221181340-172.17.0.7-1598141382692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35760,DS-f28104c5-0029-490d-96fa-3a081042f383,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-ce34914d-a732-40f9-9408-cdb81d54e7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-1fd45ca4-6a9a-436f-a0ad-3c9800022716,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-91edfe16-e11d-4794-b737-b20abb2ef8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-8be37adf-3f3a-45e9-8cd8-40928bb64086,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-d3218f52-2d4b-4e86-bc03-c7bd3aebb5de,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-50c75fa8-3529-4bde-bd13-8f808b05d94a,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-b7a7cc15-d4ca-4a35-b9e3-151296794065,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191360797-172.17.0.7-1598141813446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37923,DS-5449af35-f44a-4a31-8328-d89061cbbf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-177ca028-56d0-4105-8509-7e944f7887a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-05f61899-0e2b-44cc-b7d2-1f01fe8540b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-99e41b66-ac7a-41c1-a83e-3f8fbd44459f,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-88148bf5-dd6a-4cf4-9d24-0730f92b9aed,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-05ed6579-b412-452a-ba03-4182a8aac4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-915e2f4b-1dac-4a76-857f-397941bcfadc,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-47ce3dc4-1b81-4f48-9f04-0bc47f4e6ea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191360797-172.17.0.7-1598141813446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37923,DS-5449af35-f44a-4a31-8328-d89061cbbf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-177ca028-56d0-4105-8509-7e944f7887a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-05f61899-0e2b-44cc-b7d2-1f01fe8540b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-99e41b66-ac7a-41c1-a83e-3f8fbd44459f,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-88148bf5-dd6a-4cf4-9d24-0730f92b9aed,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-05ed6579-b412-452a-ba03-4182a8aac4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-915e2f4b-1dac-4a76-857f-397941bcfadc,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-47ce3dc4-1b81-4f48-9f04-0bc47f4e6ea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360936127-172.17.0.7-1598141969357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33625,DS-13721cec-cf92-474f-b8d9-76621d55fd10,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-e2c60c17-e2c3-4136-a791-36af9427528c,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-0e71d543-ab67-4e11-a030-146556e22153,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-90209ff6-7926-412a-b4b3-b748d5aed541,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-817122b3-2170-4e18-8b30-b3bdac6db29d,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-2c3b8d39-98f7-4ac0-9ec7-0e21634caa14,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-69b95c15-07b5-4da3-9493-c3090a592cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-af1810d1-b8a6-4a13-88e3-2427a36431eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360936127-172.17.0.7-1598141969357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33625,DS-13721cec-cf92-474f-b8d9-76621d55fd10,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-e2c60c17-e2c3-4136-a791-36af9427528c,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-0e71d543-ab67-4e11-a030-146556e22153,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-90209ff6-7926-412a-b4b3-b748d5aed541,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-817122b3-2170-4e18-8b30-b3bdac6db29d,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-2c3b8d39-98f7-4ac0-9ec7-0e21634caa14,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-69b95c15-07b5-4da3-9493-c3090a592cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-af1810d1-b8a6-4a13-88e3-2427a36431eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906001894-172.17.0.7-1598142226953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-1c94a0c7-1642-42a3-ad88-00228926b83d,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-d613c364-6f67-4c73-a84f-e6f2e0be360e,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-4fbb9ab4-b227-4d7f-9ba3-552d7f1059b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-f357adc2-ea2f-4347-a86f-a708511726f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-10a8bfbf-1106-4f7e-814d-550fdd024bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-6dd6cb54-556d-48e8-a0bc-1fe4c5811f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-eef25860-6ba0-4aeb-b3d5-6a8c7084c0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-71d03b95-346c-408c-8736-e94613d7e468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906001894-172.17.0.7-1598142226953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-1c94a0c7-1642-42a3-ad88-00228926b83d,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-d613c364-6f67-4c73-a84f-e6f2e0be360e,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-4fbb9ab4-b227-4d7f-9ba3-552d7f1059b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-f357adc2-ea2f-4347-a86f-a708511726f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-10a8bfbf-1106-4f7e-814d-550fdd024bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-6dd6cb54-556d-48e8-a0bc-1fe4c5811f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-eef25860-6ba0-4aeb-b3d5-6a8c7084c0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-71d03b95-346c-408c-8736-e94613d7e468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083624402-172.17.0.7-1598142468557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32912,DS-2be7b2d6-8a61-48ee-aed2-a4ab249c77e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-d1f449aa-fa8b-4885-9985-365bebae40ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-3067f7ac-bb96-4bf0-a42b-3125e24baba1,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-dbd53700-4dd4-4d66-a82b-f506319085b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-3e0406a3-6f2c-411a-9cd2-bf2f8fb01450,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-ad7d7be6-587f-4a10-944b-d83195ce18cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-07a86cb8-218d-450b-80d1-920582eb2ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-bb646c2a-fd3f-4b3d-8aa8-9c97164be2d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083624402-172.17.0.7-1598142468557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32912,DS-2be7b2d6-8a61-48ee-aed2-a4ab249c77e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-d1f449aa-fa8b-4885-9985-365bebae40ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-3067f7ac-bb96-4bf0-a42b-3125e24baba1,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-dbd53700-4dd4-4d66-a82b-f506319085b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-3e0406a3-6f2c-411a-9cd2-bf2f8fb01450,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-ad7d7be6-587f-4a10-944b-d83195ce18cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-07a86cb8-218d-450b-80d1-920582eb2ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-bb646c2a-fd3f-4b3d-8aa8-9c97164be2d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5320
