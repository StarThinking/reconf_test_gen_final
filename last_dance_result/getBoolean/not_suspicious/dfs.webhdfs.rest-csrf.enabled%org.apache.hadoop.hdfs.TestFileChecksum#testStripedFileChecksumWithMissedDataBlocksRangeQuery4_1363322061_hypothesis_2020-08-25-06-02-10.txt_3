reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606549054-172.17.0.5-1598335677410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37957,DS-744ea7f6-e970-4248-8fa7-429b7c4946d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-5891dd24-bb87-44dd-b23a-3d1d73f2c367,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-c3da4e0c-5914-4330-a802-a95d596eea2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-b62abb2d-b54b-4ff6-976c-6c2c17ae1bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-6d7746c1-5f5f-44eb-9d13-4064aa132754,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-ec082c30-f018-4434-99a4-d9ace234df8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-c2c2192d-270f-4269-8d7f-04e7d3d57938,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-291194fa-0777-4553-bfb0-31e544b5d2f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606549054-172.17.0.5-1598335677410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37957,DS-744ea7f6-e970-4248-8fa7-429b7c4946d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-5891dd24-bb87-44dd-b23a-3d1d73f2c367,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-c3da4e0c-5914-4330-a802-a95d596eea2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-b62abb2d-b54b-4ff6-976c-6c2c17ae1bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-6d7746c1-5f5f-44eb-9d13-4064aa132754,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-ec082c30-f018-4434-99a4-d9ace234df8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-c2c2192d-270f-4269-8d7f-04e7d3d57938,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-291194fa-0777-4553-bfb0-31e544b5d2f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049882316-172.17.0.5-1598335754582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45762,DS-7cdf64d8-156a-4401-b5d0-492bea852efc,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-632243f0-e0b9-4e9e-b714-535b37c5abd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-52b982b6-72c2-415b-b879-880cacfc936b,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-1e289d91-f9cc-4806-a26d-d75692b4f23f,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-0a7420d7-02cc-483d-bb66-5233fba2df56,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-3279570a-21c8-43ee-928e-2059bf58f544,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-6b87477d-1f48-4990-b95a-762f8af4cf39,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-a08019eb-1890-42ed-b7bc-30a252196d32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049882316-172.17.0.5-1598335754582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45762,DS-7cdf64d8-156a-4401-b5d0-492bea852efc,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-632243f0-e0b9-4e9e-b714-535b37c5abd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-52b982b6-72c2-415b-b879-880cacfc936b,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-1e289d91-f9cc-4806-a26d-d75692b4f23f,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-0a7420d7-02cc-483d-bb66-5233fba2df56,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-3279570a-21c8-43ee-928e-2059bf58f544,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-6b87477d-1f48-4990-b95a-762f8af4cf39,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-a08019eb-1890-42ed-b7bc-30a252196d32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784626380-172.17.0.5-1598336105514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38899,DS-c518b892-5ed0-4a61-9dcf-92d7c43f37b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-8c924b49-6f8c-4fa2-b00a-a3f68f004c30,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-be7dff36-8e92-4a6f-8077-35167414af96,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-15707dab-7ae4-4d10-ad6a-6932bdba14fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-de90226c-bb0d-4feb-9f03-43eea00e9616,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-3a6816d6-ecfd-424b-9c7e-c2394ed7816c,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-bd92b7b0-0373-48c0-b8f8-a28f07eb87c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-8c274503-0ddd-4709-bc96-1693627869aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784626380-172.17.0.5-1598336105514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38899,DS-c518b892-5ed0-4a61-9dcf-92d7c43f37b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-8c924b49-6f8c-4fa2-b00a-a3f68f004c30,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-be7dff36-8e92-4a6f-8077-35167414af96,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-15707dab-7ae4-4d10-ad6a-6932bdba14fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-de90226c-bb0d-4feb-9f03-43eea00e9616,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-3a6816d6-ecfd-424b-9c7e-c2394ed7816c,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-bd92b7b0-0373-48c0-b8f8-a28f07eb87c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-8c274503-0ddd-4709-bc96-1693627869aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110896452-172.17.0.5-1598336618194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34859,DS-93b3eecd-f8bf-40e4-a3bd-dfc0acee299f,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-ac7ab03d-3220-4846-85a6-1a06d358ea98,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-909bdec5-cc34-4567-8c06-28f91bbc94f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-c45536d7-8461-4e0d-ad7d-504ab7f44c88,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-6677c423-9a8e-4e51-a3e7-86fcd228b647,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-eaec155b-08d7-4b42-b0dc-d93fef679219,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-4470a792-1499-40da-84e2-8cc35099d2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-f4d27995-b1c7-4316-a374-aaf2da85af22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110896452-172.17.0.5-1598336618194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34859,DS-93b3eecd-f8bf-40e4-a3bd-dfc0acee299f,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-ac7ab03d-3220-4846-85a6-1a06d358ea98,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-909bdec5-cc34-4567-8c06-28f91bbc94f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-c45536d7-8461-4e0d-ad7d-504ab7f44c88,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-6677c423-9a8e-4e51-a3e7-86fcd228b647,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-eaec155b-08d7-4b42-b0dc-d93fef679219,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-4470a792-1499-40da-84e2-8cc35099d2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-f4d27995-b1c7-4316-a374-aaf2da85af22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643501403-172.17.0.5-1598336834418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37363,DS-9e66021a-f2c0-4073-90c0-aeec9f3cbba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-4eb8dd25-61fe-4659-878d-e0218f78f8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-556b4de7-2353-4f58-8d5b-453190e408bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-35012e84-4af9-4b37-97a6-91fd0aea7128,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-0086a210-8415-46bc-8440-b297e432466b,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-b33c007b-576d-4a9b-932e-dc4a815cb6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-ebf4c973-03d0-4452-b21b-354de10600b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-44883e7e-cf5b-4985-91f4-bb5eab289043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643501403-172.17.0.5-1598336834418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37363,DS-9e66021a-f2c0-4073-90c0-aeec9f3cbba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-4eb8dd25-61fe-4659-878d-e0218f78f8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-556b4de7-2353-4f58-8d5b-453190e408bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-35012e84-4af9-4b37-97a6-91fd0aea7128,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-0086a210-8415-46bc-8440-b297e432466b,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-b33c007b-576d-4a9b-932e-dc4a815cb6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-ebf4c973-03d0-4452-b21b-354de10600b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-44883e7e-cf5b-4985-91f4-bb5eab289043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1197933938-172.17.0.5-1598336965472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35220,DS-fed268b9-0213-4a84-88bb-d327b703d584,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-a76c956b-1f5b-4f78-9c96-5dc7cc8fab7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-b48612b6-99e4-421b-a749-a5d3e80d5961,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-fa4efcaf-2819-4b88-be85-6cf3a4b79d46,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-1578ff9e-0ac2-456c-b634-4603e35f3cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-8f7644c9-669f-485e-aad9-37d2f2a6aa08,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-edcbb0da-e53d-4b30-9573-047395a354d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-cef7c542-b591-4ec2-bc6c-639a874f7ea9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1197933938-172.17.0.5-1598336965472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35220,DS-fed268b9-0213-4a84-88bb-d327b703d584,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-a76c956b-1f5b-4f78-9c96-5dc7cc8fab7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-b48612b6-99e4-421b-a749-a5d3e80d5961,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-fa4efcaf-2819-4b88-be85-6cf3a4b79d46,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-1578ff9e-0ac2-456c-b634-4603e35f3cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-8f7644c9-669f-485e-aad9-37d2f2a6aa08,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-edcbb0da-e53d-4b30-9573-047395a354d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-cef7c542-b591-4ec2-bc6c-639a874f7ea9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141964427-172.17.0.5-1598337029490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46485,DS-ef7bc015-19ac-430c-86f9-72fcf71b77eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-13a40ec9-b0be-447d-a451-1a5c8f4e72d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-730d8aea-e663-42fa-8245-1991b63cd287,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-834691e1-c7b7-425c-bc7c-82fc8d8c3613,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-d487c8c0-05db-4e04-b6b9-7d0c3103ae4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-3c133637-03b7-4430-834a-7c6afe368789,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-48166371-74fd-4749-8fef-ae8423b19271,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-2656db22-665e-4fe8-8392-c8af045d332a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141964427-172.17.0.5-1598337029490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46485,DS-ef7bc015-19ac-430c-86f9-72fcf71b77eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-13a40ec9-b0be-447d-a451-1a5c8f4e72d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-730d8aea-e663-42fa-8245-1991b63cd287,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-834691e1-c7b7-425c-bc7c-82fc8d8c3613,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-d487c8c0-05db-4e04-b6b9-7d0c3103ae4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-3c133637-03b7-4430-834a-7c6afe368789,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-48166371-74fd-4749-8fef-ae8423b19271,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-2656db22-665e-4fe8-8392-c8af045d332a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957087564-172.17.0.5-1598337375152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42741,DS-af43f952-2d4a-4239-8f07-b2c7bef53e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-49085778-fc08-4219-9c09-380aedd32563,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-eae19dbe-1bb1-4918-8339-572b21754ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-5f58da7d-dbec-4157-b8fa-458957193314,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-f8dbc958-7225-4612-9c8d-c4b5680a8575,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-208ba8b6-dcdb-46ed-a952-687eb19e7e39,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-05957996-478f-456b-8903-aca8fa0a55d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-11966d1d-97b6-4aae-890c-b4eadd686a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957087564-172.17.0.5-1598337375152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42741,DS-af43f952-2d4a-4239-8f07-b2c7bef53e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-49085778-fc08-4219-9c09-380aedd32563,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-eae19dbe-1bb1-4918-8339-572b21754ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-5f58da7d-dbec-4157-b8fa-458957193314,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-f8dbc958-7225-4612-9c8d-c4b5680a8575,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-208ba8b6-dcdb-46ed-a952-687eb19e7e39,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-05957996-478f-456b-8903-aca8fa0a55d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-11966d1d-97b6-4aae-890c-b4eadd686a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459575242-172.17.0.5-1598338049614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39464,DS-2750e50d-ec17-40c3-a148-f22e6b0cb889,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-9d2179e6-a490-4e4b-93e1-ae980e1549eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-bedc70f7-5220-43ee-b6a5-e5135e23eb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-de044f3c-0245-42cf-9e61-afdca1c6a0de,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-9a61ecc4-3c7d-4398-9497-8f4e27c95d83,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-9c9b6a7c-30b0-49d9-af83-62ca2e294b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-86d68405-27ac-43ab-a4d7-b20657ef0189,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-ad39d388-c2e9-4137-961b-0a06047e46f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459575242-172.17.0.5-1598338049614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39464,DS-2750e50d-ec17-40c3-a148-f22e6b0cb889,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-9d2179e6-a490-4e4b-93e1-ae980e1549eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-bedc70f7-5220-43ee-b6a5-e5135e23eb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-de044f3c-0245-42cf-9e61-afdca1c6a0de,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-9a61ecc4-3c7d-4398-9497-8f4e27c95d83,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-9c9b6a7c-30b0-49d9-af83-62ca2e294b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-86d68405-27ac-43ab-a4d7-b20657ef0189,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-ad39d388-c2e9-4137-961b-0a06047e46f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455288445-172.17.0.5-1598338193432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45107,DS-53bb5cd9-0f12-400f-afab-9e6d48d6eda2,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-b9d0681b-e9cd-4efd-ad85-48941126a1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-f99cdf23-e3bc-4bac-9230-36842e5eaa27,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-2a8534c7-4774-4f68-8ca1-9d02f4ed9aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-3826ef05-d4c4-48cb-a31c-fd7898b81209,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-834789c3-f2eb-4393-9821-9ce13976a072,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-3091b559-c5f1-4de3-8104-2b1541a21a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-e24f89fe-6344-48d4-a23d-309daa53636c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455288445-172.17.0.5-1598338193432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45107,DS-53bb5cd9-0f12-400f-afab-9e6d48d6eda2,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-b9d0681b-e9cd-4efd-ad85-48941126a1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-f99cdf23-e3bc-4bac-9230-36842e5eaa27,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-2a8534c7-4774-4f68-8ca1-9d02f4ed9aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-3826ef05-d4c4-48cb-a31c-fd7898b81209,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-834789c3-f2eb-4393-9821-9ce13976a072,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-3091b559-c5f1-4de3-8104-2b1541a21a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-e24f89fe-6344-48d4-a23d-309daa53636c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-433575715-172.17.0.5-1598338230554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36743,DS-fecf980c-9855-4e6b-b3ab-cccb7c29a9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-f0945de4-27cc-471b-b10e-869d6ed57352,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-e30bee4b-14a4-4466-bfb7-bdb8001f4747,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-9f79923b-7d9e-4b1b-81b6-2f6ac4d62b36,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-80d2c4f9-a0eb-4364-bb74-fb85ebfbc3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-814d9897-ef62-4d22-a47a-453e39d8dc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-fcf56388-37bf-4c36-ae25-ad756ef261d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-0ef06558-a2df-481a-a97f-28eabf5c8882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-433575715-172.17.0.5-1598338230554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36743,DS-fecf980c-9855-4e6b-b3ab-cccb7c29a9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-f0945de4-27cc-471b-b10e-869d6ed57352,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-e30bee4b-14a4-4466-bfb7-bdb8001f4747,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-9f79923b-7d9e-4b1b-81b6-2f6ac4d62b36,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-80d2c4f9-a0eb-4364-bb74-fb85ebfbc3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-814d9897-ef62-4d22-a47a-453e39d8dc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-fcf56388-37bf-4c36-ae25-ad756ef261d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-0ef06558-a2df-481a-a97f-28eabf5c8882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096705489-172.17.0.5-1598339013248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34391,DS-90d32697-420a-4383-9ae5-7d1d30c9a049,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-17e63bb0-a999-4446-b169-a30d583065ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-f99968f6-fb31-4616-95fe-dc921dcbd43b,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-4155fb7e-e205-4b33-bf40-0bf72810b319,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-d9e83a0e-c5cb-4ac2-a4b6-ea2fcb4ca6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-0de640c1-6538-4151-85b9-7e41b5e1cff8,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-f217f7bc-5223-4c69-9a64-c0b277c8d491,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-c5cab9ad-4527-4fbf-ba62-3191a45d2ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096705489-172.17.0.5-1598339013248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34391,DS-90d32697-420a-4383-9ae5-7d1d30c9a049,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-17e63bb0-a999-4446-b169-a30d583065ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-f99968f6-fb31-4616-95fe-dc921dcbd43b,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-4155fb7e-e205-4b33-bf40-0bf72810b319,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-d9e83a0e-c5cb-4ac2-a4b6-ea2fcb4ca6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-0de640c1-6538-4151-85b9-7e41b5e1cff8,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-f217f7bc-5223-4c69-9a64-c0b277c8d491,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-c5cab9ad-4527-4fbf-ba62-3191a45d2ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739422609-172.17.0.5-1598340251625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43683,DS-27e6be75-4250-4f64-9806-df75b59bf312,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-1ff66e1e-32de-45b6-b4c3-9df549006f20,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-2716bc5d-075d-4d0d-90e6-00d88b53752a,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-44edf5b5-50fb-4472-be91-a10f9fa70b80,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-9e9e771a-a804-40be-8b22-55dd37722846,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-021c9f16-c0c2-4a66-8b09-03dd8a8666f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-db753acc-b3ee-4226-83c4-cc2a2827f0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-a75aa9f6-a8cf-435c-b44e-c84b867a7030,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739422609-172.17.0.5-1598340251625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43683,DS-27e6be75-4250-4f64-9806-df75b59bf312,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-1ff66e1e-32de-45b6-b4c3-9df549006f20,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-2716bc5d-075d-4d0d-90e6-00d88b53752a,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-44edf5b5-50fb-4472-be91-a10f9fa70b80,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-9e9e771a-a804-40be-8b22-55dd37722846,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-021c9f16-c0c2-4a66-8b09-03dd8a8666f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-db753acc-b3ee-4226-83c4-cc2a2827f0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-a75aa9f6-a8cf-435c-b44e-c84b867a7030,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137550918-172.17.0.5-1598340312754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42408,DS-48f39ed3-e245-4b57-9ee6-84ef700abf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-7e4868a2-6cce-42ab-aead-1afb003cb3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-ff2a69e9-306e-43a7-8f3b-34649472a177,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-d5f7a644-a839-4a43-a325-8a09c16ff265,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-2949737b-b0cb-43a9-bbbc-baccd5f3a10e,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-8a7c7022-0b38-4747-80e1-5a0781912a35,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-804eb0c3-0926-42e7-b439-cd6d25f79444,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-a8fcec8a-8717-489e-a903-fd59f41dac9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137550918-172.17.0.5-1598340312754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42408,DS-48f39ed3-e245-4b57-9ee6-84ef700abf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-7e4868a2-6cce-42ab-aead-1afb003cb3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-ff2a69e9-306e-43a7-8f3b-34649472a177,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-d5f7a644-a839-4a43-a325-8a09c16ff265,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-2949737b-b0cb-43a9-bbbc-baccd5f3a10e,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-8a7c7022-0b38-4747-80e1-5a0781912a35,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-804eb0c3-0926-42e7-b439-cd6d25f79444,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-a8fcec8a-8717-489e-a903-fd59f41dac9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5209
