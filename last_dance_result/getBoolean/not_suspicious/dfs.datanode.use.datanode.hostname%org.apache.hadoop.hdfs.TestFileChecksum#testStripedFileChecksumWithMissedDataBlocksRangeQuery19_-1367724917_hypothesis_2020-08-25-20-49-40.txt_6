reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946502263-172.17.0.16-1598388957117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35977,DS-e417820a-e0fb-4934-af8e-1b2bfd05b8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-e80281fd-6ba7-47da-b9b6-3a4ac1ac84b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-87065987-91c0-4787-8fd5-06747bb204db,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-f727beb8-8c2e-46b1-b939-d2a7a24c00fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-4c15b080-c1d1-44f4-9f2c-d327272eab1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-5e70c77e-1a62-4888-bf2b-4b832fdfd236,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-79ba5662-1337-486a-9087-c2328a50cf15,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-e8091022-d102-47bc-8d5b-fdb31daa38ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946502263-172.17.0.16-1598388957117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35977,DS-e417820a-e0fb-4934-af8e-1b2bfd05b8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-e80281fd-6ba7-47da-b9b6-3a4ac1ac84b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-87065987-91c0-4787-8fd5-06747bb204db,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-f727beb8-8c2e-46b1-b939-d2a7a24c00fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-4c15b080-c1d1-44f4-9f2c-d327272eab1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-5e70c77e-1a62-4888-bf2b-4b832fdfd236,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-79ba5662-1337-486a-9087-c2328a50cf15,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-e8091022-d102-47bc-8d5b-fdb31daa38ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124424149-172.17.0.16-1598389025048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43997,DS-b840241f-fec1-45ee-a346-7adac3a4a4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-237a6bed-650d-49cb-acf8-91e1fb03d257,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-c68de7fe-b751-4ec1-9b34-b8d150d38336,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-3234a7df-4d86-493f-a4d7-9476b5faecb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-824d8b2d-c1dd-4949-856f-c1e3ab1a27a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-3476436b-50e7-463d-a44d-ff2a1b02a18a,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-b221344d-16f8-4f43-8935-7f3c58a251fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-3d84d169-1aa7-4a8e-9a7b-ff7819a6033f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124424149-172.17.0.16-1598389025048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43997,DS-b840241f-fec1-45ee-a346-7adac3a4a4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-237a6bed-650d-49cb-acf8-91e1fb03d257,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-c68de7fe-b751-4ec1-9b34-b8d150d38336,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-3234a7df-4d86-493f-a4d7-9476b5faecb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-824d8b2d-c1dd-4949-856f-c1e3ab1a27a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-3476436b-50e7-463d-a44d-ff2a1b02a18a,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-b221344d-16f8-4f43-8935-7f3c58a251fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-3d84d169-1aa7-4a8e-9a7b-ff7819a6033f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970042161-172.17.0.16-1598389952550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45737,DS-8f6c1509-7232-4123-910e-afd14c52657c,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-8d20e477-1c7c-4834-bf98-6080e50bde46,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-b6f7db66-1394-4ec1-a2f9-8bde8360b45d,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-041c6a4f-e7c2-4e17-92ef-77610445e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-40ac83f4-bcc5-4b1a-86d8-51b37cf08ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-dc2852dc-7c4d-4bc4-925d-e3c1a467d95f,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-9271457a-b0be-41c5-baf2-91be8395617b,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-d6b580bd-b45e-4ac6-86bb-aa69d118205e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970042161-172.17.0.16-1598389952550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45737,DS-8f6c1509-7232-4123-910e-afd14c52657c,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-8d20e477-1c7c-4834-bf98-6080e50bde46,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-b6f7db66-1394-4ec1-a2f9-8bde8360b45d,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-041c6a4f-e7c2-4e17-92ef-77610445e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-40ac83f4-bcc5-4b1a-86d8-51b37cf08ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-dc2852dc-7c4d-4bc4-925d-e3c1a467d95f,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-9271457a-b0be-41c5-baf2-91be8395617b,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-d6b580bd-b45e-4ac6-86bb-aa69d118205e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043684168-172.17.0.16-1598390010387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44742,DS-1ffa641e-a863-4236-9a0f-78b07c07e709,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-ade90f32-f6e8-4c72-a756-73be18716428,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-5eff558a-c78d-4ce4-b5fa-dd9e6e4e4867,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-03c0afd3-2edf-4494-88a1-d996f630f7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-de3bb5fb-74e6-4d32-991c-ce4900cae9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-693c953b-2dee-4b0e-8340-b05d19b99212,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-e349c8d7-8d5f-44ea-b6eb-a68932922396,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-d26529e0-87fe-4ebe-afe4-f61f70c8a598,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043684168-172.17.0.16-1598390010387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44742,DS-1ffa641e-a863-4236-9a0f-78b07c07e709,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-ade90f32-f6e8-4c72-a756-73be18716428,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-5eff558a-c78d-4ce4-b5fa-dd9e6e4e4867,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-03c0afd3-2edf-4494-88a1-d996f630f7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-de3bb5fb-74e6-4d32-991c-ce4900cae9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-693c953b-2dee-4b0e-8340-b05d19b99212,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-e349c8d7-8d5f-44ea-b6eb-a68932922396,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-d26529e0-87fe-4ebe-afe4-f61f70c8a598,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199833259-172.17.0.16-1598390318687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42222,DS-2a2e2d3e-32b4-469a-b00d-8a54c39b8dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-8fc02711-2a9a-49c0-a0c6-3338576b8d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-c6b85648-416b-4d50-b3c3-a20f03f3d6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-1b604fed-3733-47c2-bceb-d4ba771d7b12,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-b4290868-4767-434f-8a4b-c9d3ac4748a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-768cc0b8-5bc4-4760-ae73-dd29c282f560,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-7b0084f1-545b-444a-80bb-5997c5990514,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-39e9edef-28fa-44a8-a796-5fcc23261c61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199833259-172.17.0.16-1598390318687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42222,DS-2a2e2d3e-32b4-469a-b00d-8a54c39b8dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-8fc02711-2a9a-49c0-a0c6-3338576b8d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-c6b85648-416b-4d50-b3c3-a20f03f3d6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-1b604fed-3733-47c2-bceb-d4ba771d7b12,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-b4290868-4767-434f-8a4b-c9d3ac4748a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-768cc0b8-5bc4-4760-ae73-dd29c282f560,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-7b0084f1-545b-444a-80bb-5997c5990514,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-39e9edef-28fa-44a8-a796-5fcc23261c61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256259955-172.17.0.16-1598390830018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45729,DS-3a8ef8e4-aebf-4838-b648-608cbdf4ff30,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-336ed8ac-bc24-4bf3-a10d-a4520d6e538d,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-9fefc6bc-3d95-4d50-b56e-fcc7343aa80a,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-8e3f4e84-480f-432b-b9a9-78a1e75a7343,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-d16b6a29-4a79-4cf1-9123-71252ac15070,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-039d70c0-252c-4259-b4ae-9e68054d6a63,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-731353f1-ac21-4875-814e-69565d33e111,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-63d9436b-22ca-47ca-a4c4-0bf7a92b90ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256259955-172.17.0.16-1598390830018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45729,DS-3a8ef8e4-aebf-4838-b648-608cbdf4ff30,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-336ed8ac-bc24-4bf3-a10d-a4520d6e538d,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-9fefc6bc-3d95-4d50-b56e-fcc7343aa80a,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-8e3f4e84-480f-432b-b9a9-78a1e75a7343,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-d16b6a29-4a79-4cf1-9123-71252ac15070,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-039d70c0-252c-4259-b4ae-9e68054d6a63,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-731353f1-ac21-4875-814e-69565d33e111,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-63d9436b-22ca-47ca-a4c4-0bf7a92b90ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1586461455-172.17.0.16-1598391163591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43706,DS-77e0917f-cdda-4b52-a2d2-a4cb550ce9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-70321d79-aa6e-491c-a9c6-cf73010bc43b,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-cb892076-c356-47dc-9b23-87fb4a7b5cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-abae8095-81b9-49a8-88fb-f845e6fb9804,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-b32d7534-2fb2-4d8e-bfcb-a4e7c6897143,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-a4b86925-440a-43ea-82bf-0c431bfe8b42,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-4dc1a8de-8a17-485c-bd8a-8e82e16b510d,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-4f3f4a29-7efe-4802-859a-1ca21bc2ba36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1586461455-172.17.0.16-1598391163591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43706,DS-77e0917f-cdda-4b52-a2d2-a4cb550ce9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-70321d79-aa6e-491c-a9c6-cf73010bc43b,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-cb892076-c356-47dc-9b23-87fb4a7b5cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-abae8095-81b9-49a8-88fb-f845e6fb9804,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-b32d7534-2fb2-4d8e-bfcb-a4e7c6897143,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-a4b86925-440a-43ea-82bf-0c431bfe8b42,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-4dc1a8de-8a17-485c-bd8a-8e82e16b510d,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-4f3f4a29-7efe-4802-859a-1ca21bc2ba36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192023319-172.17.0.16-1598391391820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42130,DS-6bba23bf-bc41-4639-a058-cd587b51b2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-894bf88f-4cee-4577-bd3a-de5a55189732,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-939f50c5-e90d-4ee7-b052-547e260914f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-a5740c5c-e6a8-41c0-a3ee-a4809ddbb388,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-89daf64e-21db-4e31-b90f-61d01522661b,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-3d468783-d8d9-4034-865f-5e84120e7170,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-d4e5bb0c-bb4c-4e1e-bf93-a1d5c11be0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-a92a9d5b-7d1c-411e-b63b-4dc2b9179ee9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192023319-172.17.0.16-1598391391820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42130,DS-6bba23bf-bc41-4639-a058-cd587b51b2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-894bf88f-4cee-4577-bd3a-de5a55189732,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-939f50c5-e90d-4ee7-b052-547e260914f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-a5740c5c-e6a8-41c0-a3ee-a4809ddbb388,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-89daf64e-21db-4e31-b90f-61d01522661b,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-3d468783-d8d9-4034-865f-5e84120e7170,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-d4e5bb0c-bb4c-4e1e-bf93-a1d5c11be0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-a92a9d5b-7d1c-411e-b63b-4dc2b9179ee9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-239859295-172.17.0.16-1598391555543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43603,DS-8477021d-8097-417c-b4a1-bde9a27aea1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-86b8fde0-ba88-4be6-b9f8-e71ef8711b50,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-3226e099-ea54-493c-b0e7-cabc2c91deb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-3cfcbb27-1b19-450a-9f29-cc00afbd3e99,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-38dc0cd8-cbb0-4002-bfb4-e3b55653cd01,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-0642a7c6-f903-40ed-8f0a-49521fa81f41,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-f79c97ea-dce7-4d5a-ad1a-8c25d3a12789,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-f9ac22e3-e86c-447d-8632-19ee5db23fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-239859295-172.17.0.16-1598391555543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43603,DS-8477021d-8097-417c-b4a1-bde9a27aea1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-86b8fde0-ba88-4be6-b9f8-e71ef8711b50,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-3226e099-ea54-493c-b0e7-cabc2c91deb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-3cfcbb27-1b19-450a-9f29-cc00afbd3e99,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-38dc0cd8-cbb0-4002-bfb4-e3b55653cd01,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-0642a7c6-f903-40ed-8f0a-49521fa81f41,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-f79c97ea-dce7-4d5a-ad1a-8c25d3a12789,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-f9ac22e3-e86c-447d-8632-19ee5db23fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1041175569-172.17.0.16-1598391681812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-0a7d7eef-4153-4868-a8dc-ca96ececd288,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-3d4cf4e2-606f-4738-ba88-d7dfeba56280,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-f49e47ac-6587-47f2-9d6a-4459678aa222,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-5e0dc953-6984-402e-9a02-57f52dd6c6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-fa8d82d4-959d-4798-baaa-8bb30b57f8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-ac5b4053-08c2-46c2-9bf4-2103bdea3842,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-f7354f27-cdd3-4b8f-b2e8-5ef6304fd7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-a9be2766-5e56-4d74-94e2-47d7be573414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1041175569-172.17.0.16-1598391681812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-0a7d7eef-4153-4868-a8dc-ca96ececd288,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-3d4cf4e2-606f-4738-ba88-d7dfeba56280,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-f49e47ac-6587-47f2-9d6a-4459678aa222,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-5e0dc953-6984-402e-9a02-57f52dd6c6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-fa8d82d4-959d-4798-baaa-8bb30b57f8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-ac5b4053-08c2-46c2-9bf4-2103bdea3842,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-f7354f27-cdd3-4b8f-b2e8-5ef6304fd7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-a9be2766-5e56-4d74-94e2-47d7be573414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2085596545-172.17.0.16-1598391870242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44462,DS-e2444214-040e-471f-af1f-09555e74e881,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-a9aa00c8-8f7e-4871-bdac-e0d06dbf66b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-a59a217f-fd1f-48e0-bda4-4db9e78fc47e,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-0c8eb40d-dd03-4435-b749-16ea8033830f,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-0ffdc73d-5db9-45b9-a7f8-29e3b737ce41,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-536c93b7-0fc0-4f39-a28b-7b9244a7d5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-d08e4704-75ac-4df6-a1e4-1266311c7266,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-5bb49bb6-98d1-4c8f-9d91-544da4f29218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2085596545-172.17.0.16-1598391870242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44462,DS-e2444214-040e-471f-af1f-09555e74e881,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-a9aa00c8-8f7e-4871-bdac-e0d06dbf66b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-a59a217f-fd1f-48e0-bda4-4db9e78fc47e,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-0c8eb40d-dd03-4435-b749-16ea8033830f,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-0ffdc73d-5db9-45b9-a7f8-29e3b737ce41,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-536c93b7-0fc0-4f39-a28b-7b9244a7d5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-d08e4704-75ac-4df6-a1e4-1266311c7266,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-5bb49bb6-98d1-4c8f-9d91-544da4f29218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746327063-172.17.0.16-1598391905142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-c0e3e9ed-085c-481d-b7d3-9cdb088a4195,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-507e169b-db84-40a8-acbc-85ebfbd96a78,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-6b129ba7-9d24-445e-a156-fd40beb2bdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-f95a5cc1-333e-4268-b692-a6c1549f29ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-247d6957-6747-486c-843c-c3ffb8fcc5af,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-5c51b321-a0f9-46ef-83dd-58f08f0996f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-c12ab82f-84aa-45ef-b72d-4fb8c3556801,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-4567836a-14a1-40aa-b208-fd8219045658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746327063-172.17.0.16-1598391905142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-c0e3e9ed-085c-481d-b7d3-9cdb088a4195,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-507e169b-db84-40a8-acbc-85ebfbd96a78,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-6b129ba7-9d24-445e-a156-fd40beb2bdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-f95a5cc1-333e-4268-b692-a6c1549f29ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-247d6957-6747-486c-843c-c3ffb8fcc5af,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-5c51b321-a0f9-46ef-83dd-58f08f0996f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-c12ab82f-84aa-45ef-b72d-4fb8c3556801,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-4567836a-14a1-40aa-b208-fd8219045658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1570956502-172.17.0.16-1598391933197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35642,DS-885ed05f-422e-4cce-bf7f-3b2404c681a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-9ae86e5f-1525-4a61-9898-2f6eb5b0a946,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-959820cf-fb1e-4c3a-85d1-63fda9b2f942,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-07887b53-2035-49ff-a3e0-8299b1114765,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-512c193e-ee96-49df-8010-919cf5108a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-995ce8bf-83a5-4160-86fb-6d2a5da0b35b,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-0bf50c3e-9636-400d-84f4-4e9019212043,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-1858ab03-a2ca-4dcc-8ee9-b7466bf51a9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1570956502-172.17.0.16-1598391933197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35642,DS-885ed05f-422e-4cce-bf7f-3b2404c681a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-9ae86e5f-1525-4a61-9898-2f6eb5b0a946,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-959820cf-fb1e-4c3a-85d1-63fda9b2f942,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-07887b53-2035-49ff-a3e0-8299b1114765,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-512c193e-ee96-49df-8010-919cf5108a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-995ce8bf-83a5-4160-86fb-6d2a5da0b35b,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-0bf50c3e-9636-400d-84f4-4e9019212043,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-1858ab03-a2ca-4dcc-8ee9-b7466bf51a9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326240575-172.17.0.16-1598393224970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43128,DS-090804b4-ae3a-4123-853b-6c6f92d938cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-71ad87e3-dc24-4485-8f3e-47db33359a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-584af3e0-c905-4e17-bd0d-39a6a4697b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-620af3c0-8c56-46ed-bf3f-3de46d22aef7,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-5683d386-0fba-4a78-8ea7-5dea5b58759a,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-ee679072-9818-4d20-874b-8f0ce6c0d804,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-7e3a0ebd-4f6f-4975-9d26-03e0400f7641,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-ef380523-f0ba-4cce-8740-df3eb1b02434,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326240575-172.17.0.16-1598393224970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43128,DS-090804b4-ae3a-4123-853b-6c6f92d938cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-71ad87e3-dc24-4485-8f3e-47db33359a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-584af3e0-c905-4e17-bd0d-39a6a4697b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-620af3c0-8c56-46ed-bf3f-3de46d22aef7,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-5683d386-0fba-4a78-8ea7-5dea5b58759a,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-ee679072-9818-4d20-874b-8f0ce6c0d804,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-7e3a0ebd-4f6f-4975-9d26-03e0400f7641,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-ef380523-f0ba-4cce-8740-df3eb1b02434,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 4992
