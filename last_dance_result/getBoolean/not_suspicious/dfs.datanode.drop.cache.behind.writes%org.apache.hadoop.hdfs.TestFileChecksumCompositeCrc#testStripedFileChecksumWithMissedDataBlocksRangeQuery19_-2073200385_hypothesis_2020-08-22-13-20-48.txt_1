reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016943075-172.17.0.19-1598102541497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43294,DS-bcd26099-7be4-4e9c-a64e-730ddcc6d030,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-e8f28e0e-86a9-465a-a21e-2f4be477e3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-868cb785-4ca5-4904-b9ef-f97f3efeb508,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-6270378c-6bbd-4bc6-b2e3-5fe401c86f52,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-71dde037-5c91-4e25-9218-cd451199583d,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-485f7f70-1965-48c3-b052-481773c7f115,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-4a23a957-ebc1-46ac-b210-c924bfde6857,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-a4a46bf0-7d77-4d65-ae9e-727ed9217af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016943075-172.17.0.19-1598102541497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43294,DS-bcd26099-7be4-4e9c-a64e-730ddcc6d030,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-e8f28e0e-86a9-465a-a21e-2f4be477e3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-868cb785-4ca5-4904-b9ef-f97f3efeb508,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-6270378c-6bbd-4bc6-b2e3-5fe401c86f52,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-71dde037-5c91-4e25-9218-cd451199583d,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-485f7f70-1965-48c3-b052-481773c7f115,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-4a23a957-ebc1-46ac-b210-c924bfde6857,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-a4a46bf0-7d77-4d65-ae9e-727ed9217af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1567205359-172.17.0.19-1598102791780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38580,DS-533c2957-58be-4767-b35c-2ef0e69be1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-ba23db1f-fa93-4e4e-a60b-697b62764693,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-dbd88838-1fbf-4dc4-b72a-0f8e75a81b13,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-79d55e14-ae80-4ac3-9189-0623f312aaff,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-a504b231-542e-45be-b7de-f95da6309951,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-76533676-565b-4ab9-9a36-01f9dcbff062,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-e86b04e6-6bbc-4375-b1a3-caac53977c24,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-02ff7c73-4fd3-4111-a18f-51e9bab941a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1567205359-172.17.0.19-1598102791780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38580,DS-533c2957-58be-4767-b35c-2ef0e69be1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-ba23db1f-fa93-4e4e-a60b-697b62764693,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-dbd88838-1fbf-4dc4-b72a-0f8e75a81b13,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-79d55e14-ae80-4ac3-9189-0623f312aaff,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-a504b231-542e-45be-b7de-f95da6309951,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-76533676-565b-4ab9-9a36-01f9dcbff062,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-e86b04e6-6bbc-4375-b1a3-caac53977c24,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-02ff7c73-4fd3-4111-a18f-51e9bab941a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-747016656-172.17.0.19-1598103070734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39900,DS-ae1dad9d-4578-46da-a8ca-027aa10098b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-d4015f14-5366-4edd-a478-534e1c04a43b,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-497b1d6d-0232-4aca-814c-913835e17cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-8b08847a-6786-406e-a23c-1f1ebfd1dd22,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-2d087cc8-3e28-4836-be52-b0f7e8103c73,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-28e73ca9-60f8-467b-84d4-2f1843804de1,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-d7e0958c-8b81-4996-85fb-d7078fa95a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-781d23e4-bec6-45e3-8cbb-5a1d91d01f22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-747016656-172.17.0.19-1598103070734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39900,DS-ae1dad9d-4578-46da-a8ca-027aa10098b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-d4015f14-5366-4edd-a478-534e1c04a43b,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-497b1d6d-0232-4aca-814c-913835e17cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-8b08847a-6786-406e-a23c-1f1ebfd1dd22,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-2d087cc8-3e28-4836-be52-b0f7e8103c73,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-28e73ca9-60f8-467b-84d4-2f1843804de1,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-d7e0958c-8b81-4996-85fb-d7078fa95a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-781d23e4-bec6-45e3-8cbb-5a1d91d01f22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1787104739-172.17.0.19-1598103186004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46880,DS-66cc25d3-2511-4f3f-b17f-d5decbda441b,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-ee067f35-0b06-4f1f-9715-74b442af37ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-94760de4-209a-466d-ac27-e8e9822f3926,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-e88b0783-537d-4fcd-b87b-c0e3b32e0634,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-a6bf5350-1cbc-4982-945d-b1278c9c11c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-d7718e40-3f17-4738-b8aa-030b2284e4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-fa36f297-2ea7-4956-97dc-335a24d3c4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-ec219518-7b8b-4d1f-acec-8d997873a619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1787104739-172.17.0.19-1598103186004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46880,DS-66cc25d3-2511-4f3f-b17f-d5decbda441b,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-ee067f35-0b06-4f1f-9715-74b442af37ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-94760de4-209a-466d-ac27-e8e9822f3926,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-e88b0783-537d-4fcd-b87b-c0e3b32e0634,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-a6bf5350-1cbc-4982-945d-b1278c9c11c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-d7718e40-3f17-4738-b8aa-030b2284e4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-fa36f297-2ea7-4956-97dc-335a24d3c4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-ec219518-7b8b-4d1f-acec-8d997873a619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024010771-172.17.0.19-1598103228420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38512,DS-55a7dcb6-1f15-47d6-8e2c-29f9859a9dff,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-437fcc3c-1987-40f6-9d33-a1998ddab489,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-4d7aa90c-4642-43c8-ab02-6f7634d30bad,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-a05e4bb7-55e0-4fe3-9ce4-77861e1a9ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-8d522da7-34c7-4741-b715-afcb291e2d71,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-8126037e-892c-43bd-ae80-c675271528cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-ff739d6a-7942-4705-ac19-a84e212ddf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-72286086-eb9f-4f07-aaf9-ae9558c7ff96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024010771-172.17.0.19-1598103228420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38512,DS-55a7dcb6-1f15-47d6-8e2c-29f9859a9dff,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-437fcc3c-1987-40f6-9d33-a1998ddab489,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-4d7aa90c-4642-43c8-ab02-6f7634d30bad,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-a05e4bb7-55e0-4fe3-9ce4-77861e1a9ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-8d522da7-34c7-4741-b715-afcb291e2d71,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-8126037e-892c-43bd-ae80-c675271528cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-ff739d6a-7942-4705-ac19-a84e212ddf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-72286086-eb9f-4f07-aaf9-ae9558c7ff96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357577344-172.17.0.19-1598103335357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35486,DS-ca186db4-7e23-4014-b0d9-474d6d67cc55,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-44329b16-bf3a-48ed-be69-d2881699f8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-290aa58b-06d3-4092-8b22-621748631a12,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-8011bd24-295d-47e9-a733-c5919646d3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-c8fadcc9-6d2a-486d-96a5-945a8cfd52bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-1512797f-83ba-44d7-ae96-d0832498fad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-c0eb7df2-2b14-4659-ba3d-28ea8f21d063,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-313beae6-6e7d-4bb2-92a3-979d900d38bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357577344-172.17.0.19-1598103335357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35486,DS-ca186db4-7e23-4014-b0d9-474d6d67cc55,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-44329b16-bf3a-48ed-be69-d2881699f8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-290aa58b-06d3-4092-8b22-621748631a12,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-8011bd24-295d-47e9-a733-c5919646d3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-c8fadcc9-6d2a-486d-96a5-945a8cfd52bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-1512797f-83ba-44d7-ae96-d0832498fad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-c0eb7df2-2b14-4659-ba3d-28ea8f21d063,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-313beae6-6e7d-4bb2-92a3-979d900d38bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994185884-172.17.0.19-1598104078735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46647,DS-7302c893-2993-4994-9f3b-c91d74e49206,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-ee6c1d1a-fc15-4dea-9722-38a03704f19e,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-44ff091b-31d3-4549-bb0b-024897aacde2,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-caa5331b-d12e-4c85-99b8-2ed1e1699bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-feeff984-2f7a-4758-a85d-0829d5d2b3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-7cfe0bd4-62b9-452a-ae8c-1279b834d4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-457d3af8-f612-4a2a-a2e5-545f0dbf5b22,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-173bc904-f70b-4e39-9e38-467ec1f42838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994185884-172.17.0.19-1598104078735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46647,DS-7302c893-2993-4994-9f3b-c91d74e49206,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-ee6c1d1a-fc15-4dea-9722-38a03704f19e,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-44ff091b-31d3-4549-bb0b-024897aacde2,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-caa5331b-d12e-4c85-99b8-2ed1e1699bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-feeff984-2f7a-4758-a85d-0829d5d2b3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-7cfe0bd4-62b9-452a-ae8c-1279b834d4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-457d3af8-f612-4a2a-a2e5-545f0dbf5b22,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-173bc904-f70b-4e39-9e38-467ec1f42838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553637028-172.17.0.19-1598104305667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41640,DS-07fe4969-5bea-4fe2-b2d7-94314864d6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-1c815e15-998a-4b55-b615-3f3d71fbd8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-7373722f-05c4-4a08-ad1b-b12f81bad5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-cb678d69-8a6c-413e-8647-c00b4bb49b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-dd321a30-d97c-4660-8620-4ea7c7d3d4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-b0f35ad8-f918-48dc-99e1-86d4f913d3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-5838a1d7-4b42-40fc-a2da-01d3b095ee6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-6beb2ef2-ba75-44af-aef6-d7dd0e173359,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553637028-172.17.0.19-1598104305667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41640,DS-07fe4969-5bea-4fe2-b2d7-94314864d6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-1c815e15-998a-4b55-b615-3f3d71fbd8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-7373722f-05c4-4a08-ad1b-b12f81bad5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-cb678d69-8a6c-413e-8647-c00b4bb49b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-dd321a30-d97c-4660-8620-4ea7c7d3d4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-b0f35ad8-f918-48dc-99e1-86d4f913d3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-5838a1d7-4b42-40fc-a2da-01d3b095ee6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-6beb2ef2-ba75-44af-aef6-d7dd0e173359,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397043983-172.17.0.19-1598104397336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36667,DS-b9cd292b-381a-40c5-a99e-04a863e53f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-06aa4ec9-30c5-4657-9296-2a57cafbb357,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-fe0dced8-b228-4376-9e8a-ded548e429e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-68f6cc86-628b-45fd-be8b-5488e62d9478,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-79d7c183-bc06-41d1-b9ca-5b28ad7fb2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-e70e6171-b7af-4f44-b386-08e4cbcfad0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-063848d3-8cd1-45b1-bb5d-28eceea31fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-ab05ee75-a024-4516-80ac-50e9b9e26e57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397043983-172.17.0.19-1598104397336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36667,DS-b9cd292b-381a-40c5-a99e-04a863e53f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-06aa4ec9-30c5-4657-9296-2a57cafbb357,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-fe0dced8-b228-4376-9e8a-ded548e429e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-68f6cc86-628b-45fd-be8b-5488e62d9478,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-79d7c183-bc06-41d1-b9ca-5b28ad7fb2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-e70e6171-b7af-4f44-b386-08e4cbcfad0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-063848d3-8cd1-45b1-bb5d-28eceea31fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-ab05ee75-a024-4516-80ac-50e9b9e26e57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1107594189-172.17.0.19-1598104522979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33613,DS-4b3779fb-597b-42c4-89db-1a0b87c25bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-7b4acca2-6e28-40f8-8123-0224859140dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-9d601a00-d8b3-4896-8fce-92cb2fa06085,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-560058d6-b608-4f68-a91b-89371ca9a36b,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-eb6cb183-f33b-4f0d-ad8c-016aabf23507,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-b3d54ca4-02f1-4309-80a6-8b83c9477cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-ff220e59-a6cb-4841-83d8-b318f507acd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-d6017350-8709-4f2b-99d5-4cf4c7764ed8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1107594189-172.17.0.19-1598104522979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33613,DS-4b3779fb-597b-42c4-89db-1a0b87c25bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-7b4acca2-6e28-40f8-8123-0224859140dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-9d601a00-d8b3-4896-8fce-92cb2fa06085,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-560058d6-b608-4f68-a91b-89371ca9a36b,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-eb6cb183-f33b-4f0d-ad8c-016aabf23507,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-b3d54ca4-02f1-4309-80a6-8b83c9477cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-ff220e59-a6cb-4841-83d8-b318f507acd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-d6017350-8709-4f2b-99d5-4cf4c7764ed8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1245420219-172.17.0.19-1598104588863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45337,DS-daff8dac-cfb0-48a7-9901-65e06a566995,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-43cf1bb2-81cb-43b7-8911-797532ced0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-37badbf7-796b-4fc4-9198-8126549dad9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-6b05ddc0-1064-4ed8-b698-6b6ff54ce0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-bcb39d51-a96b-4b51-a2a3-0848ecd00c23,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-55f4ac84-991d-467b-9901-d3e6a0dbc342,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-1f51b6b6-635a-4d1b-ad00-11f7e79dd25a,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-f4a803ae-993a-4594-ba1c-2ca11a5e8991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1245420219-172.17.0.19-1598104588863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45337,DS-daff8dac-cfb0-48a7-9901-65e06a566995,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-43cf1bb2-81cb-43b7-8911-797532ced0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-37badbf7-796b-4fc4-9198-8126549dad9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-6b05ddc0-1064-4ed8-b698-6b6ff54ce0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-bcb39d51-a96b-4b51-a2a3-0848ecd00c23,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-55f4ac84-991d-467b-9901-d3e6a0dbc342,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-1f51b6b6-635a-4d1b-ad00-11f7e79dd25a,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-f4a803ae-993a-4594-ba1c-2ca11a5e8991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-372880059-172.17.0.19-1598105042737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36797,DS-d4b1806d-8fbe-432d-9cd9-f4490ba7a584,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-33f98e8e-f3c9-4397-9307-48d07a88d1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-236a6989-2b3d-4695-a8b7-5680ec0d5238,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-e13d1d33-de16-4233-948d-50d8293c1287,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-3c3182ae-cdc1-4edd-9a8f-b2cd022d92b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-5e5c27a7-ec41-404b-9af7-316a0a41e235,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-071595d6-4c50-412e-a9e0-d49f243fa523,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-eeca352d-6764-434a-ac36-496bc0c0f69b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-372880059-172.17.0.19-1598105042737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36797,DS-d4b1806d-8fbe-432d-9cd9-f4490ba7a584,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-33f98e8e-f3c9-4397-9307-48d07a88d1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-236a6989-2b3d-4695-a8b7-5680ec0d5238,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-e13d1d33-de16-4233-948d-50d8293c1287,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-3c3182ae-cdc1-4edd-9a8f-b2cd022d92b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-5e5c27a7-ec41-404b-9af7-316a0a41e235,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-071595d6-4c50-412e-a9e0-d49f243fa523,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-eeca352d-6764-434a-ac36-496bc0c0f69b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401452037-172.17.0.19-1598105115252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45755,DS-4df1ef58-facb-47ae-b73f-86a94239031a,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-d2d1e729-a6c6-49dc-8b91-e96feeb3f277,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-50330ed1-5273-4b41-ae12-0a418caec21a,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-86d7febb-8f1f-4ecb-826b-0d9b4c37d3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-b93feb26-28c1-47d9-8607-871164c182a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-1eb28109-de6c-4b75-9816-9958cc3fd4da,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-3f2efc52-4a26-4e93-b62b-6386b655d8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-2e4f5100-f0d0-4804-bb89-ba258f80310f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401452037-172.17.0.19-1598105115252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45755,DS-4df1ef58-facb-47ae-b73f-86a94239031a,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-d2d1e729-a6c6-49dc-8b91-e96feeb3f277,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-50330ed1-5273-4b41-ae12-0a418caec21a,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-86d7febb-8f1f-4ecb-826b-0d9b4c37d3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-b93feb26-28c1-47d9-8607-871164c182a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-1eb28109-de6c-4b75-9816-9958cc3fd4da,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-3f2efc52-4a26-4e93-b62b-6386b655d8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-2e4f5100-f0d0-4804-bb89-ba258f80310f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274286342-172.17.0.19-1598105275209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40866,DS-f199e552-69cb-494f-9b09-9ae640b91d24,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-34745c97-685f-48fc-8c81-76cfaf446581,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-a7160b27-f958-4c1b-94d8-be59360dd2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-f9dc0495-ba8b-47ad-93ac-aca3410ea244,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-0377656c-99cd-4434-ae3c-da1e119fa056,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-cebd2a48-5069-44ce-a47b-2b4c5d1fbefe,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-576ebab4-bbeb-488a-a070-35d44c18cbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-309fb55b-7ae1-412a-b080-ec942de8f749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274286342-172.17.0.19-1598105275209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40866,DS-f199e552-69cb-494f-9b09-9ae640b91d24,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-34745c97-685f-48fc-8c81-76cfaf446581,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-a7160b27-f958-4c1b-94d8-be59360dd2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-f9dc0495-ba8b-47ad-93ac-aca3410ea244,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-0377656c-99cd-4434-ae3c-da1e119fa056,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-cebd2a48-5069-44ce-a47b-2b4c5d1fbefe,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-576ebab4-bbeb-488a-a070-35d44c18cbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-309fb55b-7ae1-412a-b080-ec942de8f749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1782277462-172.17.0.19-1598105344495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39986,DS-3e3f5e67-73e4-4d3e-9bf7-01e1b9d4e9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-670c812e-6f77-492b-86d4-eb94a1dc07fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-532954af-c840-4b02-b656-f3f2bcccb3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-c4abfc04-0a8d-4819-9fdb-80789fdbd8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-0b2d7ecd-94c0-419f-8cba-0c754e90357d,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-fb142ee1-dd0f-4e8f-b7b0-72aac8297838,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-cc1cc2aa-9446-470b-a1d2-b5ab0b889ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-6a56ab22-f6fa-4539-8666-6ed6eb5a0d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1782277462-172.17.0.19-1598105344495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39986,DS-3e3f5e67-73e4-4d3e-9bf7-01e1b9d4e9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-670c812e-6f77-492b-86d4-eb94a1dc07fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-532954af-c840-4b02-b656-f3f2bcccb3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-c4abfc04-0a8d-4819-9fdb-80789fdbd8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-0b2d7ecd-94c0-419f-8cba-0c754e90357d,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-fb142ee1-dd0f-4e8f-b7b0-72aac8297838,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-cc1cc2aa-9446-470b-a1d2-b5ab0b889ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-6a56ab22-f6fa-4539-8666-6ed6eb5a0d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312932674-172.17.0.19-1598106233701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41643,DS-df9e7c4b-440c-4a50-83b6-39f3749a895a,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-a9683f7c-ff80-4af3-9e50-bb13519d311e,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-0cfc1e5e-56a5-494d-8371-60b36126508f,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-5401ca1a-8f33-40fa-9928-6f18d1d5cfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-de9ce6b7-9b01-4391-b182-6f04bd2e9f91,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-58772538-a94f-4403-bec5-86a255584800,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-e12e039e-5be2-4604-81e5-0560d71534bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-70f7787a-2533-4936-b2ab-d778abcf3ab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312932674-172.17.0.19-1598106233701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41643,DS-df9e7c4b-440c-4a50-83b6-39f3749a895a,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-a9683f7c-ff80-4af3-9e50-bb13519d311e,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-0cfc1e5e-56a5-494d-8371-60b36126508f,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-5401ca1a-8f33-40fa-9928-6f18d1d5cfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-de9ce6b7-9b01-4391-b182-6f04bd2e9f91,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-58772538-a94f-4403-bec5-86a255584800,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-e12e039e-5be2-4604-81e5-0560d71534bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-70f7787a-2533-4936-b2ab-d778abcf3ab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997762738-172.17.0.19-1598106307505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34185,DS-66994e4f-4b84-43fa-9ea7-aa53900347b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-7c6e7d1b-4fca-4872-a7f7-1dba9e8aca37,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-7189986d-1639-4e4d-8097-8fe92b55e8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-b44193b5-eca5-4a4d-b532-c69317f31d50,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-c4d842ce-d9f8-4e50-bac4-681c2c1bdc61,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-1fb0b7e5-1248-4348-9b68-170ab0c7cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-86282489-dc6b-4ef4-8755-a8072b7912e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-60e82a7d-48fa-4ad8-b526-4a2c70eb28dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997762738-172.17.0.19-1598106307505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34185,DS-66994e4f-4b84-43fa-9ea7-aa53900347b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-7c6e7d1b-4fca-4872-a7f7-1dba9e8aca37,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-7189986d-1639-4e4d-8097-8fe92b55e8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-b44193b5-eca5-4a4d-b532-c69317f31d50,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-c4d842ce-d9f8-4e50-bac4-681c2c1bdc61,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-1fb0b7e5-1248-4348-9b68-170ab0c7cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-86282489-dc6b-4ef4-8755-a8072b7912e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-60e82a7d-48fa-4ad8-b526-4a2c70eb28dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025290714-172.17.0.19-1598106520461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41554,DS-4ff12988-43df-4358-8bcd-44175ba0a5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-7b436c2c-bbca-45d4-a300-36bbaea54b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-a2c6bf39-7b04-4e07-9faf-4984215afa35,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-0cb91d39-c02f-4452-a187-232278574994,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-57fb6a27-4f7f-4ce8-b9c4-0a6d1cfab397,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-ffe8f5b0-c6f9-48bd-b75f-67e4786d3cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-9e226856-e163-4c6a-bbe0-828bde63c1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-3bc7b56f-eee6-4cc8-bd83-6b0a978cf6c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025290714-172.17.0.19-1598106520461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41554,DS-4ff12988-43df-4358-8bcd-44175ba0a5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-7b436c2c-bbca-45d4-a300-36bbaea54b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-a2c6bf39-7b04-4e07-9faf-4984215afa35,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-0cb91d39-c02f-4452-a187-232278574994,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-57fb6a27-4f7f-4ce8-b9c4-0a6d1cfab397,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-ffe8f5b0-c6f9-48bd-b75f-67e4786d3cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-9e226856-e163-4c6a-bbe0-828bde63c1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-3bc7b56f-eee6-4cc8-bd83-6b0a978cf6c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821881241-172.17.0.19-1598107585722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46490,DS-4366ef29-c70c-4a90-950b-3a652139ef32,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-b7d38faa-816a-4938-98dc-75f288d9df4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-a7ee7923-a930-4bb9-a630-c31d51bb7abb,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-be745840-ae51-468e-ab3e-c2535364b8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-3174651e-3031-4731-b02c-5b392dbf097e,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-b4039bfd-611d-4321-9084-942f4d3ad005,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-f2d6ec83-65a1-4ebb-bc3a-4cbb4ea23803,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-0fa0f3a6-74ef-4180-9661-332d7e7d2369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821881241-172.17.0.19-1598107585722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46490,DS-4366ef29-c70c-4a90-950b-3a652139ef32,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-b7d38faa-816a-4938-98dc-75f288d9df4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-a7ee7923-a930-4bb9-a630-c31d51bb7abb,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-be745840-ae51-468e-ab3e-c2535364b8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-3174651e-3031-4731-b02c-5b392dbf097e,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-b4039bfd-611d-4321-9084-942f4d3ad005,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-f2d6ec83-65a1-4ebb-bc3a-4cbb4ea23803,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-0fa0f3a6-74ef-4180-9661-332d7e7d2369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127450161-172.17.0.19-1598107685819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44692,DS-cb36a93a-1265-424c-bcaa-22b7c32cc1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-971ee0e0-5acb-4e59-b855-18642e5c275b,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-e587ab88-b2fb-4b91-9ff1-308542f4546c,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-4ab54f0b-72d3-4412-97be-ca662e0c9233,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-2559d67d-c7f3-49b3-9cd8-86c43022358a,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-dd36a523-aaa0-4d15-9728-d54b82b5c308,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-81957180-3c75-4342-be5c-c9e5666c28b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-fab9d0ce-c2ac-4b2e-b570-2b92b876d171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127450161-172.17.0.19-1598107685819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44692,DS-cb36a93a-1265-424c-bcaa-22b7c32cc1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-971ee0e0-5acb-4e59-b855-18642e5c275b,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-e587ab88-b2fb-4b91-9ff1-308542f4546c,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-4ab54f0b-72d3-4412-97be-ca662e0c9233,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-2559d67d-c7f3-49b3-9cd8-86c43022358a,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-dd36a523-aaa0-4d15-9728-d54b82b5c308,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-81957180-3c75-4342-be5c-c9e5666c28b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-fab9d0ce-c2ac-4b2e-b570-2b92b876d171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5330
