reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803139500-172.17.0.8-1598192428961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43311,DS-87c6b913-0c80-4fc1-a74e-9ef008df9363,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-ffb33056-8751-4381-a033-c12d250a9e61,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-d8ced36f-52c7-4adb-98fc-3338d6c0b2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-3458b98e-099e-4709-b9dd-6dee7a24de4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-5cc61e23-f812-4257-95f8-37c5aea86692,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-b5e7399e-83ad-43ab-ba2b-fb6466233d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-cb17fcea-8533-4b5e-9388-b7c2e04e105f,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-540c8e8b-0927-4f14-99fc-afbef8acd34f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803139500-172.17.0.8-1598192428961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43311,DS-87c6b913-0c80-4fc1-a74e-9ef008df9363,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-ffb33056-8751-4381-a033-c12d250a9e61,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-d8ced36f-52c7-4adb-98fc-3338d6c0b2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-3458b98e-099e-4709-b9dd-6dee7a24de4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-5cc61e23-f812-4257-95f8-37c5aea86692,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-b5e7399e-83ad-43ab-ba2b-fb6466233d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-cb17fcea-8533-4b5e-9388-b7c2e04e105f,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-540c8e8b-0927-4f14-99fc-afbef8acd34f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962651007-172.17.0.8-1598192469540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41097,DS-4a5edd15-ea33-407d-bedb-109f68fdddaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-212b18a4-271e-4c47-9e63-a39074073a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-7f531750-f061-4f35-b6b9-124c156017b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-bf013866-b361-45f9-979f-7d10e90ca545,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-32a3bb9c-746a-485c-92e4-f0669d8d6ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-4bf20fbb-1b0e-43a7-aa1a-960075f7c3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-808e8adc-7db3-48a2-8968-11923287e56e,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-9bd810ff-7698-44ca-8ac6-63fd7d4f22f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962651007-172.17.0.8-1598192469540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41097,DS-4a5edd15-ea33-407d-bedb-109f68fdddaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-212b18a4-271e-4c47-9e63-a39074073a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-7f531750-f061-4f35-b6b9-124c156017b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-bf013866-b361-45f9-979f-7d10e90ca545,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-32a3bb9c-746a-485c-92e4-f0669d8d6ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-4bf20fbb-1b0e-43a7-aa1a-960075f7c3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-808e8adc-7db3-48a2-8968-11923287e56e,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-9bd810ff-7698-44ca-8ac6-63fd7d4f22f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730052004-172.17.0.8-1598192806575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44225,DS-5945945b-dd51-414a-a803-d60ebca51dee,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-631772e4-4626-401f-9212-e35911c49b28,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-82ec52a6-4bc8-4612-860a-101ca9916445,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-58018e61-38a0-46a5-aa9c-cb0b1387ea2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-3405fb1b-f8e3-4a6e-8cf6-6c9468b49b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-bac4cfa3-c2da-43b5-b4a6-ef5055a5dec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-3c899ac2-e7b7-4649-a431-aecda1aea73b,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-c2bb619a-ab30-4176-abff-4b70ec88c54f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730052004-172.17.0.8-1598192806575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44225,DS-5945945b-dd51-414a-a803-d60ebca51dee,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-631772e4-4626-401f-9212-e35911c49b28,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-82ec52a6-4bc8-4612-860a-101ca9916445,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-58018e61-38a0-46a5-aa9c-cb0b1387ea2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-3405fb1b-f8e3-4a6e-8cf6-6c9468b49b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-bac4cfa3-c2da-43b5-b4a6-ef5055a5dec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-3c899ac2-e7b7-4649-a431-aecda1aea73b,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-c2bb619a-ab30-4176-abff-4b70ec88c54f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274425030-172.17.0.8-1598192886886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38027,DS-0cd666b4-8d83-4630-b6bc-6ef3075322e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-96cbf481-54b2-4df2-8de5-adbd58ad1448,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-dc7bbf77-913f-4c18-846b-198dce9baac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-b7ee9367-ebfb-4467-9b84-d21dc0537b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-62bcd765-8b1b-4837-b480-4e27c65c3432,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-2857482d-30ef-41d6-beff-c6526a3799c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-30f0c2b5-e8b9-4202-8dad-48080aa9c65d,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-3fc5a081-420a-4956-be2b-a104db5adb33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274425030-172.17.0.8-1598192886886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38027,DS-0cd666b4-8d83-4630-b6bc-6ef3075322e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-96cbf481-54b2-4df2-8de5-adbd58ad1448,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-dc7bbf77-913f-4c18-846b-198dce9baac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-b7ee9367-ebfb-4467-9b84-d21dc0537b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-62bcd765-8b1b-4837-b480-4e27c65c3432,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-2857482d-30ef-41d6-beff-c6526a3799c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-30f0c2b5-e8b9-4202-8dad-48080aa9c65d,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-3fc5a081-420a-4956-be2b-a104db5adb33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909898938-172.17.0.8-1598193152568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33817,DS-b89c7176-d0b1-4db9-b10e-6d5238d96cff,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-014985c2-ab10-4b0d-9768-ca4a50bdbbae,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-ab178539-5d10-4cb4-ac57-1169806d44d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-6f3829ec-4563-4d15-9361-4bd0e9953f68,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-7e0d47b0-318a-4540-9bda-ddca00cc9ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-31d3c061-30f9-4f6b-a2ce-b8bf45072316,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-d9d5ee5a-6da9-4410-bcf2-0ae174124292,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-c1c52e29-8084-44ac-94a0-735c0705002c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909898938-172.17.0.8-1598193152568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33817,DS-b89c7176-d0b1-4db9-b10e-6d5238d96cff,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-014985c2-ab10-4b0d-9768-ca4a50bdbbae,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-ab178539-5d10-4cb4-ac57-1169806d44d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-6f3829ec-4563-4d15-9361-4bd0e9953f68,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-7e0d47b0-318a-4540-9bda-ddca00cc9ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-31d3c061-30f9-4f6b-a2ce-b8bf45072316,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-d9d5ee5a-6da9-4410-bcf2-0ae174124292,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-c1c52e29-8084-44ac-94a0-735c0705002c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183526378-172.17.0.8-1598193231141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43676,DS-446021b7-49a6-45fe-bc51-d98e6465155a,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-8e6c9f16-f788-4355-9104-47700557476d,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-627ba1e6-b116-49e8-9a1b-10ee9577ba64,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-3f76d184-64aa-4552-a46e-1a31d204813e,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-e0ffd002-2ef8-4baa-ad0e-b3e93077c304,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-2c7879d8-1923-4cd5-9661-bdd36d3a6933,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-3249d8c9-f0a4-4d94-afd8-b6f16af5b5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-40611a65-5d05-4951-9c0c-45bd02e928ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183526378-172.17.0.8-1598193231141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43676,DS-446021b7-49a6-45fe-bc51-d98e6465155a,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-8e6c9f16-f788-4355-9104-47700557476d,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-627ba1e6-b116-49e8-9a1b-10ee9577ba64,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-3f76d184-64aa-4552-a46e-1a31d204813e,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-e0ffd002-2ef8-4baa-ad0e-b3e93077c304,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-2c7879d8-1923-4cd5-9661-bdd36d3a6933,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-3249d8c9-f0a4-4d94-afd8-b6f16af5b5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-40611a65-5d05-4951-9c0c-45bd02e928ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330975421-172.17.0.8-1598193991725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33018,DS-292e2738-3001-444f-b151-af3808f92c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-e292c6ce-c0d5-4b84-bebd-41769daeee10,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-f9dcd67d-8ea2-4c88-928e-7675aae15da9,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-8f4c9cac-fae4-40c2-be79-7ad942033f00,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-c74a169e-d1f7-4b60-b72d-694a83406363,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-850f427b-4cf0-4a10-a37c-085075598f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-2146b6b1-f3ea-4bea-8f12-019e93d1806e,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-c19a86cf-ac78-42a3-96b6-81b8364778d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330975421-172.17.0.8-1598193991725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33018,DS-292e2738-3001-444f-b151-af3808f92c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-e292c6ce-c0d5-4b84-bebd-41769daeee10,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-f9dcd67d-8ea2-4c88-928e-7675aae15da9,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-8f4c9cac-fae4-40c2-be79-7ad942033f00,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-c74a169e-d1f7-4b60-b72d-694a83406363,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-850f427b-4cf0-4a10-a37c-085075598f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-2146b6b1-f3ea-4bea-8f12-019e93d1806e,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-c19a86cf-ac78-42a3-96b6-81b8364778d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994334259-172.17.0.8-1598194269195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34593,DS-e6edab0f-06ae-4e4a-aa79-74465928bb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-eb414471-6d29-4633-8f65-453476f84500,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-f193ab78-dac2-4919-beb7-a39d99104813,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-e91c07d6-08e9-46a2-9558-b364f87b5214,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-1a734140-3808-4a89-b2f0-c3505f191a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-b373c1b4-9a66-4c47-9e33-6956b2cac18f,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-a2e17ea0-886e-4c0b-866d-9f29a777c435,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-eaf7722a-4847-4e1f-bbad-e2b9fb13ea3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994334259-172.17.0.8-1598194269195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34593,DS-e6edab0f-06ae-4e4a-aa79-74465928bb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-eb414471-6d29-4633-8f65-453476f84500,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-f193ab78-dac2-4919-beb7-a39d99104813,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-e91c07d6-08e9-46a2-9558-b364f87b5214,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-1a734140-3808-4a89-b2f0-c3505f191a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-b373c1b4-9a66-4c47-9e33-6956b2cac18f,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-a2e17ea0-886e-4c0b-866d-9f29a777c435,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-eaf7722a-4847-4e1f-bbad-e2b9fb13ea3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874735674-172.17.0.8-1598194635923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34803,DS-102ba406-fd41-4644-8d1b-fbe73cc358dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-eb4f7c69-f257-40d2-91d4-04cbfeedf512,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-388d31e7-64e7-4621-8944-0ce12f4e5e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-b230bd35-1f4e-45d0-a21a-33d1f35cc21a,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-d4e1b335-58f3-47f6-a938-6c6043f8e468,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-5204036b-545c-4b75-b61a-3aa44551da8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-4f894296-cd86-4d8e-97e7-00b5a3b5718f,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-ed8508b2-2a26-4da6-9bb7-06edfff6f071,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874735674-172.17.0.8-1598194635923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34803,DS-102ba406-fd41-4644-8d1b-fbe73cc358dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-eb4f7c69-f257-40d2-91d4-04cbfeedf512,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-388d31e7-64e7-4621-8944-0ce12f4e5e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-b230bd35-1f4e-45d0-a21a-33d1f35cc21a,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-d4e1b335-58f3-47f6-a938-6c6043f8e468,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-5204036b-545c-4b75-b61a-3aa44551da8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-4f894296-cd86-4d8e-97e7-00b5a3b5718f,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-ed8508b2-2a26-4da6-9bb7-06edfff6f071,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234194856-172.17.0.8-1598194969553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43533,DS-fbd42eda-4238-494c-8990-d6a94b6d72b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-f9a3d2d4-d4fa-4fd5-9ef5-219520e1698c,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-28b46a86-8a5a-4e05-8e03-9191cae3f2be,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-81176497-0673-4920-8d68-ba0a20974b37,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-1dc8efcb-5b82-47f9-948b-f29816802fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-f03f128a-c922-4c3f-ac15-480830865ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-21dc233d-f07d-4e28-902d-5a0e174a3ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-2074997a-7792-4142-a722-77b1edac6b66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234194856-172.17.0.8-1598194969553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43533,DS-fbd42eda-4238-494c-8990-d6a94b6d72b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-f9a3d2d4-d4fa-4fd5-9ef5-219520e1698c,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-28b46a86-8a5a-4e05-8e03-9191cae3f2be,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-81176497-0673-4920-8d68-ba0a20974b37,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-1dc8efcb-5b82-47f9-948b-f29816802fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-f03f128a-c922-4c3f-ac15-480830865ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-21dc233d-f07d-4e28-902d-5a0e174a3ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-2074997a-7792-4142-a722-77b1edac6b66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503173360-172.17.0.8-1598195124772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36421,DS-d6009816-1ec2-48c1-935b-35a6e0802eac,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-9a838aec-c9b3-429f-816b-4acafb2974ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-6410f65c-877c-4838-8d9d-d17cb7e29f06,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-fe3c2733-d8c4-495c-a146-f6860a7c6471,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-1ca4357b-f400-4aa9-99cf-26f38ca8d274,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-36b396fd-df43-40ec-9962-b910a414af82,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-151ccf4a-6622-4720-91a9-665d65f3ca29,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-9677132a-e3dc-43f9-8371-62572735d00d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503173360-172.17.0.8-1598195124772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36421,DS-d6009816-1ec2-48c1-935b-35a6e0802eac,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-9a838aec-c9b3-429f-816b-4acafb2974ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-6410f65c-877c-4838-8d9d-d17cb7e29f06,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-fe3c2733-d8c4-495c-a146-f6860a7c6471,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-1ca4357b-f400-4aa9-99cf-26f38ca8d274,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-36b396fd-df43-40ec-9962-b910a414af82,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-151ccf4a-6622-4720-91a9-665d65f3ca29,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-9677132a-e3dc-43f9-8371-62572735d00d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754035324-172.17.0.8-1598195189001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44386,DS-ea4ef907-1fea-4a52-86f7-2c0b6390e6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-da252a1b-66e3-4a52-871c-6d7e30448650,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-1b186680-f635-4dd5-97e3-b486b28563cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-307cbab0-d9e1-45a2-9d15-3b05a5bfbd29,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-ade7c8eb-b9ef-4878-83d2-f0b80a85f435,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-b604c022-3969-4f30-9407-a455f1c51f11,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-8b9256d5-9523-4483-8423-c6d99776cced,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-3ad9c639-2f65-4ecf-94c0-59ec94aa2797,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754035324-172.17.0.8-1598195189001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44386,DS-ea4ef907-1fea-4a52-86f7-2c0b6390e6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-da252a1b-66e3-4a52-871c-6d7e30448650,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-1b186680-f635-4dd5-97e3-b486b28563cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-307cbab0-d9e1-45a2-9d15-3b05a5bfbd29,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-ade7c8eb-b9ef-4878-83d2-f0b80a85f435,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-b604c022-3969-4f30-9407-a455f1c51f11,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-8b9256d5-9523-4483-8423-c6d99776cced,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-3ad9c639-2f65-4ecf-94c0-59ec94aa2797,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633378493-172.17.0.8-1598195223376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43461,DS-a200f335-889d-4024-83e6-447813362c94,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-024a35df-96d0-490d-a99f-483d65267488,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-78086fec-f5bb-4a9f-a54e-2a30bb488290,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-fad23a62-4f68-4e81-8141-ae8e37e3a230,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-9b08ce8c-9c22-4057-8598-dee9cce85108,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-dc9004c3-7c31-44f3-b91e-be13ee57dd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-32b16e63-dbef-44d4-9878-91894dafad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-771cefd4-c537-4e56-8516-3c7935eda007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633378493-172.17.0.8-1598195223376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43461,DS-a200f335-889d-4024-83e6-447813362c94,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-024a35df-96d0-490d-a99f-483d65267488,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-78086fec-f5bb-4a9f-a54e-2a30bb488290,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-fad23a62-4f68-4e81-8141-ae8e37e3a230,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-9b08ce8c-9c22-4057-8598-dee9cce85108,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-dc9004c3-7c31-44f3-b91e-be13ee57dd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-32b16e63-dbef-44d4-9878-91894dafad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-771cefd4-c537-4e56-8516-3c7935eda007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223732106-172.17.0.8-1598195360855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39036,DS-da3fc21d-d484-4e20-88ba-ef4811d09b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-135e3e4b-5380-49d9-9f6b-4260c6a0b715,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-f4b1d1f4-de04-495d-8a52-f33dad192883,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-e1e9dc46-b961-485b-8405-e4f04aeb3eff,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-5c2cf28f-88d4-4cdd-982d-9e7e8e4e69ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-51744a9f-2018-4203-b452-489969ec686b,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-98b432fb-1731-406e-afed-1eb5b18041ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-8389c8f5-4a0c-44fc-84ce-7c56a03cb3bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223732106-172.17.0.8-1598195360855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39036,DS-da3fc21d-d484-4e20-88ba-ef4811d09b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-135e3e4b-5380-49d9-9f6b-4260c6a0b715,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-f4b1d1f4-de04-495d-8a52-f33dad192883,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-e1e9dc46-b961-485b-8405-e4f04aeb3eff,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-5c2cf28f-88d4-4cdd-982d-9e7e8e4e69ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-51744a9f-2018-4203-b452-489969ec686b,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-98b432fb-1731-406e-afed-1eb5b18041ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-8389c8f5-4a0c-44fc-84ce-7c56a03cb3bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999141047-172.17.0.8-1598195426641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40707,DS-d439a726-3c22-42f8-b9b1-15db75086cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-32aa2576-0165-494a-82cd-75f6972b1e04,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-65cee265-7111-4aea-9ee2-4b39e6342305,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-971df771-a95b-4bad-9d80-3d8c9d2c589c,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-63c7b0ab-40ab-4f5b-a4bf-5b842db46c32,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-7a6e0a6d-c739-43ab-a7a1-cac85b6b0b50,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-c4a457a7-ae22-43d3-8a1a-37df9a9359b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-04797626-d873-4752-8fe4-f72649fe9c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999141047-172.17.0.8-1598195426641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40707,DS-d439a726-3c22-42f8-b9b1-15db75086cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-32aa2576-0165-494a-82cd-75f6972b1e04,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-65cee265-7111-4aea-9ee2-4b39e6342305,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-971df771-a95b-4bad-9d80-3d8c9d2c589c,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-63c7b0ab-40ab-4f5b-a4bf-5b842db46c32,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-7a6e0a6d-c739-43ab-a7a1-cac85b6b0b50,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-c4a457a7-ae22-43d3-8a1a-37df9a9359b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-04797626-d873-4752-8fe4-f72649fe9c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321058819-172.17.0.8-1598195634334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40747,DS-6efa5171-741c-4c28-b561-4d3c86721fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-cefd9c4e-381b-4c7a-bec7-56b0c0deaa4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-20075748-ab1c-4c02-ab78-2b2f8b151e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-3693387f-00d5-46a7-a168-8ba5ff1baf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-f0fccbeb-ce65-4959-89da-517519b68a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-f3032957-c4ab-4830-b98a-c1403443469b,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-33273e8f-4e7c-49dc-a708-3648c5039ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-010214b1-1d58-4026-bc26-103b19297353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321058819-172.17.0.8-1598195634334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40747,DS-6efa5171-741c-4c28-b561-4d3c86721fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-cefd9c4e-381b-4c7a-bec7-56b0c0deaa4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-20075748-ab1c-4c02-ab78-2b2f8b151e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-3693387f-00d5-46a7-a168-8ba5ff1baf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-f0fccbeb-ce65-4959-89da-517519b68a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-f3032957-c4ab-4830-b98a-c1403443469b,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-33273e8f-4e7c-49dc-a708-3648c5039ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-010214b1-1d58-4026-bc26-103b19297353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852506171-172.17.0.8-1598195663988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36155,DS-2030e468-14a4-4647-a344-aa121ac11c49,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-1b348506-9165-4a2a-81da-4c2f80c97661,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-098fed54-e107-452b-bbd5-2924564a4fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-6406d75b-f2c3-451c-b71e-e7c69ffdc4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-14dd0544-fa6e-4306-85fa-72b61a85c9be,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-193aa0cc-66fe-4378-a5fa-dd63fb9073a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-4340f0b1-d1d1-49e5-89f6-ab949e132a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-6c15077a-d98f-4c9a-a58e-fd2e990ffa38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852506171-172.17.0.8-1598195663988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36155,DS-2030e468-14a4-4647-a344-aa121ac11c49,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-1b348506-9165-4a2a-81da-4c2f80c97661,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-098fed54-e107-452b-bbd5-2924564a4fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-6406d75b-f2c3-451c-b71e-e7c69ffdc4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-14dd0544-fa6e-4306-85fa-72b61a85c9be,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-193aa0cc-66fe-4378-a5fa-dd63fb9073a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-4340f0b1-d1d1-49e5-89f6-ab949e132a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-6c15077a-d98f-4c9a-a58e-fd2e990ffa38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709668260-172.17.0.8-1598196196633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43126,DS-91410c33-133f-432b-855d-278610528054,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-7c0188ee-99e2-466b-927a-39962f0e937d,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-8c152892-12a7-4426-a5d9-ba090808e24c,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-dcb60c43-01c3-4846-88ea-d00e01760dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-dd923008-7eb3-4a44-aae8-99501e089bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-a92e4368-1a2e-48e6-9c8c-d35883ea8831,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-7c597145-2edc-4897-92ba-92e3b8ea06a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-92a5918d-ed1e-481f-b314-bb483c690847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709668260-172.17.0.8-1598196196633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43126,DS-91410c33-133f-432b-855d-278610528054,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-7c0188ee-99e2-466b-927a-39962f0e937d,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-8c152892-12a7-4426-a5d9-ba090808e24c,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-dcb60c43-01c3-4846-88ea-d00e01760dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-dd923008-7eb3-4a44-aae8-99501e089bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-a92e4368-1a2e-48e6-9c8c-d35883ea8831,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-7c597145-2edc-4897-92ba-92e3b8ea06a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-92a5918d-ed1e-481f-b314-bb483c690847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181113736-172.17.0.8-1598196264942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43754,DS-a72c46cf-4a64-4cec-82db-e3aecc0ac3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-e9e6130e-ed1c-42c8-8774-8ceaa172454b,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-093e7b56-50a6-4b9b-aa4e-2ee6369b866e,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-1a4e3e6c-942f-40e9-aea3-1df81a8fa28f,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-fb5edbc9-0294-42ac-9074-06ea3c0ac7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-c50165cb-11ab-46aa-a5f6-dd2d234c81dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-6d3a8f2a-8f91-4698-a295-d5d6bc122577,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-ae20c0fb-2e85-4ca5-a955-739451d45908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181113736-172.17.0.8-1598196264942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43754,DS-a72c46cf-4a64-4cec-82db-e3aecc0ac3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-e9e6130e-ed1c-42c8-8774-8ceaa172454b,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-093e7b56-50a6-4b9b-aa4e-2ee6369b866e,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-1a4e3e6c-942f-40e9-aea3-1df81a8fa28f,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-fb5edbc9-0294-42ac-9074-06ea3c0ac7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-c50165cb-11ab-46aa-a5f6-dd2d234c81dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-6d3a8f2a-8f91-4698-a295-d5d6bc122577,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-ae20c0fb-2e85-4ca5-a955-739451d45908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582196541-172.17.0.8-1598196397531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41718,DS-aa439c57-484d-4700-90a3-488ec1b52747,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-c1155042-47ec-495d-bb1d-44271e00de7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-5ba88197-0e9e-4536-853f-fa91554eb465,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-6d3ec2c8-0071-4810-9a2b-48658652ce7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-9a01571b-e4d0-4b05-b622-36e4deafc78d,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-16790c10-b62b-46a4-bf8c-b341df3d5336,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-cc43c9ed-00f3-4703-bc25-d7e0dbb13030,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-ee9cf805-f9b8-43ba-b884-18d867a7bf42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582196541-172.17.0.8-1598196397531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41718,DS-aa439c57-484d-4700-90a3-488ec1b52747,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-c1155042-47ec-495d-bb1d-44271e00de7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-5ba88197-0e9e-4536-853f-fa91554eb465,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-6d3ec2c8-0071-4810-9a2b-48658652ce7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-9a01571b-e4d0-4b05-b622-36e4deafc78d,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-16790c10-b62b-46a4-bf8c-b341df3d5336,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-cc43c9ed-00f3-4703-bc25-d7e0dbb13030,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-ee9cf805-f9b8-43ba-b884-18d867a7bf42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538861804-172.17.0.8-1598196647593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37601,DS-6dd78f38-585a-4f70-a3ea-886262ed1eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-f10e2335-27e7-401f-927e-8a17e6bc2dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-84c6d40a-c9b5-4160-a7b7-819bd21f041f,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-69b1a865-e2ba-4d8d-bdc1-292548c6f09c,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-d1d6b6ce-2c70-4c64-8360-aed28c645e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-1d85c26b-7e47-4f2f-9282-50854e36b1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-cf8957f8-79ec-497c-a5f0-3456b047e372,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-dec86116-2966-4fd8-9534-9f19d0ca7eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538861804-172.17.0.8-1598196647593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37601,DS-6dd78f38-585a-4f70-a3ea-886262ed1eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-f10e2335-27e7-401f-927e-8a17e6bc2dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-84c6d40a-c9b5-4160-a7b7-819bd21f041f,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-69b1a865-e2ba-4d8d-bdc1-292548c6f09c,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-d1d6b6ce-2c70-4c64-8360-aed28c645e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-1d85c26b-7e47-4f2f-9282-50854e36b1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-cf8957f8-79ec-497c-a5f0-3456b047e372,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-dec86116-2966-4fd8-9534-9f19d0ca7eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559120142-172.17.0.8-1598196726647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39905,DS-5d9aa5fb-ae0a-4532-a6d7-dfdbecbf9b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-9c309962-a5d0-4d53-96d0-29632b6e8c17,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-f44b20c9-9430-4581-9826-e07fe6bcb3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-d3a6c516-c36a-4e89-9ee5-ee4ed83bf778,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-0112512f-41bc-41cd-9bbc-a993c6f7d3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-731964a3-284f-48f4-ab51-3efa46c2657f,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-0f6716f0-1288-4226-a3b5-d614f969531f,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-f747679e-758a-4951-88af-6e5570e66917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559120142-172.17.0.8-1598196726647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39905,DS-5d9aa5fb-ae0a-4532-a6d7-dfdbecbf9b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-9c309962-a5d0-4d53-96d0-29632b6e8c17,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-f44b20c9-9430-4581-9826-e07fe6bcb3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-d3a6c516-c36a-4e89-9ee5-ee4ed83bf778,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-0112512f-41bc-41cd-9bbc-a993c6f7d3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-731964a3-284f-48f4-ab51-3efa46c2657f,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-0f6716f0-1288-4226-a3b5-d614f969531f,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-f747679e-758a-4951-88af-6e5570e66917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300360365-172.17.0.8-1598196831810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35206,DS-0631a1c9-c128-48c3-9bb7-f37c6f212c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-d8e6b12f-ea38-4c66-8ebd-4ed5905468f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-4ff10d23-e406-4b52-862f-577f48bc0527,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-f3a38d60-c129-4435-a8a1-d5693f3f077c,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-6c73a06a-2b63-4fb2-9665-6745b992c381,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-bc9c84c2-15e1-4c29-aaed-17558e79491b,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-0ca733c8-af69-46cf-86d2-82e91651a798,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-3433c2c3-483e-497b-b156-c9b260f98a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300360365-172.17.0.8-1598196831810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35206,DS-0631a1c9-c128-48c3-9bb7-f37c6f212c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-d8e6b12f-ea38-4c66-8ebd-4ed5905468f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-4ff10d23-e406-4b52-862f-577f48bc0527,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-f3a38d60-c129-4435-a8a1-d5693f3f077c,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-6c73a06a-2b63-4fb2-9665-6745b992c381,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-bc9c84c2-15e1-4c29-aaed-17558e79491b,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-0ca733c8-af69-46cf-86d2-82e91651a798,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-3433c2c3-483e-497b-b156-c9b260f98a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87260207-172.17.0.8-1598197347441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45349,DS-4f773833-fca9-499d-b60d-cedbabe29f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-40a3c2a6-7538-4f1f-8007-8c6f51118ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-694c15f8-5040-45de-af5f-f3b3e689ca3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-a7794f50-d8e7-4c2e-a3d0-08ebd65488cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-ec1561c4-c1ad-4fd5-aae7-82141f8f97e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-091c1619-854c-4bf4-b4e8-89a06eb76c40,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-2585e3ba-f059-4188-a936-4f7dde8cdec7,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-55c18266-efa2-4c78-84a2-48b4d16997bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-87260207-172.17.0.8-1598197347441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45349,DS-4f773833-fca9-499d-b60d-cedbabe29f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-40a3c2a6-7538-4f1f-8007-8c6f51118ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-694c15f8-5040-45de-af5f-f3b3e689ca3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-a7794f50-d8e7-4c2e-a3d0-08ebd65488cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-ec1561c4-c1ad-4fd5-aae7-82141f8f97e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-091c1619-854c-4bf4-b4e8-89a06eb76c40,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-2585e3ba-f059-4188-a936-4f7dde8cdec7,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-55c18266-efa2-4c78-84a2-48b4d16997bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5337
