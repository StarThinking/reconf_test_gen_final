reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356728751-172.17.0.15-1598369486835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45025,DS-b17e608f-a886-4d19-aaaa-646759d29c11,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-3efe0e08-6c94-4977-9121-df7c32a33a22,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-c71b7533-59df-4cef-a48c-af35043939c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-7586c539-e597-4e50-a58b-c6f0b492fe4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-0bba6cfe-d23c-447d-b3e8-4d1a07b9acfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-f69af637-be2b-441a-bf77-6a8c390ca6de,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-0ced462f-c1bf-4853-8c74-c08f653116d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-d3b41c4c-c3a9-40c0-998c-e514c6ef8a07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356728751-172.17.0.15-1598369486835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45025,DS-b17e608f-a886-4d19-aaaa-646759d29c11,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-3efe0e08-6c94-4977-9121-df7c32a33a22,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-c71b7533-59df-4cef-a48c-af35043939c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-7586c539-e597-4e50-a58b-c6f0b492fe4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-0bba6cfe-d23c-447d-b3e8-4d1a07b9acfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-f69af637-be2b-441a-bf77-6a8c390ca6de,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-0ced462f-c1bf-4853-8c74-c08f653116d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-d3b41c4c-c3a9-40c0-998c-e514c6ef8a07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49576701-172.17.0.15-1598369517260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36724,DS-4bb3907c-a39e-4b55-861a-13d89fa89d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-d5e13766-ce6c-4e47-b4d1-e3889a29090e,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-e23c1f03-54c3-4a99-a7cd-dd270822c3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-ee5bd330-5b19-42d5-bf81-63f93bd7d4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-52988050-7992-4584-b68f-a953caf252e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-2ac1045f-1554-4c97-ad79-5a4ca9098367,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-9619e94c-5ff3-4da9-8d93-22d17003b863,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-3fd6a6e5-5e0a-4961-a56f-56b05645e9d8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49576701-172.17.0.15-1598369517260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36724,DS-4bb3907c-a39e-4b55-861a-13d89fa89d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-d5e13766-ce6c-4e47-b4d1-e3889a29090e,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-e23c1f03-54c3-4a99-a7cd-dd270822c3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-ee5bd330-5b19-42d5-bf81-63f93bd7d4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-52988050-7992-4584-b68f-a953caf252e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-2ac1045f-1554-4c97-ad79-5a4ca9098367,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-9619e94c-5ff3-4da9-8d93-22d17003b863,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-3fd6a6e5-5e0a-4961-a56f-56b05645e9d8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683087603-172.17.0.15-1598369552217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38518,DS-587cd263-9941-41f1-9bac-307c924973d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-9685e7f3-b9ed-4fb6-8434-7abe56b89ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-72879d4a-abcb-45a3-9f45-4a5af74aeecb,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-f9d5b038-b167-4ffc-93b0-5820d42fc716,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-bdec0bfa-d6d7-496a-839e-292c00faedef,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-3c6e911c-35b9-4002-b7ff-6c93f3b10f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-006253e5-5e94-4947-93fe-465bb18f22c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-658fd3d0-dc9d-4339-8063-fe7d06e682e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683087603-172.17.0.15-1598369552217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38518,DS-587cd263-9941-41f1-9bac-307c924973d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-9685e7f3-b9ed-4fb6-8434-7abe56b89ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-72879d4a-abcb-45a3-9f45-4a5af74aeecb,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-f9d5b038-b167-4ffc-93b0-5820d42fc716,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-bdec0bfa-d6d7-496a-839e-292c00faedef,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-3c6e911c-35b9-4002-b7ff-6c93f3b10f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-006253e5-5e94-4947-93fe-465bb18f22c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-658fd3d0-dc9d-4339-8063-fe7d06e682e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389223701-172.17.0.15-1598369714900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38034,DS-727df287-4ef1-4c33-a081-370e1191fc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-2ed17138-22cf-45b0-a98f-139b8e3cb427,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-44884c5b-85fa-471d-a03d-576a9d646d31,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-98bc6025-a167-4f08-9126-3d283087717e,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-f4bdaa34-26b3-4feb-9ad7-9680f09f6839,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-e6dc39e1-a0f1-441e-906b-177f347d39a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-ceaaf195-937b-4119-873d-52137aa315f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-27576488-58c0-4fb9-b2ed-970a33bd9aee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389223701-172.17.0.15-1598369714900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38034,DS-727df287-4ef1-4c33-a081-370e1191fc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-2ed17138-22cf-45b0-a98f-139b8e3cb427,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-44884c5b-85fa-471d-a03d-576a9d646d31,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-98bc6025-a167-4f08-9126-3d283087717e,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-f4bdaa34-26b3-4feb-9ad7-9680f09f6839,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-e6dc39e1-a0f1-441e-906b-177f347d39a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-ceaaf195-937b-4119-873d-52137aa315f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-27576488-58c0-4fb9-b2ed-970a33bd9aee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175863489-172.17.0.15-1598369822703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34913,DS-55088f25-dc6b-4ac4-b8a1-b372197d10ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-b1c6b60e-a531-47bf-9111-c7eea001a3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-396acd2d-b71b-48eb-97f8-26d884015d42,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-405c6d3f-2826-43fd-8ec3-6c5d4b9f0b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-1534b47c-010b-428c-a1fe-f51bc7f9b649,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-f7ca737f-3a58-4f32-8ef1-3b28e7b1c193,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-e41bbbc0-aefa-4a92-97dd-91e3128efda0,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-1dfbdf0c-6a89-46c3-9582-07149c88e1f8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175863489-172.17.0.15-1598369822703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34913,DS-55088f25-dc6b-4ac4-b8a1-b372197d10ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-b1c6b60e-a531-47bf-9111-c7eea001a3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-396acd2d-b71b-48eb-97f8-26d884015d42,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-405c6d3f-2826-43fd-8ec3-6c5d4b9f0b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-1534b47c-010b-428c-a1fe-f51bc7f9b649,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-f7ca737f-3a58-4f32-8ef1-3b28e7b1c193,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-e41bbbc0-aefa-4a92-97dd-91e3128efda0,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-1dfbdf0c-6a89-46c3-9582-07149c88e1f8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416150417-172.17.0.15-1598370130751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46296,DS-8316b82c-04aa-4feb-aa30-8407676876b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-7f29a7fc-4ab6-4a77-8a62-8cf0fead8004,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-3631935f-a4ef-4969-a346-58b198e09f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-9706d623-b233-4371-b78d-f7c50f55033d,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-74c05734-d8b3-43c5-aa4e-4f2d354d60b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-dcde7cd0-60d4-4fb6-998a-2a0e09002a59,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-577959c6-f214-4bb9-8db2-f6798cd6f332,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-c7adf7dd-7072-4364-83ec-50823943d8cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416150417-172.17.0.15-1598370130751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46296,DS-8316b82c-04aa-4feb-aa30-8407676876b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-7f29a7fc-4ab6-4a77-8a62-8cf0fead8004,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-3631935f-a4ef-4969-a346-58b198e09f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-9706d623-b233-4371-b78d-f7c50f55033d,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-74c05734-d8b3-43c5-aa4e-4f2d354d60b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-dcde7cd0-60d4-4fb6-998a-2a0e09002a59,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-577959c6-f214-4bb9-8db2-f6798cd6f332,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-c7adf7dd-7072-4364-83ec-50823943d8cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349997509-172.17.0.15-1598370574458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34380,DS-69df3fbc-14d2-4251-96be-89590b0c40a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-5dbb6363-60fa-4a2e-8fc8-5e84d8e44fac,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-6bd4dd5b-0f82-4d56-baf9-c0ac88b47875,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-b58212f1-237c-4af1-a724-bc9e830ddc72,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-63a5b5ba-6709-4572-8e0b-1ae1028d82ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-ebdfe351-4680-4ba4-9baa-614076c70a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-aeb3d67a-fa17-457c-91d6-58e5fa59b2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-e6398646-5c0f-41ea-96fc-6f3d8299ddbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349997509-172.17.0.15-1598370574458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34380,DS-69df3fbc-14d2-4251-96be-89590b0c40a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-5dbb6363-60fa-4a2e-8fc8-5e84d8e44fac,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-6bd4dd5b-0f82-4d56-baf9-c0ac88b47875,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-b58212f1-237c-4af1-a724-bc9e830ddc72,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-63a5b5ba-6709-4572-8e0b-1ae1028d82ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-ebdfe351-4680-4ba4-9baa-614076c70a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-aeb3d67a-fa17-457c-91d6-58e5fa59b2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-e6398646-5c0f-41ea-96fc-6f3d8299ddbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361054635-172.17.0.15-1598370763168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46085,DS-35e7f6af-16e0-45b8-ac56-aee3d5c2c6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-0bc88eef-4c6b-470f-a7cf-a09c1916d191,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-7dc93f4a-89e8-4265-b287-f0d73a23da3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-1859dc94-e4f5-4dfa-9ca9-0026c9f935a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-8a098d75-5de2-47db-bd87-ebbd15587827,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-0bbe0b03-10e7-4a91-b44c-45f35d515036,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-813b919f-061d-495f-9b70-d1a505d098c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-1fa39e42-c318-4e56-b8b3-6b3c95ee05e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361054635-172.17.0.15-1598370763168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46085,DS-35e7f6af-16e0-45b8-ac56-aee3d5c2c6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-0bc88eef-4c6b-470f-a7cf-a09c1916d191,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-7dc93f4a-89e8-4265-b287-f0d73a23da3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-1859dc94-e4f5-4dfa-9ca9-0026c9f935a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-8a098d75-5de2-47db-bd87-ebbd15587827,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-0bbe0b03-10e7-4a91-b44c-45f35d515036,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-813b919f-061d-495f-9b70-d1a505d098c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-1fa39e42-c318-4e56-b8b3-6b3c95ee05e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851790544-172.17.0.15-1598370842844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38422,DS-638b3a55-b89a-4be2-af64-fd1b15e24755,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-19e99fbb-273a-4e2e-b701-292bd9cecfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-83c31ffd-302a-4522-a29c-86ee93401f87,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-9f35f5e1-5ff6-471b-b1c2-728d4e634634,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-74c789ae-a09f-48ff-9dc3-48b7004b96ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-c47036cc-7b6c-42b5-88df-bca6bed672a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-b22eca4d-3e7b-4ff8-8cc2-0982d566c9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-e3d953de-aa8a-4a5c-a284-6f626929807f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851790544-172.17.0.15-1598370842844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38422,DS-638b3a55-b89a-4be2-af64-fd1b15e24755,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-19e99fbb-273a-4e2e-b701-292bd9cecfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-83c31ffd-302a-4522-a29c-86ee93401f87,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-9f35f5e1-5ff6-471b-b1c2-728d4e634634,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-74c789ae-a09f-48ff-9dc3-48b7004b96ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-c47036cc-7b6c-42b5-88df-bca6bed672a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-b22eca4d-3e7b-4ff8-8cc2-0982d566c9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-e3d953de-aa8a-4a5c-a284-6f626929807f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748627066-172.17.0.15-1598370958677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-d559eb76-af6e-4f42-9673-39ee11d90d11,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-adb99127-0049-40c9-b68f-1b53619454d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-1f4840e7-6e09-44e6-9a1e-626d311c3314,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-e04803bc-adb6-4a30-b935-5419e78dabf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-115769d4-a2fc-4a93-8bbd-bfcd59297626,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-6241b4cd-0f05-4226-8896-ce124c48b840,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-c215df08-51ef-43cb-8c77-8680c796f337,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-e9d81a5c-85a8-42be-9857-094c4f30c3ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748627066-172.17.0.15-1598370958677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-d559eb76-af6e-4f42-9673-39ee11d90d11,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-adb99127-0049-40c9-b68f-1b53619454d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-1f4840e7-6e09-44e6-9a1e-626d311c3314,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-e04803bc-adb6-4a30-b935-5419e78dabf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-115769d4-a2fc-4a93-8bbd-bfcd59297626,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-6241b4cd-0f05-4226-8896-ce124c48b840,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-c215df08-51ef-43cb-8c77-8680c796f337,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-e9d81a5c-85a8-42be-9857-094c4f30c3ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269805202-172.17.0.15-1598371108823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38135,DS-4adb1520-981b-4555-a168-99e02a8fb006,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-06961d2e-ec40-4877-8b74-e7db0a74d6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-9f98ca74-0376-470b-8637-5c96180077af,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-bb8aae95-27db-4023-81e2-9fe0e8413916,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-09d421a2-284d-410e-99de-f6e82b2fc047,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-0e876079-4640-4dea-b68f-7b08e89b8c09,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-28f390c2-a835-4591-a597-6817c5c9dff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-9f947d3c-810c-45df-9f7a-056cd03985b0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269805202-172.17.0.15-1598371108823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38135,DS-4adb1520-981b-4555-a168-99e02a8fb006,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-06961d2e-ec40-4877-8b74-e7db0a74d6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-9f98ca74-0376-470b-8637-5c96180077af,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-bb8aae95-27db-4023-81e2-9fe0e8413916,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-09d421a2-284d-410e-99de-f6e82b2fc047,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-0e876079-4640-4dea-b68f-7b08e89b8c09,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-28f390c2-a835-4591-a597-6817c5c9dff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-9f947d3c-810c-45df-9f7a-056cd03985b0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1513720866-172.17.0.15-1598371224489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39361,DS-a4610432-57ca-4bd4-be72-ae947578f2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-a0d7499d-fe55-4ccb-bc41-9c486f26544d,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-159a5085-4b48-4034-9494-cd11b792c02b,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-8d168e99-54a1-475a-bb7d-e9514508e230,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-e4c6eb34-e33c-461e-84a4-b3935f908f57,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-ded890ad-85ea-42d3-9d66-e33634e50dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-d49fe529-4f35-4372-9b1f-2511dae4509b,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-9cdb0f62-508c-480e-8ff4-2f8e8be3b257,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1513720866-172.17.0.15-1598371224489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39361,DS-a4610432-57ca-4bd4-be72-ae947578f2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-a0d7499d-fe55-4ccb-bc41-9c486f26544d,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-159a5085-4b48-4034-9494-cd11b792c02b,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-8d168e99-54a1-475a-bb7d-e9514508e230,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-e4c6eb34-e33c-461e-84a4-b3935f908f57,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-ded890ad-85ea-42d3-9d66-e33634e50dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-d49fe529-4f35-4372-9b1f-2511dae4509b,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-9cdb0f62-508c-480e-8ff4-2f8e8be3b257,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717897271-172.17.0.15-1598371296816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43240,DS-26255d6e-159e-4639-9ae4-e352003654c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-2391fe9c-0b02-4a16-bf52-27936ca0ce8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-113ee04a-5252-4ad5-89cc-5e383103cf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-5a40a806-28cc-49ef-90c2-4b0491a8d112,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-fa03bf4f-1864-4603-b7f2-6aa86f08ab9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-df203f9f-5f91-45fa-9756-09c7e18b81c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-676f0261-1d86-4638-9e34-bd2c9eaae397,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-2accd7d1-ea2d-46b2-95e6-b8a3bf272486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717897271-172.17.0.15-1598371296816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43240,DS-26255d6e-159e-4639-9ae4-e352003654c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-2391fe9c-0b02-4a16-bf52-27936ca0ce8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-113ee04a-5252-4ad5-89cc-5e383103cf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-5a40a806-28cc-49ef-90c2-4b0491a8d112,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-fa03bf4f-1864-4603-b7f2-6aa86f08ab9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-df203f9f-5f91-45fa-9756-09c7e18b81c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-676f0261-1d86-4638-9e34-bd2c9eaae397,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-2accd7d1-ea2d-46b2-95e6-b8a3bf272486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331432531-172.17.0.15-1598371411848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36202,DS-91a81525-7592-40ae-818b-4052bcedbbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-18f36486-9bf1-43db-8097-5d4e1950c3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-8f8c04b8-d840-43cc-a54e-dfdb2c414654,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-e9003d1b-979e-43a8-9236-0125450bff2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-c566a9c7-f4a4-4d27-8a29-f95a3861d7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-5660e798-3ba5-43c4-95c3-0a2d45167227,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-41c21ede-50e3-4bf9-a11b-43026d4033e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-eaa03a8b-5251-4bc5-8e9b-a7b683dec92e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331432531-172.17.0.15-1598371411848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36202,DS-91a81525-7592-40ae-818b-4052bcedbbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-18f36486-9bf1-43db-8097-5d4e1950c3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-8f8c04b8-d840-43cc-a54e-dfdb2c414654,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-e9003d1b-979e-43a8-9236-0125450bff2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-c566a9c7-f4a4-4d27-8a29-f95a3861d7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-5660e798-3ba5-43c4-95c3-0a2d45167227,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-41c21ede-50e3-4bf9-a11b-43026d4033e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-eaa03a8b-5251-4bc5-8e9b-a7b683dec92e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489859507-172.17.0.15-1598371511624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42833,DS-7a8f48a1-e2dd-460b-bd09-ada052fe33b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-fca7b754-499f-4ae6-80d9-27d70cd0f1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-88da5814-5ff0-47b4-9078-075dd0f40ece,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-e11579a8-06b5-4e28-8d4b-6cf55e089e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-575b6b42-045f-4657-a36e-455184ba960e,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-37ecbc32-af29-448d-b5f8-a8c0509b1f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-7ab9d594-04d4-4518-8551-1603b1af5797,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-1520bef7-f2e2-4944-9434-96063b5737a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489859507-172.17.0.15-1598371511624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42833,DS-7a8f48a1-e2dd-460b-bd09-ada052fe33b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-fca7b754-499f-4ae6-80d9-27d70cd0f1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-88da5814-5ff0-47b4-9078-075dd0f40ece,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-e11579a8-06b5-4e28-8d4b-6cf55e089e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-575b6b42-045f-4657-a36e-455184ba960e,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-37ecbc32-af29-448d-b5f8-a8c0509b1f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-7ab9d594-04d4-4518-8551-1603b1af5797,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-1520bef7-f2e2-4944-9434-96063b5737a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736937790-172.17.0.15-1598371689833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34919,DS-2a94f1c0-f18f-4d4f-96ec-23c574dcbb00,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-b5cd3832-22dc-45fd-aa97-631a8e11f9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-92d355ab-ddd8-4ef1-8567-9d8a3458b6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-c2bb6d09-a2bc-48bd-9551-19e96c0a6229,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-df623579-751a-41a7-be6e-7eb83b1fe562,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-5e24d52b-8024-4efc-b1b4-3ae4fe0a4bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-b2e1f649-220f-4fb1-b7ab-a0a4785e6aee,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-7657c077-263c-4ded-b0b6-e594f49b843b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736937790-172.17.0.15-1598371689833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34919,DS-2a94f1c0-f18f-4d4f-96ec-23c574dcbb00,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-b5cd3832-22dc-45fd-aa97-631a8e11f9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-92d355ab-ddd8-4ef1-8567-9d8a3458b6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-c2bb6d09-a2bc-48bd-9551-19e96c0a6229,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-df623579-751a-41a7-be6e-7eb83b1fe562,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-5e24d52b-8024-4efc-b1b4-3ae4fe0a4bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-b2e1f649-220f-4fb1-b7ab-a0a4785e6aee,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-7657c077-263c-4ded-b0b6-e594f49b843b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632672913-172.17.0.15-1598371892468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42160,DS-d989fa5b-258b-4ded-9ac1-88f727753fac,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-474d0891-558d-48e1-aca1-cbe1dd1f3452,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-6ea2cbea-720c-4bf2-ae98-4dd033e705cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-1c01a0aa-ed34-4fdd-a560-90e5a9a394cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-942f4630-2b7f-4bb4-be55-59588d217e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-aa95da76-38cb-421b-81f7-03f8037e46fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-fc9a4161-57e7-4aa8-9c8f-a97adc3194b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-dcaad93c-578e-4299-a9da-53c842eee01a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632672913-172.17.0.15-1598371892468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42160,DS-d989fa5b-258b-4ded-9ac1-88f727753fac,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-474d0891-558d-48e1-aca1-cbe1dd1f3452,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-6ea2cbea-720c-4bf2-ae98-4dd033e705cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-1c01a0aa-ed34-4fdd-a560-90e5a9a394cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-942f4630-2b7f-4bb4-be55-59588d217e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-aa95da76-38cb-421b-81f7-03f8037e46fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-fc9a4161-57e7-4aa8-9c8f-a97adc3194b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-dcaad93c-578e-4299-a9da-53c842eee01a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-633738824-172.17.0.15-1598372010089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44924,DS-cbbc1142-1a05-4a09-a139-137c568bdf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-debd1b25-d202-4c02-a8c5-d0bbe420ad9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-12c570b4-b9c9-44fb-9727-5727dd56319f,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-48e34bcb-7db0-4ce7-9ffc-3e7540c62377,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-a5a1cd3f-d073-4e49-be6b-89fca890ca49,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-7c61fa29-073f-4fd3-8f11-6f3978a41099,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-cc62a64c-8305-4f85-a10f-7bf4ad1805ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-a1451d30-94c5-4509-87ec-6fa7c17cfab6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-633738824-172.17.0.15-1598372010089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44924,DS-cbbc1142-1a05-4a09-a139-137c568bdf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-debd1b25-d202-4c02-a8c5-d0bbe420ad9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-12c570b4-b9c9-44fb-9727-5727dd56319f,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-48e34bcb-7db0-4ce7-9ffc-3e7540c62377,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-a5a1cd3f-d073-4e49-be6b-89fca890ca49,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-7c61fa29-073f-4fd3-8f11-6f3978a41099,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-cc62a64c-8305-4f85-a10f-7bf4ad1805ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-a1451d30-94c5-4509-87ec-6fa7c17cfab6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342711999-172.17.0.15-1598372043071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39864,DS-9fe67bfc-eacb-4442-b5e7-8c938fe9340f,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-b827b761-9bd5-4994-9fe8-0c748ed2fa54,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-987dad07-d8e5-42ec-8296-553109937ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-23bbe9c0-8aa3-4971-9891-ccbf4c6f1253,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-b257327d-f533-477b-894b-d2c892b01d00,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-ef11d9fd-db07-40eb-aa6e-ff910575fa28,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-f629bab4-bd6c-467e-b402-fc8e4bbfdef5,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-e8c8cc1c-7f9b-4162-a575-394627ae03e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342711999-172.17.0.15-1598372043071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39864,DS-9fe67bfc-eacb-4442-b5e7-8c938fe9340f,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-b827b761-9bd5-4994-9fe8-0c748ed2fa54,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-987dad07-d8e5-42ec-8296-553109937ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-23bbe9c0-8aa3-4971-9891-ccbf4c6f1253,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-b257327d-f533-477b-894b-d2c892b01d00,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-ef11d9fd-db07-40eb-aa6e-ff910575fa28,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-f629bab4-bd6c-467e-b402-fc8e4bbfdef5,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-e8c8cc1c-7f9b-4162-a575-394627ae03e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678410883-172.17.0.15-1598372103601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46346,DS-591b7528-ea4f-4ec0-8702-78c36852ae67,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-92e142dd-3314-4b1d-afbf-928fb5753350,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-d1dc279e-de6a-4507-9fd4-d5a4e888b881,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-6feb3fb8-684a-4259-9487-33700709b1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-11f12ce2-b270-4a0f-802c-7b77da8da5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-7660bdcc-ae8d-4481-a721-1e61fbdfe4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-395f6b57-20b7-42cd-818e-d37a1ce81daf,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-c48c535d-7089-4c1c-9e08-c3b57fb86d64,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678410883-172.17.0.15-1598372103601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46346,DS-591b7528-ea4f-4ec0-8702-78c36852ae67,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-92e142dd-3314-4b1d-afbf-928fb5753350,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-d1dc279e-de6a-4507-9fd4-d5a4e888b881,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-6feb3fb8-684a-4259-9487-33700709b1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-11f12ce2-b270-4a0f-802c-7b77da8da5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-7660bdcc-ae8d-4481-a721-1e61fbdfe4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-395f6b57-20b7-42cd-818e-d37a1ce81daf,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-c48c535d-7089-4c1c-9e08-c3b57fb86d64,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268836441-172.17.0.15-1598372404907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37271,DS-07a05385-6e8d-45b6-8371-0cd25ff61e97,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-0cf585f5-ae4b-45ab-ae1a-5241514785a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-8a7da918-9d96-4e6d-a030-eee9b8282a20,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-fe025ee9-2f95-4429-b903-33e7b0d68dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-28a036d7-71ec-4396-84f7-e63a2821e28d,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-55192bc8-b060-49fb-ae95-d39e81b9fd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-60572ee5-73b5-4373-a27c-44b9d0e54d43,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-7975fa19-96fb-4f89-9b60-20918d81d485,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268836441-172.17.0.15-1598372404907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37271,DS-07a05385-6e8d-45b6-8371-0cd25ff61e97,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-0cf585f5-ae4b-45ab-ae1a-5241514785a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-8a7da918-9d96-4e6d-a030-eee9b8282a20,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-fe025ee9-2f95-4429-b903-33e7b0d68dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-28a036d7-71ec-4396-84f7-e63a2821e28d,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-55192bc8-b060-49fb-ae95-d39e81b9fd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-60572ee5-73b5-4373-a27c-44b9d0e54d43,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-7975fa19-96fb-4f89-9b60-20918d81d485,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971309743-172.17.0.15-1598372484126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33122,DS-4f2621f1-f169-4af6-b948-1351bfd05640,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-d388874b-7380-404c-91d0-bef968f91311,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-cbca744a-f26d-45f1-b068-0b5e261bfd34,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-9fb57a92-e75b-4248-b9f6-e7d340299ede,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-505fb980-54b4-491c-8d02-9aa6fb1804f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-725f23a0-66ba-4beb-9dc6-852fae2f054f,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-6b7cdf82-d60d-4aeb-97f6-083ee73eec49,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-f96d7575-4b51-40fe-aa64-21d39349f5c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971309743-172.17.0.15-1598372484126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33122,DS-4f2621f1-f169-4af6-b948-1351bfd05640,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-d388874b-7380-404c-91d0-bef968f91311,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-cbca744a-f26d-45f1-b068-0b5e261bfd34,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-9fb57a92-e75b-4248-b9f6-e7d340299ede,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-505fb980-54b4-491c-8d02-9aa6fb1804f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-725f23a0-66ba-4beb-9dc6-852fae2f054f,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-6b7cdf82-d60d-4aeb-97f6-083ee73eec49,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-f96d7575-4b51-40fe-aa64-21d39349f5c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403581419-172.17.0.15-1598372727217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44953,DS-09043bc4-9fc5-432c-ab9e-44b75c028fed,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-a14f9e50-4e48-4ea5-a501-3361843e90f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-11976f7b-3f47-4669-bec5-6317c6d3a421,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-c889d067-2c46-454a-9ec9-c9c540eecb42,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-fe4ecf61-ec1a-4b76-8290-8f7306b9f84d,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-0a60db08-d4ca-468f-933a-fd01a9a8efd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-8509775c-f3b9-42a7-a679-4d5b3e0788f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-bd21bf34-3978-4714-825a-8d12842653d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403581419-172.17.0.15-1598372727217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44953,DS-09043bc4-9fc5-432c-ab9e-44b75c028fed,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-a14f9e50-4e48-4ea5-a501-3361843e90f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-11976f7b-3f47-4669-bec5-6317c6d3a421,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-c889d067-2c46-454a-9ec9-c9c540eecb42,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-fe4ecf61-ec1a-4b76-8290-8f7306b9f84d,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-0a60db08-d4ca-468f-933a-fd01a9a8efd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-8509775c-f3b9-42a7-a679-4d5b3e0788f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-bd21bf34-3978-4714-825a-8d12842653d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392116782-172.17.0.15-1598372800865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38469,DS-80e8e467-213e-4a1f-805a-19a3b5ae6c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-5ffdc586-c6ee-4ddd-a461-b981e9edc29c,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-62ea0813-78f8-4385-95f6-2756ac5a9f83,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-7ad83411-2aca-465a-9612-9ccccbf30f89,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-080fab9b-39ec-43fd-b2dd-94d381115e91,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-066aec06-bb31-42de-afb3-27772273d363,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-153088d4-d17f-48a7-9955-b99b39270977,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-5998b7db-2290-48ec-a572-cc6644819fe6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392116782-172.17.0.15-1598372800865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38469,DS-80e8e467-213e-4a1f-805a-19a3b5ae6c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-5ffdc586-c6ee-4ddd-a461-b981e9edc29c,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-62ea0813-78f8-4385-95f6-2756ac5a9f83,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-7ad83411-2aca-465a-9612-9ccccbf30f89,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-080fab9b-39ec-43fd-b2dd-94d381115e91,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-066aec06-bb31-42de-afb3-27772273d363,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-153088d4-d17f-48a7-9955-b99b39270977,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-5998b7db-2290-48ec-a572-cc6644819fe6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724155382-172.17.0.15-1598373104048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33036,DS-653de772-3051-42ef-a01e-72c0494f7829,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-848464de-86e2-4183-b08b-fb5e7e8657f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-0822eb7e-ffea-4da8-bc66-4af6c44cd731,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-bee3359d-7275-4cdd-95b1-77293225fb69,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-2e46713c-e557-405c-a921-1011449a636b,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-61706684-7e9b-438e-8182-d4aae0fd6872,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-d00bbd45-2d60-4383-80f2-e9d978d176e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-6cefe2d1-b7c5-4a0c-a4d4-b3d7e36118d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724155382-172.17.0.15-1598373104048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33036,DS-653de772-3051-42ef-a01e-72c0494f7829,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-848464de-86e2-4183-b08b-fb5e7e8657f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-0822eb7e-ffea-4da8-bc66-4af6c44cd731,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-bee3359d-7275-4cdd-95b1-77293225fb69,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-2e46713c-e557-405c-a921-1011449a636b,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-61706684-7e9b-438e-8182-d4aae0fd6872,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-d00bbd45-2d60-4383-80f2-e9d978d176e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-6cefe2d1-b7c5-4a0c-a4d4-b3d7e36118d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951696569-172.17.0.15-1598373333653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41754,DS-62505936-cf30-4034-b30c-6bf3f72e8c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-95a22109-5712-4586-adf4-312dd424ac98,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-2cbf9a02-f8b6-4d9a-9b12-cd9c16cdc467,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-a45a5475-e888-416d-9906-f1705e470f00,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-de8524a0-c8ce-4d25-bb27-6d27307e3cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-b1ea9e57-8903-437f-bbcf-e4ce8e6d79c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-c339532b-68a9-4b9b-82bf-3d922188b4de,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-0aa9db93-f2b2-46d2-aeba-8fd7fbae3a22,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951696569-172.17.0.15-1598373333653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41754,DS-62505936-cf30-4034-b30c-6bf3f72e8c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-95a22109-5712-4586-adf4-312dd424ac98,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-2cbf9a02-f8b6-4d9a-9b12-cd9c16cdc467,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-a45a5475-e888-416d-9906-f1705e470f00,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-de8524a0-c8ce-4d25-bb27-6d27307e3cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-b1ea9e57-8903-437f-bbcf-e4ce8e6d79c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-c339532b-68a9-4b9b-82bf-3d922188b4de,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-0aa9db93-f2b2-46d2-aeba-8fd7fbae3a22,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670342236-172.17.0.15-1598373364973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44735,DS-c7380bf9-0c62-4685-aebe-df2ade1a1c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-68d27f39-a7cd-49f7-b36b-fc7ae12c3d86,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-b2d3b131-f4d4-41d4-9f25-06c10b511aae,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-6f176691-5d6a-4f76-bf77-ed5b36529e57,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-7919b13b-206a-4595-b4ec-871987d8f6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-42d0b6fd-d218-44f8-87e7-95c69fd77422,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-15371806-111c-434a-90e8-2a3bca5bc7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-0e883d32-21df-46d1-b8c6-314f113a0246,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670342236-172.17.0.15-1598373364973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44735,DS-c7380bf9-0c62-4685-aebe-df2ade1a1c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-68d27f39-a7cd-49f7-b36b-fc7ae12c3d86,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-b2d3b131-f4d4-41d4-9f25-06c10b511aae,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-6f176691-5d6a-4f76-bf77-ed5b36529e57,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-7919b13b-206a-4595-b4ec-871987d8f6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-42d0b6fd-d218-44f8-87e7-95c69fd77422,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-15371806-111c-434a-90e8-2a3bca5bc7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-0e883d32-21df-46d1-b8c6-314f113a0246,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54756943-172.17.0.15-1598373724646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43053,DS-fd326371-eb94-4a7b-8b0b-ed045c619ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-dc018534-2514-40f6-a7a7-1d736358cb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-c6cc958a-c77e-4afc-9efa-dad515cc6305,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-880d3492-5259-4813-a197-83b2c97a5be3,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-6ddd21e4-a308-4db5-a0c0-8a9d15b83d62,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-3d1fa074-baf6-4ff3-a4d9-2b2771028836,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-35dae46a-5c72-4229-9502-a783e05bcf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-25c46e19-2b4d-4b33-bde3-d8bd9f0bf944,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54756943-172.17.0.15-1598373724646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43053,DS-fd326371-eb94-4a7b-8b0b-ed045c619ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-dc018534-2514-40f6-a7a7-1d736358cb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-c6cc958a-c77e-4afc-9efa-dad515cc6305,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-880d3492-5259-4813-a197-83b2c97a5be3,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-6ddd21e4-a308-4db5-a0c0-8a9d15b83d62,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-3d1fa074-baf6-4ff3-a4d9-2b2771028836,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-35dae46a-5c72-4229-9502-a783e05bcf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-25c46e19-2b4d-4b33-bde3-d8bd9f0bf944,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076733101-172.17.0.15-1598373829107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36593,DS-e68d3919-9ed8-4b47-ad5a-157fa8a706bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-e02dcf73-f423-4a51-a63e-127e5f9a6772,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-a5fb74e6-f7fd-4101-b1b7-6fe19985016d,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-dc4fa819-fd5f-4736-b92c-d71d03ba4e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-5776708c-8c00-4617-bd32-25a3ac2ea0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-80c5cc75-416e-45bf-a682-5c48b3ed055d,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-18b2bfb0-0576-4b07-9c5b-35a4b088fcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-c25a2e7e-57fd-4804-a902-1f64795286b5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076733101-172.17.0.15-1598373829107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36593,DS-e68d3919-9ed8-4b47-ad5a-157fa8a706bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-e02dcf73-f423-4a51-a63e-127e5f9a6772,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-a5fb74e6-f7fd-4101-b1b7-6fe19985016d,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-dc4fa819-fd5f-4736-b92c-d71d03ba4e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-5776708c-8c00-4617-bd32-25a3ac2ea0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-80c5cc75-416e-45bf-a682-5c48b3ed055d,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-18b2bfb0-0576-4b07-9c5b-35a4b088fcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-c25a2e7e-57fd-4804-a902-1f64795286b5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416224395-172.17.0.15-1598373970632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42873,DS-6fe04b7d-0140-443b-b2c3-a469a2ae0468,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-f371a23f-67a3-4b69-8c61-48bb4742ebaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-6c063ba8-7c62-4396-ab4d-0142bea309df,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-369ff649-f0dc-4e0a-a8f4-847b99420997,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-fdde724b-7867-439a-9ddc-d27c681b7d57,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-244e2b08-013a-462e-8a82-f546a1446cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-ff26b17d-8c0c-4318-99fd-df455b11b0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-ac2fcdf1-e464-4a0c-973d-8fdd2e644a3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416224395-172.17.0.15-1598373970632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42873,DS-6fe04b7d-0140-443b-b2c3-a469a2ae0468,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-f371a23f-67a3-4b69-8c61-48bb4742ebaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-6c063ba8-7c62-4396-ab4d-0142bea309df,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-369ff649-f0dc-4e0a-a8f4-847b99420997,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-fdde724b-7867-439a-9ddc-d27c681b7d57,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-244e2b08-013a-462e-8a82-f546a1446cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-ff26b17d-8c0c-4318-99fd-df455b11b0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-ac2fcdf1-e464-4a0c-973d-8fdd2e644a3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030334452-172.17.0.15-1598374148755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45204,DS-10d8f8cd-23ed-46b4-9d2e-7b272a1db6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-219267e5-b55d-4d02-8b6b-66ee68fd1eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-91bb412d-17ac-4f61-94a3-14b6520702de,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-ae0cea05-4424-44ef-b243-24ebad66d2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-c6f49d55-2910-461a-be20-bfb72147cfbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-ca06ccc2-5274-4a8e-b92e-900e4eb87ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-f1665d99-b2dd-4bc4-87a4-62d746c7b6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-dedd510a-cfe5-48c3-b87b-6b64f325bcb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030334452-172.17.0.15-1598374148755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45204,DS-10d8f8cd-23ed-46b4-9d2e-7b272a1db6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-219267e5-b55d-4d02-8b6b-66ee68fd1eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-91bb412d-17ac-4f61-94a3-14b6520702de,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-ae0cea05-4424-44ef-b243-24ebad66d2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-c6f49d55-2910-461a-be20-bfb72147cfbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-ca06ccc2-5274-4a8e-b92e-900e4eb87ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-f1665d99-b2dd-4bc4-87a4-62d746c7b6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-dedd510a-cfe5-48c3-b87b-6b64f325bcb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427724582-172.17.0.15-1598374679503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35357,DS-e3c5c0e7-1217-4723-b35f-f945e4660ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-38597fd1-0627-42e8-9e2f-db8a05e9a280,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-1158a42f-64f5-4e04-9bf7-99d32be129f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-15398043-fdf9-4f4f-bbfe-62f95a57aaed,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-f2626f46-ab03-4f2c-8980-814227c09865,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-74c06bd7-a7e8-4f8f-aa70-bb764cde262e,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-6e4377aa-299c-4b19-99cb-bccf55ac7d42,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-63cd4742-3507-4807-b9fd-086c956c9bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427724582-172.17.0.15-1598374679503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35357,DS-e3c5c0e7-1217-4723-b35f-f945e4660ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-38597fd1-0627-42e8-9e2f-db8a05e9a280,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-1158a42f-64f5-4e04-9bf7-99d32be129f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-15398043-fdf9-4f4f-bbfe-62f95a57aaed,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-f2626f46-ab03-4f2c-8980-814227c09865,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-74c06bd7-a7e8-4f8f-aa70-bb764cde262e,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-6e4377aa-299c-4b19-99cb-bccf55ac7d42,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-63cd4742-3507-4807-b9fd-086c956c9bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404881699-172.17.0.15-1598374750958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40172,DS-97f13990-8abc-437e-8ad5-71a1f14a7f78,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-e5045bbc-31f0-477d-a38e-de63a101d944,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-d5da2e0d-a9f8-4f02-823b-db60e29ee775,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-f836ad1f-2dbb-45b8-8096-f1a35fd5976f,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-4a3d332b-1ae4-41a7-9a12-d3b1ba92f4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-1660de5f-6a11-4e7f-a275-cb5045878d44,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-81d9050c-1ed6-417c-974d-3c79af76ee83,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-184e1786-7611-4051-b36c-989fcacc6681,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404881699-172.17.0.15-1598374750958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40172,DS-97f13990-8abc-437e-8ad5-71a1f14a7f78,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-e5045bbc-31f0-477d-a38e-de63a101d944,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-d5da2e0d-a9f8-4f02-823b-db60e29ee775,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-f836ad1f-2dbb-45b8-8096-f1a35fd5976f,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-4a3d332b-1ae4-41a7-9a12-d3b1ba92f4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-1660de5f-6a11-4e7f-a275-cb5045878d44,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-81d9050c-1ed6-417c-974d-3c79af76ee83,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-184e1786-7611-4051-b36c-989fcacc6681,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199190243-172.17.0.15-1598374860487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46759,DS-e340dbba-ae67-4ee3-9e81-13159cb0b14a,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-9326744f-fd61-45b4-9101-985ee442b3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-050080e3-b05d-48e6-8038-7fd4c0d0f264,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-b55057bd-9f65-4d74-a9db-3d9d893d8e43,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-10454370-ef60-49e8-b0d2-319b45516ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-b412b59d-53f2-4ebb-b8d8-7e9e48984f79,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-bc5b9983-532f-4031-88e1-3de1a8572dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-f3601108-6aba-4e53-baff-04ae45121952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199190243-172.17.0.15-1598374860487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46759,DS-e340dbba-ae67-4ee3-9e81-13159cb0b14a,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-9326744f-fd61-45b4-9101-985ee442b3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-050080e3-b05d-48e6-8038-7fd4c0d0f264,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-b55057bd-9f65-4d74-a9db-3d9d893d8e43,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-10454370-ef60-49e8-b0d2-319b45516ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-b412b59d-53f2-4ebb-b8d8-7e9e48984f79,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-bc5b9983-532f-4031-88e1-3de1a8572dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-f3601108-6aba-4e53-baff-04ae45121952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 5419
