reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618857320-172.17.0.17-1598111699341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-9330dd04-6374-418c-a18e-2612fd79e6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-fe2ae740-1009-465e-8262-acc50374347a,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-944a627a-20d4-4991-8ef4-1aab9f311258,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-5a4d989e-f2d6-4ccb-9ef0-3016e2b66f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-ac8abec4-63e6-4bea-a350-10acbcb13a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-db551aa8-3b03-40f4-944b-d688df043f90,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-def98f9b-c53b-4785-b4b3-4f65153f4919,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-2fced830-3001-4ab7-a6e8-5c388f9e88b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618857320-172.17.0.17-1598111699341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-9330dd04-6374-418c-a18e-2612fd79e6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-fe2ae740-1009-465e-8262-acc50374347a,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-944a627a-20d4-4991-8ef4-1aab9f311258,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-5a4d989e-f2d6-4ccb-9ef0-3016e2b66f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-ac8abec4-63e6-4bea-a350-10acbcb13a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-db551aa8-3b03-40f4-944b-d688df043f90,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-def98f9b-c53b-4785-b4b3-4f65153f4919,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-2fced830-3001-4ab7-a6e8-5c388f9e88b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969093271-172.17.0.17-1598111999513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44551,DS-16dfb644-500a-4acc-9cce-ec52d304b111,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-2e25ae58-c98a-4a5f-a3d8-a3e9a48c99e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-6acc719c-b207-4295-a221-fb51a88387f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-43e7bda4-63aa-4a86-bf70-ce1ecfbe0971,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-a92f0039-5864-43d4-bba1-0077a25e2eec,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-d78c91ab-a611-4741-aeae-88fedfbca383,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-7e9957df-ada7-4290-b1a5-0b057a1513ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-99a9d850-f267-4720-b455-03f4b97d740d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969093271-172.17.0.17-1598111999513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44551,DS-16dfb644-500a-4acc-9cce-ec52d304b111,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-2e25ae58-c98a-4a5f-a3d8-a3e9a48c99e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-6acc719c-b207-4295-a221-fb51a88387f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-43e7bda4-63aa-4a86-bf70-ce1ecfbe0971,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-a92f0039-5864-43d4-bba1-0077a25e2eec,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-d78c91ab-a611-4741-aeae-88fedfbca383,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-7e9957df-ada7-4290-b1a5-0b057a1513ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-99a9d850-f267-4720-b455-03f4b97d740d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1005255679-172.17.0.17-1598112040462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-ebee98f5-87a3-47ea-bea5-4eeac8bf6962,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-e61fe56b-0957-4c95-8a47-efd5fd884469,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-bb5eddd7-61fb-4146-b1a0-8ae58fb5b9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-6eea4d5c-ced0-4c61-af28-5b636bdadcba,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-4bb7d72b-8d51-4019-9ec1-d3356d23b5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-159af78d-dbb9-4f19-aaba-87e9b1c17a00,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-d88f6d92-2ba7-445d-a277-b53950d3ccdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-40dd4824-8b9c-4650-a8d1-21bf7c4dfef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1005255679-172.17.0.17-1598112040462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-ebee98f5-87a3-47ea-bea5-4eeac8bf6962,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-e61fe56b-0957-4c95-8a47-efd5fd884469,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-bb5eddd7-61fb-4146-b1a0-8ae58fb5b9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-6eea4d5c-ced0-4c61-af28-5b636bdadcba,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-4bb7d72b-8d51-4019-9ec1-d3356d23b5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-159af78d-dbb9-4f19-aaba-87e9b1c17a00,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-d88f6d92-2ba7-445d-a277-b53950d3ccdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-40dd4824-8b9c-4650-a8d1-21bf7c4dfef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1385303696-172.17.0.17-1598112259931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34103,DS-8e37fefe-7345-4b39-a042-819f06f9b042,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-4c1bc228-2faa-411e-bec1-26445f2bd730,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-27c895ed-1b1d-43d5-b27c-6062c1cc3cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-fa8a3da6-8d6c-44a5-90de-3db8e37befe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-ba41bc55-8255-48ed-9009-c97c25d76b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-52176ff7-9ae3-4dc9-828f-071cbbca3e62,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-b6e031bc-9489-436e-8075-710f9da5314c,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-909bf41d-a780-40f4-96ce-32f4d46f5340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1385303696-172.17.0.17-1598112259931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34103,DS-8e37fefe-7345-4b39-a042-819f06f9b042,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-4c1bc228-2faa-411e-bec1-26445f2bd730,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-27c895ed-1b1d-43d5-b27c-6062c1cc3cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-fa8a3da6-8d6c-44a5-90de-3db8e37befe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-ba41bc55-8255-48ed-9009-c97c25d76b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-52176ff7-9ae3-4dc9-828f-071cbbca3e62,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-b6e031bc-9489-436e-8075-710f9da5314c,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-909bf41d-a780-40f4-96ce-32f4d46f5340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918121338-172.17.0.17-1598112396301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44540,DS-88b27404-7f9b-4d9e-adaf-e5a138d80ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-b40bf600-0736-4a44-a7b4-159adde669cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-ce896351-0ba6-481a-b665-67b0de047302,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-51acc49e-f8b5-418c-8661-d7e2fbf6bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-4a827d5c-38ac-4094-a502-f09022711251,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-3768d29a-925d-46de-9cb4-f9450a5e9388,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-b48adc5f-142f-442f-b09d-0394013d657d,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-dd525e56-e6f4-4f1b-86b2-a2e2540f4779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918121338-172.17.0.17-1598112396301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44540,DS-88b27404-7f9b-4d9e-adaf-e5a138d80ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-b40bf600-0736-4a44-a7b4-159adde669cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-ce896351-0ba6-481a-b665-67b0de047302,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-51acc49e-f8b5-418c-8661-d7e2fbf6bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-4a827d5c-38ac-4094-a502-f09022711251,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-3768d29a-925d-46de-9cb4-f9450a5e9388,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-b48adc5f-142f-442f-b09d-0394013d657d,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-dd525e56-e6f4-4f1b-86b2-a2e2540f4779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-121058379-172.17.0.17-1598112830486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40801,DS-d2bd7bd9-d4a4-43bd-b5d0-9059505e55f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-cf840b83-fe16-4b7b-b07b-61651fd21c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-458d41a8-46c7-48d8-aae3-eb7b65e13fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-a3e39138-f421-46d9-b3b6-061e22cabe61,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-edc3249a-338e-4a15-8022-f27387dd71b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-ec0cf28a-9cb4-4bce-9b3f-0a49843fc834,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-ca3c3a3b-c3fa-43c5-978c-02fdd6cebcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-224d5803-1b2d-4094-83b8-3996b28514bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-121058379-172.17.0.17-1598112830486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40801,DS-d2bd7bd9-d4a4-43bd-b5d0-9059505e55f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-cf840b83-fe16-4b7b-b07b-61651fd21c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-458d41a8-46c7-48d8-aae3-eb7b65e13fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-a3e39138-f421-46d9-b3b6-061e22cabe61,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-edc3249a-338e-4a15-8022-f27387dd71b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-ec0cf28a-9cb4-4bce-9b3f-0a49843fc834,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-ca3c3a3b-c3fa-43c5-978c-02fdd6cebcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-224d5803-1b2d-4094-83b8-3996b28514bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1628607297-172.17.0.17-1598113114678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43870,DS-ffca3528-ce0d-4104-9194-eeffe8a7d717,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-491d75ea-c79f-424b-9b35-7fe7d4f2d2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-4ff8ee8b-723e-4dda-ad1a-80c2cb33bd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-6fff0eb6-bcf1-4ab3-a28b-a5b21d8c0108,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-7774192a-6371-4b97-920a-9726bb0287f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-e783b39f-f850-4dc6-9950-5ef1a706e1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-a3af9a2d-5ff6-4caf-9511-96a00f2ed721,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-350b7f07-bdf3-4991-86dd-84cbb7b03d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1628607297-172.17.0.17-1598113114678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43870,DS-ffca3528-ce0d-4104-9194-eeffe8a7d717,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-491d75ea-c79f-424b-9b35-7fe7d4f2d2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-4ff8ee8b-723e-4dda-ad1a-80c2cb33bd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-6fff0eb6-bcf1-4ab3-a28b-a5b21d8c0108,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-7774192a-6371-4b97-920a-9726bb0287f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-e783b39f-f850-4dc6-9950-5ef1a706e1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-a3af9a2d-5ff6-4caf-9511-96a00f2ed721,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-350b7f07-bdf3-4991-86dd-84cbb7b03d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1598642809-172.17.0.17-1598113160718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45463,DS-7ec72dab-de58-4f72-b3b5-da08e1fc48f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-a7046ef0-78a8-448e-b28e-72e7576a2984,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-6c933d39-78a8-4e5e-bc2f-82e3cdcb30b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-3cd5e2e6-d943-4ca9-81bc-1677ab895027,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-c0390d44-28de-4b91-9b47-0fd5bb98ef63,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-6329045f-9193-4a6a-810a-3b1a4a1dad91,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-72c68a30-ce2a-45dd-aeca-7ddacb8d6e12,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-eada6e67-a380-410f-9dfa-982b2866dc33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1598642809-172.17.0.17-1598113160718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45463,DS-7ec72dab-de58-4f72-b3b5-da08e1fc48f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-a7046ef0-78a8-448e-b28e-72e7576a2984,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-6c933d39-78a8-4e5e-bc2f-82e3cdcb30b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-3cd5e2e6-d943-4ca9-81bc-1677ab895027,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-c0390d44-28de-4b91-9b47-0fd5bb98ef63,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-6329045f-9193-4a6a-810a-3b1a4a1dad91,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-72c68a30-ce2a-45dd-aeca-7ddacb8d6e12,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-eada6e67-a380-410f-9dfa-982b2866dc33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066104565-172.17.0.17-1598113752926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39550,DS-4a0d2e0b-e75d-4510-bd0f-5fbb79a8b83e,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-c5321889-8238-4fd3-abb4-c47a3d838d87,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-ab967ca6-621a-42f5-9616-ae9669ab6061,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-70399573-579f-40c8-8caa-163980cde0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-109e7ae4-71fc-4896-8e89-5447e3f5e3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-861ce2cc-be77-4784-92ed-944a640dec65,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-55737650-d01d-43c6-8034-abb6d91e5d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-d011ec53-3bb5-4bb5-ba3b-7a50ba1a3b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066104565-172.17.0.17-1598113752926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39550,DS-4a0d2e0b-e75d-4510-bd0f-5fbb79a8b83e,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-c5321889-8238-4fd3-abb4-c47a3d838d87,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-ab967ca6-621a-42f5-9616-ae9669ab6061,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-70399573-579f-40c8-8caa-163980cde0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-109e7ae4-71fc-4896-8e89-5447e3f5e3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-861ce2cc-be77-4784-92ed-944a640dec65,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-55737650-d01d-43c6-8034-abb6d91e5d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-d011ec53-3bb5-4bb5-ba3b-7a50ba1a3b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486318275-172.17.0.17-1598113983230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33966,DS-ec187421-6782-4ec2-9781-5c103064ed69,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-5ae43e6e-aec3-43eb-af41-417775c5bc21,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-7ac846a5-3f29-498f-8103-547e472c39ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-bb8efc0c-a0fe-47ca-a452-a648685fbe77,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-e96ee27e-09e7-496f-8e4c-2fd2de222d23,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-c8ee1f48-8dea-4c4d-ae39-a5377f1c8135,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-eee00acd-a2ea-4e79-9ea3-0467ee037966,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-5b626d52-a829-43bb-b0f9-24d972ea2d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486318275-172.17.0.17-1598113983230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33966,DS-ec187421-6782-4ec2-9781-5c103064ed69,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-5ae43e6e-aec3-43eb-af41-417775c5bc21,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-7ac846a5-3f29-498f-8103-547e472c39ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-bb8efc0c-a0fe-47ca-a452-a648685fbe77,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-e96ee27e-09e7-496f-8e4c-2fd2de222d23,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-c8ee1f48-8dea-4c4d-ae39-a5377f1c8135,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-eee00acd-a2ea-4e79-9ea3-0467ee037966,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-5b626d52-a829-43bb-b0f9-24d972ea2d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656478692-172.17.0.17-1598114680743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38349,DS-797709cf-e81c-4b7e-bc81-fb6003aa3a55,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-f9978c72-0d2d-447d-9c50-85fc4d2c690c,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-3f8975ee-b681-4634-b4c0-69674f9a8116,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-fd4e9479-a488-4222-b166-02077392817c,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-eb3ab09f-8173-4d04-83ae-6204ac6a79d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-f94ae867-66ee-4539-9d27-1a9f6b7bf534,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-33747e9a-a30e-4361-a151-d749bc29dce6,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-8531a12b-8fbd-405e-a554-cc1cf15209b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656478692-172.17.0.17-1598114680743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38349,DS-797709cf-e81c-4b7e-bc81-fb6003aa3a55,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-f9978c72-0d2d-447d-9c50-85fc4d2c690c,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-3f8975ee-b681-4634-b4c0-69674f9a8116,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-fd4e9479-a488-4222-b166-02077392817c,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-eb3ab09f-8173-4d04-83ae-6204ac6a79d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-f94ae867-66ee-4539-9d27-1a9f6b7bf534,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-33747e9a-a30e-4361-a151-d749bc29dce6,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-8531a12b-8fbd-405e-a554-cc1cf15209b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113455020-172.17.0.17-1598114813814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38640,DS-2cafd2c2-cf53-496e-8e67-f2ff7dfd8f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-df425619-603d-4033-aa3c-aa435233985b,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-14de5a6b-45ff-48b3-ba6d-6b6ebf3778f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-175013e2-0628-457c-9a05-4bedc38aa9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-ca97bf85-e9ca-4a3f-984e-515813fc0eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-0d242904-24f2-42f8-a6a4-38aa09c4de18,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-d49cd215-0e8d-403a-ad3d-ccbfe5eac2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-c8cb7030-dec1-4906-a952-5e09fff842a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113455020-172.17.0.17-1598114813814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38640,DS-2cafd2c2-cf53-496e-8e67-f2ff7dfd8f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-df425619-603d-4033-aa3c-aa435233985b,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-14de5a6b-45ff-48b3-ba6d-6b6ebf3778f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-175013e2-0628-457c-9a05-4bedc38aa9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-ca97bf85-e9ca-4a3f-984e-515813fc0eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-0d242904-24f2-42f8-a6a4-38aa09c4de18,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-d49cd215-0e8d-403a-ad3d-ccbfe5eac2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-c8cb7030-dec1-4906-a952-5e09fff842a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666351048-172.17.0.17-1598114937702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33473,DS-52fb1c87-971b-4075-b991-909397f7020e,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-a4e09238-0020-4122-a315-ad4b83c1ce7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-774ffd8a-83d2-4aaf-9aa2-a0e55338872b,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-53cda861-8cc4-4f0b-9720-4895cab3629f,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-438fbe82-e204-42f2-9caf-4120897b6c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-3eb43749-5288-4c82-b285-16467032bc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-cc0d2a6a-35e2-415d-a794-e6caeae8ef3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-9fee730d-52bc-4144-831b-1fabbaf31bdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666351048-172.17.0.17-1598114937702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33473,DS-52fb1c87-971b-4075-b991-909397f7020e,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-a4e09238-0020-4122-a315-ad4b83c1ce7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-774ffd8a-83d2-4aaf-9aa2-a0e55338872b,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-53cda861-8cc4-4f0b-9720-4895cab3629f,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-438fbe82-e204-42f2-9caf-4120897b6c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-3eb43749-5288-4c82-b285-16467032bc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-cc0d2a6a-35e2-415d-a794-e6caeae8ef3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-9fee730d-52bc-4144-831b-1fabbaf31bdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1056394801-172.17.0.17-1598115138226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35237,DS-3a59ea8b-20de-4da0-a294-091ed4229e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-af3e6b7f-94cf-4911-b755-1ce38f7d1a85,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-04f07848-685f-4fa6-a08f-c5be8f96e870,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-d73da154-2521-4fd4-ac98-08834374c356,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-65def0b4-26f8-4d50-a92f-a9ddb4f11e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-42b45581-b448-4203-acdf-44b3e7f1c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-a1ac9d80-7016-4d62-adf9-6473eea381ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-eaf342f2-4653-45f5-9074-f2c982edc25d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1056394801-172.17.0.17-1598115138226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35237,DS-3a59ea8b-20de-4da0-a294-091ed4229e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-af3e6b7f-94cf-4911-b755-1ce38f7d1a85,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-04f07848-685f-4fa6-a08f-c5be8f96e870,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-d73da154-2521-4fd4-ac98-08834374c356,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-65def0b4-26f8-4d50-a92f-a9ddb4f11e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-42b45581-b448-4203-acdf-44b3e7f1c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-a1ac9d80-7016-4d62-adf9-6473eea381ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-eaf342f2-4653-45f5-9074-f2c982edc25d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1347026248-172.17.0.17-1598115768027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42751,DS-a8057fef-333e-4656-b20a-4c237cd8fee5,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-ce83b30c-b744-49f0-a94b-f68642411213,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-68c290c6-862e-4844-8910-f176d672eaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-8c79433f-9fb9-42ab-ab19-d5d58086942b,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-687c4cce-bd18-4b8b-ae9d-dcc03846a4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-f695fb71-15b6-48c5-981a-309d549a1ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-c33bf4bd-f945-47db-8f3e-175381f2478f,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-7d969689-e10f-4521-a262-87c3e75668b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1347026248-172.17.0.17-1598115768027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42751,DS-a8057fef-333e-4656-b20a-4c237cd8fee5,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-ce83b30c-b744-49f0-a94b-f68642411213,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-68c290c6-862e-4844-8910-f176d672eaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-8c79433f-9fb9-42ab-ab19-d5d58086942b,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-687c4cce-bd18-4b8b-ae9d-dcc03846a4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-f695fb71-15b6-48c5-981a-309d549a1ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-c33bf4bd-f945-47db-8f3e-175381f2478f,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-7d969689-e10f-4521-a262-87c3e75668b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-437169221-172.17.0.17-1598116150995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38565,DS-9ed37f3e-5d8c-485a-87ff-99e7cdcdde0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-7f62d0da-7306-46bd-a803-0b0f25e1133b,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-4471256a-4cbc-4e70-a116-a44e64c072bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-3847705c-16bc-4201-91c6-e6b74f82c11b,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-13ef5b89-5139-41a1-8f71-365400ef45bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-24f4e6f9-0de6-4fda-b7fe-f5cdd1fbed93,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-d1d855d0-9e95-493c-9d64-46e15d289fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-6ac33d5c-2ea0-46d4-bf3e-e495e806d2b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-437169221-172.17.0.17-1598116150995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38565,DS-9ed37f3e-5d8c-485a-87ff-99e7cdcdde0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-7f62d0da-7306-46bd-a803-0b0f25e1133b,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-4471256a-4cbc-4e70-a116-a44e64c072bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-3847705c-16bc-4201-91c6-e6b74f82c11b,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-13ef5b89-5139-41a1-8f71-365400ef45bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-24f4e6f9-0de6-4fda-b7fe-f5cdd1fbed93,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-d1d855d0-9e95-493c-9d64-46e15d289fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-6ac33d5c-2ea0-46d4-bf3e-e495e806d2b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470600873-172.17.0.17-1598116427135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44717,DS-c9fc253b-0c19-427e-8cff-799d8161fbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-958b3b62-44fb-4f09-817a-f569ff399a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-4205950e-8419-4d42-9577-e64b302030f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-5b5467f2-daf9-42bf-ac32-31a786c9c008,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-7721c66e-852a-4e48-9900-76585162d074,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-60b4653d-72a1-4d2b-9643-010f08a6d8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-238dc9e4-6050-4beb-8c47-1a7d6d520f31,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-57ff4074-9ab2-4141-a09a-b58b549703b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1470600873-172.17.0.17-1598116427135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44717,DS-c9fc253b-0c19-427e-8cff-799d8161fbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-958b3b62-44fb-4f09-817a-f569ff399a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-4205950e-8419-4d42-9577-e64b302030f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-5b5467f2-daf9-42bf-ac32-31a786c9c008,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-7721c66e-852a-4e48-9900-76585162d074,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-60b4653d-72a1-4d2b-9643-010f08a6d8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-238dc9e4-6050-4beb-8c47-1a7d6d520f31,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-57ff4074-9ab2-4141-a09a-b58b549703b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1691836322-172.17.0.17-1598117223020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45694,DS-628cfb40-b132-4210-89cf-49cee7929e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-89fd8bff-d411-44c2-9499-5862434eaf07,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-2a04d0bf-6808-4dae-9087-39d33815b0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-fe78d35b-b2c2-4129-a155-9c203e74e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-d7b962bc-cda9-4ba8-87af-dfbb855c6193,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-be2c27ea-18bd-4c47-868f-69e24c9eb147,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-3a32c8bf-d8f8-4836-aa69-3f846fbcc01b,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-25a7d153-2b88-444d-bfea-d3136014043b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1691836322-172.17.0.17-1598117223020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45694,DS-628cfb40-b132-4210-89cf-49cee7929e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-89fd8bff-d411-44c2-9499-5862434eaf07,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-2a04d0bf-6808-4dae-9087-39d33815b0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-fe78d35b-b2c2-4129-a155-9c203e74e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-d7b962bc-cda9-4ba8-87af-dfbb855c6193,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-be2c27ea-18bd-4c47-868f-69e24c9eb147,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-3a32c8bf-d8f8-4836-aa69-3f846fbcc01b,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-25a7d153-2b88-444d-bfea-d3136014043b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788544257-172.17.0.17-1598117350323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40858,DS-98590491-d227-4efa-aa16-7acd3eab5900,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-98feb8be-2f70-4540-94f8-cd6e127ceb78,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-fc8a2b0c-8d90-4dbe-9ba9-6c3101fa22ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-a8fd61c9-2ce0-474f-935f-f6aaf0ecacb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-3be270f0-63db-4b98-bc78-04539babefca,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-5a830612-5308-4500-b301-fa70bfa58609,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-4748c45a-d2d0-42d6-ba86-b88de2e5e117,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-1c4108d1-52c3-497f-9c3d-419a54f2dc22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788544257-172.17.0.17-1598117350323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40858,DS-98590491-d227-4efa-aa16-7acd3eab5900,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-98feb8be-2f70-4540-94f8-cd6e127ceb78,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-fc8a2b0c-8d90-4dbe-9ba9-6c3101fa22ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-a8fd61c9-2ce0-474f-935f-f6aaf0ecacb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-3be270f0-63db-4b98-bc78-04539babefca,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-5a830612-5308-4500-b301-fa70bfa58609,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-4748c45a-d2d0-42d6-ba86-b88de2e5e117,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-1c4108d1-52c3-497f-9c3d-419a54f2dc22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524308942-172.17.0.17-1598117833308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39717,DS-d0c2b911-c20a-4d28-aa2e-f03b90d2ad84,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-922810e8-ae1a-425a-8e81-8a3572d39f30,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-0ca0be53-7ac5-4a6d-aebe-9cf7bdb1fbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-77ed19b9-db19-4050-9bb5-e0638aa5113b,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-6cbaaf4d-1a0d-4330-b72a-604a1daf8581,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-b14fbe9e-e815-401e-81bc-393ef61572b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-ece65116-7fc3-4d34-a602-3e9a786aa020,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-9ddcdc08-2f70-4ec2-ac2c-5f9fdd09d3b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524308942-172.17.0.17-1598117833308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39717,DS-d0c2b911-c20a-4d28-aa2e-f03b90d2ad84,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-922810e8-ae1a-425a-8e81-8a3572d39f30,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-0ca0be53-7ac5-4a6d-aebe-9cf7bdb1fbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-77ed19b9-db19-4050-9bb5-e0638aa5113b,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-6cbaaf4d-1a0d-4330-b72a-604a1daf8581,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-b14fbe9e-e815-401e-81bc-393ef61572b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-ece65116-7fc3-4d34-a602-3e9a786aa020,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-9ddcdc08-2f70-4ec2-ac2c-5f9fdd09d3b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6851
