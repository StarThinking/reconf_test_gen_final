reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861873999-172.17.0.20-1598168178759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44607,DS-e519d782-7a8c-43d3-8ab6-d25c7dc8546d,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-59899841-1422-4992-a7d9-c16ffb35b843,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-bd201ebb-6bbc-4812-a140-297c03dc149f,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-3d46e42b-7b3f-4543-a30d-d7e479c548de,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-b2129be3-0d73-4915-a002-e82e3375b6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-88618d0d-ee74-49f0-bd09-22f190b8ce7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-0f152fff-6abd-49bb-bf3f-a071c38f6ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-9a3157e9-6e76-4986-90ab-fa86355a7662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861873999-172.17.0.20-1598168178759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44607,DS-e519d782-7a8c-43d3-8ab6-d25c7dc8546d,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-59899841-1422-4992-a7d9-c16ffb35b843,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-bd201ebb-6bbc-4812-a140-297c03dc149f,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-3d46e42b-7b3f-4543-a30d-d7e479c548de,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-b2129be3-0d73-4915-a002-e82e3375b6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-88618d0d-ee74-49f0-bd09-22f190b8ce7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-0f152fff-6abd-49bb-bf3f-a071c38f6ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-9a3157e9-6e76-4986-90ab-fa86355a7662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361251036-172.17.0.20-1598168287078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34776,DS-3fb87817-921b-4be8-9024-8bc1cf743d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-89226e55-ac2e-4f3a-b591-61da4c608c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-b2b6af17-59e0-4abb-99fb-fde4d696d6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-de27f822-f82f-4a7f-9666-58988b518c29,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-4a5cfe33-2fc0-43d6-b144-28b77d618be6,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-eb34c465-3cfe-42fa-87e3-0373a4e9f4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-c37061a3-1e01-473e-9051-178e45c01d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-74b0b5c4-0abf-4a3f-97d8-2a610e5a2884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361251036-172.17.0.20-1598168287078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34776,DS-3fb87817-921b-4be8-9024-8bc1cf743d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-89226e55-ac2e-4f3a-b591-61da4c608c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-b2b6af17-59e0-4abb-99fb-fde4d696d6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-de27f822-f82f-4a7f-9666-58988b518c29,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-4a5cfe33-2fc0-43d6-b144-28b77d618be6,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-eb34c465-3cfe-42fa-87e3-0373a4e9f4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-c37061a3-1e01-473e-9051-178e45c01d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-74b0b5c4-0abf-4a3f-97d8-2a610e5a2884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088010821-172.17.0.20-1598168670914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34356,DS-9dd526ff-f6a2-4c69-82da-37d0a997a1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-57c70d94-1467-420b-bf4a-9a0364aea6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-13667d63-5222-4e59-9543-9f6c1741da85,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-9f20fc93-fcc8-4b88-b372-2411c719d855,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-903327fc-177e-4b97-9493-dea575e79ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-9c1bcd67-269c-4469-a01e-0416be21fa04,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-aac34082-1d81-4408-92f1-9a5195212431,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-4cc31953-c176-45de-82f6-23858f00fed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088010821-172.17.0.20-1598168670914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34356,DS-9dd526ff-f6a2-4c69-82da-37d0a997a1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-57c70d94-1467-420b-bf4a-9a0364aea6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-13667d63-5222-4e59-9543-9f6c1741da85,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-9f20fc93-fcc8-4b88-b372-2411c719d855,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-903327fc-177e-4b97-9493-dea575e79ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-9c1bcd67-269c-4469-a01e-0416be21fa04,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-aac34082-1d81-4408-92f1-9a5195212431,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-4cc31953-c176-45de-82f6-23858f00fed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-736189959-172.17.0.20-1598169426391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-3dc7fe08-549f-48d3-83aa-a4a245838546,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-66b0ef96-a1cb-4d04-ba28-1dc0578da2af,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-272a4c3f-a330-4156-abeb-758e0be742be,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-3da3c740-bcce-42ee-8f75-6bff6af1d0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-76d2b63f-332b-4f12-95b8-7aa2b20dbade,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-c167da64-fd21-4fe7-9e4d-56fa2a049fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-f03bfb87-1cd6-4df0-a83c-3605d5ea6360,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-6895ed7f-a23a-4788-b0db-96f0e6c2f756,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-736189959-172.17.0.20-1598169426391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-3dc7fe08-549f-48d3-83aa-a4a245838546,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-66b0ef96-a1cb-4d04-ba28-1dc0578da2af,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-272a4c3f-a330-4156-abeb-758e0be742be,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-3da3c740-bcce-42ee-8f75-6bff6af1d0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-76d2b63f-332b-4f12-95b8-7aa2b20dbade,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-c167da64-fd21-4fe7-9e4d-56fa2a049fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-f03bfb87-1cd6-4df0-a83c-3605d5ea6360,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-6895ed7f-a23a-4788-b0db-96f0e6c2f756,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137500981-172.17.0.20-1598169615375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43007,DS-a7f84937-a43b-4da7-86d7-344d1f57ffde,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-0b81b051-7bb2-4d17-8072-896f4d6da874,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-d7357930-0dd7-48be-bf26-8b714ef89707,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-133acb2f-0591-46f3-9682-004ba69965f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-229be682-8002-41e8-8e6e-2177bf6371d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-334e4fb1-221b-43a3-bad0-e392d7304a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-f8e99cf6-e792-49fb-a7d3-649ac0d78d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-c1d6b29f-0234-4e39-ae71-33953364e0be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137500981-172.17.0.20-1598169615375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43007,DS-a7f84937-a43b-4da7-86d7-344d1f57ffde,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-0b81b051-7bb2-4d17-8072-896f4d6da874,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-d7357930-0dd7-48be-bf26-8b714ef89707,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-133acb2f-0591-46f3-9682-004ba69965f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-229be682-8002-41e8-8e6e-2177bf6371d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-334e4fb1-221b-43a3-bad0-e392d7304a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-f8e99cf6-e792-49fb-a7d3-649ac0d78d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-c1d6b29f-0234-4e39-ae71-33953364e0be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1984106301-172.17.0.20-1598169729893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41320,DS-a9d3f9e3-a58e-456e-9ac7-107d7cf7e3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-e2ae8b77-74ca-42e1-acbb-ef8d12b1903d,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-6a5f9c19-a673-4322-8991-8ee7dbc82478,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-ce26353e-3a6e-48dc-8bd1-db99b8dc67b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-3b08c539-4a18-4884-8828-91ae5b41e35a,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-50fc53b6-238f-417e-9588-df827c98fd52,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-c064558d-799b-4d51-948b-1cd8dd877567,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-de7db6f8-cee3-4e84-9e60-bc116af1a498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1984106301-172.17.0.20-1598169729893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41320,DS-a9d3f9e3-a58e-456e-9ac7-107d7cf7e3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-e2ae8b77-74ca-42e1-acbb-ef8d12b1903d,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-6a5f9c19-a673-4322-8991-8ee7dbc82478,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-ce26353e-3a6e-48dc-8bd1-db99b8dc67b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-3b08c539-4a18-4884-8828-91ae5b41e35a,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-50fc53b6-238f-417e-9588-df827c98fd52,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-c064558d-799b-4d51-948b-1cd8dd877567,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-de7db6f8-cee3-4e84-9e60-bc116af1a498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021388640-172.17.0.20-1598169811647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41564,DS-b3405be3-f692-4120-bdd9-fde4e8598997,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-8819fb57-1ce9-4d1e-99bd-4039982b707f,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-47c5bd5c-f60f-4386-878c-fbd8ad22048e,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-51739b9e-d7a4-45c5-baa2-90f50fdc1dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-09fefa75-5929-47c0-9de8-74e30f6648d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-3d7b4e60-2e6b-4067-815b-8b1c4c55f06c,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-afa84470-a880-4f98-bbf9-ba3bc284ee17,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-3ad6fffb-4558-46da-a6df-3bc63257c3ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021388640-172.17.0.20-1598169811647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41564,DS-b3405be3-f692-4120-bdd9-fde4e8598997,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-8819fb57-1ce9-4d1e-99bd-4039982b707f,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-47c5bd5c-f60f-4386-878c-fbd8ad22048e,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-51739b9e-d7a4-45c5-baa2-90f50fdc1dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-09fefa75-5929-47c0-9de8-74e30f6648d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-3d7b4e60-2e6b-4067-815b-8b1c4c55f06c,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-afa84470-a880-4f98-bbf9-ba3bc284ee17,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-3ad6fffb-4558-46da-a6df-3bc63257c3ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178324021-172.17.0.20-1598169917452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45317,DS-78df7886-7ad0-486a-86e5-39e4f2ee6831,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-bdf956ae-706a-4099-9ad7-2eb82c2f32b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-f6d95875-bb3f-4f44-8a0c-de8b38b4e6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-8f1cfdfd-e07f-4640-bbcc-0ea3f3139585,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-fd2920fd-5985-4626-bf30-90a28685879a,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-76058713-0f97-4e0d-8f86-1fc3275c1269,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-f0286bba-01e5-41a3-84fc-10e25c760637,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-9fe1c3b0-e886-40d9-95ca-1d0e430e49fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178324021-172.17.0.20-1598169917452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45317,DS-78df7886-7ad0-486a-86e5-39e4f2ee6831,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-bdf956ae-706a-4099-9ad7-2eb82c2f32b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-f6d95875-bb3f-4f44-8a0c-de8b38b4e6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-8f1cfdfd-e07f-4640-bbcc-0ea3f3139585,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-fd2920fd-5985-4626-bf30-90a28685879a,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-76058713-0f97-4e0d-8f86-1fc3275c1269,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-f0286bba-01e5-41a3-84fc-10e25c760637,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-9fe1c3b0-e886-40d9-95ca-1d0e430e49fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-653260257-172.17.0.20-1598169984763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42477,DS-c1e44bf7-10af-4961-8590-1fc90d167204,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-44abf496-6310-4909-b51b-da5bf45cc483,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-482aed16-5090-4737-a345-5713c7573284,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-000f0cb6-3d66-4d0f-8a1e-b81fb0c3cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-f630d37f-6c20-4f21-b341-ee0821f0add2,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-293ebb43-5ed0-499b-969c-e22d5713afc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-793c7794-a311-4f9f-b101-549c397bd7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-d3e88302-06e2-4efe-9978-d3a25933f5bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-653260257-172.17.0.20-1598169984763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42477,DS-c1e44bf7-10af-4961-8590-1fc90d167204,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-44abf496-6310-4909-b51b-da5bf45cc483,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-482aed16-5090-4737-a345-5713c7573284,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-000f0cb6-3d66-4d0f-8a1e-b81fb0c3cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-f630d37f-6c20-4f21-b341-ee0821f0add2,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-293ebb43-5ed0-499b-969c-e22d5713afc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-793c7794-a311-4f9f-b101-549c397bd7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-d3e88302-06e2-4efe-9978-d3a25933f5bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100796811-172.17.0.20-1598170198204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35558,DS-01a8f7be-fe61-41c8-a59e-22a3b33098ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-5ebedc33-a55f-4072-a3b9-50bb824619cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-d50a375b-dd70-4a32-835a-869a32f1c3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-db16837d-c83b-48ea-ae09-d3a9848a6919,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-3e532ad3-7974-477c-8fc5-728ea917d75f,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-0477b0ef-1c54-43f2-9731-6b20c9471376,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-fdd79624-74b8-4677-bfe1-20dc236aa91b,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-c8375109-63d4-4627-97af-6fecb032e307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100796811-172.17.0.20-1598170198204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35558,DS-01a8f7be-fe61-41c8-a59e-22a3b33098ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-5ebedc33-a55f-4072-a3b9-50bb824619cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-d50a375b-dd70-4a32-835a-869a32f1c3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-db16837d-c83b-48ea-ae09-d3a9848a6919,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-3e532ad3-7974-477c-8fc5-728ea917d75f,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-0477b0ef-1c54-43f2-9731-6b20c9471376,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-fdd79624-74b8-4677-bfe1-20dc236aa91b,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-c8375109-63d4-4627-97af-6fecb032e307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329427721-172.17.0.20-1598171795536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38219,DS-13d7afe7-dd28-4b5c-ad92-bc268831583d,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-931880b1-5d64-493f-9f8a-3fee6563f892,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-94ce51b5-4521-4f4d-8c48-0cd3f7c2a0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-155f4bc4-b71e-4849-9105-5b0f5999b175,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-1d564fbb-f938-4958-bde8-061153c49279,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-ff54e73c-b67d-42c8-b9f7-c490125cc536,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-690045d8-50fb-42d4-b6b9-903e0bb5a683,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-16a232f8-395c-4b47-a857-375e27e05813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329427721-172.17.0.20-1598171795536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38219,DS-13d7afe7-dd28-4b5c-ad92-bc268831583d,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-931880b1-5d64-493f-9f8a-3fee6563f892,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-94ce51b5-4521-4f4d-8c48-0cd3f7c2a0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-155f4bc4-b71e-4849-9105-5b0f5999b175,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-1d564fbb-f938-4958-bde8-061153c49279,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-ff54e73c-b67d-42c8-b9f7-c490125cc536,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-690045d8-50fb-42d4-b6b9-903e0bb5a683,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-16a232f8-395c-4b47-a857-375e27e05813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305662971-172.17.0.20-1598172173386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41140,DS-e64f441b-3a07-4596-b4f0-b41603256da5,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-3a21bd30-b76f-4946-b6ef-f2f1793dbd21,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-973ef772-9ba8-473b-86a5-ad832bb50d83,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-1000af49-5b06-4c01-b42d-a9a7d43b187d,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-07bcc544-a56b-4e98-bc1c-1ef063d9a0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-4b170a63-aa76-4b1e-a4a0-c6ccae855dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-e9225449-275b-4cb5-bf04-26ccf007ee2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-cf3693a6-869a-4561-96bf-1a23b9337d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305662971-172.17.0.20-1598172173386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41140,DS-e64f441b-3a07-4596-b4f0-b41603256da5,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-3a21bd30-b76f-4946-b6ef-f2f1793dbd21,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-973ef772-9ba8-473b-86a5-ad832bb50d83,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-1000af49-5b06-4c01-b42d-a9a7d43b187d,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-07bcc544-a56b-4e98-bc1c-1ef063d9a0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-4b170a63-aa76-4b1e-a4a0-c6ccae855dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-e9225449-275b-4cb5-bf04-26ccf007ee2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-cf3693a6-869a-4561-96bf-1a23b9337d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59248741-172.17.0.20-1598172499813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39903,DS-aa213b88-7b2c-4966-8e08-2b4a04ac2172,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-14ef75da-20b5-4a5a-904f-ea1b606c55c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-d337e563-419d-47ea-8ba9-96383b64077b,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-4c5d69ba-4b9c-4e26-9760-958926918ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-d102fdc4-db35-4308-aa0f-c70bc022cca2,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-4a46cf23-0e09-4b9c-8ec4-a1be589e826c,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-70960598-cea4-4468-831b-c6d2f78d976c,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-3d068508-f665-488b-86c3-6f6be9202c74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59248741-172.17.0.20-1598172499813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39903,DS-aa213b88-7b2c-4966-8e08-2b4a04ac2172,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-14ef75da-20b5-4a5a-904f-ea1b606c55c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-d337e563-419d-47ea-8ba9-96383b64077b,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-4c5d69ba-4b9c-4e26-9760-958926918ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-d102fdc4-db35-4308-aa0f-c70bc022cca2,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-4a46cf23-0e09-4b9c-8ec4-a1be589e826c,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-70960598-cea4-4468-831b-c6d2f78d976c,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-3d068508-f665-488b-86c3-6f6be9202c74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-367640072-172.17.0.20-1598173001301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42814,DS-dbc602e8-d2c1-46fd-aa57-41da2efbf60e,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-19e59685-bbe0-49ae-8842-8a9c0704d787,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-851d70c1-22be-4bc2-b68c-710caf03eda5,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-ba08645b-1b6c-417c-b72c-6576205b858a,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-e2b8a27a-e3d4-4390-9e90-652dbf6a5c05,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-0dcb87c7-a566-49c9-aeb2-dcb24f7fa095,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-fd2b8ae4-d5e0-4f52-9279-ad870e8b9625,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-1a8a73de-3ff4-4c17-9163-59ac0e0d2667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-367640072-172.17.0.20-1598173001301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42814,DS-dbc602e8-d2c1-46fd-aa57-41da2efbf60e,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-19e59685-bbe0-49ae-8842-8a9c0704d787,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-851d70c1-22be-4bc2-b68c-710caf03eda5,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-ba08645b-1b6c-417c-b72c-6576205b858a,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-e2b8a27a-e3d4-4390-9e90-652dbf6a5c05,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-0dcb87c7-a566-49c9-aeb2-dcb24f7fa095,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-fd2b8ae4-d5e0-4f52-9279-ad870e8b9625,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-1a8a73de-3ff4-4c17-9163-59ac0e0d2667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731072411-172.17.0.20-1598173080094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40995,DS-97c472c9-6ca7-4c49-b142-6479fac82f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-d761820d-9c6a-4dec-bdab-b2b50adb2fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-9da5c993-f237-4159-8ec7-c55aa481b951,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-8f491e1a-0a73-4ef1-be8e-c8ed51c59c17,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-c0e9e33e-113d-412a-a795-3eb4d57c4c69,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-52547539-7922-4058-b1de-8193eb95ef6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-8425d3f3-d53b-4636-8277-bfd9abf05814,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-ffbf039e-dc22-4281-a590-a90b2d6258a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731072411-172.17.0.20-1598173080094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40995,DS-97c472c9-6ca7-4c49-b142-6479fac82f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-d761820d-9c6a-4dec-bdab-b2b50adb2fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-9da5c993-f237-4159-8ec7-c55aa481b951,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-8f491e1a-0a73-4ef1-be8e-c8ed51c59c17,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-c0e9e33e-113d-412a-a795-3eb4d57c4c69,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-52547539-7922-4058-b1de-8193eb95ef6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-8425d3f3-d53b-4636-8277-bfd9abf05814,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-ffbf039e-dc22-4281-a590-a90b2d6258a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1158604878-172.17.0.20-1598173165021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42094,DS-09e256a1-a72a-415a-99a0-92648905d98e,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-9d4e1f23-39ae-4119-85bb-d9d5be87cd92,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-5011ea42-5aea-4bba-9692-f0f8d0c2b175,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-4f6b89a7-b37a-4aeb-b51a-101ffbf8c3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-cd32c3f1-6054-42f6-8c31-6a61a68d6183,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-615208dc-f0ea-45f3-b4d9-5a1285fda8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-9dc2e08e-c2c3-4af1-81c6-0643d1fa1159,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-50263f6a-2f8e-488a-8bb0-38c2e16753fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1158604878-172.17.0.20-1598173165021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42094,DS-09e256a1-a72a-415a-99a0-92648905d98e,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-9d4e1f23-39ae-4119-85bb-d9d5be87cd92,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-5011ea42-5aea-4bba-9692-f0f8d0c2b175,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-4f6b89a7-b37a-4aeb-b51a-101ffbf8c3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-cd32c3f1-6054-42f6-8c31-6a61a68d6183,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-615208dc-f0ea-45f3-b4d9-5a1285fda8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-9dc2e08e-c2c3-4af1-81c6-0643d1fa1159,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-50263f6a-2f8e-488a-8bb0-38c2e16753fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5556
