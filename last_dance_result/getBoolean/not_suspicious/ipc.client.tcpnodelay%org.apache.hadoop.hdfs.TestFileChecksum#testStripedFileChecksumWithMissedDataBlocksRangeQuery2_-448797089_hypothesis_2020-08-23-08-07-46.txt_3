reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388276260-172.17.0.10-1598170163435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38850,DS-d48ffb80-b3b0-434e-83da-7b4b764fd509,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-84ec4ec9-cb39-4ca0-8127-2c9586fe3f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-449a8af2-274a-4319-bb02-f0c6858ccf54,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-4fe41fa4-f886-4df5-8603-f5736e27931b,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-58f7718c-f69e-455c-a5e1-f0f6435cce17,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-c10377d6-cc9a-41c6-bfe6-9cd1c411fcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-49080d42-841f-4dab-8240-367f6eae1070,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-c6d601a7-c910-48ec-a119-a475453f004f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388276260-172.17.0.10-1598170163435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38850,DS-d48ffb80-b3b0-434e-83da-7b4b764fd509,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-84ec4ec9-cb39-4ca0-8127-2c9586fe3f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-449a8af2-274a-4319-bb02-f0c6858ccf54,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-4fe41fa4-f886-4df5-8603-f5736e27931b,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-58f7718c-f69e-455c-a5e1-f0f6435cce17,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-c10377d6-cc9a-41c6-bfe6-9cd1c411fcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-49080d42-841f-4dab-8240-367f6eae1070,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-c6d601a7-c910-48ec-a119-a475453f004f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659043287-172.17.0.10-1598170731596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-b3f4fa4f-85f9-435f-b97c-3786a27fde17,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-03388b49-0b7d-4645-b5c5-eca03f3adee6,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-aea9034c-db9f-453b-a705-d3ea929cab08,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-54d58fbd-07f1-4128-8e1c-c094994358af,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-3b3ca0f4-bac7-4f52-b94a-c500129c829e,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-e4dc0de4-a003-44ec-ad85-a1c26d93e07b,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-0d0da07b-46f6-4176-854a-60fdd3f67407,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-5df93846-a04b-4ce9-8fbf-86f4d69add93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659043287-172.17.0.10-1598170731596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-b3f4fa4f-85f9-435f-b97c-3786a27fde17,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-03388b49-0b7d-4645-b5c5-eca03f3adee6,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-aea9034c-db9f-453b-a705-d3ea929cab08,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-54d58fbd-07f1-4128-8e1c-c094994358af,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-3b3ca0f4-bac7-4f52-b94a-c500129c829e,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-e4dc0de4-a003-44ec-ad85-a1c26d93e07b,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-0d0da07b-46f6-4176-854a-60fdd3f67407,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-5df93846-a04b-4ce9-8fbf-86f4d69add93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758519429-172.17.0.10-1598170880437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32844,DS-2e839d09-c9c1-40d3-a770-573c9705e711,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-198b2daf-24aa-4a2f-9e70-a0c648ee9357,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-f2e5919f-0982-48c0-8fac-e4ebd7b60cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-90617cf7-fb4a-4012-adcf-f1d994744fea,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-71c7a109-0cf7-4a78-a523-aabdb867a0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-9bf294ea-fe3c-42d4-8c3f-c7448d07561d,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-65505d3d-cc77-4fcf-996c-197892aa6cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-81c078f6-de58-4a10-8d4b-eb161fdf84ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758519429-172.17.0.10-1598170880437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32844,DS-2e839d09-c9c1-40d3-a770-573c9705e711,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-198b2daf-24aa-4a2f-9e70-a0c648ee9357,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-f2e5919f-0982-48c0-8fac-e4ebd7b60cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-90617cf7-fb4a-4012-adcf-f1d994744fea,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-71c7a109-0cf7-4a78-a523-aabdb867a0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-9bf294ea-fe3c-42d4-8c3f-c7448d07561d,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-65505d3d-cc77-4fcf-996c-197892aa6cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-81c078f6-de58-4a10-8d4b-eb161fdf84ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957207-172.17.0.10-1598171053131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33159,DS-7c4d5a31-0b8c-40ba-ad94-20ee4b56cfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-14b6be91-7a51-41f2-8d25-ff2c57a4c519,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-a14b3eb7-6853-4a9c-bc90-328222121af8,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-f23de870-31f1-48c4-b224-694281fdd68c,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-3ed746de-138e-4abf-8126-5c7e1db9751f,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-21f36435-f5b6-4717-ada4-e0d7b2ffe2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-38ead6b0-9b9d-456f-b9fb-324ff6bff9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-c03ceac0-5199-47b7-9db2-32a44c8c3304,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957207-172.17.0.10-1598171053131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33159,DS-7c4d5a31-0b8c-40ba-ad94-20ee4b56cfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-14b6be91-7a51-41f2-8d25-ff2c57a4c519,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-a14b3eb7-6853-4a9c-bc90-328222121af8,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-f23de870-31f1-48c4-b224-694281fdd68c,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-3ed746de-138e-4abf-8126-5c7e1db9751f,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-21f36435-f5b6-4717-ada4-e0d7b2ffe2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-38ead6b0-9b9d-456f-b9fb-324ff6bff9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-c03ceac0-5199-47b7-9db2-32a44c8c3304,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876216484-172.17.0.10-1598171547339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40140,DS-b0f04ce7-f576-418b-8344-5ea4448fa39a,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-057121d0-1d17-4034-85df-65df68878c20,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-d0a5a2e5-c5fe-4e79-99d3-ff000c4e91ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-7cb06e60-ee0e-4c4d-abf5-e0468c840466,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-0c11c200-72d2-44c3-98cc-b204411d29ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-cabbeda8-e006-4b77-a6e2-de89396fecd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-45fbf2e6-ebed-4f74-9b66-3acb49bb38bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-f1edfa2c-b5a1-4b4b-8df3-56e15f4dd6d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876216484-172.17.0.10-1598171547339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40140,DS-b0f04ce7-f576-418b-8344-5ea4448fa39a,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-057121d0-1d17-4034-85df-65df68878c20,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-d0a5a2e5-c5fe-4e79-99d3-ff000c4e91ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-7cb06e60-ee0e-4c4d-abf5-e0468c840466,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-0c11c200-72d2-44c3-98cc-b204411d29ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-cabbeda8-e006-4b77-a6e2-de89396fecd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-45fbf2e6-ebed-4f74-9b66-3acb49bb38bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-f1edfa2c-b5a1-4b4b-8df3-56e15f4dd6d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811528329-172.17.0.10-1598171806728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42596,DS-e28e6882-0b8d-4184-ac31-aa7277ab2e61,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-c6aaebce-cb10-4de1-a9fe-558850bace4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-bd8bb28a-92cb-4167-a9eb-54de7f9b833b,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-7a0bf51e-1591-443f-b737-94678e859da3,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-36f81626-bdc7-4ca2-a9ab-7557b53abe21,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-bb13fa56-68d9-46bc-9d9a-a13970d420df,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-77a3b11e-90cc-4d6e-9338-e7ad62b74579,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-6ca99209-4881-4117-93d4-188e69a0676c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811528329-172.17.0.10-1598171806728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42596,DS-e28e6882-0b8d-4184-ac31-aa7277ab2e61,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-c6aaebce-cb10-4de1-a9fe-558850bace4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-bd8bb28a-92cb-4167-a9eb-54de7f9b833b,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-7a0bf51e-1591-443f-b737-94678e859da3,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-36f81626-bdc7-4ca2-a9ab-7557b53abe21,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-bb13fa56-68d9-46bc-9d9a-a13970d420df,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-77a3b11e-90cc-4d6e-9338-e7ad62b74579,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-6ca99209-4881-4117-93d4-188e69a0676c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757058548-172.17.0.10-1598172113956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38032,DS-1d22e7b5-8263-450f-a629-5eb66674117d,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-f63f12ea-5979-473a-8f26-376e762f9f74,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-73a8d37a-02e0-4800-bb27-78ef65bb29eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-a404e097-940d-4e66-8553-74f0dae33563,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-8cf29341-93aa-4751-9071-ee3213135296,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-9094c2d8-9005-4591-aa66-9b4e49001fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-93cbea95-ec7f-4022-b04c-c90f4124af0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-1a7c65fe-b2cc-4a51-b795-b95d35ed8015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757058548-172.17.0.10-1598172113956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38032,DS-1d22e7b5-8263-450f-a629-5eb66674117d,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-f63f12ea-5979-473a-8f26-376e762f9f74,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-73a8d37a-02e0-4800-bb27-78ef65bb29eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-a404e097-940d-4e66-8553-74f0dae33563,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-8cf29341-93aa-4751-9071-ee3213135296,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-9094c2d8-9005-4591-aa66-9b4e49001fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-93cbea95-ec7f-4022-b04c-c90f4124af0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-1a7c65fe-b2cc-4a51-b795-b95d35ed8015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836127018-172.17.0.10-1598172186019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33492,DS-1e7bea74-7674-4495-b10c-834a7629c147,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-d2d40d5c-a0f0-449c-9996-361698543ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-13becc10-9b01-474a-a37e-de01176fa528,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-d05e5111-e4bc-4fcf-a3c1-7589c6b386ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-8162c7a4-3faf-4dbe-9117-8a2f59dd2bda,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-20102a9f-0d43-42bd-a7a0-3289b44b2304,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-b440e21a-a21d-4441-b00f-1be33d78066a,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-4450cbdd-abd1-436a-accb-1a892d91af98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836127018-172.17.0.10-1598172186019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33492,DS-1e7bea74-7674-4495-b10c-834a7629c147,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-d2d40d5c-a0f0-449c-9996-361698543ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-13becc10-9b01-474a-a37e-de01176fa528,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-d05e5111-e4bc-4fcf-a3c1-7589c6b386ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-8162c7a4-3faf-4dbe-9117-8a2f59dd2bda,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-20102a9f-0d43-42bd-a7a0-3289b44b2304,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-b440e21a-a21d-4441-b00f-1be33d78066a,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-4450cbdd-abd1-436a-accb-1a892d91af98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363692025-172.17.0.10-1598172340347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40866,DS-ba38a250-f43d-41db-99d8-516a6af79651,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-a0d684ad-1405-444a-8e2d-d84cba028206,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-22413b0d-dec0-4d54-83fc-0a27978ccd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-40906e7c-629e-46d7-9531-dd799763bb19,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-b3711a3c-b927-4e26-b91a-6efffd854f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-4a5c8c4e-7c0d-4d2e-b0ac-d654404d5688,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-6d76044a-31d5-4d42-8a26-946b7590423f,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-c0c479fa-ab0b-4c50-b7a9-aebe7df0f8f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363692025-172.17.0.10-1598172340347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40866,DS-ba38a250-f43d-41db-99d8-516a6af79651,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-a0d684ad-1405-444a-8e2d-d84cba028206,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-22413b0d-dec0-4d54-83fc-0a27978ccd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-40906e7c-629e-46d7-9531-dd799763bb19,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-b3711a3c-b927-4e26-b91a-6efffd854f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-4a5c8c4e-7c0d-4d2e-b0ac-d654404d5688,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-6d76044a-31d5-4d42-8a26-946b7590423f,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-c0c479fa-ab0b-4c50-b7a9-aebe7df0f8f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93823671-172.17.0.10-1598172562036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34609,DS-27abdfdc-3cbe-441d-b87b-2b6eb4c9d4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-940955f4-45e3-4ecc-9113-875afde218db,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-d947b716-7529-43b8-85dc-8c149e96faf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-3704ce9d-07fd-4aef-96ed-fcfe9fa34d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-f1fa9268-ab5b-43ec-9977-ba019af43412,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-f0d7723d-1a0a-4f5d-92d3-7ccea4e2da91,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-5e6c8855-6e01-4b41-8284-7622b7b200fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-e292524a-ea28-4056-9aa6-1d02114826dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93823671-172.17.0.10-1598172562036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34609,DS-27abdfdc-3cbe-441d-b87b-2b6eb4c9d4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-940955f4-45e3-4ecc-9113-875afde218db,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-d947b716-7529-43b8-85dc-8c149e96faf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-3704ce9d-07fd-4aef-96ed-fcfe9fa34d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-f1fa9268-ab5b-43ec-9977-ba019af43412,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-f0d7723d-1a0a-4f5d-92d3-7ccea4e2da91,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-5e6c8855-6e01-4b41-8284-7622b7b200fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-e292524a-ea28-4056-9aa6-1d02114826dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958852521-172.17.0.10-1598173216333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33593,DS-f1f0fad5-779e-4d6b-b1b7-f61f37c36946,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-b51e2ee2-623f-4bec-ae07-482343945e47,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-989dfe77-52c3-40df-a3aa-1411ded0971f,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-ac47424e-2393-4ba9-811f-a91cfd45970d,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-d6e4595b-cbbe-4fa3-b0f8-2ad8a2a461d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-380a4649-4515-4d1a-80c1-f33fc6083eac,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-56a8bc41-74c7-4d63-93ba-58ee663a1244,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-651272f1-ee0d-413c-9932-98c21a30efb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958852521-172.17.0.10-1598173216333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33593,DS-f1f0fad5-779e-4d6b-b1b7-f61f37c36946,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-b51e2ee2-623f-4bec-ae07-482343945e47,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-989dfe77-52c3-40df-a3aa-1411ded0971f,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-ac47424e-2393-4ba9-811f-a91cfd45970d,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-d6e4595b-cbbe-4fa3-b0f8-2ad8a2a461d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-380a4649-4515-4d1a-80c1-f33fc6083eac,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-56a8bc41-74c7-4d63-93ba-58ee663a1244,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-651272f1-ee0d-413c-9932-98c21a30efb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741729595-172.17.0.10-1598173263275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43361,DS-8feb65f2-d6c1-42f4-a495-e22495d93cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-e52cd8cc-8354-4c00-b275-3e5458e7c24b,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-e065b219-64c8-4351-bf0f-a9c6da254f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-c383fdeb-67e2-481e-b854-619553c91372,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-38c313ab-8ac2-45fa-824f-d6b7709b6e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-f2290a14-27bb-463b-8266-f304e416e928,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-536463da-8e6e-4667-8356-94fbb8a63b84,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-097b0c4c-6b4b-4569-a8b4-93ba23ecbd36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741729595-172.17.0.10-1598173263275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43361,DS-8feb65f2-d6c1-42f4-a495-e22495d93cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-e52cd8cc-8354-4c00-b275-3e5458e7c24b,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-e065b219-64c8-4351-bf0f-a9c6da254f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-c383fdeb-67e2-481e-b854-619553c91372,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-38c313ab-8ac2-45fa-824f-d6b7709b6e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-f2290a14-27bb-463b-8266-f304e416e928,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-536463da-8e6e-4667-8356-94fbb8a63b84,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-097b0c4c-6b4b-4569-a8b4-93ba23ecbd36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566403242-172.17.0.10-1598173632421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36926,DS-cb34ec99-6a33-4e7a-b2e2-59b05490eae6,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-9b040d27-28d3-4a25-b9f5-64d6f6f215a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-cf8bb6e8-5b7a-42e1-bbb8-d1b9435744bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-bc6e10c2-738b-4348-89d6-d8c66a44ad0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-07b19047-2f37-4ff1-a94c-e2b22a7b2f74,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-183f0de2-c19e-4d3f-a9fc-3735653c8cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-2aac17f9-bce2-4c11-a1ef-538e5977a827,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-fd6389d3-f378-42a8-8a99-2df58627be5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566403242-172.17.0.10-1598173632421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36926,DS-cb34ec99-6a33-4e7a-b2e2-59b05490eae6,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-9b040d27-28d3-4a25-b9f5-64d6f6f215a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-cf8bb6e8-5b7a-42e1-bbb8-d1b9435744bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-bc6e10c2-738b-4348-89d6-d8c66a44ad0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-07b19047-2f37-4ff1-a94c-e2b22a7b2f74,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-183f0de2-c19e-4d3f-a9fc-3735653c8cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-2aac17f9-bce2-4c11-a1ef-538e5977a827,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-fd6389d3-f378-42a8-8a99-2df58627be5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696019270-172.17.0.10-1598174334212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34364,DS-6e2b17a3-69d1-4e7e-a985-62aa8a0fb9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-cdfc3d80-9b74-4734-8fd7-97fcc74b189a,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-449aa941-202b-4d57-9ab1-e8a90de99346,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-6bb0974f-98d5-47d9-b3d3-afb9f2e82f50,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-0639af71-fc92-4f31-856d-27d0f94d1893,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-9f74b443-6f6d-4f04-9544-8c34b9f8b2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-e858c869-9683-4ba5-b397-6c097df8174a,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-466d8fcd-ab80-4d24-8fff-24e4cb7b46d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696019270-172.17.0.10-1598174334212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34364,DS-6e2b17a3-69d1-4e7e-a985-62aa8a0fb9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-cdfc3d80-9b74-4734-8fd7-97fcc74b189a,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-449aa941-202b-4d57-9ab1-e8a90de99346,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-6bb0974f-98d5-47d9-b3d3-afb9f2e82f50,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-0639af71-fc92-4f31-856d-27d0f94d1893,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-9f74b443-6f6d-4f04-9544-8c34b9f8b2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-e858c869-9683-4ba5-b397-6c097df8174a,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-466d8fcd-ab80-4d24-8fff-24e4cb7b46d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123996398-172.17.0.10-1598174449159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35842,DS-050a9163-40ed-48a5-9697-45dda97a0de3,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-8e140035-6d9f-41d6-b3f7-71ccaef95108,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-e1b33e16-da70-40a8-9842-7c644f2f0008,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-6e9601a2-4ccb-468a-a684-677ddb3e090b,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-74db1daa-3130-4135-9f1f-7f37a1dfe249,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-7114edbb-b2a6-4374-85ae-32b9e69b4dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-93ed49b2-28d1-4e3e-8123-9b16e40f0feb,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-46418cf0-2987-4f64-9e90-1e4a33767ed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123996398-172.17.0.10-1598174449159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35842,DS-050a9163-40ed-48a5-9697-45dda97a0de3,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-8e140035-6d9f-41d6-b3f7-71ccaef95108,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-e1b33e16-da70-40a8-9842-7c644f2f0008,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-6e9601a2-4ccb-468a-a684-677ddb3e090b,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-74db1daa-3130-4135-9f1f-7f37a1dfe249,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-7114edbb-b2a6-4374-85ae-32b9e69b4dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-93ed49b2-28d1-4e3e-8123-9b16e40f0feb,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-46418cf0-2987-4f64-9e90-1e4a33767ed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918058948-172.17.0.10-1598174599304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39686,DS-8a924203-aa88-491f-b6ce-0876c8abc348,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-580fad47-de21-431a-a856-34ce827d35ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-cb836954-fc1b-4999-bb27-bd1ee0e8fa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-dd689c2f-b693-42e8-ad00-ccf76e1c55ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-f9e71ae2-4500-42c0-b873-17e6d67e3a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-2876f7b9-0b91-4298-9dfd-5982c629048e,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-163d4d9c-ac8d-4d32-9c1a-e408b880bcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-0e9e6423-c3a4-48f0-ace5-3c527dc51673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918058948-172.17.0.10-1598174599304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39686,DS-8a924203-aa88-491f-b6ce-0876c8abc348,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-580fad47-de21-431a-a856-34ce827d35ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-cb836954-fc1b-4999-bb27-bd1ee0e8fa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-dd689c2f-b693-42e8-ad00-ccf76e1c55ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-f9e71ae2-4500-42c0-b873-17e6d67e3a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-2876f7b9-0b91-4298-9dfd-5982c629048e,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-163d4d9c-ac8d-4d32-9c1a-e408b880bcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-0e9e6423-c3a4-48f0-ace5-3c527dc51673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620017922-172.17.0.10-1598174902716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45229,DS-615d3ba3-1c68-47a4-a721-0a841b8022bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-68ee386f-39b3-4405-92b4-44b412daf6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-e2f710f3-02c6-4701-888c-40993be466b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-294e9aff-1ab3-45d2-83e1-6cd908a15525,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-6e56cace-8b64-4878-a4ee-3a78dc588dce,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-575b89e6-0d41-4000-b047-49dacc6a00c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-8b1d0b1f-cf7d-47e7-aba4-f0e24c952059,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-5cfff8fa-b7e7-45cf-979e-708bb3699740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620017922-172.17.0.10-1598174902716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45229,DS-615d3ba3-1c68-47a4-a721-0a841b8022bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-68ee386f-39b3-4405-92b4-44b412daf6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-e2f710f3-02c6-4701-888c-40993be466b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-294e9aff-1ab3-45d2-83e1-6cd908a15525,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-6e56cace-8b64-4878-a4ee-3a78dc588dce,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-575b89e6-0d41-4000-b047-49dacc6a00c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-8b1d0b1f-cf7d-47e7-aba4-f0e24c952059,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-5cfff8fa-b7e7-45cf-979e-708bb3699740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976023694-172.17.0.10-1598175162245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36677,DS-31a748f2-05de-49ae-85d0-8869d4368f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-4a69219d-7516-4990-9ab5-3072f2c9cb70,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-74e32540-662c-4d04-98b3-4bca235481b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-25caed9a-3999-4a78-ae27-44b3703c10bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-b1800e6d-2015-4726-a7a0-10b43aa41d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-b7c7ca3e-4e23-47ed-8ef5-78ca2347e1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-78efd40a-5afb-4be1-a49d-8d85337db4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-1bed41df-cdbc-4420-ad13-271bbbb4d8ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976023694-172.17.0.10-1598175162245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36677,DS-31a748f2-05de-49ae-85d0-8869d4368f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-4a69219d-7516-4990-9ab5-3072f2c9cb70,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-74e32540-662c-4d04-98b3-4bca235481b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-25caed9a-3999-4a78-ae27-44b3703c10bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-b1800e6d-2015-4726-a7a0-10b43aa41d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-b7c7ca3e-4e23-47ed-8ef5-78ca2347e1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-78efd40a-5afb-4be1-a49d-8d85337db4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-1bed41df-cdbc-4420-ad13-271bbbb4d8ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896471513-172.17.0.10-1598175487167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33349,DS-9750af6d-51d8-4a5f-8bcf-0035138b1aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-1812f1fa-fc9b-4d39-a6d7-52e3af916997,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-326515bb-660f-4cfe-bcda-896a1dcf3173,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-70e78991-07c2-4ac7-8e3f-9e12a43f039d,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-d5fe95d2-f65e-4300-90e5-bfc5f336aebf,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-078610ef-e1b1-439f-8af6-9d260d3d80f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-c95ea594-7660-4495-9f8d-bf79b80256f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-0fd9dc96-3e1b-4644-a71a-ea488513b344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896471513-172.17.0.10-1598175487167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33349,DS-9750af6d-51d8-4a5f-8bcf-0035138b1aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-1812f1fa-fc9b-4d39-a6d7-52e3af916997,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-326515bb-660f-4cfe-bcda-896a1dcf3173,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-70e78991-07c2-4ac7-8e3f-9e12a43f039d,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-d5fe95d2-f65e-4300-90e5-bfc5f336aebf,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-078610ef-e1b1-439f-8af6-9d260d3d80f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-c95ea594-7660-4495-9f8d-bf79b80256f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-0fd9dc96-3e1b-4644-a71a-ea488513b344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5636
