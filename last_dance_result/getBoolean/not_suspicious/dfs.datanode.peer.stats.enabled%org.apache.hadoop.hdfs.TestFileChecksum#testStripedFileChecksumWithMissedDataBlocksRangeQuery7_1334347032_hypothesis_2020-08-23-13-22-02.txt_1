reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400357634-172.17.0.7-1598189027659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36775,DS-cae1f50d-9eac-4da7-9edd-366c5b46048a,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-9c8dbd8a-b8ec-431a-8f7e-fb2a352cfc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-3a13d266-cc0d-40ef-b4f5-dce3379e78d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-4464af07-b33c-4c22-aaee-9ce33119a6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-30d7afc3-c547-4f2e-aa43-31de0ae662b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-04675d81-20ef-4ac0-87af-c147a058d168,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-05e887ad-13e7-4d1e-875f-18f99c7debfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-26297654-5b2f-4bcc-b1f7-cfc459aa5717,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400357634-172.17.0.7-1598189027659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36775,DS-cae1f50d-9eac-4da7-9edd-366c5b46048a,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-9c8dbd8a-b8ec-431a-8f7e-fb2a352cfc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-3a13d266-cc0d-40ef-b4f5-dce3379e78d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-4464af07-b33c-4c22-aaee-9ce33119a6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-30d7afc3-c547-4f2e-aa43-31de0ae662b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-04675d81-20ef-4ac0-87af-c147a058d168,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-05e887ad-13e7-4d1e-875f-18f99c7debfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-26297654-5b2f-4bcc-b1f7-cfc459aa5717,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012037076-172.17.0.7-1598189286581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46375,DS-e9e3b469-1ffe-41b8-a502-c08085ec2085,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-76d5f11c-ea27-4ed0-a5dd-d4fa7635af15,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-a541132c-158a-4b9a-9e96-bc9dae3f37a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-b6c883de-a04e-4856-a6e7-803a20ebeb48,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-87875864-1d95-4f7e-a061-76771152e6df,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-10b0bb83-482d-4cb0-8a83-9cffd54b18e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-8ec54682-1b6e-4b2b-84d1-cd0bbaaa104c,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-e20cb944-9e63-4fdd-95fe-c6e6d1b0537d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012037076-172.17.0.7-1598189286581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46375,DS-e9e3b469-1ffe-41b8-a502-c08085ec2085,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-76d5f11c-ea27-4ed0-a5dd-d4fa7635af15,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-a541132c-158a-4b9a-9e96-bc9dae3f37a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-b6c883de-a04e-4856-a6e7-803a20ebeb48,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-87875864-1d95-4f7e-a061-76771152e6df,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-10b0bb83-482d-4cb0-8a83-9cffd54b18e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-8ec54682-1b6e-4b2b-84d1-cd0bbaaa104c,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-e20cb944-9e63-4fdd-95fe-c6e6d1b0537d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915082526-172.17.0.7-1598189326270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43725,DS-4d02e5d3-4246-4140-80b1-104c79aed6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-4bc8e75f-c1a8-4dec-92bb-baaa31cf063b,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-6b52bb46-3fbf-406e-b6fd-840c0f47eac9,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-ebbf9d0f-413b-4098-89ea-a1b298a31dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-01a39264-61bc-47c3-b805-711b5f2f6849,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-a56e3d53-c8f4-451e-82bd-3561f01bf32b,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-5c01d490-3676-4254-880d-e6bd8288e172,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-beb1aac8-b76a-4429-9518-87b260e1b401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915082526-172.17.0.7-1598189326270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43725,DS-4d02e5d3-4246-4140-80b1-104c79aed6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-4bc8e75f-c1a8-4dec-92bb-baaa31cf063b,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-6b52bb46-3fbf-406e-b6fd-840c0f47eac9,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-ebbf9d0f-413b-4098-89ea-a1b298a31dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-01a39264-61bc-47c3-b805-711b5f2f6849,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-a56e3d53-c8f4-451e-82bd-3561f01bf32b,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-5c01d490-3676-4254-880d-e6bd8288e172,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-beb1aac8-b76a-4429-9518-87b260e1b401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983125751-172.17.0.7-1598189717575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40393,DS-b8ad99fa-c12a-4ea7-ad9e-f40da2f6828e,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-ab158a68-83a4-4601-8d2d-5491e4cf2745,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-8405130b-2340-46cb-9632-fe82e025dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-c1880244-f072-4799-9900-a60261420a62,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-7bdd0ca2-41b5-4867-a0be-d7d25e432558,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-5607aeb2-b2c2-4c57-a2c7-934cc6ccebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-2e8b145f-39a4-4ab3-9ecc-17d1ca358042,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-39dbc165-c257-4f56-b074-1169092905e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983125751-172.17.0.7-1598189717575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40393,DS-b8ad99fa-c12a-4ea7-ad9e-f40da2f6828e,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-ab158a68-83a4-4601-8d2d-5491e4cf2745,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-8405130b-2340-46cb-9632-fe82e025dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-c1880244-f072-4799-9900-a60261420a62,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-7bdd0ca2-41b5-4867-a0be-d7d25e432558,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-5607aeb2-b2c2-4c57-a2c7-934cc6ccebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-2e8b145f-39a4-4ab3-9ecc-17d1ca358042,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-39dbc165-c257-4f56-b074-1169092905e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394942993-172.17.0.7-1598189808697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35499,DS-b178e2ee-13c2-4183-b7ea-bd5657fb6128,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-7a54b0c7-40be-4051-b185-dfd270d118f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-0c1583b2-f2b4-423e-9d91-99fc7bdd1e27,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-404e250f-e060-4894-a10b-e7e7c17f011a,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-7fd53280-3431-411a-a274-e0d1de9f22a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-8246e870-f197-41f9-81f0-f1bb5bf3bbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-d0a939d0-abf1-44e8-9880-9a45b5826344,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-76b340b0-ddc4-4824-88c1-dc98db08874b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394942993-172.17.0.7-1598189808697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35499,DS-b178e2ee-13c2-4183-b7ea-bd5657fb6128,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-7a54b0c7-40be-4051-b185-dfd270d118f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-0c1583b2-f2b4-423e-9d91-99fc7bdd1e27,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-404e250f-e060-4894-a10b-e7e7c17f011a,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-7fd53280-3431-411a-a274-e0d1de9f22a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-8246e870-f197-41f9-81f0-f1bb5bf3bbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-d0a939d0-abf1-44e8-9880-9a45b5826344,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-76b340b0-ddc4-4824-88c1-dc98db08874b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340452574-172.17.0.7-1598189938027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38803,DS-30dbc06c-b28f-4a8a-a81a-b8b0cd2d07e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-e3ac86aa-f900-4ab9-9128-35fc9939a5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-7eb6ccc8-8e2e-4a5f-96a3-56b6edeaed3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-dd3bcf69-08b2-4906-b155-78d13b4fb77b,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-6bb2ecc6-d2f0-4005-80ef-8e025756f50f,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-bd78be1d-6f22-4b41-ac38-685f028acbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-f2c40c51-78f5-4800-aca9-0f2a319fa498,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-a3878044-9f55-4f9d-9c50-24e066952e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340452574-172.17.0.7-1598189938027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38803,DS-30dbc06c-b28f-4a8a-a81a-b8b0cd2d07e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-e3ac86aa-f900-4ab9-9128-35fc9939a5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-7eb6ccc8-8e2e-4a5f-96a3-56b6edeaed3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-dd3bcf69-08b2-4906-b155-78d13b4fb77b,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-6bb2ecc6-d2f0-4005-80ef-8e025756f50f,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-bd78be1d-6f22-4b41-ac38-685f028acbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-f2c40c51-78f5-4800-aca9-0f2a319fa498,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-a3878044-9f55-4f9d-9c50-24e066952e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513212767-172.17.0.7-1598190163648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45939,DS-aa0c088b-66ca-498f-8f75-193b28183344,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-b17c69b2-e6cd-40db-b154-7a00986d4913,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-8b4318bf-d679-4ac5-8941-a6ad13bea768,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-4a8e5e0e-ba2a-4f0c-8453-2a91f11f0370,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-d37caef2-9fab-4765-bf8a-f178ae2a0fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-7793e957-ff29-4971-837a-cc191c0e1c95,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-30fb7a9c-5ff4-4b7f-a29f-0c1bea0c5a56,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-015cee74-f462-4c30-b557-d770ca16b00e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513212767-172.17.0.7-1598190163648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45939,DS-aa0c088b-66ca-498f-8f75-193b28183344,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-b17c69b2-e6cd-40db-b154-7a00986d4913,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-8b4318bf-d679-4ac5-8941-a6ad13bea768,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-4a8e5e0e-ba2a-4f0c-8453-2a91f11f0370,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-d37caef2-9fab-4765-bf8a-f178ae2a0fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-7793e957-ff29-4971-837a-cc191c0e1c95,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-30fb7a9c-5ff4-4b7f-a29f-0c1bea0c5a56,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-015cee74-f462-4c30-b557-d770ca16b00e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902878413-172.17.0.7-1598190349429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46432,DS-c9b17b4d-403d-42d1-be52-b80c082d25e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-6722ede3-67da-47f7-8d51-71cee58ad125,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-dce8595a-eadb-4bca-83b6-36a7a44cb2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-0972be5c-f2b9-4477-bd18-6bddf85ed36e,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-bf7fd456-337a-4d35-af1a-a24f78903a39,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-4a6b2722-5509-4955-828c-808eed74dd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-5209a571-784d-4f54-bbaf-7b69d8fc9e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-e4fe55af-b679-44a0-aa49-052f32b885e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902878413-172.17.0.7-1598190349429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46432,DS-c9b17b4d-403d-42d1-be52-b80c082d25e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-6722ede3-67da-47f7-8d51-71cee58ad125,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-dce8595a-eadb-4bca-83b6-36a7a44cb2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-0972be5c-f2b9-4477-bd18-6bddf85ed36e,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-bf7fd456-337a-4d35-af1a-a24f78903a39,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-4a6b2722-5509-4955-828c-808eed74dd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-5209a571-784d-4f54-bbaf-7b69d8fc9e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-e4fe55af-b679-44a0-aa49-052f32b885e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823588096-172.17.0.7-1598190482549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35714,DS-d1a2d840-ba88-4179-800b-3c8acd02ef0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-d182dc3e-cd0e-4720-893f-f2a8489b4b22,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-5f2b0cb3-fba1-4a8d-9060-84e0fa9f03f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-b3bfabfc-6402-4664-93b5-6d0c338d1494,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-2618bec8-49ff-416f-bd97-03a2e3bccf9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-1f430fc5-614a-4701-89bc-ec621d341800,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-8cc205e7-d148-4e33-ad9d-475bfc62ee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-406c9f3f-1ec0-4907-8a49-d41ff511a19e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823588096-172.17.0.7-1598190482549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35714,DS-d1a2d840-ba88-4179-800b-3c8acd02ef0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-d182dc3e-cd0e-4720-893f-f2a8489b4b22,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-5f2b0cb3-fba1-4a8d-9060-84e0fa9f03f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-b3bfabfc-6402-4664-93b5-6d0c338d1494,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-2618bec8-49ff-416f-bd97-03a2e3bccf9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-1f430fc5-614a-4701-89bc-ec621d341800,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-8cc205e7-d148-4e33-ad9d-475bfc62ee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-406c9f3f-1ec0-4907-8a49-d41ff511a19e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341106387-172.17.0.7-1598190685147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-bb7a9679-a17e-405f-bcb2-86ac94d79cae,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-02acbb1f-8ff4-422a-9727-53b2dfd3c04f,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-8cd996b4-9166-4578-8ba8-835b405b4056,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-ccbc6241-4245-4509-886a-50f11f508e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-30929f06-4954-45f0-a8f6-1ecf3daa6256,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-05c0cf26-175d-4afa-928f-564b17a74d07,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-d78a80d2-d344-4bcf-8e6b-812da95f0aec,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-69f50b79-b00a-4756-bf82-70374c6e5c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341106387-172.17.0.7-1598190685147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-bb7a9679-a17e-405f-bcb2-86ac94d79cae,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-02acbb1f-8ff4-422a-9727-53b2dfd3c04f,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-8cd996b4-9166-4578-8ba8-835b405b4056,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-ccbc6241-4245-4509-886a-50f11f508e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-30929f06-4954-45f0-a8f6-1ecf3daa6256,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-05c0cf26-175d-4afa-928f-564b17a74d07,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-d78a80d2-d344-4bcf-8e6b-812da95f0aec,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-69f50b79-b00a-4756-bf82-70374c6e5c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194764455-172.17.0.7-1598190728426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41756,DS-e6742268-aced-4406-b60b-a8609c29c758,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-300c5b9d-0387-40f9-974a-784f37c6ed88,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-db78c1d2-3b3d-4765-b430-d83639a55e52,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-5e6ed9b6-7558-4aef-87c2-53e36084d6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-e7017d4b-0277-4225-97ce-60e7809c12cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-f0ae4498-2437-483c-87a0-3425dce3076e,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-5176b48e-77f3-4fda-98bf-47246db17f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-414774c4-8373-46d9-b9f1-4c29d2f66379,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194764455-172.17.0.7-1598190728426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41756,DS-e6742268-aced-4406-b60b-a8609c29c758,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-300c5b9d-0387-40f9-974a-784f37c6ed88,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-db78c1d2-3b3d-4765-b430-d83639a55e52,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-5e6ed9b6-7558-4aef-87c2-53e36084d6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-e7017d4b-0277-4225-97ce-60e7809c12cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-f0ae4498-2437-483c-87a0-3425dce3076e,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-5176b48e-77f3-4fda-98bf-47246db17f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-414774c4-8373-46d9-b9f1-4c29d2f66379,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832829833-172.17.0.7-1598191059453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45440,DS-afc1b62e-d8ab-41b2-bc4b-6fb8bc27d5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-11ba608d-9104-4509-b11b-b89f4be0a43b,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-04aced82-6b78-4a4a-ae70-9bd0e3cb6bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-8db6ba38-716f-449a-8df2-c4f52d20e621,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-40c1bf3f-40ee-4127-b819-14eb18ab39e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-ee0b875f-c3c7-48ac-b9ff-4184591123bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-de79b1c2-1af4-4483-b100-e29b5adbb39f,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-84389461-bc49-44fd-bc7d-02c4609ecd08,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832829833-172.17.0.7-1598191059453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45440,DS-afc1b62e-d8ab-41b2-bc4b-6fb8bc27d5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-11ba608d-9104-4509-b11b-b89f4be0a43b,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-04aced82-6b78-4a4a-ae70-9bd0e3cb6bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-8db6ba38-716f-449a-8df2-c4f52d20e621,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-40c1bf3f-40ee-4127-b819-14eb18ab39e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-ee0b875f-c3c7-48ac-b9ff-4184591123bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-de79b1c2-1af4-4483-b100-e29b5adbb39f,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-84389461-bc49-44fd-bc7d-02c4609ecd08,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394202952-172.17.0.7-1598191090358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39983,DS-32eb0787-1012-4bf1-9efa-3f3cabb8b4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-00cee81e-d8d7-41ea-942f-837120807f93,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-979e4fef-fe1e-42c2-bcd9-b2b4c801b3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-3498eb6c-0058-4a18-b5f7-84ec8d94818c,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-fc74bb28-6bc7-4e35-a4fc-8617a4d48691,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-3024896c-96c5-4ac9-991b-8671ebaa728e,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-227ecc59-fcf2-4373-9dd4-7eb8c4ea42b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-89f377e6-9ac3-4292-853d-9e42fe1f883f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394202952-172.17.0.7-1598191090358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39983,DS-32eb0787-1012-4bf1-9efa-3f3cabb8b4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-00cee81e-d8d7-41ea-942f-837120807f93,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-979e4fef-fe1e-42c2-bcd9-b2b4c801b3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-3498eb6c-0058-4a18-b5f7-84ec8d94818c,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-fc74bb28-6bc7-4e35-a4fc-8617a4d48691,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-3024896c-96c5-4ac9-991b-8671ebaa728e,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-227ecc59-fcf2-4373-9dd4-7eb8c4ea42b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-89f377e6-9ac3-4292-853d-9e42fe1f883f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144663839-172.17.0.7-1598191163437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42203,DS-f748decb-dd63-4ecd-a7ab-be89da4950d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-26e6ed13-8637-4bf6-bf0b-e1297271bad4,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-4fc10fc0-970a-4de8-aa2c-e37309ca72b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-dd8d8caa-10de-4562-b03d-9c90ece1f29e,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-6a7499ed-d120-4a67-aaf9-317fac6455db,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-1930090b-8136-4058-b0e5-2cc3fb1c31a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-e1f8dc27-e484-4c89-bd06-878a0bd6ee4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-f59221a1-b075-4e57-94c4-1406fabbc970,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144663839-172.17.0.7-1598191163437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42203,DS-f748decb-dd63-4ecd-a7ab-be89da4950d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-26e6ed13-8637-4bf6-bf0b-e1297271bad4,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-4fc10fc0-970a-4de8-aa2c-e37309ca72b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-dd8d8caa-10de-4562-b03d-9c90ece1f29e,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-6a7499ed-d120-4a67-aaf9-317fac6455db,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-1930090b-8136-4058-b0e5-2cc3fb1c31a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-e1f8dc27-e484-4c89-bd06-878a0bd6ee4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-f59221a1-b075-4e57-94c4-1406fabbc970,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686160149-172.17.0.7-1598191204366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44922,DS-e8598617-5cc5-4510-b010-60526f809a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-7c2b4870-e64a-4eb2-a475-63d01f0bc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-b48d207f-3a4e-4897-84de-a4544892f425,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-c78e45c0-5023-4349-a947-5f05a1a5d86a,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-ec4ef630-1c9d-4777-a19f-36f3008f9e30,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-d39a87ba-f57e-4edd-adb4-742f4d51cf94,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-0ea5ee78-f07e-45aa-8361-ca1dcd2d2c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-4c763a8e-6001-48bb-ba0b-56306ebaddc4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686160149-172.17.0.7-1598191204366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44922,DS-e8598617-5cc5-4510-b010-60526f809a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-7c2b4870-e64a-4eb2-a475-63d01f0bc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-b48d207f-3a4e-4897-84de-a4544892f425,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-c78e45c0-5023-4349-a947-5f05a1a5d86a,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-ec4ef630-1c9d-4777-a19f-36f3008f9e30,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-d39a87ba-f57e-4edd-adb4-742f4d51cf94,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-0ea5ee78-f07e-45aa-8361-ca1dcd2d2c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-4c763a8e-6001-48bb-ba0b-56306ebaddc4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106342010-172.17.0.7-1598191460212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35989,DS-fde4a264-df7a-452c-a241-26f4682fff64,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-78be48ca-8655-49be-bd61-13472a1957f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-38da0210-37c5-4102-b41c-f5abc10278e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-402d88a0-eea6-4204-bbe0-6ea1a8081061,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-d811ddb7-c132-4177-a19c-afc9b719c39c,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-9193c369-dd01-4137-b05c-94500484788d,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-6eec1c9c-815d-42d4-99c2-c06a0a7d1827,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-b933f9aa-bbf3-4e77-a599-efd700ca3e9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106342010-172.17.0.7-1598191460212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35989,DS-fde4a264-df7a-452c-a241-26f4682fff64,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-78be48ca-8655-49be-bd61-13472a1957f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-38da0210-37c5-4102-b41c-f5abc10278e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-402d88a0-eea6-4204-bbe0-6ea1a8081061,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-d811ddb7-c132-4177-a19c-afc9b719c39c,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-9193c369-dd01-4137-b05c-94500484788d,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-6eec1c9c-815d-42d4-99c2-c06a0a7d1827,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-b933f9aa-bbf3-4e77-a599-efd700ca3e9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588348623-172.17.0.7-1598191578039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41633,DS-71bda4dd-40fa-49dd-8951-f22e395e9e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-1e6573a7-1da0-47b8-b2aa-eacf57ae7e68,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-d5504015-98cc-495e-8451-268badadb6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-8e9afa2f-beb0-432c-9bff-e6137f2fb2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-dd9385c9-90e0-4d96-bd1e-1f77e8b755a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-2d3e7937-3288-4f28-89f9-36dbb66c19cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-972e79c5-bb8d-4881-bbfd-8e6046b1135e,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-255ec5a3-de8f-48d0-b9f3-a7e5318d4814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588348623-172.17.0.7-1598191578039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41633,DS-71bda4dd-40fa-49dd-8951-f22e395e9e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-1e6573a7-1da0-47b8-b2aa-eacf57ae7e68,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-d5504015-98cc-495e-8451-268badadb6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-8e9afa2f-beb0-432c-9bff-e6137f2fb2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-dd9385c9-90e0-4d96-bd1e-1f77e8b755a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-2d3e7937-3288-4f28-89f9-36dbb66c19cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-972e79c5-bb8d-4881-bbfd-8e6046b1135e,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-255ec5a3-de8f-48d0-b9f3-a7e5318d4814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109466231-172.17.0.7-1598191920600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34358,DS-9413e1e2-6560-4ba3-a049-61279bd98ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-c5c8bc1a-5542-45ea-a5fc-8edf17ae6d46,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-46ecef09-ac50-4110-a152-f1d850ff2533,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-44db3e1a-5c99-4c79-9eae-fa95bb5e1d78,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-e6e8fbd2-03ce-4b47-9c8b-abf513ca9a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-8fb9c571-1108-4edb-8c54-bc0639559674,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-86d64da9-202e-4ee1-9a34-7d42b7f1afae,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-8e2cd01d-43e6-441e-b4e1-2c9d10720b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109466231-172.17.0.7-1598191920600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34358,DS-9413e1e2-6560-4ba3-a049-61279bd98ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-c5c8bc1a-5542-45ea-a5fc-8edf17ae6d46,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-46ecef09-ac50-4110-a152-f1d850ff2533,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-44db3e1a-5c99-4c79-9eae-fa95bb5e1d78,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-e6e8fbd2-03ce-4b47-9c8b-abf513ca9a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-8fb9c571-1108-4edb-8c54-bc0639559674,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-86d64da9-202e-4ee1-9a34-7d42b7f1afae,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-8e2cd01d-43e6-441e-b4e1-2c9d10720b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176920474-172.17.0.7-1598192056271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43424,DS-b7493f1a-9e4d-4403-94a2-ffd7db3a6185,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-af6abd14-c093-4b07-9117-79d763831e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-7552a55b-786c-4d5e-8916-b3e35f3b6f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-d6c0b142-36c4-4397-b8af-5406ec083a73,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-0fce00f6-7e64-493e-9fc3-3f51f0803807,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-0fd3273a-67ca-4684-b1ab-e8275642f62b,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-d1f12d87-f178-40b1-a896-dd09d13411d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-e5a3c825-283f-4dcd-9e2a-3f78b7c1f2a7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176920474-172.17.0.7-1598192056271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43424,DS-b7493f1a-9e4d-4403-94a2-ffd7db3a6185,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-af6abd14-c093-4b07-9117-79d763831e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-7552a55b-786c-4d5e-8916-b3e35f3b6f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-d6c0b142-36c4-4397-b8af-5406ec083a73,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-0fce00f6-7e64-493e-9fc3-3f51f0803807,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-0fd3273a-67ca-4684-b1ab-e8275642f62b,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-d1f12d87-f178-40b1-a896-dd09d13411d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-e5a3c825-283f-4dcd-9e2a-3f78b7c1f2a7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319674239-172.17.0.7-1598192340236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44515,DS-9d88c9ae-cbd1-45f9-a466-3a85968043d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-c74d6598-4ab8-4cf7-bb46-5cb10748c0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-ac40d19d-8083-40b2-95c1-d69a86434f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-97be2b29-808b-40e1-888c-15681ba2f119,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-361fe353-917f-43db-a333-3718e4872fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-1bc11e39-41cf-459e-b091-abe375b43254,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-784c96a4-8d2e-4915-a6fd-d996c543eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-ea3c0010-4eb9-456f-b126-6723d286c9eb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319674239-172.17.0.7-1598192340236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44515,DS-9d88c9ae-cbd1-45f9-a466-3a85968043d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-c74d6598-4ab8-4cf7-bb46-5cb10748c0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-ac40d19d-8083-40b2-95c1-d69a86434f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-97be2b29-808b-40e1-888c-15681ba2f119,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-361fe353-917f-43db-a333-3718e4872fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-1bc11e39-41cf-459e-b091-abe375b43254,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-784c96a4-8d2e-4915-a6fd-d996c543eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-ea3c0010-4eb9-456f-b126-6723d286c9eb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743469787-172.17.0.7-1598192435881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40046,DS-2db1362f-aa8e-425b-bbdb-58bdc41b3679,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-3d566397-97cc-4069-80bb-c1c8fe355f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-51d49f45-c246-4489-9768-6b20c816ff24,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-52cbf7ef-2f4d-40c7-b090-b1e364ef4197,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-430bb3d2-2d75-42c3-a6d2-41eaffd32efa,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-78958b50-7878-4b2f-8df2-515d1f33ff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-7a91f8d6-7802-4298-b6a5-6c3863f8320d,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-671e18f5-94ce-4020-aee2-e00180a65e11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743469787-172.17.0.7-1598192435881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40046,DS-2db1362f-aa8e-425b-bbdb-58bdc41b3679,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-3d566397-97cc-4069-80bb-c1c8fe355f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-51d49f45-c246-4489-9768-6b20c816ff24,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-52cbf7ef-2f4d-40c7-b090-b1e364ef4197,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-430bb3d2-2d75-42c3-a6d2-41eaffd32efa,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-78958b50-7878-4b2f-8df2-515d1f33ff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-7a91f8d6-7802-4298-b6a5-6c3863f8320d,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-671e18f5-94ce-4020-aee2-e00180a65e11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305985289-172.17.0.7-1598192476245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40213,DS-68b9a50f-bb2b-4a9c-8834-be235024c93e,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-54e98e9d-6b85-464d-bd0d-22de80d66ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-309bb805-5966-435b-95e5-5f6b16682a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-5d9b6af1-a4fc-4ffb-b42d-c356851dca64,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-574fc64b-be41-4288-ba6e-5eea50d3ea6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-cd86dc56-a353-4eb2-a5fb-7b61308a480e,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-475b60e1-cb0f-49ae-bd79-e96f588c3a96,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-21a60145-1d95-43ff-a0e3-fe16148ae510,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305985289-172.17.0.7-1598192476245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40213,DS-68b9a50f-bb2b-4a9c-8834-be235024c93e,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-54e98e9d-6b85-464d-bd0d-22de80d66ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-309bb805-5966-435b-95e5-5f6b16682a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-5d9b6af1-a4fc-4ffb-b42d-c356851dca64,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-574fc64b-be41-4288-ba6e-5eea50d3ea6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-cd86dc56-a353-4eb2-a5fb-7b61308a480e,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-475b60e1-cb0f-49ae-bd79-e96f588c3a96,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-21a60145-1d95-43ff-a0e3-fe16148ae510,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879809740-172.17.0.7-1598192578362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43694,DS-a7076b78-d25e-4836-8074-d899ff9bd4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-78e6f75e-7ec9-4a77-8493-3268b19366c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-21b1e134-e1d2-463a-bba7-3eb0df3042dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-8be36c47-11b4-4b38-8896-65856b6e3bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-02419781-9a75-4c98-a7e8-31a7fcea8171,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-8fb6ae81-3f69-464e-a6f5-9079c9b0b976,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-191b9ff3-ce96-407e-84c0-d8ec5fe8bdee,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-121fd0ba-e4af-4d02-a955-366fef31a5af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879809740-172.17.0.7-1598192578362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43694,DS-a7076b78-d25e-4836-8074-d899ff9bd4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-78e6f75e-7ec9-4a77-8493-3268b19366c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-21b1e134-e1d2-463a-bba7-3eb0df3042dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-8be36c47-11b4-4b38-8896-65856b6e3bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-02419781-9a75-4c98-a7e8-31a7fcea8171,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-8fb6ae81-3f69-464e-a6f5-9079c9b0b976,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-191b9ff3-ce96-407e-84c0-d8ec5fe8bdee,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-121fd0ba-e4af-4d02-a955-366fef31a5af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767811737-172.17.0.7-1598193186320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39107,DS-f3534dfb-b4da-4f67-ac72-2c56d96d561d,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-5586f2d8-d785-4c28-9ee9-6b50bab0275a,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-37e544f0-99d9-4ba4-b068-edbe6a745151,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-02983c13-e572-4c2e-9126-402f1595aa06,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-a6ab48e8-8dbb-4f6d-81e9-c24f16f60ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-203e41c0-69e4-40a7-81d8-bd4b4b4ea83c,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-8f48ab94-a8c6-4efd-bf33-236d1286e679,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-db4868a6-a19b-4830-bb00-8f9934d72e99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767811737-172.17.0.7-1598193186320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39107,DS-f3534dfb-b4da-4f67-ac72-2c56d96d561d,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-5586f2d8-d785-4c28-9ee9-6b50bab0275a,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-37e544f0-99d9-4ba4-b068-edbe6a745151,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-02983c13-e572-4c2e-9126-402f1595aa06,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-a6ab48e8-8dbb-4f6d-81e9-c24f16f60ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-203e41c0-69e4-40a7-81d8-bd4b4b4ea83c,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-8f48ab94-a8c6-4efd-bf33-236d1286e679,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-db4868a6-a19b-4830-bb00-8f9934d72e99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401828045-172.17.0.7-1598193369923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37760,DS-dba87e48-363a-42d6-8458-56bb965d4f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-319dd412-4114-455c-9957-b31bd5ce6bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-04e2effc-3ad1-46f0-8836-26d9fc439f41,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-5c49720b-6a60-49da-9885-fa84df08666b,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-52c5c7a5-29b7-4053-879d-bdacc647fa7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-dbcc7384-95a3-4a96-9011-e36d0d5720b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-7fca7afb-1b8b-4d07-b8f8-7cfa68b78854,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-b89cbb90-6a9b-470e-8754-c0981438e2d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401828045-172.17.0.7-1598193369923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37760,DS-dba87e48-363a-42d6-8458-56bb965d4f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-319dd412-4114-455c-9957-b31bd5ce6bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-04e2effc-3ad1-46f0-8836-26d9fc439f41,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-5c49720b-6a60-49da-9885-fa84df08666b,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-52c5c7a5-29b7-4053-879d-bdacc647fa7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-dbcc7384-95a3-4a96-9011-e36d0d5720b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-7fca7afb-1b8b-4d07-b8f8-7cfa68b78854,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-b89cbb90-6a9b-470e-8754-c0981438e2d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-861887505-172.17.0.7-1598193404563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46509,DS-47809a24-50b3-4add-b4cd-9077d69b6d71,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-f0ffd349-d501-4fb9-b3e3-992c9f11e0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-f8737267-98d8-4beb-8197-4e8b668f22c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-43e89934-cdb9-4f23-b076-fff25bdfc313,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-8d36e6db-3bb6-42df-a47d-54cf5a155f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-a371533a-6ad5-4d5a-96fb-61826ffacbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-b6f9b4d4-2b4f-4ad3-8e42-f27fd4219151,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-267dc1f5-69b1-4c93-9689-e1c97b9ebda7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-861887505-172.17.0.7-1598193404563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46509,DS-47809a24-50b3-4add-b4cd-9077d69b6d71,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-f0ffd349-d501-4fb9-b3e3-992c9f11e0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-f8737267-98d8-4beb-8197-4e8b668f22c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-43e89934-cdb9-4f23-b076-fff25bdfc313,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-8d36e6db-3bb6-42df-a47d-54cf5a155f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-a371533a-6ad5-4d5a-96fb-61826ffacbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-b6f9b4d4-2b4f-4ad3-8e42-f27fd4219151,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-267dc1f5-69b1-4c93-9689-e1c97b9ebda7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917395404-172.17.0.7-1598193622936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38620,DS-8bc2595e-310f-46af-ad23-3133da236a53,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-1ef14e54-6c57-4b5d-8911-6db625dc6782,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-01788e06-986a-44b6-b1d9-50462cb41dab,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-1daf29d6-e7c9-462b-81a3-24a8e4ebbf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-2a4767d1-c2de-4645-bcbb-aba53b3b9996,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-0172f427-6324-4964-aea7-5759461faa47,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-c373ad42-f116-44d3-bc63-fe50edcc792f,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-06c3cfba-3623-4041-89aa-0f0b990a1c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917395404-172.17.0.7-1598193622936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38620,DS-8bc2595e-310f-46af-ad23-3133da236a53,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-1ef14e54-6c57-4b5d-8911-6db625dc6782,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-01788e06-986a-44b6-b1d9-50462cb41dab,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-1daf29d6-e7c9-462b-81a3-24a8e4ebbf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-2a4767d1-c2de-4645-bcbb-aba53b3b9996,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-0172f427-6324-4964-aea7-5759461faa47,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-c373ad42-f116-44d3-bc63-fe50edcc792f,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-06c3cfba-3623-4041-89aa-0f0b990a1c35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037260822-172.17.0.7-1598193795592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42237,DS-1cde97d2-74d2-4427-bbe0-ee5d9410257b,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-f05dfa96-a8e9-4bdc-8a92-4e7bf43b0777,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-91f6d737-d9f8-4006-a19b-cc2dc31ed59d,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-70d0ed5d-92e5-4d04-a6c2-623286498425,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-3d5e32df-b136-441e-97d7-f21bbb68080b,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-ac865495-5fd5-4b1c-8df9-dd1b79ec8027,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-0ff95b73-00f4-4ceb-99d1-81a04498dbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-d16463b7-9971-4840-a1fc-4f079bd7e9fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037260822-172.17.0.7-1598193795592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42237,DS-1cde97d2-74d2-4427-bbe0-ee5d9410257b,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-f05dfa96-a8e9-4bdc-8a92-4e7bf43b0777,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-91f6d737-d9f8-4006-a19b-cc2dc31ed59d,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-70d0ed5d-92e5-4d04-a6c2-623286498425,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-3d5e32df-b136-441e-97d7-f21bbb68080b,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-ac865495-5fd5-4b1c-8df9-dd1b79ec8027,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-0ff95b73-00f4-4ceb-99d1-81a04498dbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-d16463b7-9971-4840-a1fc-4f079bd7e9fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37930630-172.17.0.7-1598193880474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45335,DS-ef8f40c6-a58c-42ce-892a-72ae5b2fd166,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-1606d687-621e-493c-9aa4-30a705cb2f15,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-65c8a8d1-3dd5-4f4e-ad62-2e6792acdc47,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-69662c9d-0350-4756-9d80-f16af11e8e86,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-767451b0-a2db-49ac-bc36-5e3c95feca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-5f0d7235-ac69-4f6c-8b7b-689c24b2e6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-b3143262-7310-49e8-9378-cb61c902bf00,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-1cfa6f8e-c539-4468-ba89-e848fcd4998a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37930630-172.17.0.7-1598193880474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45335,DS-ef8f40c6-a58c-42ce-892a-72ae5b2fd166,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-1606d687-621e-493c-9aa4-30a705cb2f15,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-65c8a8d1-3dd5-4f4e-ad62-2e6792acdc47,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-69662c9d-0350-4756-9d80-f16af11e8e86,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-767451b0-a2db-49ac-bc36-5e3c95feca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-5f0d7235-ac69-4f6c-8b7b-689c24b2e6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-b3143262-7310-49e8-9378-cb61c902bf00,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-1cfa6f8e-c539-4468-ba89-e848fcd4998a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1787222432-172.17.0.7-1598194882992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37201,DS-313ab18c-6ee9-4829-879b-08cf1c1e5902,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-5276996f-eab3-49cf-962a-9b0f5a753a77,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-e2673781-f513-4410-aa60-2f0f7f2ea6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-1cde51d7-f459-4456-a277-4fd4d1752030,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-cb165345-cdba-4b05-a345-f2890f2a06e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-df53ece4-58f7-4596-8ccc-95d4be19784a,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-299d3a8c-2e6f-4f02-9fb0-d19903d9d356,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-b4711059-6731-4d4a-8f10-ae8903875a10,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1787222432-172.17.0.7-1598194882992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37201,DS-313ab18c-6ee9-4829-879b-08cf1c1e5902,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-5276996f-eab3-49cf-962a-9b0f5a753a77,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-e2673781-f513-4410-aa60-2f0f7f2ea6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-1cde51d7-f459-4456-a277-4fd4d1752030,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-cb165345-cdba-4b05-a345-f2890f2a06e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-df53ece4-58f7-4596-8ccc-95d4be19784a,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-299d3a8c-2e6f-4f02-9fb0-d19903d9d356,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-b4711059-6731-4d4a-8f10-ae8903875a10,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487359198-172.17.0.7-1598194929114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41339,DS-f312563c-001c-417c-8198-4da4ba71aa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-4632f6df-a27c-41d5-ad8b-fce31c2afa30,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-9ef22b7a-62d6-4080-98c9-4bb1f06b3f65,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-34f2cccc-77d4-4ac6-b352-4a9caa238338,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-fcecc25a-8d54-400a-8040-31b93388c886,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-d3408eab-505f-49a5-9634-a7a0704ade39,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-06b7f204-07ff-47fa-922d-11e301fab171,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-d3162388-178a-4618-9bb7-ba229eda8bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487359198-172.17.0.7-1598194929114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41339,DS-f312563c-001c-417c-8198-4da4ba71aa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-4632f6df-a27c-41d5-ad8b-fce31c2afa30,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-9ef22b7a-62d6-4080-98c9-4bb1f06b3f65,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-34f2cccc-77d4-4ac6-b352-4a9caa238338,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-fcecc25a-8d54-400a-8040-31b93388c886,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-d3408eab-505f-49a5-9634-a7a0704ade39,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-06b7f204-07ff-47fa-922d-11e301fab171,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-d3162388-178a-4618-9bb7-ba229eda8bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846054248-172.17.0.7-1598195010880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41206,DS-9f998d23-753d-4f54-926f-15993ca8e43b,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-8e7e4652-540b-4d4e-8abf-c63a4448cdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-3ca2b727-5631-4f4a-a9b1-39b8af46bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-038b84f3-70ef-41f7-b31b-3892860562ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-2d7de209-746f-46cf-b723-bb4299f68271,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-cc6ad6e7-ee95-437e-9131-b9e703f917cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-5dd550cb-a8d0-4266-a7b1-8f21235f1f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-dd25cc89-c008-4b90-a320-b59727b3a96a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846054248-172.17.0.7-1598195010880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41206,DS-9f998d23-753d-4f54-926f-15993ca8e43b,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-8e7e4652-540b-4d4e-8abf-c63a4448cdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-3ca2b727-5631-4f4a-a9b1-39b8af46bbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-038b84f3-70ef-41f7-b31b-3892860562ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-2d7de209-746f-46cf-b723-bb4299f68271,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-cc6ad6e7-ee95-437e-9131-b9e703f917cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-5dd550cb-a8d0-4266-a7b1-8f21235f1f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-dd25cc89-c008-4b90-a320-b59727b3a96a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830233369-172.17.0.7-1598195057677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36233,DS-114ce6f3-d66c-460c-968b-1d874c69bbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-9082a016-cf2a-4f8c-b99a-4869d29717d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-60575f4b-4f1f-46f7-b485-393722c984a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-17dbee7a-dc83-4a1c-a8af-c455f07d70a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-9f038148-f5c1-4829-9f4e-26c69402f47e,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-398444d9-8c68-47a8-af45-372ce57a0bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-f7089224-7e51-459d-9745-55fe13c7db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-14db84bf-623a-4e78-abb7-a16990bff987,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830233369-172.17.0.7-1598195057677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36233,DS-114ce6f3-d66c-460c-968b-1d874c69bbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-9082a016-cf2a-4f8c-b99a-4869d29717d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-60575f4b-4f1f-46f7-b485-393722c984a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-17dbee7a-dc83-4a1c-a8af-c455f07d70a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-9f038148-f5c1-4829-9f4e-26c69402f47e,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-398444d9-8c68-47a8-af45-372ce57a0bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-f7089224-7e51-459d-9745-55fe13c7db9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-14db84bf-623a-4e78-abb7-a16990bff987,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347755483-172.17.0.7-1598195197877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36898,DS-8354fe48-4cd5-433b-858b-96ce6489ec51,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-aeaebeb6-4588-4ff3-ba39-60e2269f7f55,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-956fe81b-720c-4a0b-8472-45e3c88d485f,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-f158e3d6-5e64-420b-8dce-25094b4ce470,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-8f0555bc-6499-421d-8d4d-81b4921e3bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-24ed7225-6fa4-407b-823f-45b632db5e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-6e6b9a96-07c4-41ef-a160-b659fbdb2893,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-2e3a233e-7f56-43dd-8422-301e95a9f54b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347755483-172.17.0.7-1598195197877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36898,DS-8354fe48-4cd5-433b-858b-96ce6489ec51,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-aeaebeb6-4588-4ff3-ba39-60e2269f7f55,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-956fe81b-720c-4a0b-8472-45e3c88d485f,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-f158e3d6-5e64-420b-8dce-25094b4ce470,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-8f0555bc-6499-421d-8d4d-81b4921e3bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-24ed7225-6fa4-407b-823f-45b632db5e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-6e6b9a96-07c4-41ef-a160-b659fbdb2893,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-2e3a233e-7f56-43dd-8422-301e95a9f54b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262762453-172.17.0.7-1598195369728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39105,DS-5e176a4a-06b4-4757-9c9f-20b4b4e56d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-fc5bd9d7-41f8-4337-b3b7-f88453e117f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-0c6cba74-65e6-40eb-ac5b-f6b536e0325a,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-2e117d95-4af1-4c4d-9938-557b90de7ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-b494fd6b-8b87-460c-9681-e67a3c8f099c,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-4ed3afec-e09d-4d8a-b9fd-aeffce137dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-dd4f1940-1269-48d9-a269-a398b008870c,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-b0497077-5ef2-4de9-a96e-ff2b247c6b6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262762453-172.17.0.7-1598195369728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39105,DS-5e176a4a-06b4-4757-9c9f-20b4b4e56d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-fc5bd9d7-41f8-4337-b3b7-f88453e117f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-0c6cba74-65e6-40eb-ac5b-f6b536e0325a,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-2e117d95-4af1-4c4d-9938-557b90de7ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-b494fd6b-8b87-460c-9681-e67a3c8f099c,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-4ed3afec-e09d-4d8a-b9fd-aeffce137dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-dd4f1940-1269-48d9-a269-a398b008870c,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-b0497077-5ef2-4de9-a96e-ff2b247c6b6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 23 out of 50
result: false positive !!!
Total execution time in seconds : 6648
