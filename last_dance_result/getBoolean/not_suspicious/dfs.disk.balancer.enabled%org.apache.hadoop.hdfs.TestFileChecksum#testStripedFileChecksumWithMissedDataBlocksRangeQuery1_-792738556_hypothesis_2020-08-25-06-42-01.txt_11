reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288255374-172.17.0.10-1598337849299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-1f394c3a-f4a1-4229-9c61-2a1b87a97a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-97f84c1e-ea37-43b4-905e-b3969c5ba638,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-f76252c0-9256-40c4-8dee-d5aae1de5ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-571cb6e8-2801-44b4-a1c4-980a211ef4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-4049743e-514a-48e5-947d-9a8a2a7d8957,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-4a3b370d-ceef-43bc-99ae-194f7096b653,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-90e370c5-2898-4af1-8aba-c70e9bcc4bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-08cf8d5b-e0f2-4bff-89a9-a07ea13224a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288255374-172.17.0.10-1598337849299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44846,DS-1f394c3a-f4a1-4229-9c61-2a1b87a97a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-97f84c1e-ea37-43b4-905e-b3969c5ba638,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-f76252c0-9256-40c4-8dee-d5aae1de5ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-571cb6e8-2801-44b4-a1c4-980a211ef4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-4049743e-514a-48e5-947d-9a8a2a7d8957,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-4a3b370d-ceef-43bc-99ae-194f7096b653,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-90e370c5-2898-4af1-8aba-c70e9bcc4bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-08cf8d5b-e0f2-4bff-89a9-a07ea13224a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305803933-172.17.0.10-1598338642362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36033,DS-07732294-9656-4c69-a8d3-dc83dc9d1b98,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-4a91131c-5dba-4036-8f04-662c5fd4b05f,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-04e67dc3-fab5-441b-9dd7-6406214c40ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-f64b37bd-f124-4968-8cfb-5dc235a330f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-dd0a94ad-6c92-4778-ac70-d48e9bb084a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-030e7c31-cf90-4faf-b01c-776d24b057db,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-ff55bca3-b0f5-46f5-a0ee-fb42e52f895e,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-ddf9719c-a48c-40f3-b7ed-fc983d810de1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305803933-172.17.0.10-1598338642362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36033,DS-07732294-9656-4c69-a8d3-dc83dc9d1b98,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-4a91131c-5dba-4036-8f04-662c5fd4b05f,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-04e67dc3-fab5-441b-9dd7-6406214c40ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-f64b37bd-f124-4968-8cfb-5dc235a330f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-dd0a94ad-6c92-4778-ac70-d48e9bb084a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-030e7c31-cf90-4faf-b01c-776d24b057db,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-ff55bca3-b0f5-46f5-a0ee-fb42e52f895e,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-ddf9719c-a48c-40f3-b7ed-fc983d810de1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004526348-172.17.0.10-1598339483225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41805,DS-425ab5ee-45e3-4b44-b3d0-92ae3a1b5488,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-bff26c44-7be5-48bf-a809-3bf721453181,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-b3941460-8eb7-4439-a199-e06393d02af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-0be739e4-9e53-4b13-b9a6-06f795298c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-0957611f-1696-42f3-b72d-79852eef98c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-d89c557d-29c7-4d30-8cca-2137baf1e537,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-d3f5a0b8-e945-4f15-9f10-b9ea4175c752,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-723fa3bd-7dcc-4b9f-a63c-9c9b1dcecdc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004526348-172.17.0.10-1598339483225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41805,DS-425ab5ee-45e3-4b44-b3d0-92ae3a1b5488,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-bff26c44-7be5-48bf-a809-3bf721453181,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-b3941460-8eb7-4439-a199-e06393d02af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-0be739e4-9e53-4b13-b9a6-06f795298c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-0957611f-1696-42f3-b72d-79852eef98c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-d89c557d-29c7-4d30-8cca-2137baf1e537,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-d3f5a0b8-e945-4f15-9f10-b9ea4175c752,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-723fa3bd-7dcc-4b9f-a63c-9c9b1dcecdc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271600298-172.17.0.10-1598339901000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38725,DS-677b1b7f-2e58-41a0-923c-ecbbfd3adeee,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-99d7859c-28e8-4591-a5de-42a204c30f13,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-59bac622-7a3e-435b-ba87-e6c12407a92c,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-c4b72c22-58f6-41db-8aa1-77fef7895c01,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-34606174-2b3e-4bbb-b81f-0631f9560b82,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-bbafd2c1-9322-498c-9ae8-0720990d5f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-c41743b3-0129-465c-9d45-bd24def63b48,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-650cb535-3e45-4b9e-9b52-51627956ad51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271600298-172.17.0.10-1598339901000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38725,DS-677b1b7f-2e58-41a0-923c-ecbbfd3adeee,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-99d7859c-28e8-4591-a5de-42a204c30f13,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-59bac622-7a3e-435b-ba87-e6c12407a92c,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-c4b72c22-58f6-41db-8aa1-77fef7895c01,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-34606174-2b3e-4bbb-b81f-0631f9560b82,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-bbafd2c1-9322-498c-9ae8-0720990d5f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-c41743b3-0129-465c-9d45-bd24def63b48,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-650cb535-3e45-4b9e-9b52-51627956ad51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867219499-172.17.0.10-1598339985435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43472,DS-866d72b5-a2f9-43a7-90a4-360ec118be7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-dd057ebe-ca1e-4213-b430-16e2afef8e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-75991d30-cb6f-4d99-8be8-a0b4e198ff94,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-20e300a9-a7c5-4066-aa60-d9c4f86ec1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-a9824a0c-74a7-43ce-843f-28d26e8658d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-135a49ac-3aa4-4fa3-acaf-e7cdef27979c,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-63c39dec-2277-4f7d-aa45-0ae445b9c491,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-e0698490-381e-402a-8874-e5deabc6b103,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867219499-172.17.0.10-1598339985435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43472,DS-866d72b5-a2f9-43a7-90a4-360ec118be7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-dd057ebe-ca1e-4213-b430-16e2afef8e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-75991d30-cb6f-4d99-8be8-a0b4e198ff94,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-20e300a9-a7c5-4066-aa60-d9c4f86ec1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-a9824a0c-74a7-43ce-843f-28d26e8658d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-135a49ac-3aa4-4fa3-acaf-e7cdef27979c,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-63c39dec-2277-4f7d-aa45-0ae445b9c491,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-e0698490-381e-402a-8874-e5deabc6b103,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369558411-172.17.0.10-1598340454103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42090,DS-82e6c117-f430-4e91-99a6-9072435c5a67,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-02b11b23-0fbc-4bd2-94bd-dc4d0d35b871,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-7179d1ca-0acf-4904-96da-e725fc3891e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-9a33f213-e610-4136-aaa0-386cea644a33,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-7368e758-26c8-4ea1-a028-e02b168f0627,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-392fd5b3-b0bf-47c1-94d3-a13b639c46b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-b7824aec-1147-4acf-9a40-d5dd60ed4b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-0800ae71-c304-4773-af2e-d5d26fcbe8a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369558411-172.17.0.10-1598340454103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42090,DS-82e6c117-f430-4e91-99a6-9072435c5a67,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-02b11b23-0fbc-4bd2-94bd-dc4d0d35b871,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-7179d1ca-0acf-4904-96da-e725fc3891e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-9a33f213-e610-4136-aaa0-386cea644a33,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-7368e758-26c8-4ea1-a028-e02b168f0627,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-392fd5b3-b0bf-47c1-94d3-a13b639c46b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-b7824aec-1147-4acf-9a40-d5dd60ed4b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-0800ae71-c304-4773-af2e-d5d26fcbe8a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220906020-172.17.0.10-1598340853423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38070,DS-d2ecc8e1-2c4c-4078-9f34-5b132136870d,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-746f60d3-d309-45ab-94e4-f27e9e106373,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-f4945fc6-bcc4-47dc-9cfc-6b6fa8884b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-1d995eac-9173-4d97-ae44-d31a8155822f,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-e5652399-48c0-45a7-b0db-94103738a045,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-6d8edc7b-4739-42ce-a0c1-7e65c325e639,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-00438e05-514d-41b4-b837-c4fac795c466,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-99892c3c-313d-45a8-a191-c9537b6bc5af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220906020-172.17.0.10-1598340853423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38070,DS-d2ecc8e1-2c4c-4078-9f34-5b132136870d,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-746f60d3-d309-45ab-94e4-f27e9e106373,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-f4945fc6-bcc4-47dc-9cfc-6b6fa8884b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-1d995eac-9173-4d97-ae44-d31a8155822f,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-e5652399-48c0-45a7-b0db-94103738a045,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-6d8edc7b-4739-42ce-a0c1-7e65c325e639,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-00438e05-514d-41b4-b837-c4fac795c466,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-99892c3c-313d-45a8-a191-c9537b6bc5af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794404012-172.17.0.10-1598340900945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46301,DS-520f0d06-bbdd-453f-b575-a5ca6a92209c,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-33e8acd2-3324-47b7-afce-18244a1eec48,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-879a20e5-7b95-4007-a081-05e622f069d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-5aaefc55-fd8e-4588-ad3d-97165d427484,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-3477cd9a-01cf-464b-8db1-28b7f4b1b2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-be44ff7f-8124-4a75-bb6e-2199b8a267e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-ef676ad9-b1eb-4023-8e38-377fa4693afd,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-f7c53140-521f-4de5-8efa-7c33568ae505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794404012-172.17.0.10-1598340900945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46301,DS-520f0d06-bbdd-453f-b575-a5ca6a92209c,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-33e8acd2-3324-47b7-afce-18244a1eec48,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-879a20e5-7b95-4007-a081-05e622f069d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-5aaefc55-fd8e-4588-ad3d-97165d427484,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-3477cd9a-01cf-464b-8db1-28b7f4b1b2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-be44ff7f-8124-4a75-bb6e-2199b8a267e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-ef676ad9-b1eb-4023-8e38-377fa4693afd,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-f7c53140-521f-4de5-8efa-7c33568ae505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483132073-172.17.0.10-1598341109713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41388,DS-7c881cb2-90d2-411d-b135-717f3587b44b,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-0fa3ee5b-6503-4fd3-a195-2fadea5c6675,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-efd5934d-dca1-4fb4-b3a0-a63d211a0e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-a6564837-6a9e-42e1-8e9a-b1cbe352049e,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-6e92c72c-2a50-462e-94f0-3188786de916,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-f39f8490-2c03-4233-8cba-a03c72dbe603,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-d2ed2c20-0acb-4a85-956c-185f65f37058,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-cd182051-b0b8-4183-ad4c-c99618dbedce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483132073-172.17.0.10-1598341109713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41388,DS-7c881cb2-90d2-411d-b135-717f3587b44b,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-0fa3ee5b-6503-4fd3-a195-2fadea5c6675,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-efd5934d-dca1-4fb4-b3a0-a63d211a0e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-a6564837-6a9e-42e1-8e9a-b1cbe352049e,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-6e92c72c-2a50-462e-94f0-3188786de916,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-f39f8490-2c03-4233-8cba-a03c72dbe603,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-d2ed2c20-0acb-4a85-956c-185f65f37058,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-cd182051-b0b8-4183-ad4c-c99618dbedce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607363101-172.17.0.10-1598341278161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40189,DS-5f36f7ae-3b6b-4cef-860b-06de0d3e883c,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-c9c96804-9c81-4c51-b0cb-2356aee52ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-09dc42be-e86a-49d9-a644-4f7c0f4a20f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-ce59f325-95d8-4a71-9883-e35b5aa1b7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-d5dd84aa-aa03-4ec0-991d-3b5cd850d201,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-4b36feb0-b9b0-4a65-8d49-3c420aea745c,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-6a1112c9-6a0f-40ea-b08a-259a03c7be8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-0811a309-4933-452a-a2cb-25429499725f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607363101-172.17.0.10-1598341278161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40189,DS-5f36f7ae-3b6b-4cef-860b-06de0d3e883c,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-c9c96804-9c81-4c51-b0cb-2356aee52ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-09dc42be-e86a-49d9-a644-4f7c0f4a20f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-ce59f325-95d8-4a71-9883-e35b5aa1b7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-d5dd84aa-aa03-4ec0-991d-3b5cd850d201,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-4b36feb0-b9b0-4a65-8d49-3c420aea745c,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-6a1112c9-6a0f-40ea-b08a-259a03c7be8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-0811a309-4933-452a-a2cb-25429499725f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309253851-172.17.0.10-1598341315958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37483,DS-76db1322-89a5-4687-94f6-5a68770f0aba,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-656c89d3-d0d1-4b34-9840-49e1a83948ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-79d1f644-15b4-4759-ab1f-be1dc3459144,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-2823b4bd-99fa-4ee3-aab7-4da9123827cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-86511bda-f7ab-4e14-99b0-cdd5dc27ef4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-e4f4c179-03f6-4f0b-8d95-617932045d08,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-70e87112-068b-4173-9021-988cff199f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-e308b5b3-be7a-456f-9b76-aca8c17b1132,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309253851-172.17.0.10-1598341315958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37483,DS-76db1322-89a5-4687-94f6-5a68770f0aba,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-656c89d3-d0d1-4b34-9840-49e1a83948ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-79d1f644-15b4-4759-ab1f-be1dc3459144,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-2823b4bd-99fa-4ee3-aab7-4da9123827cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-86511bda-f7ab-4e14-99b0-cdd5dc27ef4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-e4f4c179-03f6-4f0b-8d95-617932045d08,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-70e87112-068b-4173-9021-988cff199f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-e308b5b3-be7a-456f-9b76-aca8c17b1132,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039514786-172.17.0.10-1598341638482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45488,DS-215dc51a-707a-4663-8729-3696e43b0d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-840cff4d-d255-44c2-ba0d-716725a6d19e,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-4fd47a54-92b1-4331-bb6a-c09a6a173be0,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-b71fe613-c4be-4e67-96d5-f5aa0d0a9119,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-d8d420e5-7d62-4ec4-9045-8a00de3bc720,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-dd36bdd5-bd86-48ba-881f-6e4f5980fb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-ab028f19-07f7-4d89-aecc-d72fa9f2aca6,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-c7e8df45-2283-4dac-aef2-2fad13ef18de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039514786-172.17.0.10-1598341638482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45488,DS-215dc51a-707a-4663-8729-3696e43b0d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-840cff4d-d255-44c2-ba0d-716725a6d19e,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-4fd47a54-92b1-4331-bb6a-c09a6a173be0,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-b71fe613-c4be-4e67-96d5-f5aa0d0a9119,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-d8d420e5-7d62-4ec4-9045-8a00de3bc720,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-dd36bdd5-bd86-48ba-881f-6e4f5980fb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-ab028f19-07f7-4d89-aecc-d72fa9f2aca6,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-c7e8df45-2283-4dac-aef2-2fad13ef18de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255520684-172.17.0.10-1598342159425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46230,DS-f2e34e5a-304c-4e59-9e7b-2f2ca2ce3a89,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-a0c8b7c5-e473-48a0-8b5b-d5a148dd18fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-cee933cc-6728-457e-bc58-138497095d85,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-79a7ca41-fe6a-43c2-8b7f-939d87c46654,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-99f5d9d4-9441-41ba-a3e9-ee7cdac60c31,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-6b5b16ee-046d-4e1f-9ce0-281f6aafb8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-841a549e-a32b-4269-8e41-ed0bb3b16f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-4bd0b75b-7c7d-4427-9db9-458c0187cf0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255520684-172.17.0.10-1598342159425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46230,DS-f2e34e5a-304c-4e59-9e7b-2f2ca2ce3a89,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-a0c8b7c5-e473-48a0-8b5b-d5a148dd18fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-cee933cc-6728-457e-bc58-138497095d85,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-79a7ca41-fe6a-43c2-8b7f-939d87c46654,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-99f5d9d4-9441-41ba-a3e9-ee7cdac60c31,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-6b5b16ee-046d-4e1f-9ce0-281f6aafb8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-841a549e-a32b-4269-8e41-ed0bb3b16f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-4bd0b75b-7c7d-4427-9db9-458c0187cf0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707605261-172.17.0.10-1598342192659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44509,DS-095cec40-36c8-45fb-88d5-bc89aed6285d,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-8d8225e1-8385-4c5a-858c-83c67f7c9eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-9386eb6c-dc01-42f0-89b8-4a610a313d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-505bf358-ccb5-4dc5-845a-d8200a0be304,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-dd8a9f5f-6c88-4373-b2b9-a79c961e9475,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-1f4e4637-dea7-4187-8a88-7f7086219eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-3bd66427-a6a7-4f7b-8432-1b4f5dd812e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-84e1106a-94b9-42d2-ba46-ab0e38985efd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707605261-172.17.0.10-1598342192659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44509,DS-095cec40-36c8-45fb-88d5-bc89aed6285d,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-8d8225e1-8385-4c5a-858c-83c67f7c9eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-9386eb6c-dc01-42f0-89b8-4a610a313d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-505bf358-ccb5-4dc5-845a-d8200a0be304,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-dd8a9f5f-6c88-4373-b2b9-a79c961e9475,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-1f4e4637-dea7-4187-8a88-7f7086219eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-3bd66427-a6a7-4f7b-8432-1b4f5dd812e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-84e1106a-94b9-42d2-ba46-ab0e38985efd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251242724-172.17.0.10-1598342290041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44451,DS-5f7f9a7f-d443-4f85-aac9-3f552d46f0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-26e35706-e1b3-4306-b8d7-512521a2cce4,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-c7d99353-bde5-4767-b022-0f67383f30d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-2168cd1b-af4b-4fce-b5ae-d06013c252b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-e2b1203f-08f4-44a5-abee-49b85fb14395,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-cbb17a0e-8eed-41cd-8b3c-8bb077ff9c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-224d5741-2cfd-4213-8db7-20aab5671163,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-44305fe9-a8e0-48a2-b4b3-9f7f69bb2104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251242724-172.17.0.10-1598342290041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44451,DS-5f7f9a7f-d443-4f85-aac9-3f552d46f0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-26e35706-e1b3-4306-b8d7-512521a2cce4,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-c7d99353-bde5-4767-b022-0f67383f30d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-2168cd1b-af4b-4fce-b5ae-d06013c252b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-e2b1203f-08f4-44a5-abee-49b85fb14395,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-cbb17a0e-8eed-41cd-8b3c-8bb077ff9c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-224d5741-2cfd-4213-8db7-20aab5671163,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-44305fe9-a8e0-48a2-b4b3-9f7f69bb2104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303399182-172.17.0.10-1598342388814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44885,DS-d2882836-7e59-4b69-a2dc-82d4355dccb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-8967fbfb-4a68-4cfb-97b3-23b318f7ac50,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-63ca8501-e2ae-44f0-a883-c60841650a76,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-1b815d97-5b4f-41e5-83da-7e784dd715a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-d36e647a-0033-4755-abe6-dec886572f20,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-4ca341ea-744a-4ae8-b7e3-72cdc3eb8c38,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-f983db3b-f362-4e45-a5d4-cbf03b346d59,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-3de43c6d-4d46-4f89-9476-ccfaff01f230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303399182-172.17.0.10-1598342388814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44885,DS-d2882836-7e59-4b69-a2dc-82d4355dccb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-8967fbfb-4a68-4cfb-97b3-23b318f7ac50,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-63ca8501-e2ae-44f0-a883-c60841650a76,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-1b815d97-5b4f-41e5-83da-7e784dd715a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-d36e647a-0033-4755-abe6-dec886572f20,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-4ca341ea-744a-4ae8-b7e3-72cdc3eb8c38,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-f983db3b-f362-4e45-a5d4-cbf03b346d59,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-3de43c6d-4d46-4f89-9476-ccfaff01f230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027991169-172.17.0.10-1598342731681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46004,DS-b95f9c6c-6fa8-4b48-8cf3-274309f7fdde,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-4fd64d84-0438-43e5-98b6-7a09ca6d90d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-e2f79bf0-c85c-459e-8325-5c747fa60b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-254121fa-2576-4277-95b7-e30aaa91aae1,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-2d252731-7733-40e8-8fb4-4ad0b472c7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-49474dce-e8d6-4297-9a58-90dac9347947,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-5322cd37-d103-4655-9b49-8e32e5807c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-7583dfbc-1b99-4bbc-9a49-a8fb1f326b93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027991169-172.17.0.10-1598342731681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46004,DS-b95f9c6c-6fa8-4b48-8cf3-274309f7fdde,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-4fd64d84-0438-43e5-98b6-7a09ca6d90d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-e2f79bf0-c85c-459e-8325-5c747fa60b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-254121fa-2576-4277-95b7-e30aaa91aae1,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-2d252731-7733-40e8-8fb4-4ad0b472c7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-49474dce-e8d6-4297-9a58-90dac9347947,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-5322cd37-d103-4655-9b49-8e32e5807c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-7583dfbc-1b99-4bbc-9a49-a8fb1f326b93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545812407-172.17.0.10-1598342770867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41839,DS-bedf3dfc-c077-4ad9-98b8-d349751596f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-3f8fed3c-1f54-4d60-affe-4f525e1f06d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-7da15326-ede5-4d68-aaa7-54db79e88de4,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-c9bfbcd9-a303-4d66-a9d2-7ecdd9da90c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-e31459d6-27f6-449b-96d3-d2aea44a3f90,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-e98f0678-d2e5-41c8-a610-f384a584c06f,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-dedd8ac9-1567-4448-9888-434cab7e3c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-1855a669-1cbf-4d80-8605-490d5ed73a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545812407-172.17.0.10-1598342770867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41839,DS-bedf3dfc-c077-4ad9-98b8-d349751596f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-3f8fed3c-1f54-4d60-affe-4f525e1f06d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-7da15326-ede5-4d68-aaa7-54db79e88de4,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-c9bfbcd9-a303-4d66-a9d2-7ecdd9da90c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-e31459d6-27f6-449b-96d3-d2aea44a3f90,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-e98f0678-d2e5-41c8-a610-f384a584c06f,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-dedd8ac9-1567-4448-9888-434cab7e3c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-1855a669-1cbf-4d80-8605-490d5ed73a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596947682-172.17.0.10-1598342840782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33953,DS-28d692f7-1299-49ff-aebf-e1c3a7c5b64b,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-092269ba-6015-4c9c-bbf0-68a5f0a0900e,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-6979d8f3-6076-4d61-a3b8-4ded3508df9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-4f471cdd-2b21-4baf-ad15-f47402b836d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-916e144a-705a-48b9-9d58-12613a0fdc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-3d8a6bee-cd0d-4687-8602-028e6e02faa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-00c26c3f-ecbd-4c2b-bd0a-111daa213548,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-5b79d301-887b-48b1-bbb5-b03562df062f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596947682-172.17.0.10-1598342840782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33953,DS-28d692f7-1299-49ff-aebf-e1c3a7c5b64b,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-092269ba-6015-4c9c-bbf0-68a5f0a0900e,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-6979d8f3-6076-4d61-a3b8-4ded3508df9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-4f471cdd-2b21-4baf-ad15-f47402b836d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-916e144a-705a-48b9-9d58-12613a0fdc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-3d8a6bee-cd0d-4687-8602-028e6e02faa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-00c26c3f-ecbd-4c2b-bd0a-111daa213548,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-5b79d301-887b-48b1-bbb5-b03562df062f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5489
