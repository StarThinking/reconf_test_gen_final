reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300951440-172.17.0.6-1598177535115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-d9c5e466-a4b1-4514-ac28-a0ff86b9d0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-781498c6-f3b6-4145-b970-d4827b12654c,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-9bff4818-755b-4068-aced-ed7bf899b588,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-1c79ef0e-5252-4022-909c-d1a161fe245a,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-28142cdf-cf0c-407d-81c8-be23c6406079,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-b754274c-b79d-40f3-9b58-23a6bcd76aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-4a8c79f6-41ab-4193-b4af-7653536b92da,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-13087715-9dca-42f9-99d1-3d9a98e6611b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300951440-172.17.0.6-1598177535115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-d9c5e466-a4b1-4514-ac28-a0ff86b9d0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-781498c6-f3b6-4145-b970-d4827b12654c,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-9bff4818-755b-4068-aced-ed7bf899b588,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-1c79ef0e-5252-4022-909c-d1a161fe245a,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-28142cdf-cf0c-407d-81c8-be23c6406079,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-b754274c-b79d-40f3-9b58-23a6bcd76aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-4a8c79f6-41ab-4193-b4af-7653536b92da,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-13087715-9dca-42f9-99d1-3d9a98e6611b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185251656-172.17.0.6-1598177729214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41682,DS-558f89db-eb5b-48dd-9e2b-211c98c999ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-bce9156b-cdc4-4e97-8e7b-599142c1fde8,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-c9a9d29b-e82a-4fea-a64a-10f200cc110b,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-1ba2717f-2d05-48b6-ae2e-3fa53b0f615a,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-41277ece-d055-4530-850b-c04906163986,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-70055d66-ab3b-454f-ac5c-83cba2c3d88e,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-9e226704-3d8f-4e9e-89e0-2f7d4957c5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-025e915e-6791-4851-b57f-21e155d6d31e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185251656-172.17.0.6-1598177729214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41682,DS-558f89db-eb5b-48dd-9e2b-211c98c999ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-bce9156b-cdc4-4e97-8e7b-599142c1fde8,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-c9a9d29b-e82a-4fea-a64a-10f200cc110b,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-1ba2717f-2d05-48b6-ae2e-3fa53b0f615a,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-41277ece-d055-4530-850b-c04906163986,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-70055d66-ab3b-454f-ac5c-83cba2c3d88e,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-9e226704-3d8f-4e9e-89e0-2f7d4957c5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-025e915e-6791-4851-b57f-21e155d6d31e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107521901-172.17.0.6-1598178243500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35788,DS-aa76b2b8-f3e6-408a-917f-6b3527c08cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-a80befe2-cf6c-486a-8de1-f168c79de3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-9ace8c9e-b92d-4fd0-8906-8163bebb211b,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-0712d05f-1642-4a9b-96f2-a751c23b26c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-9898714b-5208-4b87-89c0-38787c625e40,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-c757a946-a175-4a37-82f8-f43fdc6841ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-627995ea-2e82-46d0-a1af-3734f574f0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-dff2ac4a-f828-41eb-85c2-913ab6529e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107521901-172.17.0.6-1598178243500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35788,DS-aa76b2b8-f3e6-408a-917f-6b3527c08cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-a80befe2-cf6c-486a-8de1-f168c79de3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-9ace8c9e-b92d-4fd0-8906-8163bebb211b,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-0712d05f-1642-4a9b-96f2-a751c23b26c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-9898714b-5208-4b87-89c0-38787c625e40,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-c757a946-a175-4a37-82f8-f43fdc6841ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-627995ea-2e82-46d0-a1af-3734f574f0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-dff2ac4a-f828-41eb-85c2-913ab6529e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483032574-172.17.0.6-1598178557849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44929,DS-27f03310-8f0c-46ee-8a00-28029473b46f,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-3a683131-1463-48bf-8c5d-4282362d04d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-012aaa9f-9799-4357-a560-3336761e26df,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-efd1d223-85f0-42db-b578-82226b0e6ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-56b20521-25c9-4491-8d37-9e5cab01d090,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-7cddfb93-a90d-470b-9f8b-df4e0f087ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-0fe43231-cd86-43e7-98f4-4dfa18682591,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-50333b7a-5ecc-4373-98f4-2603a6efc960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483032574-172.17.0.6-1598178557849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44929,DS-27f03310-8f0c-46ee-8a00-28029473b46f,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-3a683131-1463-48bf-8c5d-4282362d04d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-012aaa9f-9799-4357-a560-3336761e26df,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-efd1d223-85f0-42db-b578-82226b0e6ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-56b20521-25c9-4491-8d37-9e5cab01d090,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-7cddfb93-a90d-470b-9f8b-df4e0f087ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-0fe43231-cd86-43e7-98f4-4dfa18682591,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-50333b7a-5ecc-4373-98f4-2603a6efc960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220548721-172.17.0.6-1598178730550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45201,DS-3d34d587-ff52-47c8-baf7-437356004be3,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-2615efae-dbc0-455c-ada9-9dff71f5719b,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-e5491544-4a63-49cd-97c4-064c16205a86,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-0603139e-70bf-4318-9718-311a102d558d,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-f36f1770-e8f4-4603-aa98-842ce8bddd11,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-d4a46de3-65ee-466a-923e-585a16eff79a,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-52f91781-1218-4d34-8eb7-8e7b3643784a,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-4f3dd938-d849-49b9-950f-77a30a2e5ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220548721-172.17.0.6-1598178730550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45201,DS-3d34d587-ff52-47c8-baf7-437356004be3,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-2615efae-dbc0-455c-ada9-9dff71f5719b,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-e5491544-4a63-49cd-97c4-064c16205a86,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-0603139e-70bf-4318-9718-311a102d558d,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-f36f1770-e8f4-4603-aa98-842ce8bddd11,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-d4a46de3-65ee-466a-923e-585a16eff79a,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-52f91781-1218-4d34-8eb7-8e7b3643784a,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-4f3dd938-d849-49b9-950f-77a30a2e5ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545237170-172.17.0.6-1598178837107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43833,DS-8ed09a21-0f4c-4b71-9778-89e2c775b404,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-659a4fc8-f879-404f-abb9-0d046f0138e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-cf38c9cc-2252-455c-ac1b-923c9eb90517,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-775d998c-2e68-4f9e-9ba2-0d25ee34e1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-f1b378ab-7783-490b-97bb-a709c982d798,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-2d02bb02-d81c-4f27-97ad-070246f48c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-7f7cf178-5578-427b-af87-44861bb26bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-45ca7b94-4c66-418b-bcd6-2ed4a0acbdcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545237170-172.17.0.6-1598178837107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43833,DS-8ed09a21-0f4c-4b71-9778-89e2c775b404,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-659a4fc8-f879-404f-abb9-0d046f0138e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-cf38c9cc-2252-455c-ac1b-923c9eb90517,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-775d998c-2e68-4f9e-9ba2-0d25ee34e1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-f1b378ab-7783-490b-97bb-a709c982d798,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-2d02bb02-d81c-4f27-97ad-070246f48c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-7f7cf178-5578-427b-af87-44861bb26bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-45ca7b94-4c66-418b-bcd6-2ed4a0acbdcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867680226-172.17.0.6-1598179224209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-c2c933b4-182c-4a47-8693-ae27216af1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-f12afad7-9ffc-48c9-bce9-0a253565a2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-daa5ee98-34a0-470f-bdf8-64313a348e66,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-d289abe0-5424-4f05-9bc5-9824cb08eac1,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-7ae59536-5794-4b5a-99bd-665cbade9a30,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-f6a65dbd-3296-487f-85e8-912070d9ceaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-cf581206-50cd-4348-b1ee-b8afce6a1a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-4ee2e588-8d42-4bf9-9409-a23055c966ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867680226-172.17.0.6-1598179224209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-c2c933b4-182c-4a47-8693-ae27216af1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-f12afad7-9ffc-48c9-bce9-0a253565a2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-daa5ee98-34a0-470f-bdf8-64313a348e66,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-d289abe0-5424-4f05-9bc5-9824cb08eac1,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-7ae59536-5794-4b5a-99bd-665cbade9a30,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-f6a65dbd-3296-487f-85e8-912070d9ceaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-cf581206-50cd-4348-b1ee-b8afce6a1a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-4ee2e588-8d42-4bf9-9409-a23055c966ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093030624-172.17.0.6-1598179808652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37328,DS-67e27271-ca62-47bf-ad18-30dce4ed9748,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-8f428605-f4fc-43ba-80e0-bb8be57c8e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-826165c4-615d-4f87-bee3-a8ed339df011,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-a2c18559-95d0-4937-aa41-4a7d0426486b,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-a4d416e9-6a12-42f6-8963-d77f5ce32baf,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-c2bd5409-b7d8-4a29-af6f-8f49db108a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-ff7bccbb-d263-4352-93da-c0cbd3980898,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-abc2b380-acd6-45bb-9d9b-c980c6c1f694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093030624-172.17.0.6-1598179808652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37328,DS-67e27271-ca62-47bf-ad18-30dce4ed9748,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-8f428605-f4fc-43ba-80e0-bb8be57c8e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-826165c4-615d-4f87-bee3-a8ed339df011,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-a2c18559-95d0-4937-aa41-4a7d0426486b,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-a4d416e9-6a12-42f6-8963-d77f5ce32baf,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-c2bd5409-b7d8-4a29-af6f-8f49db108a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-ff7bccbb-d263-4352-93da-c0cbd3980898,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-abc2b380-acd6-45bb-9d9b-c980c6c1f694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951557966-172.17.0.6-1598180008680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36058,DS-bc0d1b01-22ac-4f32-b185-855f0bcfbebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-3a067fc4-d5b9-44fd-85ef-2fc6bed90bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-09a753e2-3c13-41b8-b173-9c157cc28945,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-90331aef-bde0-4235-b125-894caba1f9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-a5de78f8-9c91-409c-96b3-6f1b254e0acc,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-f040d294-3650-4fc0-9e61-7b4b44555536,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-7ccb7851-1068-4b43-890a-f8b7698f7236,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-2cf4922b-13e0-4775-a8cf-8d63a3a6701f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951557966-172.17.0.6-1598180008680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36058,DS-bc0d1b01-22ac-4f32-b185-855f0bcfbebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-3a067fc4-d5b9-44fd-85ef-2fc6bed90bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-09a753e2-3c13-41b8-b173-9c157cc28945,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-90331aef-bde0-4235-b125-894caba1f9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-a5de78f8-9c91-409c-96b3-6f1b254e0acc,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-f040d294-3650-4fc0-9e61-7b4b44555536,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-7ccb7851-1068-4b43-890a-f8b7698f7236,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-2cf4922b-13e0-4775-a8cf-8d63a3a6701f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535039264-172.17.0.6-1598180416252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43281,DS-99d00ebd-23bb-449f-b087-55fc99e984aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-844040b9-fdf1-4886-ac11-221f61044f30,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-cde68aab-4154-4da4-9da9-c2d27af6339e,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-c10197b3-d52f-43aa-b18a-23d0df019d04,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-47a86c2d-bf17-46ff-9486-dd70329eb928,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-a50658c8-6f4a-4e0d-a598-6ee56ca050da,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-2f452ee7-1cc6-4e99-87ef-3d265d6e8b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-005c730f-40f2-4391-b015-2adb2be69dfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535039264-172.17.0.6-1598180416252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43281,DS-99d00ebd-23bb-449f-b087-55fc99e984aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-844040b9-fdf1-4886-ac11-221f61044f30,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-cde68aab-4154-4da4-9da9-c2d27af6339e,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-c10197b3-d52f-43aa-b18a-23d0df019d04,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-47a86c2d-bf17-46ff-9486-dd70329eb928,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-a50658c8-6f4a-4e0d-a598-6ee56ca050da,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-2f452ee7-1cc6-4e99-87ef-3d265d6e8b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-005c730f-40f2-4391-b015-2adb2be69dfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725647915-172.17.0.6-1598181401031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40896,DS-6db83729-5b03-4ccd-b6ed-8ca5e44d103b,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-34bff455-b3ab-4c35-91b4-fa1c12ae0e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-e943ab47-4439-41e3-8440-f3eb4ab521d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-fc255a38-7652-496d-ab0b-e43739db0a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-7222c302-378d-4c0c-b8b0-d556a043cecd,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-8c249ff9-ec21-4c58-a35d-ecfe97c5909b,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-1080c25a-f472-4ee2-ad18-ddff2ca0f9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-7fa1be67-aa22-4450-8e21-2b5b9e23a964,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725647915-172.17.0.6-1598181401031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40896,DS-6db83729-5b03-4ccd-b6ed-8ca5e44d103b,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-34bff455-b3ab-4c35-91b4-fa1c12ae0e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-e943ab47-4439-41e3-8440-f3eb4ab521d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-fc255a38-7652-496d-ab0b-e43739db0a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-7222c302-378d-4c0c-b8b0-d556a043cecd,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-8c249ff9-ec21-4c58-a35d-ecfe97c5909b,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-1080c25a-f472-4ee2-ad18-ddff2ca0f9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-7fa1be67-aa22-4450-8e21-2b5b9e23a964,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396133698-172.17.0.6-1598181484416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34451,DS-b48a23b0-32c7-4c92-80a8-26f30b86a69d,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-27a2c84c-e051-405c-80fa-56e5149db0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-4ce88bc3-f604-48bd-9a2b-89717124b922,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-1dba27dd-887b-4cf2-a9d3-eb6b268a0bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-10326941-0c11-41a1-a54a-90434eb2d3de,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-c7ae5be0-0248-4adb-800d-75ca4d714198,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-6d1170c3-31a1-4234-9ca1-793ac7a952eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-8548dfea-6358-4a7a-b127-e0134dda5590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396133698-172.17.0.6-1598181484416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34451,DS-b48a23b0-32c7-4c92-80a8-26f30b86a69d,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-27a2c84c-e051-405c-80fa-56e5149db0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-4ce88bc3-f604-48bd-9a2b-89717124b922,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-1dba27dd-887b-4cf2-a9d3-eb6b268a0bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-10326941-0c11-41a1-a54a-90434eb2d3de,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-c7ae5be0-0248-4adb-800d-75ca4d714198,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-6d1170c3-31a1-4234-9ca1-793ac7a952eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-8548dfea-6358-4a7a-b127-e0134dda5590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.posix.acl.inheritance.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404298442-172.17.0.6-1598182234286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33751,DS-a88ee9b5-35e9-47ad-b5b9-bed35f647017,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-5859ba49-2d3d-44a7-89c7-e51ea5d5e8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-9c0e8f85-8dda-4e27-ae6f-7ece11d983dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-06bb0b72-c8d7-42e8-bc0a-72a1a1e24f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-9f4a72c1-3dd6-4ec7-804b-43de9f2b9edc,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-b51a68c1-98ac-4c2c-9e26-4596059015fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-54e20704-da46-4520-84e8-da2dfc9afdee,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-8c9ea758-9e89-48cd-b9b4-b7b5f460faec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404298442-172.17.0.6-1598182234286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33751,DS-a88ee9b5-35e9-47ad-b5b9-bed35f647017,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-5859ba49-2d3d-44a7-89c7-e51ea5d5e8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-9c0e8f85-8dda-4e27-ae6f-7ece11d983dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-06bb0b72-c8d7-42e8-bc0a-72a1a1e24f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-9f4a72c1-3dd6-4ec7-804b-43de9f2b9edc,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-b51a68c1-98ac-4c2c-9e26-4596059015fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-54e20704-da46-4520-84e8-da2dfc9afdee,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-8c9ea758-9e89-48cd-b9b4-b7b5f460faec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5346
