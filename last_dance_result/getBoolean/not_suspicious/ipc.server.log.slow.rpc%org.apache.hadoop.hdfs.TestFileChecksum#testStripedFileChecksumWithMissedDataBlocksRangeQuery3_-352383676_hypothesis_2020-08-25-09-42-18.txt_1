reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294211297-172.17.0.7-1598348617196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41077,DS-9ad2dbef-3043-4e4e-b083-7b0f79984e04,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-ef79650f-4a99-45d6-b6a6-1d5f5c6cbdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-19f9e32d-139d-4be3-87bd-97279d31a395,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-18aa4ef1-9f08-4bcf-b7a4-3fd31ac56ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-5a6c8ed6-6922-43c0-ba8c-86f7c4a9b919,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-ea07a77f-ba5b-41ea-bd8f-dbbdb222f3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-30c86f65-1afc-4576-b5e1-f8a11b6b3d83,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-88785048-14ce-4274-820f-97f6d28ae1f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294211297-172.17.0.7-1598348617196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41077,DS-9ad2dbef-3043-4e4e-b083-7b0f79984e04,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-ef79650f-4a99-45d6-b6a6-1d5f5c6cbdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-19f9e32d-139d-4be3-87bd-97279d31a395,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-18aa4ef1-9f08-4bcf-b7a4-3fd31ac56ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-5a6c8ed6-6922-43c0-ba8c-86f7c4a9b919,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-ea07a77f-ba5b-41ea-bd8f-dbbdb222f3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-30c86f65-1afc-4576-b5e1-f8a11b6b3d83,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-88785048-14ce-4274-820f-97f6d28ae1f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418641859-172.17.0.7-1598349051661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37606,DS-10f1fb42-eccc-4834-95a7-7e76ab2c2e33,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-42f48201-5061-414f-b896-8dc352b25ada,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-965704e1-07eb-4fe0-baa1-f8150bb2c9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-0bb1ad1f-c3f7-4282-a296-8dae5222500b,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-84d9c884-4913-4d90-9754-04c316f3168a,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-e0e4a815-8cbd-4d8d-b61c-98f4185c0b14,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-faf6273b-9526-4b28-8605-62dd3e3cf06f,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-2853e314-cc6f-45ce-9380-1c995651f2bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418641859-172.17.0.7-1598349051661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37606,DS-10f1fb42-eccc-4834-95a7-7e76ab2c2e33,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-42f48201-5061-414f-b896-8dc352b25ada,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-965704e1-07eb-4fe0-baa1-f8150bb2c9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-0bb1ad1f-c3f7-4282-a296-8dae5222500b,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-84d9c884-4913-4d90-9754-04c316f3168a,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-e0e4a815-8cbd-4d8d-b61c-98f4185c0b14,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-faf6273b-9526-4b28-8605-62dd3e3cf06f,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-2853e314-cc6f-45ce-9380-1c995651f2bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47591652-172.17.0.7-1598349329682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40533,DS-42d3b235-0d8e-4496-b5db-5fa54b6e1b74,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-993bfcf7-275e-4646-a14e-8dd0b5371348,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-40bc16e9-da1e-4665-b5c5-63a1f2bdc52c,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-5043022e-e50b-4b3c-a59e-af68a098ae5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-e8848e39-ee3c-4c0e-8b10-098831b695f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-bbed7555-2b3e-4515-9d75-5bec0db3cea3,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-f6416e59-a0b3-42b5-89d4-adebb21acbae,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-f5ccb8e9-935c-4c36-970c-878455a4ac77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47591652-172.17.0.7-1598349329682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40533,DS-42d3b235-0d8e-4496-b5db-5fa54b6e1b74,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-993bfcf7-275e-4646-a14e-8dd0b5371348,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-40bc16e9-da1e-4665-b5c5-63a1f2bdc52c,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-5043022e-e50b-4b3c-a59e-af68a098ae5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-e8848e39-ee3c-4c0e-8b10-098831b695f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-bbed7555-2b3e-4515-9d75-5bec0db3cea3,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-f6416e59-a0b3-42b5-89d4-adebb21acbae,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-f5ccb8e9-935c-4c36-970c-878455a4ac77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611117343-172.17.0.7-1598349711085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33751,DS-59ee36b1-9901-49fd-af18-87b1a2a0117a,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-6e34c1ac-4a1d-4343-af3c-1d996a67d9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-b5171a8f-9a62-4407-b653-5be77bbe317e,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-a419177a-7c6a-4901-9879-da20d77ee668,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-66e1aa1e-9732-408b-b593-47b5ad8778a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-6b53fe71-65bf-4884-a3a7-b6444c67476d,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-43d3a0c6-774d-49e3-b005-d93e859743a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-5b2036e7-1ec8-4593-b45b-b001ffd53bab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611117343-172.17.0.7-1598349711085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33751,DS-59ee36b1-9901-49fd-af18-87b1a2a0117a,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-6e34c1ac-4a1d-4343-af3c-1d996a67d9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-b5171a8f-9a62-4407-b653-5be77bbe317e,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-a419177a-7c6a-4901-9879-da20d77ee668,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-66e1aa1e-9732-408b-b593-47b5ad8778a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-6b53fe71-65bf-4884-a3a7-b6444c67476d,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-43d3a0c6-774d-49e3-b005-d93e859743a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-5b2036e7-1ec8-4593-b45b-b001ffd53bab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423716925-172.17.0.7-1598349871162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36661,DS-eb401466-f937-4bc8-8e06-60c7b4c56827,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-3dfb858e-998d-41fb-977a-8d70bfe5387f,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-02250f9f-7909-412f-9be9-ba53346660ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-3c528503-f967-4ea3-8281-863bc01d1920,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-9959e233-0786-44cc-87ae-675ca52a9506,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-8b2db9e3-dc32-40b0-9929-07bc270ae268,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-84588595-a041-4e00-b4c4-e59ff37f7fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-0468798c-5cf0-45ad-9a62-74681a967fe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423716925-172.17.0.7-1598349871162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36661,DS-eb401466-f937-4bc8-8e06-60c7b4c56827,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-3dfb858e-998d-41fb-977a-8d70bfe5387f,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-02250f9f-7909-412f-9be9-ba53346660ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-3c528503-f967-4ea3-8281-863bc01d1920,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-9959e233-0786-44cc-87ae-675ca52a9506,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-8b2db9e3-dc32-40b0-9929-07bc270ae268,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-84588595-a041-4e00-b4c4-e59ff37f7fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-0468798c-5cf0-45ad-9a62-74681a967fe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567891780-172.17.0.7-1598350340182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43871,DS-e22a9562-0923-4c48-bc90-67dd2ef4ac33,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-c31d7952-6187-4ac0-97e7-aea0dd29b313,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-f185c68c-fe5d-430b-9e29-a60911a11d94,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-54cf95b7-d3b0-4232-9815-305982c8aa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-d932bb4f-d89e-42b9-a475-6f1bc6a1b698,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-b248cdcd-a896-4626-a0e9-1855d7dd63ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-ea00e267-0b1b-4c4e-8e19-c15acf05bf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-7be3128f-7a93-49c8-9fc1-554f56eeb5e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567891780-172.17.0.7-1598350340182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43871,DS-e22a9562-0923-4c48-bc90-67dd2ef4ac33,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-c31d7952-6187-4ac0-97e7-aea0dd29b313,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-f185c68c-fe5d-430b-9e29-a60911a11d94,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-54cf95b7-d3b0-4232-9815-305982c8aa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-d932bb4f-d89e-42b9-a475-6f1bc6a1b698,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-b248cdcd-a896-4626-a0e9-1855d7dd63ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-ea00e267-0b1b-4c4e-8e19-c15acf05bf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-7be3128f-7a93-49c8-9fc1-554f56eeb5e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916622263-172.17.0.7-1598350491721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44777,DS-edc53c72-ae08-49c8-8a0b-967b1840c663,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-f065f3fd-c358-4c17-a94f-1e0e4170ee15,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-b1c289ea-021b-4785-9a04-73f857547102,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-5619ca06-6106-433d-bd58-f0e2dc325840,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-c469aff1-7e19-4cc5-abb0-fb316534cb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-521f5236-e714-44f3-b5a9-5ec4055ec554,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-5a4d714d-8bc5-4ca8-a7c8-28f2bc94b13e,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-b9cf3ce1-f99f-4c9a-8301-b3331da5b260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916622263-172.17.0.7-1598350491721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44777,DS-edc53c72-ae08-49c8-8a0b-967b1840c663,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-f065f3fd-c358-4c17-a94f-1e0e4170ee15,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-b1c289ea-021b-4785-9a04-73f857547102,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-5619ca06-6106-433d-bd58-f0e2dc325840,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-c469aff1-7e19-4cc5-abb0-fb316534cb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-521f5236-e714-44f3-b5a9-5ec4055ec554,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-5a4d714d-8bc5-4ca8-a7c8-28f2bc94b13e,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-b9cf3ce1-f99f-4c9a-8301-b3331da5b260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536949561-172.17.0.7-1598350632864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36482,DS-41014446-9c7f-4559-83b0-f3628f8f015d,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-de141574-40dd-4a2d-b683-1cf54003faf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-d8101432-8d3b-41bd-88d4-262c9317fdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-47f6c785-b057-4bb3-ab97-f4444d00ab0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-de373d60-5902-4bd7-89df-05774f898028,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-0626972a-fecd-40ac-8b04-870970b5ae00,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-ad2cf716-c99c-4c58-ae15-a469f8885223,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-1fb6a64c-620b-4791-a039-798827b293ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536949561-172.17.0.7-1598350632864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36482,DS-41014446-9c7f-4559-83b0-f3628f8f015d,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-de141574-40dd-4a2d-b683-1cf54003faf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-d8101432-8d3b-41bd-88d4-262c9317fdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-47f6c785-b057-4bb3-ab97-f4444d00ab0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-de373d60-5902-4bd7-89df-05774f898028,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-0626972a-fecd-40ac-8b04-870970b5ae00,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-ad2cf716-c99c-4c58-ae15-a469f8885223,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-1fb6a64c-620b-4791-a039-798827b293ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484588487-172.17.0.7-1598351097154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42769,DS-45637a6f-aacf-4e42-8f63-0764addb9f30,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-bf9d5ac3-cbf6-4578-b34e-351c73023da8,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-4fbdd41d-874b-4562-8f25-ed19f711206a,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-65ac7587-3443-4fa9-a86f-62c4bfe74b12,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-9107dc97-b5aa-4ce7-8390-6d5e3b42ec06,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-f72929ce-8808-436b-83ce-8d37eb214e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-0326ceb4-ee07-470f-bf0d-65d3a0d41fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-de452899-d3b3-42ae-9515-48100677bfde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484588487-172.17.0.7-1598351097154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42769,DS-45637a6f-aacf-4e42-8f63-0764addb9f30,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-bf9d5ac3-cbf6-4578-b34e-351c73023da8,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-4fbdd41d-874b-4562-8f25-ed19f711206a,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-65ac7587-3443-4fa9-a86f-62c4bfe74b12,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-9107dc97-b5aa-4ce7-8390-6d5e3b42ec06,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-f72929ce-8808-436b-83ce-8d37eb214e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-0326ceb4-ee07-470f-bf0d-65d3a0d41fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-de452899-d3b3-42ae-9515-48100677bfde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749549870-172.17.0.7-1598351135138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34027,DS-787058e5-016e-4ac6-b632-79f6d20bc239,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-8be20cff-064c-4562-9b5c-3d6d6a53379d,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-cb7edaa3-9021-48cd-b832-faf2e5a57c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-a4ea6fdb-f7dc-474d-b307-1f75cd10f3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-5516699d-61bb-4f87-8ea1-c31247ff7f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-e6a1241e-2288-4ecf-939c-604c590af0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-119f784d-e641-4a10-98ea-e50338b857f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-89aa8bb7-7f58-4899-825b-d5ec91cb5823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749549870-172.17.0.7-1598351135138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34027,DS-787058e5-016e-4ac6-b632-79f6d20bc239,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-8be20cff-064c-4562-9b5c-3d6d6a53379d,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-cb7edaa3-9021-48cd-b832-faf2e5a57c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-a4ea6fdb-f7dc-474d-b307-1f75cd10f3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-5516699d-61bb-4f87-8ea1-c31247ff7f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-e6a1241e-2288-4ecf-939c-604c590af0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-119f784d-e641-4a10-98ea-e50338b857f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-89aa8bb7-7f58-4899-825b-d5ec91cb5823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124801546-172.17.0.7-1598352441393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33986,DS-98df5f66-04b2-4048-937f-58682491a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-b3629684-168f-4408-8e2d-e10b57db7b00,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-b62f57a2-7825-462a-81fa-83e009531c52,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-febfc475-d127-421a-b780-7602d013412f,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-cd2bec7e-916c-49c8-98f1-9543dc4e9d61,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-4958c93e-dc65-4f24-a385-0cb1e18a3aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-c2a4649b-cc82-4cd8-9086-216a12421a14,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-09af4dba-c468-4465-8156-b7141e88836c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124801546-172.17.0.7-1598352441393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33986,DS-98df5f66-04b2-4048-937f-58682491a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-b3629684-168f-4408-8e2d-e10b57db7b00,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-b62f57a2-7825-462a-81fa-83e009531c52,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-febfc475-d127-421a-b780-7602d013412f,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-cd2bec7e-916c-49c8-98f1-9543dc4e9d61,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-4958c93e-dc65-4f24-a385-0cb1e18a3aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-c2a4649b-cc82-4cd8-9086-216a12421a14,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-09af4dba-c468-4465-8156-b7141e88836c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-738194073-172.17.0.7-1598352519993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-67c0e29c-5a5d-4045-b4bf-863eaa1b0ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-789b4108-4d53-49b2-968a-2defbec84bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-3ff57b58-9cae-41a0-a01b-e928cf9acdff,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-3fa4e4c5-4194-46aa-81b7-cb85b6b0ab4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-a360a224-4f0b-49c6-93e6-3855d24426d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-4140aea9-493f-4629-bcb8-631abe170901,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-8851e7d9-f40c-4a8b-ad95-d493ed03d7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-24eea3f5-26e7-4c89-9b30-bc66dc6c6037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-738194073-172.17.0.7-1598352519993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-67c0e29c-5a5d-4045-b4bf-863eaa1b0ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-789b4108-4d53-49b2-968a-2defbec84bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-3ff57b58-9cae-41a0-a01b-e928cf9acdff,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-3fa4e4c5-4194-46aa-81b7-cb85b6b0ab4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-a360a224-4f0b-49c6-93e6-3855d24426d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-4140aea9-493f-4629-bcb8-631abe170901,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-8851e7d9-f40c-4a8b-ad95-d493ed03d7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-24eea3f5-26e7-4c89-9b30-bc66dc6c6037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630273614-172.17.0.7-1598352600076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46610,DS-63c31904-fbe1-42d0-b1bb-a5a641626f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-d1f94fb4-b07e-4193-ab10-b37f9a10b076,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-48f837b6-ec13-4ff1-bc0d-f4c2014a8fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-dbbc5b85-0a05-4b4a-a607-896568d50cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-2ebcbc72-01cf-4078-96ae-66b06c98f5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-4cfcff0e-ef31-418e-aee5-7d5cd416a703,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-a37492b8-b1a5-4c1c-907d-da798ef8b2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-406514b2-62f2-495e-8e4f-b10cf167b43b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630273614-172.17.0.7-1598352600076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46610,DS-63c31904-fbe1-42d0-b1bb-a5a641626f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-d1f94fb4-b07e-4193-ab10-b37f9a10b076,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-48f837b6-ec13-4ff1-bc0d-f4c2014a8fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-dbbc5b85-0a05-4b4a-a607-896568d50cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-2ebcbc72-01cf-4078-96ae-66b06c98f5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-4cfcff0e-ef31-418e-aee5-7d5cd416a703,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-a37492b8-b1a5-4c1c-907d-da798ef8b2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-406514b2-62f2-495e-8e4f-b10cf167b43b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863339652-172.17.0.7-1598352711694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40520,DS-a8547f9c-1717-484b-9823-fa83511b7ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-ca35119a-f71d-451a-813e-060952c9af63,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-2a3b6573-0d19-4428-b5fd-f84ef07159f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-3c8b6d37-df4a-4f32-8459-e1200929b4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-75790941-d49a-4164-90a6-476e06a53234,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-0c421f4b-1347-4128-87f1-2c86bb3652c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-39d854a7-86d4-4e43-9de7-a97bedafeaba,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-f608b9f2-3b32-4d19-a630-ed93a4b1662d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863339652-172.17.0.7-1598352711694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40520,DS-a8547f9c-1717-484b-9823-fa83511b7ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-ca35119a-f71d-451a-813e-060952c9af63,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-2a3b6573-0d19-4428-b5fd-f84ef07159f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-3c8b6d37-df4a-4f32-8459-e1200929b4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-75790941-d49a-4164-90a6-476e06a53234,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-0c421f4b-1347-4128-87f1-2c86bb3652c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-39d854a7-86d4-4e43-9de7-a97bedafeaba,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-f608b9f2-3b32-4d19-a630-ed93a4b1662d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243404309-172.17.0.7-1598353066396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38775,DS-5e05fbfc-91ad-4861-a195-dd43a068b116,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-47968d03-6f89-4878-a16c-00c7ad67377b,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-0811ccbe-359b-45b5-900a-a441d8188248,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-d574408c-a162-46e9-8341-c9d3f3a09355,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-6044c1fa-ebcc-4902-b55c-3ed496ac65c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-9d147ab4-ede5-4ff9-9f97-79b2809e2f10,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-7327837d-b3dc-41f8-92d3-7c1f9e2fa1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-b7e6dc49-1921-429a-b702-ebf318ff3057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243404309-172.17.0.7-1598353066396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38775,DS-5e05fbfc-91ad-4861-a195-dd43a068b116,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-47968d03-6f89-4878-a16c-00c7ad67377b,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-0811ccbe-359b-45b5-900a-a441d8188248,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-d574408c-a162-46e9-8341-c9d3f3a09355,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-6044c1fa-ebcc-4902-b55c-3ed496ac65c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-9d147ab4-ede5-4ff9-9f97-79b2809e2f10,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-7327837d-b3dc-41f8-92d3-7c1f9e2fa1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-b7e6dc49-1921-429a-b702-ebf318ff3057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277899873-172.17.0.7-1598353401850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38831,DS-a91c3206-bb59-4a4e-9c37-9e1031edad75,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-6a4ddbae-d71a-46bd-ac45-a0fe7d6219eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-66b8400f-a782-4dfc-9756-8f24b982ec26,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-e6a7391e-1a16-4ea5-8bf3-8cd1edea618f,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-39a575da-3548-4b42-b38f-d9448956bd79,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-a5cdbcc5-794a-4d1f-b4c6-fec4cb19c4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-792aa0c8-9fa9-4e49-961b-3373100b1294,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-029f276b-cd08-414c-b0ce-d1a466a834af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277899873-172.17.0.7-1598353401850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38831,DS-a91c3206-bb59-4a4e-9c37-9e1031edad75,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-6a4ddbae-d71a-46bd-ac45-a0fe7d6219eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-66b8400f-a782-4dfc-9756-8f24b982ec26,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-e6a7391e-1a16-4ea5-8bf3-8cd1edea618f,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-39a575da-3548-4b42-b38f-d9448956bd79,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-a5cdbcc5-794a-4d1f-b4c6-fec4cb19c4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-792aa0c8-9fa9-4e49-961b-3373100b1294,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-029f276b-cd08-414c-b0ce-d1a466a834af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1591635767-172.17.0.7-1598353680390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44589,DS-79873b78-0533-491b-96b2-ff9a80d53974,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-e40d1d53-42f8-4bbe-9d86-8cbdff2350ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-19862f87-a4a3-4b01-b10b-576522b887f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-04423548-eba7-499a-881a-d9454438cc74,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-553420b3-bf9d-4580-81b9-52fa116fb368,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-906d9172-0e83-408a-bd51-d9bf2e7bf4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-d338119d-52f2-454d-89b3-44c2aa16a9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-27cdd549-4274-4a6b-97a1-6b531939bcd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1591635767-172.17.0.7-1598353680390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44589,DS-79873b78-0533-491b-96b2-ff9a80d53974,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-e40d1d53-42f8-4bbe-9d86-8cbdff2350ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-19862f87-a4a3-4b01-b10b-576522b887f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-04423548-eba7-499a-881a-d9454438cc74,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-553420b3-bf9d-4580-81b9-52fa116fb368,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-906d9172-0e83-408a-bd51-d9bf2e7bf4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-d338119d-52f2-454d-89b3-44c2aa16a9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-27cdd549-4274-4a6b-97a1-6b531939bcd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131196231-172.17.0.7-1598353811855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33390,DS-820a7d4b-c865-40c7-989d-f55d5d1538c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-ba772aa8-4002-463f-8b3d-a4e7a13754c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-a88c6ff0-2601-4520-9159-dd2f6ecf6fad,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-98c64781-5090-4117-888f-3956bf95c5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-4d0941e1-7917-4eae-b375-80bd3c74a050,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-66c0b9c8-0176-4c39-a0ff-32fa36f15cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-cc6621e4-4a09-49b4-92c4-219b1693b76c,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-0b4189a1-3499-42d7-bc2c-c8e70c80b7c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131196231-172.17.0.7-1598353811855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33390,DS-820a7d4b-c865-40c7-989d-f55d5d1538c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-ba772aa8-4002-463f-8b3d-a4e7a13754c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-a88c6ff0-2601-4520-9159-dd2f6ecf6fad,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-98c64781-5090-4117-888f-3956bf95c5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-4d0941e1-7917-4eae-b375-80bd3c74a050,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-66c0b9c8-0176-4c39-a0ff-32fa36f15cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-cc6621e4-4a09-49b4-92c4-219b1693b76c,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-0b4189a1-3499-42d7-bc2c-c8e70c80b7c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941106638-172.17.0.7-1598353909104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33514,DS-90831cd0-504d-451a-8b67-4c083b303872,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-08082284-09f6-42a6-89b6-8a2781b0878f,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-7e968d01-512a-4257-8932-ec6ebc3afae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-5edc3804-2a6c-4ed9-9a6b-99c8fdfe0939,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-79a1485a-0bb4-4eac-b898-88d4e1eedb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-6d8937e5-36c4-4838-bfb3-89a5d78aecc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-467ba308-4047-42d4-bc90-ba6734a769c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-4fd8d94d-0408-4dc5-aeaa-12dcce18aff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941106638-172.17.0.7-1598353909104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33514,DS-90831cd0-504d-451a-8b67-4c083b303872,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-08082284-09f6-42a6-89b6-8a2781b0878f,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-7e968d01-512a-4257-8932-ec6ebc3afae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-5edc3804-2a6c-4ed9-9a6b-99c8fdfe0939,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-79a1485a-0bb4-4eac-b898-88d4e1eedb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-6d8937e5-36c4-4838-bfb3-89a5d78aecc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-467ba308-4047-42d4-bc90-ba6734a769c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-4fd8d94d-0408-4dc5-aeaa-12dcce18aff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620339020-172.17.0.7-1598353978015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46353,DS-64a24a81-5281-4d8a-8d42-8d21d545f43d,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-bdc80801-b717-4000-8d19-ee72e494eb61,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-752f728d-7b39-4430-b8a3-e55dfb07dc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-74e27d0b-3df2-4727-96c3-2979afccb5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-08fb0bf3-81d8-4ba4-8314-990f9182e795,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-2c8272bf-3673-4d73-b290-d7c531c9031e,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-d3b08ef4-35b2-4449-a1d1-d7af591d18a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-14b74437-57ed-431e-98b7-1144cce3ed51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620339020-172.17.0.7-1598353978015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46353,DS-64a24a81-5281-4d8a-8d42-8d21d545f43d,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-bdc80801-b717-4000-8d19-ee72e494eb61,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-752f728d-7b39-4430-b8a3-e55dfb07dc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-74e27d0b-3df2-4727-96c3-2979afccb5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-08fb0bf3-81d8-4ba4-8314-990f9182e795,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-2c8272bf-3673-4d73-b290-d7c531c9031e,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-d3b08ef4-35b2-4449-a1d1-d7af591d18a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-14b74437-57ed-431e-98b7-1144cce3ed51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5489
