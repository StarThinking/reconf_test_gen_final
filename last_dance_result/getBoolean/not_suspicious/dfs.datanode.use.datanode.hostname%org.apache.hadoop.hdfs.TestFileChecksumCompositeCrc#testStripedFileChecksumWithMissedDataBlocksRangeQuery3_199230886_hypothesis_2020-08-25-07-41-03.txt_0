reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860352771-172.17.0.5-1598341377322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37963,DS-3a13d31f-7803-40c4-9087-495ec387db4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-a722e917-5be0-45ed-8894-ac0e504e74ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-b49974f0-98f1-41c7-8706-c8ab88e045e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-97bbb35e-02b7-4e8d-8d39-88fd4e76cd19,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-78468a4b-b9d2-4d2c-a2a0-6e972ad3ad9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-0afe7381-4df9-457f-b740-787e905db3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-9d86031f-dbbe-4e68-ba82-44f59ece4e05,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-650825eb-3802-4578-bed8-0f319180b70b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860352771-172.17.0.5-1598341377322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37963,DS-3a13d31f-7803-40c4-9087-495ec387db4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-a722e917-5be0-45ed-8894-ac0e504e74ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-b49974f0-98f1-41c7-8706-c8ab88e045e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-97bbb35e-02b7-4e8d-8d39-88fd4e76cd19,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-78468a4b-b9d2-4d2c-a2a0-6e972ad3ad9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-0afe7381-4df9-457f-b740-787e905db3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-9d86031f-dbbe-4e68-ba82-44f59ece4e05,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-650825eb-3802-4578-bed8-0f319180b70b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057614858-172.17.0.5-1598341568991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-a2f0b39b-b046-4788-8164-b5f6952f4c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-cf98e55f-c16a-4488-b62c-ed85db94df39,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-f45ee144-93b5-4580-82b1-dce921d40998,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-17facdfc-cbe8-4b22-8ab3-4f710482e9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-7e35b58a-f0c9-418b-bc52-214e8bd464b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-90b61fbc-c330-433b-8753-b61ecd8c7bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-76851782-be58-4043-a09f-3667de94c0da,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-6b987515-a481-4df6-9f67-82a3cbff9ce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057614858-172.17.0.5-1598341568991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-a2f0b39b-b046-4788-8164-b5f6952f4c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-cf98e55f-c16a-4488-b62c-ed85db94df39,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-f45ee144-93b5-4580-82b1-dce921d40998,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-17facdfc-cbe8-4b22-8ab3-4f710482e9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-7e35b58a-f0c9-418b-bc52-214e8bd464b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-90b61fbc-c330-433b-8753-b61ecd8c7bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-76851782-be58-4043-a09f-3667de94c0da,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-6b987515-a481-4df6-9f67-82a3cbff9ce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10196283-172.17.0.5-1598342404872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35313,DS-9284ade2-a861-433e-bba4-65f016c68fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-ddf8b170-3c15-48e1-ad7d-e09f4905ba7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-82f19195-d183-47f1-b926-eaa359f8de9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-36d73973-f59a-4096-8830-2a49bdd8f776,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-769d9680-ce98-4522-9a3c-f7832242b78b,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-15612642-b5b3-4946-9fd0-2c3a01aa058e,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-ec575283-b62b-4362-852d-966d420b3dff,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-28a1284c-551e-43ed-9ad1-1381a88db08b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10196283-172.17.0.5-1598342404872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35313,DS-9284ade2-a861-433e-bba4-65f016c68fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-ddf8b170-3c15-48e1-ad7d-e09f4905ba7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-82f19195-d183-47f1-b926-eaa359f8de9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-36d73973-f59a-4096-8830-2a49bdd8f776,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-769d9680-ce98-4522-9a3c-f7832242b78b,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-15612642-b5b3-4946-9fd0-2c3a01aa058e,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-ec575283-b62b-4362-852d-966d420b3dff,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-28a1284c-551e-43ed-9ad1-1381a88db08b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202652029-172.17.0.5-1598342505366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40313,DS-37aaabc4-e3c7-4301-8c02-a7ca40111ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-1eecf16f-a9ab-4be6-9527-a81f57bf5922,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-f417ccf4-3308-4016-b688-abdd753ff790,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-4b31f7cb-0542-47b9-bcff-281c8cc5b44e,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-30547ff6-b956-412c-b0bc-16041e2fd63a,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-6ba5b812-8a93-41ab-b537-242e7885126d,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-00074308-db78-40d3-936c-b2f391ccd978,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-bd0c77a3-92ce-40e5-a6e5-6c19feabf99c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202652029-172.17.0.5-1598342505366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40313,DS-37aaabc4-e3c7-4301-8c02-a7ca40111ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-1eecf16f-a9ab-4be6-9527-a81f57bf5922,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-f417ccf4-3308-4016-b688-abdd753ff790,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-4b31f7cb-0542-47b9-bcff-281c8cc5b44e,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-30547ff6-b956-412c-b0bc-16041e2fd63a,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-6ba5b812-8a93-41ab-b537-242e7885126d,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-00074308-db78-40d3-936c-b2f391ccd978,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-bd0c77a3-92ce-40e5-a6e5-6c19feabf99c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443867208-172.17.0.5-1598343612010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40795,DS-84c61ae5-6f4f-41bc-bd0c-97550e0e2473,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-37386dd7-d7ff-4b9f-a0b3-64ed9c6edd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-0ad7b072-a9a5-4b40-86d6-b8490f6d9147,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-388b752d-e539-4b58-bf52-b1458e7bf0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-04f5f60f-5442-49f5-8a2c-e77b0ffd701f,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-ef9aa7fa-57fa-4e4f-a3d5-693f04945e90,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-367e3357-9e69-436d-958e-1a9d9a998697,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-566408e9-0e21-4740-a531-2a790374bc7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443867208-172.17.0.5-1598343612010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40795,DS-84c61ae5-6f4f-41bc-bd0c-97550e0e2473,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-37386dd7-d7ff-4b9f-a0b3-64ed9c6edd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-0ad7b072-a9a5-4b40-86d6-b8490f6d9147,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-388b752d-e539-4b58-bf52-b1458e7bf0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-04f5f60f-5442-49f5-8a2c-e77b0ffd701f,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-ef9aa7fa-57fa-4e4f-a3d5-693f04945e90,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-367e3357-9e69-436d-958e-1a9d9a998697,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-566408e9-0e21-4740-a531-2a790374bc7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016837094-172.17.0.5-1598344043355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44420,DS-e20ef0de-fc10-4455-b520-9299f1609df2,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-73efc560-67ef-4591-939e-47e726d96d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-a908d43f-33ab-4b7c-8f41-31e27b225d27,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-3222137a-b98c-40dc-b7dc-9229d1c5cc60,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-0089ed20-e7fe-46a8-bcd2-4920faef83d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-514d8db9-ecdc-4c43-9121-0fa823862563,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-1b3e21db-a9dc-4eee-a641-16f273284af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-e537c39c-5c13-4483-9db4-4ba00d41c3a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016837094-172.17.0.5-1598344043355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44420,DS-e20ef0de-fc10-4455-b520-9299f1609df2,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-73efc560-67ef-4591-939e-47e726d96d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-a908d43f-33ab-4b7c-8f41-31e27b225d27,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-3222137a-b98c-40dc-b7dc-9229d1c5cc60,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-0089ed20-e7fe-46a8-bcd2-4920faef83d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-514d8db9-ecdc-4c43-9121-0fa823862563,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-1b3e21db-a9dc-4eee-a641-16f273284af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-e537c39c-5c13-4483-9db4-4ba00d41c3a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325441897-172.17.0.5-1598344119465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45280,DS-dae954b8-f977-4c5f-886e-8cb6488b8dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-0706817c-51e2-442b-98b3-aff49c4a2856,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-6e2ee2ab-43ac-4c44-baf1-975213dbc321,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-3d0e0918-7c86-4d05-9410-4ec023d7fa57,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-fe68cb79-6c3d-46e3-bd2c-34a9b8223dea,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-5e2b81b5-13b7-40ab-a71b-451dc5720296,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-7681e4af-4950-441e-ab65-9b96cb52ffd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-dc0d8136-2c35-4662-919d-36ba948070ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325441897-172.17.0.5-1598344119465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45280,DS-dae954b8-f977-4c5f-886e-8cb6488b8dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-0706817c-51e2-442b-98b3-aff49c4a2856,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-6e2ee2ab-43ac-4c44-baf1-975213dbc321,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-3d0e0918-7c86-4d05-9410-4ec023d7fa57,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-fe68cb79-6c3d-46e3-bd2c-34a9b8223dea,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-5e2b81b5-13b7-40ab-a71b-451dc5720296,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-7681e4af-4950-441e-ab65-9b96cb52ffd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-dc0d8136-2c35-4662-919d-36ba948070ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007139733-172.17.0.5-1598344323707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36616,DS-e72bae71-2054-47af-a912-ab1fbc40fb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-bc31b789-b66a-438c-9233-008bf764b1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-4715328e-2630-4baf-8ac2-1bf32fcd0a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-ab451aa8-f0c1-4446-84ef-31a53b16f07c,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-9f62ffda-4a0a-428f-96df-9be24dfa6f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-456c30ac-6eef-4a1f-9bb9-c882c2bb5952,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-927ecef9-c83f-4db2-8eb2-1f55b6e9bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-44ed6465-7eef-4b5f-bb45-36722e1e5813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007139733-172.17.0.5-1598344323707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36616,DS-e72bae71-2054-47af-a912-ab1fbc40fb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-bc31b789-b66a-438c-9233-008bf764b1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-4715328e-2630-4baf-8ac2-1bf32fcd0a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-ab451aa8-f0c1-4446-84ef-31a53b16f07c,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-9f62ffda-4a0a-428f-96df-9be24dfa6f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-456c30ac-6eef-4a1f-9bb9-c882c2bb5952,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-927ecef9-c83f-4db2-8eb2-1f55b6e9bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-44ed6465-7eef-4b5f-bb45-36722e1e5813,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471249284-172.17.0.5-1598344433610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40575,DS-1e987dfe-224b-4b0c-95bb-e66d45df8c34,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-73a7f00c-c6cd-4749-844c-be85e4afeb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-a89b1e2a-0ca7-4695-a893-83e4735d8422,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-4eb046d8-5cef-46b9-96ee-d38050cd07a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-27e9092e-9ae4-4a60-9ffc-5af0ae810f29,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-9bc955fa-a869-4f10-90dd-f5ec10d2abcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-3d99ba23-cf2b-4b02-b922-5b8a0cc42a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-99269c47-a550-4e7d-83b0-31a046f3b4da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471249284-172.17.0.5-1598344433610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40575,DS-1e987dfe-224b-4b0c-95bb-e66d45df8c34,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-73a7f00c-c6cd-4749-844c-be85e4afeb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-a89b1e2a-0ca7-4695-a893-83e4735d8422,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-4eb046d8-5cef-46b9-96ee-d38050cd07a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-27e9092e-9ae4-4a60-9ffc-5af0ae810f29,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-9bc955fa-a869-4f10-90dd-f5ec10d2abcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-3d99ba23-cf2b-4b02-b922-5b8a0cc42a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-99269c47-a550-4e7d-83b0-31a046f3b4da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044814797-172.17.0.5-1598344465873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35134,DS-d9d5e32e-e271-450a-a0e0-a4d44f8b464c,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-58711363-9dc3-4686-b065-3ba14a7db5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-fe828daf-29b9-4539-9bd2-4bce0ca758c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-7fcfa87b-a4e6-4db1-8488-153345b144ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-140f5f7b-c0cc-4f24-91e2-ac2aeddb3159,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-fb4d74b4-6916-48cc-b4bd-716575a3dbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-6d90d80f-fc9e-4736-9b9c-c9868429bc87,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-8bf6e6df-7656-4721-9a98-8bfd1dfee024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044814797-172.17.0.5-1598344465873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35134,DS-d9d5e32e-e271-450a-a0e0-a4d44f8b464c,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-58711363-9dc3-4686-b065-3ba14a7db5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-fe828daf-29b9-4539-9bd2-4bce0ca758c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-7fcfa87b-a4e6-4db1-8488-153345b144ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-140f5f7b-c0cc-4f24-91e2-ac2aeddb3159,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-fb4d74b4-6916-48cc-b4bd-716575a3dbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-6d90d80f-fc9e-4736-9b9c-c9868429bc87,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-8bf6e6df-7656-4721-9a98-8bfd1dfee024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417652440-172.17.0.5-1598344542166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37283,DS-a37a3744-75ea-455d-8374-47ae9544c49b,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-2e18498c-af29-4be4-8404-09902a387031,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-b059c562-8a2f-48a9-88cc-09070831b807,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-4c27b4fe-4a0e-47c2-8af4-a563f8a69383,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-f9e55403-2fcc-4b92-bb85-bf010b6e4054,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-9de7020e-e3c0-4bca-8910-b0102c2320b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-a67e7e60-886a-4631-9c5d-0047aec73a62,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-7dc47424-bf52-4477-b103-af41d88d5e69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417652440-172.17.0.5-1598344542166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37283,DS-a37a3744-75ea-455d-8374-47ae9544c49b,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-2e18498c-af29-4be4-8404-09902a387031,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-b059c562-8a2f-48a9-88cc-09070831b807,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-4c27b4fe-4a0e-47c2-8af4-a563f8a69383,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-f9e55403-2fcc-4b92-bb85-bf010b6e4054,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-9de7020e-e3c0-4bca-8910-b0102c2320b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-a67e7e60-886a-4631-9c5d-0047aec73a62,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-7dc47424-bf52-4477-b103-af41d88d5e69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026115060-172.17.0.5-1598344654153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40845,DS-ae0c9269-bfca-4aa8-8e7b-c1b6502295ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-9a75644b-66cb-4780-9917-204d09eda9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-6dc23052-b6da-4e24-bacd-29c83a7c8ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-f872504b-aa84-4506-a7cd-775600532387,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-b5e644ef-0bc1-4530-b407-8bafdc9d479d,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-61715ea8-da03-4259-bb09-bbc1b469136c,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-ccf7a9d0-1da5-4fa3-ae0c-71e76c63e38c,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-ee27e7a9-59c2-4d0c-a51d-051f62749930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026115060-172.17.0.5-1598344654153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40845,DS-ae0c9269-bfca-4aa8-8e7b-c1b6502295ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-9a75644b-66cb-4780-9917-204d09eda9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-6dc23052-b6da-4e24-bacd-29c83a7c8ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-f872504b-aa84-4506-a7cd-775600532387,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-b5e644ef-0bc1-4530-b407-8bafdc9d479d,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-61715ea8-da03-4259-bb09-bbc1b469136c,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-ccf7a9d0-1da5-4fa3-ae0c-71e76c63e38c,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-ee27e7a9-59c2-4d0c-a51d-051f62749930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113226770-172.17.0.5-1598345109920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45311,DS-9a18dd0e-c82c-4c09-bc83-c07b057c55de,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-e7f4310f-e7bd-4a46-950d-c1f7e3fe4c75,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-c5bee39f-6eba-42e5-b20d-f67cadd80d06,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-876b97d9-f18c-4612-8323-220f16d92bca,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-35354058-58ea-41da-a33f-3f663d5e0ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-fc0329f1-bfea-49bc-8b53-e80e3205e840,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-a2324d22-f5bb-410e-a591-9593e2f6b809,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-de78b216-872f-4bfc-bee9-366411e8de8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113226770-172.17.0.5-1598345109920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45311,DS-9a18dd0e-c82c-4c09-bc83-c07b057c55de,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-e7f4310f-e7bd-4a46-950d-c1f7e3fe4c75,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-c5bee39f-6eba-42e5-b20d-f67cadd80d06,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-876b97d9-f18c-4612-8323-220f16d92bca,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-35354058-58ea-41da-a33f-3f663d5e0ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-fc0329f1-bfea-49bc-8b53-e80e3205e840,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-a2324d22-f5bb-410e-a591-9593e2f6b809,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-de78b216-872f-4bfc-bee9-366411e8de8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-33151907-172.17.0.5-1598345382130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43843,DS-8d6ce3fb-9166-488f-b87e-648deb189853,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-aeb83479-70f5-4ec6-88fd-376c26399473,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-b53b5175-6974-4c2e-baef-69941be2a28d,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-dc5dda9e-2a5e-4cb9-b7a0-17c7bb332d12,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-74afe2f5-5470-4938-a968-b0f08db460c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-22cb9c4f-9004-4e55-bf9e-3fb099b45717,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-1d67f1fa-0924-4211-b395-d5a2137477aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-a3f945b1-bbed-493b-8f87-95c25f52be15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-33151907-172.17.0.5-1598345382130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43843,DS-8d6ce3fb-9166-488f-b87e-648deb189853,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-aeb83479-70f5-4ec6-88fd-376c26399473,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-b53b5175-6974-4c2e-baef-69941be2a28d,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-dc5dda9e-2a5e-4cb9-b7a0-17c7bb332d12,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-74afe2f5-5470-4938-a968-b0f08db460c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-22cb9c4f-9004-4e55-bf9e-3fb099b45717,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-1d67f1fa-0924-4211-b395-d5a2137477aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-a3f945b1-bbed-493b-8f87-95c25f52be15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976173652-172.17.0.5-1598345861277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46735,DS-9951e62a-5284-407c-8d2a-c45d32559b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-51a09a79-4a8e-443d-9102-f56306b14dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-96e2c124-5788-4b8e-a4d7-bee21ccb9ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-d0a9b00b-9529-42bf-be4f-d948235438bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-da59f5fa-3217-4da3-811f-65f3e2fb1e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-74f87567-12ac-4516-a6f9-dbef5471ea08,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-68ee5c85-ea0c-4a92-bac8-04492adecab9,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-823d91b0-104c-40f7-97e4-6b6504b8b318,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976173652-172.17.0.5-1598345861277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46735,DS-9951e62a-5284-407c-8d2a-c45d32559b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-51a09a79-4a8e-443d-9102-f56306b14dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-96e2c124-5788-4b8e-a4d7-bee21ccb9ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-d0a9b00b-9529-42bf-be4f-d948235438bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-da59f5fa-3217-4da3-811f-65f3e2fb1e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-74f87567-12ac-4516-a6f9-dbef5471ea08,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-68ee5c85-ea0c-4a92-bac8-04492adecab9,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-823d91b0-104c-40f7-97e4-6b6504b8b318,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128589435-172.17.0.5-1598346294429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45527,DS-49a4c3f5-2803-4dd1-a209-7488ac74b80e,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-2b6987b4-09e9-470a-b72e-2c6c6b269a37,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-ad8dea19-2c80-4cf6-a6c2-65aca1bc4a81,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-81726128-2500-40ae-b012-f9d91c940ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-a8c1fef1-2ddc-4db0-965d-c4648e877004,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-9c46df1f-b213-495f-b411-d11979914ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-07fcd679-bd33-4a91-9f0c-1ebce2464bac,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-ca6899f9-3d01-4b46-9526-5e05c4048d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128589435-172.17.0.5-1598346294429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45527,DS-49a4c3f5-2803-4dd1-a209-7488ac74b80e,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-2b6987b4-09e9-470a-b72e-2c6c6b269a37,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-ad8dea19-2c80-4cf6-a6c2-65aca1bc4a81,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-81726128-2500-40ae-b012-f9d91c940ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-a8c1fef1-2ddc-4db0-965d-c4648e877004,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-9c46df1f-b213-495f-b411-d11979914ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-07fcd679-bd33-4a91-9f0c-1ebce2464bac,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-ca6899f9-3d01-4b46-9526-5e05c4048d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470514560-172.17.0.5-1598346331804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34443,DS-03167ae7-79a5-40b2-856e-a66aa2831013,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-080586e0-becd-4e3d-b7e8-3b2b6f2aa6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-10815287-1211-4f49-8873-679e1f7c36d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-95d12a08-70aa-4094-be9c-708888f7f3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-e7b67a25-7c6e-4c12-97b1-4102d04726e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-478cb241-535e-4326-9495-15637d81df4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-1fff0a6c-00cd-4da9-9829-eb29372294aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-545233e8-2837-4f2e-a18b-e78f7e24e91d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470514560-172.17.0.5-1598346331804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34443,DS-03167ae7-79a5-40b2-856e-a66aa2831013,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-080586e0-becd-4e3d-b7e8-3b2b6f2aa6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-10815287-1211-4f49-8873-679e1f7c36d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-95d12a08-70aa-4094-be9c-708888f7f3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-e7b67a25-7c6e-4c12-97b1-4102d04726e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-478cb241-535e-4326-9495-15637d81df4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-1fff0a6c-00cd-4da9-9829-eb29372294aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-545233e8-2837-4f2e-a18b-e78f7e24e91d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108628267-172.17.0.5-1598346362756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39645,DS-0865da09-21e8-40f7-ae0e-c63847ad362c,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-26007d93-4f84-4a75-81fd-b3dcf5d9de5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-01671610-fbd6-4b0b-ad72-62a5819dbc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-d5c601f4-c1b5-43e3-81ef-b84c39458ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-04e196d8-d2fb-4ad1-ad45-34e68dbb4033,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-459d9c74-ff33-41da-b3d9-37edd98760a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-a1078051-38a4-4800-ad3b-cf0c201a102a,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-4333185c-2c1a-483d-bbfd-39521745d93d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108628267-172.17.0.5-1598346362756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39645,DS-0865da09-21e8-40f7-ae0e-c63847ad362c,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-26007d93-4f84-4a75-81fd-b3dcf5d9de5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-01671610-fbd6-4b0b-ad72-62a5819dbc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-d5c601f4-c1b5-43e3-81ef-b84c39458ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-04e196d8-d2fb-4ad1-ad45-34e68dbb4033,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-459d9c74-ff33-41da-b3d9-37edd98760a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-a1078051-38a4-4800-ad3b-cf0c201a102a,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-4333185c-2c1a-483d-bbfd-39521745d93d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5347
