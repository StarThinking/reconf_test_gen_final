reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141923049-172.17.0.2-1598383376262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44136,DS-8005e83f-861a-48ed-9b2f-6c4b4a2c8b24,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-25af45ed-cd06-4986-a4f4-3ada5ffe25c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-8ddbbe78-d1d4-49ce-a343-3e1cc9efdec2,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-1d4375cc-0256-42b3-ad0a-765c96534f28,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-7be25d4e-8386-4291-9f57-5d161000a974,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-9e31d982-9e48-44ce-8d6f-566a0bf56d30,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-a39b1323-059f-4880-a63e-593d04a5a83c,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-bb423fa8-ad2e-4a7b-a3dc-e1c7097467bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141923049-172.17.0.2-1598383376262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44136,DS-8005e83f-861a-48ed-9b2f-6c4b4a2c8b24,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-25af45ed-cd06-4986-a4f4-3ada5ffe25c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-8ddbbe78-d1d4-49ce-a343-3e1cc9efdec2,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-1d4375cc-0256-42b3-ad0a-765c96534f28,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-7be25d4e-8386-4291-9f57-5d161000a974,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-9e31d982-9e48-44ce-8d6f-566a0bf56d30,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-a39b1323-059f-4880-a63e-593d04a5a83c,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-bb423fa8-ad2e-4a7b-a3dc-e1c7097467bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346485144-172.17.0.2-1598383468890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37688,DS-f30a66cd-f161-4d03-90ab-52af0cf758ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-ff42b466-64b9-48e8-b4cf-1b0cbceee6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-5944cce1-2c28-4bfd-a2a6-7648ec2f86e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-4749735c-6651-41b0-bd35-24ab8f6994d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-890afea8-79ae-4cfa-897f-c3f79ca4b28e,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-5b73a487-30e8-4140-8ac7-7144f8c61445,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-ef6718f4-4b21-4c3d-99a3-f162669e7fec,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-bc8ddd53-9801-4d68-b6b4-a93c1674d851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346485144-172.17.0.2-1598383468890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37688,DS-f30a66cd-f161-4d03-90ab-52af0cf758ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-ff42b466-64b9-48e8-b4cf-1b0cbceee6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-5944cce1-2c28-4bfd-a2a6-7648ec2f86e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-4749735c-6651-41b0-bd35-24ab8f6994d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-890afea8-79ae-4cfa-897f-c3f79ca4b28e,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-5b73a487-30e8-4140-8ac7-7144f8c61445,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-ef6718f4-4b21-4c3d-99a3-f162669e7fec,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-bc8ddd53-9801-4d68-b6b4-a93c1674d851,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002166888-172.17.0.2-1598383497931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33513,DS-7b454b8d-dede-41b3-aebf-37ef5ffc5286,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-78d16745-fd8d-4b5c-a4c6-0d5ab08477ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-ce237a19-8b38-4130-acbe-c557304efb50,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-0ce46004-d294-4a5c-bda7-e90eed3e51f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-acfe229b-96f7-494d-80b6-8731d12ab068,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-8e101ad8-0909-4e8b-864b-d1f8350c0a80,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-38109ddd-cf9e-4321-b5a8-0f8fd9663928,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-436b25a3-f076-48d6-aacf-47f395662309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002166888-172.17.0.2-1598383497931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33513,DS-7b454b8d-dede-41b3-aebf-37ef5ffc5286,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-78d16745-fd8d-4b5c-a4c6-0d5ab08477ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-ce237a19-8b38-4130-acbe-c557304efb50,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-0ce46004-d294-4a5c-bda7-e90eed3e51f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-acfe229b-96f7-494d-80b6-8731d12ab068,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-8e101ad8-0909-4e8b-864b-d1f8350c0a80,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-38109ddd-cf9e-4321-b5a8-0f8fd9663928,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-436b25a3-f076-48d6-aacf-47f395662309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671668804-172.17.0.2-1598384272679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40242,DS-53eb6f3e-c312-40b6-aedc-7013f4ea71cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-6996e540-a32b-44f3-b222-8bb569da911d,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-1f338e06-d089-434c-a41e-d5317c2d7299,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-7be23835-567b-4ba6-9786-30ba54cb9cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-00d92435-d094-4803-9999-59a66da7f4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-97fc90cd-5ebb-445d-9e62-e49818d5e227,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-30401970-a481-4cc2-bd9b-eb74f2923c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-37c2934f-ec3b-46fd-bdd5-f510c5965f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671668804-172.17.0.2-1598384272679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40242,DS-53eb6f3e-c312-40b6-aedc-7013f4ea71cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-6996e540-a32b-44f3-b222-8bb569da911d,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-1f338e06-d089-434c-a41e-d5317c2d7299,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-7be23835-567b-4ba6-9786-30ba54cb9cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-00d92435-d094-4803-9999-59a66da7f4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-97fc90cd-5ebb-445d-9e62-e49818d5e227,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-30401970-a481-4cc2-bd9b-eb74f2923c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-37c2934f-ec3b-46fd-bdd5-f510c5965f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923713345-172.17.0.2-1598384451202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35315,DS-e92e31e7-f735-456b-9f6f-8a9106d675cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-b823ae24-6eac-4cc6-bfb6-ddc4fd518491,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-770319e7-471d-48d6-89c1-c44ec9025d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-89e27f0a-50d0-49a6-bbdc-7d89be463764,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-e8cd2e50-a2af-47fc-b0a2-559f2875c8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-5c07ff41-11fd-4fcf-a359-5e1be3222c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-a136fe24-9886-4b6b-9d3c-63b76ff0ae6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-c83a128b-0a25-4363-82e5-2832a96aaeaf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923713345-172.17.0.2-1598384451202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35315,DS-e92e31e7-f735-456b-9f6f-8a9106d675cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-b823ae24-6eac-4cc6-bfb6-ddc4fd518491,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-770319e7-471d-48d6-89c1-c44ec9025d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-89e27f0a-50d0-49a6-bbdc-7d89be463764,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-e8cd2e50-a2af-47fc-b0a2-559f2875c8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-5c07ff41-11fd-4fcf-a359-5e1be3222c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-a136fe24-9886-4b6b-9d3c-63b76ff0ae6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-c83a128b-0a25-4363-82e5-2832a96aaeaf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456462387-172.17.0.2-1598384484021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44583,DS-b0b392c3-4aa8-461b-ba83-eb71eb83faf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-62a714c7-8aa8-4962-977b-bba9cfc0182f,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-6e488a86-4828-4aed-af6a-6491587ca9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-c546ddba-d69e-4e1a-9486-941c80b29953,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-6f1bf800-d04e-4fb0-966d-f213a3a86f24,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-a6525b67-dfe1-4c3f-a167-73104ebe43ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-b3056934-2765-407d-ae93-7ea0009accdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-8baf4604-3cf5-480c-a332-a21e64e0cd4a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456462387-172.17.0.2-1598384484021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44583,DS-b0b392c3-4aa8-461b-ba83-eb71eb83faf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-62a714c7-8aa8-4962-977b-bba9cfc0182f,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-6e488a86-4828-4aed-af6a-6491587ca9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-c546ddba-d69e-4e1a-9486-941c80b29953,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-6f1bf800-d04e-4fb0-966d-f213a3a86f24,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-a6525b67-dfe1-4c3f-a167-73104ebe43ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-b3056934-2765-407d-ae93-7ea0009accdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-8baf4604-3cf5-480c-a332-a21e64e0cd4a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164269941-172.17.0.2-1598384518196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43658,DS-58b93b6a-a2d2-48b2-b026-d465a932dc20,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-0495bd6b-632e-417f-8438-13dfc6905f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-60b66fb8-f5ee-489e-8f2c-ed0ecc951365,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-16fe5e72-7910-4c63-b4b1-03756732cdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-7e9f9106-10d9-4d6f-a279-d8934af14aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-213f5705-8c52-4e8c-bb4d-8ca2ae41dd75,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-95a1baed-b133-4693-bb69-f4f1ed259d29,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-5a389964-c9bc-41f2-8814-297d646a73ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164269941-172.17.0.2-1598384518196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43658,DS-58b93b6a-a2d2-48b2-b026-d465a932dc20,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-0495bd6b-632e-417f-8438-13dfc6905f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-60b66fb8-f5ee-489e-8f2c-ed0ecc951365,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-16fe5e72-7910-4c63-b4b1-03756732cdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-7e9f9106-10d9-4d6f-a279-d8934af14aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-213f5705-8c52-4e8c-bb4d-8ca2ae41dd75,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-95a1baed-b133-4693-bb69-f4f1ed259d29,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-5a389964-c9bc-41f2-8814-297d646a73ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653902443-172.17.0.2-1598384909299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33615,DS-cc371729-3921-4861-86de-b2d5d8b0ada8,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-48c9fd33-71c7-4690-82c9-b3d71c0cc8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-9ac5428b-af6f-453e-875f-d12bce5204a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-935ee1a7-0b45-49f2-9b57-1b444b9629b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-388883d9-a956-4d4d-a9f3-cc77d55f2c78,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-ecfba718-107f-4368-abaf-304f99f7bb12,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-d7467a34-57a5-4e2c-8991-330954147f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-4414d1e8-0ef3-40a6-9d68-0913b00eb211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653902443-172.17.0.2-1598384909299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33615,DS-cc371729-3921-4861-86de-b2d5d8b0ada8,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-48c9fd33-71c7-4690-82c9-b3d71c0cc8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-9ac5428b-af6f-453e-875f-d12bce5204a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-935ee1a7-0b45-49f2-9b57-1b444b9629b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-388883d9-a956-4d4d-a9f3-cc77d55f2c78,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-ecfba718-107f-4368-abaf-304f99f7bb12,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-d7467a34-57a5-4e2c-8991-330954147f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-4414d1e8-0ef3-40a6-9d68-0913b00eb211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587658845-172.17.0.2-1598384946198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45731,DS-5b411cc4-921d-47f9-b3ea-4fccc6c95ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-e7e96ae2-e74e-4d80-b7f2-67da92ae06ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-68fb30d3-179b-447d-9a36-0fe67388aa02,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-313e21b3-16de-48e3-bd34-648f3da31416,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-9db6ca71-093d-4e0b-bda2-f5401e0a4b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-65238603-c372-499d-9431-2d22697a311a,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-9283a7d9-656d-49ef-b4b7-036c275ca973,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-2eee0064-67fa-4627-9c21-0e08b6e1f12f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587658845-172.17.0.2-1598384946198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45731,DS-5b411cc4-921d-47f9-b3ea-4fccc6c95ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-e7e96ae2-e74e-4d80-b7f2-67da92ae06ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-68fb30d3-179b-447d-9a36-0fe67388aa02,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-313e21b3-16de-48e3-bd34-648f3da31416,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-9db6ca71-093d-4e0b-bda2-f5401e0a4b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-65238603-c372-499d-9431-2d22697a311a,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-9283a7d9-656d-49ef-b4b7-036c275ca973,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-2eee0064-67fa-4627-9c21-0e08b6e1f12f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172048257-172.17.0.2-1598385116487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45829,DS-3c3ac938-af83-4fdc-9d98-d140e3d15781,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-2a7f9e44-f110-49fd-935f-a3660e83c83d,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-e9c839d5-0617-4e4b-ab7f-957cd163b5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-d2a0de2f-62f5-4221-82d3-d59d7cc8b5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-30312676-0ee2-488e-9311-d00c8d25870a,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-289de43c-a550-4b4d-aa95-50ab04e30ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-bec70b58-f53d-4684-a83f-f3639e496e81,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-368314e0-3be8-45a5-8b2c-ac0e00273c7d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172048257-172.17.0.2-1598385116487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45829,DS-3c3ac938-af83-4fdc-9d98-d140e3d15781,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-2a7f9e44-f110-49fd-935f-a3660e83c83d,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-e9c839d5-0617-4e4b-ab7f-957cd163b5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-d2a0de2f-62f5-4221-82d3-d59d7cc8b5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-30312676-0ee2-488e-9311-d00c8d25870a,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-289de43c-a550-4b4d-aa95-50ab04e30ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-bec70b58-f53d-4684-a83f-f3639e496e81,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-368314e0-3be8-45a5-8b2c-ac0e00273c7d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910211768-172.17.0.2-1598385260040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45837,DS-051fd2d6-7846-4083-a354-72e74ebb45fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-5d89d6be-e083-4cc8-8956-d5f9580160b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-f7cbe4a3-5c53-491a-a50c-21feb0230cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-0c39b741-8410-441d-86f9-8c0a9358a36a,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-4950c835-31dd-43c2-bacf-caf4bd4ecc87,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-45940a09-913c-41f8-ae85-59051197e822,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-3e6f01b8-26f8-4301-9e45-4c792598abc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-2b5a6676-8153-404a-a844-0677105509f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910211768-172.17.0.2-1598385260040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45837,DS-051fd2d6-7846-4083-a354-72e74ebb45fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-5d89d6be-e083-4cc8-8956-d5f9580160b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-f7cbe4a3-5c53-491a-a50c-21feb0230cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-0c39b741-8410-441d-86f9-8c0a9358a36a,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-4950c835-31dd-43c2-bacf-caf4bd4ecc87,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-45940a09-913c-41f8-ae85-59051197e822,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-3e6f01b8-26f8-4301-9e45-4c792598abc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-2b5a6676-8153-404a-a844-0677105509f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680600506-172.17.0.2-1598385519933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46345,DS-13f4f1bf-b05c-446c-ac16-a49adf820b67,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-aea7c302-d875-4f51-bc90-8661f263a606,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-31da604b-0f7c-4e4f-9687-bf01b121e1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-44771bfb-9a17-468c-95d1-caf819423258,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-404f0b64-1ab4-4dd7-924e-68ebbb97f1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-0cd1f37e-3338-4551-9f99-352ccfc2af78,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-e97a1b4c-be12-4bd1-b731-ee54a530a732,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-d0856e10-2b72-4671-8370-4ec0a85b25e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680600506-172.17.0.2-1598385519933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46345,DS-13f4f1bf-b05c-446c-ac16-a49adf820b67,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-aea7c302-d875-4f51-bc90-8661f263a606,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-31da604b-0f7c-4e4f-9687-bf01b121e1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-44771bfb-9a17-468c-95d1-caf819423258,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-404f0b64-1ab4-4dd7-924e-68ebbb97f1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-0cd1f37e-3338-4551-9f99-352ccfc2af78,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-e97a1b4c-be12-4bd1-b731-ee54a530a732,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-d0856e10-2b72-4671-8370-4ec0a85b25e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497757030-172.17.0.2-1598385616450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37345,DS-636a14d2-4e3f-4cfb-9dd0-d7bf9a925a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-2c5aac69-2472-41bf-bdb8-d36c8c0054cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-bfbae682-d1a2-4f90-b09b-433c688e50cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-c0f21c70-f9ba-4ddb-981e-898d4b8c8f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-2f54996f-c0d9-41cf-97cc-f70066b653ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-c01d839a-ae2d-49a8-a2a4-454cf9863386,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-19b1ae9b-029b-4a7c-9c92-c5783b4cbe17,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-2d8f9559-9274-48f7-a06e-a0e2c4d4fa8a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497757030-172.17.0.2-1598385616450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37345,DS-636a14d2-4e3f-4cfb-9dd0-d7bf9a925a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-2c5aac69-2472-41bf-bdb8-d36c8c0054cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-bfbae682-d1a2-4f90-b09b-433c688e50cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-c0f21c70-f9ba-4ddb-981e-898d4b8c8f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-2f54996f-c0d9-41cf-97cc-f70066b653ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-c01d839a-ae2d-49a8-a2a4-454cf9863386,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-19b1ae9b-029b-4a7c-9c92-c5783b4cbe17,DISK], DatanodeInfoWithStorage[127.0.0.1:45348,DS-2d8f9559-9274-48f7-a06e-a0e2c4d4fa8a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174441363-172.17.0.2-1598385775879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34022,DS-802637c2-0d1b-4b65-833b-3cfbe1dbd8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-3b9e9cfc-9635-43c5-9524-f299ad0154db,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-24d211ae-0da6-4bd4-b1d4-a176726324ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-4231c6de-2b38-47da-86de-3262ee79b46f,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-0414ee20-5ebd-4d18-a314-9f97f94371bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-bba70cdb-94a9-4d98-ad4d-c2da8ec88de0,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-60dbd990-2f81-43ec-86f0-6489fac56fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-60ecb583-cac9-4daf-9446-d7657e2d3a7e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174441363-172.17.0.2-1598385775879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34022,DS-802637c2-0d1b-4b65-833b-3cfbe1dbd8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-3b9e9cfc-9635-43c5-9524-f299ad0154db,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-24d211ae-0da6-4bd4-b1d4-a176726324ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-4231c6de-2b38-47da-86de-3262ee79b46f,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-0414ee20-5ebd-4d18-a314-9f97f94371bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-bba70cdb-94a9-4d98-ad4d-c2da8ec88de0,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-60dbd990-2f81-43ec-86f0-6489fac56fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-60ecb583-cac9-4daf-9446-d7657e2d3a7e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49894208-172.17.0.2-1598386069736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38951,DS-85d7333f-0bf5-4bc5-a80d-4ac5635029e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-17e844db-24f8-4241-8918-f5f1235f3108,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-bae05876-122b-4e55-a00d-bc4989a13cac,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-5be92fbb-98c8-4802-9a83-452c91aaaa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-b80ae156-d8ac-4678-8c13-e6f91cb2c305,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-287d86fe-0424-4c27-856d-98ea6107df3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-2dd64dd1-ac8c-4b88-af52-2ce2fdcca843,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-6d98f3e5-c2d3-4e9d-a9d2-45db30a27116,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49894208-172.17.0.2-1598386069736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38951,DS-85d7333f-0bf5-4bc5-a80d-4ac5635029e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-17e844db-24f8-4241-8918-f5f1235f3108,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-bae05876-122b-4e55-a00d-bc4989a13cac,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-5be92fbb-98c8-4802-9a83-452c91aaaa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-b80ae156-d8ac-4678-8c13-e6f91cb2c305,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-287d86fe-0424-4c27-856d-98ea6107df3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-2dd64dd1-ac8c-4b88-af52-2ce2fdcca843,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-6d98f3e5-c2d3-4e9d-a9d2-45db30a27116,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523716427-172.17.0.2-1598386161803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39979,DS-6d57dcfe-3d52-416e-a33c-d79f4b0fc2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-50441807-4cb6-4ca4-8394-31a719e2695e,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-aecc08f1-b494-48e8-9912-69ec5068a930,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-0f9ecaa1-6d11-4324-99fb-d195ffa6b960,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-84b002da-4778-4009-ae0b-5f1f5665ff23,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-23b5e78e-ca62-4fd8-82f4-b424d94a27a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-80ed7fea-ae69-42f8-a5d0-312401d4ef74,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-a874e830-c3f4-40d6-8e7b-121183c20244,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523716427-172.17.0.2-1598386161803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39979,DS-6d57dcfe-3d52-416e-a33c-d79f4b0fc2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-50441807-4cb6-4ca4-8394-31a719e2695e,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-aecc08f1-b494-48e8-9912-69ec5068a930,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-0f9ecaa1-6d11-4324-99fb-d195ffa6b960,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-84b002da-4778-4009-ae0b-5f1f5665ff23,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-23b5e78e-ca62-4fd8-82f4-b424d94a27a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-80ed7fea-ae69-42f8-a5d0-312401d4ef74,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-a874e830-c3f4-40d6-8e7b-121183c20244,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133749543-172.17.0.2-1598387026866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40402,DS-6534cf5b-0c8a-40b4-b3d2-bdb4311bc223,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-aee7a116-246f-4ba7-971c-2a193e0a736e,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-e9b65a73-96cb-45e8-b16f-8ee5700d581c,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-b96f92ab-0aa7-4a9d-bf1f-944618a6d32b,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-2bc346df-35b0-4fb2-9cb4-fb87aab0b379,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-4a970077-7ef3-4722-b104-c9919b5a7eed,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-d53a25fa-c4fc-4bfa-908a-603aa40dcbff,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-075d0248-86ec-4e8a-b15c-8660c864f3f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133749543-172.17.0.2-1598387026866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40402,DS-6534cf5b-0c8a-40b4-b3d2-bdb4311bc223,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-aee7a116-246f-4ba7-971c-2a193e0a736e,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-e9b65a73-96cb-45e8-b16f-8ee5700d581c,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-b96f92ab-0aa7-4a9d-bf1f-944618a6d32b,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-2bc346df-35b0-4fb2-9cb4-fb87aab0b379,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-4a970077-7ef3-4722-b104-c9919b5a7eed,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-d53a25fa-c4fc-4bfa-908a-603aa40dcbff,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-075d0248-86ec-4e8a-b15c-8660c864f3f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039250141-172.17.0.2-1598387195962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37917,DS-6bad1518-a568-4052-ab26-aaa1cf5b2b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-d112434b-4248-4f21-98a3-303fff5560a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-3cdf5102-7caf-4da9-b66c-58a7da2c2795,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-8934e35b-8dfc-42d5-a6b2-ebfe6baf4886,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-f3e19d3b-bf19-4069-ba43-b9e2db4c5dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-d6697d6d-340c-4afa-a7d3-6c4b56c4b288,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-fb1a5930-7c70-4434-83d8-6f2dc375723a,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-d7ef80b2-d375-43e7-886b-3977b4ad5613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039250141-172.17.0.2-1598387195962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37917,DS-6bad1518-a568-4052-ab26-aaa1cf5b2b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-d112434b-4248-4f21-98a3-303fff5560a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-3cdf5102-7caf-4da9-b66c-58a7da2c2795,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-8934e35b-8dfc-42d5-a6b2-ebfe6baf4886,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-f3e19d3b-bf19-4069-ba43-b9e2db4c5dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-d6697d6d-340c-4afa-a7d3-6c4b56c4b288,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-fb1a5930-7c70-4434-83d8-6f2dc375723a,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-d7ef80b2-d375-43e7-886b-3977b4ad5613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144366428-172.17.0.2-1598387486303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41064,DS-9dca0853-b225-4b75-b4e6-6ec69e192001,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-dded9975-a122-4921-930c-42916fc14cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-aed0185a-c7ff-423c-ba7c-c64c877a9ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-16cef8cc-add8-4e72-844e-2b7b9fad8284,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-44aaa19e-279b-4eb2-b0bb-43f8389e5999,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-48409bc3-ad6a-456e-b0d4-3b181bc4e0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-12a7ffd2-4809-47b4-8932-783ae7a5d417,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-78a1e6b2-15bd-4718-b2a8-8d82f2731955,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144366428-172.17.0.2-1598387486303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41064,DS-9dca0853-b225-4b75-b4e6-6ec69e192001,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-dded9975-a122-4921-930c-42916fc14cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-aed0185a-c7ff-423c-ba7c-c64c877a9ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-16cef8cc-add8-4e72-844e-2b7b9fad8284,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-44aaa19e-279b-4eb2-b0bb-43f8389e5999,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-48409bc3-ad6a-456e-b0d4-3b181bc4e0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-12a7ffd2-4809-47b4-8932-783ae7a5d417,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-78a1e6b2-15bd-4718-b2a8-8d82f2731955,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013162927-172.17.0.2-1598387556597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46666,DS-e55072b1-22a9-49e3-904e-6a4967fc67d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-b9afb025-e9ff-4724-b567-465f09fc43f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-a9715e75-7688-4fec-b9ed-a44243ba0531,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-3d0ae8c9-cc77-45dd-b36b-b749d1c20d83,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-f9be1ae6-89f5-4484-97de-22cce33de646,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-ca1466c5-83ec-4b9b-b16c-1fe3efcd2864,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-f86b4a59-b58d-4b8c-8117-9b03bef3b031,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-a1d0f8a6-deba-497c-afac-00bc6f99a2f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013162927-172.17.0.2-1598387556597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46666,DS-e55072b1-22a9-49e3-904e-6a4967fc67d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-b9afb025-e9ff-4724-b567-465f09fc43f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-a9715e75-7688-4fec-b9ed-a44243ba0531,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-3d0ae8c9-cc77-45dd-b36b-b749d1c20d83,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-f9be1ae6-89f5-4484-97de-22cce33de646,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-ca1466c5-83ec-4b9b-b16c-1fe3efcd2864,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-f86b4a59-b58d-4b8c-8117-9b03bef3b031,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-a1d0f8a6-deba-497c-afac-00bc6f99a2f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121985936-172.17.0.2-1598387887770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39990,DS-3f6378cb-e488-4811-9160-4d9d3c8e6695,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-9aa66386-63fd-4bc9-8967-fc1b089974dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-ae086a47-aa38-4f9f-9464-a9e5168b4036,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-473b3a25-7a2d-4d03-b61c-92114b89c1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-2798989b-862e-4e44-8e8a-bf0ab1e492a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-6f433e46-436e-4e29-a17d-83f61da53518,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-31a5a14e-8249-4d81-bbea-d60303f20054,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-9957631f-47a7-4e46-bde9-7017eb00b020,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121985936-172.17.0.2-1598387887770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39990,DS-3f6378cb-e488-4811-9160-4d9d3c8e6695,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-9aa66386-63fd-4bc9-8967-fc1b089974dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-ae086a47-aa38-4f9f-9464-a9e5168b4036,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-473b3a25-7a2d-4d03-b61c-92114b89c1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-2798989b-862e-4e44-8e8a-bf0ab1e492a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-6f433e46-436e-4e29-a17d-83f61da53518,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-31a5a14e-8249-4d81-bbea-d60303f20054,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-9957631f-47a7-4e46-bde9-7017eb00b020,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874665409-172.17.0.2-1598388177717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34169,DS-eb0f98e7-49c0-46f6-9b8d-f85658ccfbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-b4cd9626-2333-409f-b360-ffc32b13142f,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-8670a99e-c527-4f28-aeda-0d6f2d5c8b24,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-6fb510e4-cb6c-4947-8f45-9e4de25e8d26,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-927cb045-3c80-4ce9-8066-2fabf5aca858,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-7525c2fd-1b70-4786-9458-9478be2bffeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-afa19a42-30bb-42b5-b584-d7972a636167,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-15d6fd9d-1811-4921-8198-b01afb656126,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874665409-172.17.0.2-1598388177717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34169,DS-eb0f98e7-49c0-46f6-9b8d-f85658ccfbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-b4cd9626-2333-409f-b360-ffc32b13142f,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-8670a99e-c527-4f28-aeda-0d6f2d5c8b24,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-6fb510e4-cb6c-4947-8f45-9e4de25e8d26,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-927cb045-3c80-4ce9-8066-2fabf5aca858,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-7525c2fd-1b70-4786-9458-9478be2bffeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-afa19a42-30bb-42b5-b584-d7972a636167,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-15d6fd9d-1811-4921-8198-b01afb656126,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096395045-172.17.0.2-1598388379408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45652,DS-aa55bb24-c1d9-4306-8b4d-6f0c468a6a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-1581b8ae-e857-4fa2-a3c0-2218e5cf50ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-3bd9f776-bcea-4f47-9bd8-e28231459ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-de78b355-43de-4ae6-b22c-14d2730b2dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-d660cfac-c2c3-4ac5-b87e-0eaafd289461,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-e1018ccd-1e18-4f0d-812f-c7f49a6f5687,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-9487f8e9-bc5e-40f7-8e32-653f6be8e96d,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-c5e83f47-55c0-4bd6-a5fd-0f6c451f0b0c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096395045-172.17.0.2-1598388379408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45652,DS-aa55bb24-c1d9-4306-8b4d-6f0c468a6a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-1581b8ae-e857-4fa2-a3c0-2218e5cf50ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-3bd9f776-bcea-4f47-9bd8-e28231459ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-de78b355-43de-4ae6-b22c-14d2730b2dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-d660cfac-c2c3-4ac5-b87e-0eaafd289461,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-e1018ccd-1e18-4f0d-812f-c7f49a6f5687,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-9487f8e9-bc5e-40f7-8e32-653f6be8e96d,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-c5e83f47-55c0-4bd6-a5fd-0f6c451f0b0c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5135
