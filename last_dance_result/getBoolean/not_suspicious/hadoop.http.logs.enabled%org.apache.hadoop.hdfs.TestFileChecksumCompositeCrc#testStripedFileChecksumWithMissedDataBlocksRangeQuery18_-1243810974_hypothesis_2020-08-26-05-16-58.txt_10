reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104950273-172.17.0.4-1598419308237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33093,DS-96c33c83-2fde-4994-9fe0-44872037b82b,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-aa6a7367-3ec1-44d9-8c5c-5b18f077ac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-4cc10002-49cd-413c-9f2e-5fa2bc7f8fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-456203d4-cd79-4864-9382-539f3c701233,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-966d0e2e-531a-4b8c-b2f7-33f69becaf20,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-2b499541-9239-4fbb-856c-fd0e4a63237c,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-c8e0105a-bc5d-458a-8bb9-1cac1e38feeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-36119e15-f18b-46fc-b719-186bf8e526c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104950273-172.17.0.4-1598419308237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33093,DS-96c33c83-2fde-4994-9fe0-44872037b82b,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-aa6a7367-3ec1-44d9-8c5c-5b18f077ac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-4cc10002-49cd-413c-9f2e-5fa2bc7f8fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-456203d4-cd79-4864-9382-539f3c701233,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-966d0e2e-531a-4b8c-b2f7-33f69becaf20,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-2b499541-9239-4fbb-856c-fd0e4a63237c,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-c8e0105a-bc5d-458a-8bb9-1cac1e38feeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-36119e15-f18b-46fc-b719-186bf8e526c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046416565-172.17.0.4-1598419702355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44095,DS-7d911e75-8b4c-45db-903d-3d5ea17a5727,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-d154f0af-9bab-499d-82d3-22dc5c2e1e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-0699de16-86af-4d0e-b327-1ac930f51f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-869f173a-7e5d-4223-bc52-39ded3763469,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-67a4e15d-d1d1-4477-924d-1e1aaa4eeafb,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-c08f9d73-b8d4-4f30-8e57-189f271f99c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-8421e4a1-c6a4-4da6-b607-de5349ac02fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-d51a304c-709e-4535-bde6-4c14f254456e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046416565-172.17.0.4-1598419702355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44095,DS-7d911e75-8b4c-45db-903d-3d5ea17a5727,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-d154f0af-9bab-499d-82d3-22dc5c2e1e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-0699de16-86af-4d0e-b327-1ac930f51f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-869f173a-7e5d-4223-bc52-39ded3763469,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-67a4e15d-d1d1-4477-924d-1e1aaa4eeafb,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-c08f9d73-b8d4-4f30-8e57-189f271f99c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-8421e4a1-c6a4-4da6-b607-de5349ac02fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-d51a304c-709e-4535-bde6-4c14f254456e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604899732-172.17.0.4-1598419922589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44607,DS-321d4371-405a-4475-865b-f7c4c15a65a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-9d451391-15dc-404a-b647-b8e0984b7912,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-f5b51b15-1232-4e37-9ad5-cd58c3a96d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-35c7b8ee-53f8-4195-aa26-725bea3ab200,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-de6e9177-6a99-4de3-ba94-50bd101c63d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-fde79c5e-825d-4360-b5df-143123a34ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-7a8f10d5-91f4-43e9-ac42-3e04155a5622,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-12742999-ce37-490f-8115-d6360a0094e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604899732-172.17.0.4-1598419922589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44607,DS-321d4371-405a-4475-865b-f7c4c15a65a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-9d451391-15dc-404a-b647-b8e0984b7912,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-f5b51b15-1232-4e37-9ad5-cd58c3a96d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-35c7b8ee-53f8-4195-aa26-725bea3ab200,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-de6e9177-6a99-4de3-ba94-50bd101c63d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-fde79c5e-825d-4360-b5df-143123a34ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-7a8f10d5-91f4-43e9-ac42-3e04155a5622,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-12742999-ce37-490f-8115-d6360a0094e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2119835025-172.17.0.4-1598420081533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37921,DS-0373c9fc-9c15-43da-a3a8-961eb5e7d5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-1a86987f-8847-4ed9-841f-cca260afca20,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-0c10416e-863d-4086-b99b-7e56f216907f,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-68a879d3-a2a2-47e4-b28f-39387b8a189a,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-1b3a38c4-0392-407b-bce0-bcee2d756ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-1abb755e-99a3-4fd4-a256-aed0cafe10ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-5f338a73-d42f-4d59-b1aa-04c5a37096f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-e82ef00a-f657-49c8-8f8b-9d15d165a113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2119835025-172.17.0.4-1598420081533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37921,DS-0373c9fc-9c15-43da-a3a8-961eb5e7d5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-1a86987f-8847-4ed9-841f-cca260afca20,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-0c10416e-863d-4086-b99b-7e56f216907f,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-68a879d3-a2a2-47e4-b28f-39387b8a189a,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-1b3a38c4-0392-407b-bce0-bcee2d756ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-1abb755e-99a3-4fd4-a256-aed0cafe10ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-5f338a73-d42f-4d59-b1aa-04c5a37096f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-e82ef00a-f657-49c8-8f8b-9d15d165a113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598074288-172.17.0.4-1598420407123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38051,DS-eaddec45-a9e4-4b7e-8ab8-70a0068b7777,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-8412777a-d0b8-4c39-808b-9a558ac2ddca,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-9253bc83-64c1-42ce-943d-af01f422a01f,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-d9e7c979-dd91-44d5-9422-0adccdcbb895,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-f73ebae6-c542-4969-8ced-6df6fc3d253c,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-e14f6b38-1943-494b-9cdc-7f5447dcdc90,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-3dfdad01-6464-48e7-9718-f7ccc3219a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-a96eac7d-a3b7-4de7-9d4b-edebc0286780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598074288-172.17.0.4-1598420407123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38051,DS-eaddec45-a9e4-4b7e-8ab8-70a0068b7777,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-8412777a-d0b8-4c39-808b-9a558ac2ddca,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-9253bc83-64c1-42ce-943d-af01f422a01f,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-d9e7c979-dd91-44d5-9422-0adccdcbb895,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-f73ebae6-c542-4969-8ced-6df6fc3d253c,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-e14f6b38-1943-494b-9cdc-7f5447dcdc90,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-3dfdad01-6464-48e7-9718-f7ccc3219a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-a96eac7d-a3b7-4de7-9d4b-edebc0286780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2120113145-172.17.0.4-1598420985772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39697,DS-5da3aa07-936e-425e-8915-4196f1f8570e,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-673a6549-64d3-4cf8-a778-acbb7aba61af,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-e791e336-d805-434e-84a4-88887ec6c5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-838a0972-3333-41f1-a68f-e76b8f1addaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-ce905900-636d-46c7-9d28-a4e36fa70166,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-8e6422f2-c8d0-4ad3-bdc2-0780a1da8a73,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-5f4c9cb1-2511-4540-8f9e-e7bf17fbe95d,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-3d74b13a-687c-4082-b603-b773f27d8a8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2120113145-172.17.0.4-1598420985772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39697,DS-5da3aa07-936e-425e-8915-4196f1f8570e,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-673a6549-64d3-4cf8-a778-acbb7aba61af,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-e791e336-d805-434e-84a4-88887ec6c5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-838a0972-3333-41f1-a68f-e76b8f1addaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-ce905900-636d-46c7-9d28-a4e36fa70166,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-8e6422f2-c8d0-4ad3-bdc2-0780a1da8a73,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-5f4c9cb1-2511-4540-8f9e-e7bf17fbe95d,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-3d74b13a-687c-4082-b603-b773f27d8a8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-939189014-172.17.0.4-1598421247034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37253,DS-7ee0134c-0c26-406a-9e91-7a821f1069f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-a27899c0-be42-4364-b469-01cebaf2a22f,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-6ef03a05-9b9a-4961-b8da-f791daf39914,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-7170b85a-00f4-4df5-9430-c5b374e2a1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-8e71537c-defa-4ab3-9eb0-968204e2a762,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-75f559e5-e505-4c5c-8a38-e61cbb814072,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-2d0a870d-db41-4fab-b1a8-155af13ee526,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-72acfbc6-8b2c-458e-95b0-bf6566b39d82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-939189014-172.17.0.4-1598421247034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37253,DS-7ee0134c-0c26-406a-9e91-7a821f1069f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-a27899c0-be42-4364-b469-01cebaf2a22f,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-6ef03a05-9b9a-4961-b8da-f791daf39914,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-7170b85a-00f4-4df5-9430-c5b374e2a1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-8e71537c-defa-4ab3-9eb0-968204e2a762,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-75f559e5-e505-4c5c-8a38-e61cbb814072,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-2d0a870d-db41-4fab-b1a8-155af13ee526,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-72acfbc6-8b2c-458e-95b0-bf6566b39d82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147853108-172.17.0.4-1598421648895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34590,DS-536ad462-5c30-449a-ae5a-277c5c7bb945,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-fa1a9890-52bd-42db-a176-693e27facb06,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-145876ef-f274-4863-a657-aa915cc87bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-f76f514c-6fab-4eab-b902-35fc8f7100d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-9eff99dd-1f41-4c14-9733-222f6d6aabc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-af6b4548-66fc-41f9-a5e9-45fc61c67b68,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-d963a4a7-027b-42d6-85c2-4924b0ff2da3,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-ef1491ff-7344-4507-b2da-4475a15fd33f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147853108-172.17.0.4-1598421648895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34590,DS-536ad462-5c30-449a-ae5a-277c5c7bb945,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-fa1a9890-52bd-42db-a176-693e27facb06,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-145876ef-f274-4863-a657-aa915cc87bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-f76f514c-6fab-4eab-b902-35fc8f7100d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-9eff99dd-1f41-4c14-9733-222f6d6aabc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-af6b4548-66fc-41f9-a5e9-45fc61c67b68,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-d963a4a7-027b-42d6-85c2-4924b0ff2da3,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-ef1491ff-7344-4507-b2da-4475a15fd33f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722562566-172.17.0.4-1598421804200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45263,DS-4ed664f3-d4eb-403a-82b4-7e41d62ef20b,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-3ab69d7a-2c68-4da3-8d82-2287745357b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-ab26d606-610f-4420-913a-ed22de090d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-cc217652-7d04-4711-8970-0b46ff8cff04,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-9d87c6c9-dfee-4445-a838-5caec9afba4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-4394331c-66e6-4d11-836c-c06fe856d80e,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-b8005a85-a715-4403-ae8f-dae2a1cdd3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-356e84f7-b596-4551-9739-850b2bd03724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722562566-172.17.0.4-1598421804200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45263,DS-4ed664f3-d4eb-403a-82b4-7e41d62ef20b,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-3ab69d7a-2c68-4da3-8d82-2287745357b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-ab26d606-610f-4420-913a-ed22de090d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-cc217652-7d04-4711-8970-0b46ff8cff04,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-9d87c6c9-dfee-4445-a838-5caec9afba4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-4394331c-66e6-4d11-836c-c06fe856d80e,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-b8005a85-a715-4403-ae8f-dae2a1cdd3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-356e84f7-b596-4551-9739-850b2bd03724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-716477612-172.17.0.4-1598422443350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34107,DS-05cb4ab5-abdf-4f56-9ec1-a959a819f811,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-e3bc15b7-546d-44d4-9e18-0eff3d33426e,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-b64d7029-3658-4e65-84d0-2cb1a5f54cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-09e8c014-e485-417d-a2aa-f37d5bce4306,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-b3a622a3-8efe-458e-8efb-b252d6eb317e,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-b125ee4c-4b5f-4fb2-94b2-ea759a8b6546,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-3b6c7d15-a124-4a77-b63a-3ac9bbb0837d,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-41373751-fc9f-4fbc-b33a-2b06b5c04caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-716477612-172.17.0.4-1598422443350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34107,DS-05cb4ab5-abdf-4f56-9ec1-a959a819f811,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-e3bc15b7-546d-44d4-9e18-0eff3d33426e,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-b64d7029-3658-4e65-84d0-2cb1a5f54cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-09e8c014-e485-417d-a2aa-f37d5bce4306,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-b3a622a3-8efe-458e-8efb-b252d6eb317e,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-b125ee4c-4b5f-4fb2-94b2-ea759a8b6546,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-3b6c7d15-a124-4a77-b63a-3ac9bbb0837d,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-41373751-fc9f-4fbc-b33a-2b06b5c04caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1149143118-172.17.0.4-1598423010331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-1a71e05c-bac0-4824-bfca-334e0a2cdf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-1821a841-2395-4f41-96cd-c6f34667e18b,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-c068d5af-57d6-4d5b-ac24-6ca6cc5260b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-294e022b-efb4-42e5-99b9-43801dd2f272,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-6b08f185-8d43-44a2-9abb-e19f4038f8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-a1985e26-7726-48b5-8ee3-34acf5ec5e35,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-d5bb6867-5ca6-43a8-b697-2f29ba6c6bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-c9980188-12a8-49ef-921e-26e649f1ac21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1149143118-172.17.0.4-1598423010331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-1a71e05c-bac0-4824-bfca-334e0a2cdf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-1821a841-2395-4f41-96cd-c6f34667e18b,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-c068d5af-57d6-4d5b-ac24-6ca6cc5260b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-294e022b-efb4-42e5-99b9-43801dd2f272,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-6b08f185-8d43-44a2-9abb-e19f4038f8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-a1985e26-7726-48b5-8ee3-34acf5ec5e35,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-d5bb6867-5ca6-43a8-b697-2f29ba6c6bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-c9980188-12a8-49ef-921e-26e649f1ac21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-37210035-172.17.0.4-1598423358687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42665,DS-20433d40-8e86-488d-9f7c-b3c0f88981e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-a785c621-a4f0-414e-8416-352c3a5cfeab,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-8dce7789-73b2-4ff3-9433-4f4bbdc3b7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-eeb1eca4-8335-4e2e-8de6-f0c741006a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-6a8d771c-f0ae-4a65-a9fd-6c45ad31ef17,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-b5ffc205-503d-46bb-8923-868ef2763fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-f92cb7fa-235f-407e-9776-8cffe3d97d69,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-ff077ba2-b0b8-4990-945e-83d42dd415a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-37210035-172.17.0.4-1598423358687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42665,DS-20433d40-8e86-488d-9f7c-b3c0f88981e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-a785c621-a4f0-414e-8416-352c3a5cfeab,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-8dce7789-73b2-4ff3-9433-4f4bbdc3b7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-eeb1eca4-8335-4e2e-8de6-f0c741006a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-6a8d771c-f0ae-4a65-a9fd-6c45ad31ef17,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-b5ffc205-503d-46bb-8923-868ef2763fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-f92cb7fa-235f-407e-9776-8cffe3d97d69,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-ff077ba2-b0b8-4990-945e-83d42dd415a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635054946-172.17.0.4-1598423433368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37434,DS-fedd3eec-f1b5-4a87-aa97-9a783c778793,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-4ad44e3f-2e58-4fd3-b0fa-c1a7e6e751e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-6c5c736b-ce1d-4f78-8ae2-073aacbe2785,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-7895b515-23e5-4990-9821-dc3c020d1f25,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-2773c369-5510-4de7-896d-1381ad951169,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-8c9c7149-0b0a-4f29-b098-a806046b963a,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-407954f1-47e6-46fe-ae19-82ca5b688685,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-37f3a1d3-784a-46df-9725-1ed5889759b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635054946-172.17.0.4-1598423433368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37434,DS-fedd3eec-f1b5-4a87-aa97-9a783c778793,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-4ad44e3f-2e58-4fd3-b0fa-c1a7e6e751e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-6c5c736b-ce1d-4f78-8ae2-073aacbe2785,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-7895b515-23e5-4990-9821-dc3c020d1f25,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-2773c369-5510-4de7-896d-1381ad951169,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-8c9c7149-0b0a-4f29-b098-a806046b963a,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-407954f1-47e6-46fe-ae19-82ca5b688685,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-37f3a1d3-784a-46df-9725-1ed5889759b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-943501822-172.17.0.4-1598423463932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38839,DS-96e87a2d-7bfa-4c66-a976-37309002ae61,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-702bce27-1d4a-41d1-bf18-0efd73105c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-74e42deb-519b-4218-863d-9376d3ccfb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-1796c359-9a31-4aa1-a876-51b626dfb80d,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-6fc17f9b-7875-43ba-9dc4-90b399040f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-ccb6b6ce-4163-41bc-b56a-f85257f8e704,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-ad4c24fa-d89c-465d-8335-c799a75cf656,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-be3c3217-cd8c-438c-b68e-077efd76faf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-943501822-172.17.0.4-1598423463932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38839,DS-96e87a2d-7bfa-4c66-a976-37309002ae61,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-702bce27-1d4a-41d1-bf18-0efd73105c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-74e42deb-519b-4218-863d-9376d3ccfb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-1796c359-9a31-4aa1-a876-51b626dfb80d,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-6fc17f9b-7875-43ba-9dc4-90b399040f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-ccb6b6ce-4163-41bc-b56a-f85257f8e704,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-ad4c24fa-d89c-465d-8335-c799a75cf656,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-be3c3217-cd8c-438c-b68e-077efd76faf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665096795-172.17.0.4-1598423503152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39473,DS-6a5c16c1-3876-4851-baca-e75a96b9c960,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-a0b304d9-46a3-4dfa-b14d-a98a1bc41b41,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-e869d1c8-0c06-4a0e-babb-6fa5d0586390,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-037657bb-81e3-4ea2-8dbe-91c850cca44f,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-735f5626-30ea-4de0-88e0-1f5a68ef4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-9f0591a5-da72-4fae-a819-4cd4fc50d404,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-4b126110-bc16-42e6-8c03-569399a24fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-2b7190a3-d8d4-499c-8c99-b13797208058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665096795-172.17.0.4-1598423503152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39473,DS-6a5c16c1-3876-4851-baca-e75a96b9c960,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-a0b304d9-46a3-4dfa-b14d-a98a1bc41b41,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-e869d1c8-0c06-4a0e-babb-6fa5d0586390,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-037657bb-81e3-4ea2-8dbe-91c850cca44f,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-735f5626-30ea-4de0-88e0-1f5a68ef4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-9f0591a5-da72-4fae-a819-4cd4fc50d404,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-4b126110-bc16-42e6-8c03-569399a24fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-2b7190a3-d8d4-499c-8c99-b13797208058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758587698-172.17.0.4-1598423536271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44081,DS-507ef7bf-8577-4a36-baea-8c37859e182d,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-491c7689-4ef1-449b-b5ea-28f39545cdde,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-bed4a93d-8403-4291-93e1-1b32351fb932,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-b1c965e4-7a77-4f9d-97db-ef13faf57c95,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-1c95d60d-df81-4658-84d1-7c3b19dc760e,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-1a4969c3-1947-4006-b718-350c84d1440c,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-985dd6b7-ec5a-40a1-8cf9-28749bff056e,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-7df4f80d-40c6-4480-b45b-4eeaecf5efad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758587698-172.17.0.4-1598423536271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44081,DS-507ef7bf-8577-4a36-baea-8c37859e182d,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-491c7689-4ef1-449b-b5ea-28f39545cdde,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-bed4a93d-8403-4291-93e1-1b32351fb932,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-b1c965e4-7a77-4f9d-97db-ef13faf57c95,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-1c95d60d-df81-4658-84d1-7c3b19dc760e,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-1a4969c3-1947-4006-b718-350c84d1440c,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-985dd6b7-ec5a-40a1-8cf9-28749bff056e,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-7df4f80d-40c6-4480-b45b-4eeaecf5efad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1552768549-172.17.0.4-1598423825084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-953749ad-c46e-47ce-8466-9294ce896acf,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-4fc20634-7c9c-46a1-9ba6-3c94ebeed893,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-0223431b-f099-471b-902d-378b417660f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-ff4d560f-c763-495a-874c-bd837ce7d44e,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-77dbc6fe-0c8c-43bf-b0f0-5e81f2a19ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-8ce3bbd5-e056-422c-9ae3-fa33bf5f36d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-0fa4095f-9ffc-4df4-aa25-cdf66a80ac7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-2e039b09-15fa-4847-9aa6-ca92f2c38962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1552768549-172.17.0.4-1598423825084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-953749ad-c46e-47ce-8466-9294ce896acf,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-4fc20634-7c9c-46a1-9ba6-3c94ebeed893,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-0223431b-f099-471b-902d-378b417660f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-ff4d560f-c763-495a-874c-bd837ce7d44e,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-77dbc6fe-0c8c-43bf-b0f0-5e81f2a19ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-8ce3bbd5-e056-422c-9ae3-fa33bf5f36d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-0fa4095f-9ffc-4df4-aa25-cdf66a80ac7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-2e039b09-15fa-4847-9aa6-ca92f2c38962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1720496554-172.17.0.4-1598423862266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-6ae2b70e-0e2a-41f6-99b3-9194c7cfb446,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-24c0c746-17fa-4aee-83d6-8a8f810c4bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-3de56c7d-63e5-46ff-876a-73b5efea2241,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-1fc26695-8c61-4c40-8162-416e27f514d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-ebb66122-17d2-483e-a559-bf58a5ee2ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-17219c3a-5a18-4975-83c0-339624f4a030,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-636681e5-3e3f-40f4-aeea-96166e2a037f,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-a69f2b42-d6bd-466c-9e31-dbf4e3171b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1720496554-172.17.0.4-1598423862266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-6ae2b70e-0e2a-41f6-99b3-9194c7cfb446,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-24c0c746-17fa-4aee-83d6-8a8f810c4bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-3de56c7d-63e5-46ff-876a-73b5efea2241,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-1fc26695-8c61-4c40-8162-416e27f514d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-ebb66122-17d2-483e-a559-bf58a5ee2ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-17219c3a-5a18-4975-83c0-339624f4a030,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-636681e5-3e3f-40f4-aeea-96166e2a037f,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-a69f2b42-d6bd-466c-9e31-dbf4e3171b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-260295394-172.17.0.4-1598424101746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34920,DS-90c0a83d-d806-4856-8d0a-05f6971e2db0,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-0e59b14c-f5fd-4aec-b781-addf27ad96c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-732016a5-a651-4966-b8bf-a215c1c264e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-6a23098d-4b1b-47a8-a837-fa54d8d56eed,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-69262fe0-a2d2-4a6d-9e89-e5f2e721aea2,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-e9d2ba32-cf33-4819-8e63-1a5d04139bca,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-86f2852f-48ec-4e69-ab8b-fb49bb94e27e,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-16b2ac8b-ade8-4423-ae1d-4622220edcff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-260295394-172.17.0.4-1598424101746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34920,DS-90c0a83d-d806-4856-8d0a-05f6971e2db0,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-0e59b14c-f5fd-4aec-b781-addf27ad96c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-732016a5-a651-4966-b8bf-a215c1c264e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-6a23098d-4b1b-47a8-a837-fa54d8d56eed,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-69262fe0-a2d2-4a6d-9e89-e5f2e721aea2,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-e9d2ba32-cf33-4819-8e63-1a5d04139bca,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-86f2852f-48ec-4e69-ab8b-fb49bb94e27e,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-16b2ac8b-ade8-4423-ae1d-4622220edcff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5494
