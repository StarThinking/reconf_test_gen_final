reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91730956-172.17.0.9-1598102582335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42115,DS-61b76bfc-d243-4958-a4ea-82bfe3274a69,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-22f1ce05-0b00-436a-a604-f9be53137e24,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-02df2b0f-3618-48d7-a1c8-b9cc16273e42,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-8832a0bf-b031-4629-a635-4944b97ac756,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-1c64437a-ef85-4c2e-b9de-cb9fbd152ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-106c75ae-0f6a-4d1f-9053-043dee9968ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-1e2d0066-841c-4915-8742-7068a7ff2055,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-7a0480cf-722e-4716-86e0-a9d3a170a97b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91730956-172.17.0.9-1598102582335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42115,DS-61b76bfc-d243-4958-a4ea-82bfe3274a69,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-22f1ce05-0b00-436a-a604-f9be53137e24,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-02df2b0f-3618-48d7-a1c8-b9cc16273e42,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-8832a0bf-b031-4629-a635-4944b97ac756,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-1c64437a-ef85-4c2e-b9de-cb9fbd152ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-106c75ae-0f6a-4d1f-9053-043dee9968ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-1e2d0066-841c-4915-8742-7068a7ff2055,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-7a0480cf-722e-4716-86e0-a9d3a170a97b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139586811-172.17.0.9-1598102822054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40352,DS-9400b92c-d398-4da3-906b-662c680d412f,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-88531b13-bf58-451c-b837-6419cd9e9c51,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-e9ec9238-3973-489d-92fb-4122154ba192,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-a679ca20-fa43-4a56-8e0f-00e1b33105b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-6bca0140-24a9-4fe3-854f-79114290b7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-d7f0790f-5e67-4b7c-91a4-7a3da6013b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-fd4aba11-efb3-4ee8-ba12-f2606383f14b,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-9e6be2c9-32b4-4b44-831c-15024e4896c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139586811-172.17.0.9-1598102822054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40352,DS-9400b92c-d398-4da3-906b-662c680d412f,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-88531b13-bf58-451c-b837-6419cd9e9c51,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-e9ec9238-3973-489d-92fb-4122154ba192,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-a679ca20-fa43-4a56-8e0f-00e1b33105b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-6bca0140-24a9-4fe3-854f-79114290b7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-d7f0790f-5e67-4b7c-91a4-7a3da6013b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-fd4aba11-efb3-4ee8-ba12-f2606383f14b,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-9e6be2c9-32b4-4b44-831c-15024e4896c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977356370-172.17.0.9-1598102893731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36020,DS-c5227226-052d-4d77-bfdd-71e94a75aae9,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-8d6fcb68-06cd-47e1-a2ef-d341421edcff,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-ae06048f-8541-4618-b6a5-650629359e61,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-2ecaebbb-1269-4cd9-b705-874a2f16de2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-6fe862a2-ddb2-45fc-ad53-e1cb5f889741,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-c9946812-ddb0-44d5-8ba0-1e9da9f37363,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-a44900ac-d7d6-443c-8a45-cd9bab84d108,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-31750c06-1d03-4888-b590-21d01def8b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977356370-172.17.0.9-1598102893731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36020,DS-c5227226-052d-4d77-bfdd-71e94a75aae9,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-8d6fcb68-06cd-47e1-a2ef-d341421edcff,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-ae06048f-8541-4618-b6a5-650629359e61,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-2ecaebbb-1269-4cd9-b705-874a2f16de2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-6fe862a2-ddb2-45fc-ad53-e1cb5f889741,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-c9946812-ddb0-44d5-8ba0-1e9da9f37363,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-a44900ac-d7d6-443c-8a45-cd9bab84d108,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-31750c06-1d03-4888-b590-21d01def8b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2122802591-172.17.0.9-1598103196967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45245,DS-d8eebfd4-0265-4aab-888b-3801fd01f4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-1afd4f06-05c1-4cc2-ad2a-11240d0f2fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-7becd1d2-7861-43af-9337-6084b645ad94,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-46ce5f81-8831-445f-97e3-6ee52d00fd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-720cc54e-db57-4671-9461-9aa190519bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-3f0bcaa6-96c7-4bd0-bb01-08e0203d2721,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-cecd3e8c-36fe-47c8-bd37-90d87ff92544,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-fd65f4ac-0fbb-40ec-89af-9c94f0af8a68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2122802591-172.17.0.9-1598103196967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45245,DS-d8eebfd4-0265-4aab-888b-3801fd01f4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-1afd4f06-05c1-4cc2-ad2a-11240d0f2fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-7becd1d2-7861-43af-9337-6084b645ad94,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-46ce5f81-8831-445f-97e3-6ee52d00fd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-720cc54e-db57-4671-9461-9aa190519bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-3f0bcaa6-96c7-4bd0-bb01-08e0203d2721,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-cecd3e8c-36fe-47c8-bd37-90d87ff92544,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-fd65f4ac-0fbb-40ec-89af-9c94f0af8a68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083257739-172.17.0.9-1598103345940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35159,DS-e84d5924-96c2-4ec0-bc99-feabb184e59d,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-e7957422-f718-42ee-9265-f41b47fd7752,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-5c2282d1-f521-4d0a-85cb-1ae5249acc98,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-96521b57-81e8-46fe-9a0d-1094ed9b8d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-ee490562-c322-4830-97fe-3cc024ecf38e,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-f743a65f-71c2-45ba-9529-8d7acde8a71c,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-6657bffd-e3fb-4414-a363-58cf732e71eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-a3bb3c27-3038-4a72-8da4-d9ed9fb11bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083257739-172.17.0.9-1598103345940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35159,DS-e84d5924-96c2-4ec0-bc99-feabb184e59d,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-e7957422-f718-42ee-9265-f41b47fd7752,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-5c2282d1-f521-4d0a-85cb-1ae5249acc98,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-96521b57-81e8-46fe-9a0d-1094ed9b8d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-ee490562-c322-4830-97fe-3cc024ecf38e,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-f743a65f-71c2-45ba-9529-8d7acde8a71c,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-6657bffd-e3fb-4414-a363-58cf732e71eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-a3bb3c27-3038-4a72-8da4-d9ed9fb11bda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96230970-172.17.0.9-1598103914510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39264,DS-41af1891-1a91-402d-999a-fcb716623e24,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-7e74af59-70e6-45f4-b000-a96fdfb97b15,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-86f63bf3-4a2d-4b71-bd0b-f3ef2ed535e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-48a761a4-e410-4c38-91da-a78e5a4c04a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-fa54f64b-4d10-416f-9710-8bc98821e7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-a93310a9-738a-4f1c-aa7d-f219f45cf58f,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-78ec65be-53f1-4fde-a8a4-9c5a70d28ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-ee30876e-fe09-4404-8063-288b924d3814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96230970-172.17.0.9-1598103914510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39264,DS-41af1891-1a91-402d-999a-fcb716623e24,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-7e74af59-70e6-45f4-b000-a96fdfb97b15,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-86f63bf3-4a2d-4b71-bd0b-f3ef2ed535e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-48a761a4-e410-4c38-91da-a78e5a4c04a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-fa54f64b-4d10-416f-9710-8bc98821e7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-a93310a9-738a-4f1c-aa7d-f219f45cf58f,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-78ec65be-53f1-4fde-a8a4-9c5a70d28ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-ee30876e-fe09-4404-8063-288b924d3814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492168258-172.17.0.9-1598104604245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42395,DS-0306a1b6-f489-4327-954f-aed7bd33167c,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-181b0589-72ac-44fd-8f52-0b4d5f586e55,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-256720d3-65cf-4b02-a397-89ddae4aad31,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-67b043db-7f6c-4240-b054-e28426405a22,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-7d498971-9798-4b94-9f66-43da5de60a53,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-7a23a073-cec8-45a2-a4fb-10e4436ea612,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-7c531ede-aee6-4f60-a01f-8cd9dacd4524,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-c4db526d-81df-4745-957f-57bf3c80fd82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492168258-172.17.0.9-1598104604245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42395,DS-0306a1b6-f489-4327-954f-aed7bd33167c,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-181b0589-72ac-44fd-8f52-0b4d5f586e55,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-256720d3-65cf-4b02-a397-89ddae4aad31,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-67b043db-7f6c-4240-b054-e28426405a22,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-7d498971-9798-4b94-9f66-43da5de60a53,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-7a23a073-cec8-45a2-a4fb-10e4436ea612,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-7c531ede-aee6-4f60-a01f-8cd9dacd4524,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-c4db526d-81df-4745-957f-57bf3c80fd82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593055828-172.17.0.9-1598105032948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44261,DS-8d69de62-1204-422b-a8c0-c20604a2aeca,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-abe8db26-fbd5-4c5a-b81e-da45eafc7e88,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-16c74929-bebb-4659-a0d4-a21b999f11b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-ea5995eb-d45f-42a2-88b2-f7856981de66,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-545519c7-310f-4a0a-9c0e-461438b3945f,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-4429d3c8-f758-4caf-8e83-067fa1905b11,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-29ce53bf-a606-4a57-995b-083ef82ac131,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-9c2122c6-7596-436c-b294-4de5b7cf3929,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593055828-172.17.0.9-1598105032948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44261,DS-8d69de62-1204-422b-a8c0-c20604a2aeca,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-abe8db26-fbd5-4c5a-b81e-da45eafc7e88,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-16c74929-bebb-4659-a0d4-a21b999f11b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-ea5995eb-d45f-42a2-88b2-f7856981de66,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-545519c7-310f-4a0a-9c0e-461438b3945f,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-4429d3c8-f758-4caf-8e83-067fa1905b11,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-29ce53bf-a606-4a57-995b-083ef82ac131,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-9c2122c6-7596-436c-b294-4de5b7cf3929,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938362610-172.17.0.9-1598105617891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45789,DS-b9306f48-17ec-42dc-ba41-38ea25f5aaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-ea3d1ae8-7361-4621-839f-05b359718cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-41df4d62-41be-4a83-968e-9780c6fa8b00,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-ec29d865-1d48-48a5-bfa8-8f85258ccaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-8c2279b7-a376-48c9-836a-826adcaeef7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-bcc3c810-4465-4829-8886-4126c8384cef,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-8d42c107-021b-40cf-be6f-d8693ba4adff,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-3377c38e-d203-42ac-9094-dad28d5d12a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938362610-172.17.0.9-1598105617891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45789,DS-b9306f48-17ec-42dc-ba41-38ea25f5aaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-ea3d1ae8-7361-4621-839f-05b359718cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-41df4d62-41be-4a83-968e-9780c6fa8b00,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-ec29d865-1d48-48a5-bfa8-8f85258ccaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-8c2279b7-a376-48c9-836a-826adcaeef7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-bcc3c810-4465-4829-8886-4126c8384cef,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-8d42c107-021b-40cf-be6f-d8693ba4adff,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-3377c38e-d203-42ac-9094-dad28d5d12a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632743060-172.17.0.9-1598105762277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46229,DS-de98f630-fcf4-420c-819f-40a4d3ee82f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-780c2133-3240-4daa-a0e8-5335fe69e62b,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-57520826-64fc-4d47-a24b-1256f8aca92a,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-83bf6124-fefe-4291-b70b-5f3ac8592d36,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-6f369aed-30c3-4343-8536-fbe839654471,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-adaaede7-d9c7-43d8-83a9-06081c4ac7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-06dbc220-8e96-4003-8aaf-5e39bf6ca580,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-2e400f94-21f9-45a1-bcfd-52caa54bd2c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632743060-172.17.0.9-1598105762277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46229,DS-de98f630-fcf4-420c-819f-40a4d3ee82f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-780c2133-3240-4daa-a0e8-5335fe69e62b,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-57520826-64fc-4d47-a24b-1256f8aca92a,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-83bf6124-fefe-4291-b70b-5f3ac8592d36,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-6f369aed-30c3-4343-8536-fbe839654471,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-adaaede7-d9c7-43d8-83a9-06081c4ac7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-06dbc220-8e96-4003-8aaf-5e39bf6ca580,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-2e400f94-21f9-45a1-bcfd-52caa54bd2c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295118553-172.17.0.9-1598105841333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44891,DS-8c5427a3-11bb-4cbb-b0fe-9f1e6e1bc171,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-0c0e4810-fdfa-477a-9d10-079f95a66ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-34431554-a6c3-47cb-9841-24efcf865bda,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-b14b6786-c331-4a66-a464-a5b536735b29,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-cbda2064-b08e-4d7f-b38a-91d3f42c5335,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-9667e5b4-2936-4088-b11f-d884d92430cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-65f7e2c4-c677-4621-bb65-cf9b1778e21a,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-52dd54d1-5537-4919-9a16-aa8b71e36a02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295118553-172.17.0.9-1598105841333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44891,DS-8c5427a3-11bb-4cbb-b0fe-9f1e6e1bc171,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-0c0e4810-fdfa-477a-9d10-079f95a66ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-34431554-a6c3-47cb-9841-24efcf865bda,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-b14b6786-c331-4a66-a464-a5b536735b29,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-cbda2064-b08e-4d7f-b38a-91d3f42c5335,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-9667e5b4-2936-4088-b11f-d884d92430cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-65f7e2c4-c677-4621-bb65-cf9b1778e21a,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-52dd54d1-5537-4919-9a16-aa8b71e36a02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522403256-172.17.0.9-1598106099631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44276,DS-e1fc12e7-ea3e-4c85-80f4-13969582234a,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-f7a8d90a-d98d-4d6f-b5c6-5fbeb2b66bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-a53f6035-fa06-423f-8e46-fe44573594b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-e86444b6-e7c9-4084-a65e-4d034f04d82a,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-7f635793-9c15-49a3-9e29-1ae3aea533a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-46740417-ed0f-4bda-a686-a0e410c1e4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-b6b16b86-1e1a-4169-867f-125389df2859,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-88eea4fa-acfc-4662-b6be-023563cd5d71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522403256-172.17.0.9-1598106099631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44276,DS-e1fc12e7-ea3e-4c85-80f4-13969582234a,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-f7a8d90a-d98d-4d6f-b5c6-5fbeb2b66bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-a53f6035-fa06-423f-8e46-fe44573594b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-e86444b6-e7c9-4084-a65e-4d034f04d82a,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-7f635793-9c15-49a3-9e29-1ae3aea533a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-46740417-ed0f-4bda-a686-a0e410c1e4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-b6b16b86-1e1a-4169-867f-125389df2859,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-88eea4fa-acfc-4662-b6be-023563cd5d71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964957814-172.17.0.9-1598106251828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35107,DS-492eb989-9b05-4ac9-8506-9fcf6d20971f,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-9dd50cbc-33b3-4df9-8408-2cfb925d276d,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-505cfed9-dfc6-4ace-b937-0392c56ed8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-74a04719-2557-4b8b-a124-7d55a77e62ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-8f2024f8-9437-4c25-8f31-b97bc5c5735f,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-6832fe33-ba41-4c51-9f2b-1abf07d7ddd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-1e3ec102-eb65-4419-b0e5-e1bbc6951bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-597f2fe3-f1d4-4ea4-9340-59e5b92d7642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964957814-172.17.0.9-1598106251828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35107,DS-492eb989-9b05-4ac9-8506-9fcf6d20971f,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-9dd50cbc-33b3-4df9-8408-2cfb925d276d,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-505cfed9-dfc6-4ace-b937-0392c56ed8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-74a04719-2557-4b8b-a124-7d55a77e62ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-8f2024f8-9437-4c25-8f31-b97bc5c5735f,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-6832fe33-ba41-4c51-9f2b-1abf07d7ddd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-1e3ec102-eb65-4419-b0e5-e1bbc6951bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-597f2fe3-f1d4-4ea4-9340-59e5b92d7642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016059752-172.17.0.9-1598106365762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40145,DS-40a03347-87c0-4faf-b519-ac4a178f3bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-5ae79229-df60-40bd-bfed-51dd99f06e41,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-6be02bc5-f9e8-4182-89f8-6f092e9d1b09,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-7811d248-c257-4cf2-9118-257f5a78b3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-0951b1e2-6960-44c6-a475-1435d90139e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-3e1bcb3f-af54-4ea5-81cd-80ac7b245ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-5d5db644-0c84-4f80-b879-2358d4bdfa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-de219cfe-b08e-41fd-9dcb-dd4e2d2d7271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016059752-172.17.0.9-1598106365762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40145,DS-40a03347-87c0-4faf-b519-ac4a178f3bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-5ae79229-df60-40bd-bfed-51dd99f06e41,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-6be02bc5-f9e8-4182-89f8-6f092e9d1b09,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-7811d248-c257-4cf2-9118-257f5a78b3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-0951b1e2-6960-44c6-a475-1435d90139e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-3e1bcb3f-af54-4ea5-81cd-80ac7b245ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-5d5db644-0c84-4f80-b879-2358d4bdfa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-de219cfe-b08e-41fd-9dcb-dd4e2d2d7271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716428551-172.17.0.9-1598106402109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41953,DS-2d5a40df-8b9a-4079-afff-12eb52498a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-a5e0a498-4dc3-410c-98c5-bd7428abdac8,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-5f28dfd6-7d4f-459d-aac2-e4cbce668d65,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-1bc665e2-e049-487e-8acb-a96dabb1d1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-400a6943-1f6e-43bc-a91b-58f3bb34e89a,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-96067042-9726-4d06-834b-e957cef532a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-f18e64be-5e14-42ec-b9c5-3aa87d306156,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-cadcf9b2-a734-460a-a156-033ac071fbde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716428551-172.17.0.9-1598106402109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41953,DS-2d5a40df-8b9a-4079-afff-12eb52498a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-a5e0a498-4dc3-410c-98c5-bd7428abdac8,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-5f28dfd6-7d4f-459d-aac2-e4cbce668d65,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-1bc665e2-e049-487e-8acb-a96dabb1d1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-400a6943-1f6e-43bc-a91b-58f3bb34e89a,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-96067042-9726-4d06-834b-e957cef532a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-f18e64be-5e14-42ec-b9c5-3aa87d306156,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-cadcf9b2-a734-460a-a156-033ac071fbde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527415268-172.17.0.9-1598106811480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42237,DS-92256600-db3d-4746-9d1f-291c1a575c05,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-995f9181-f81f-48dc-9a7e-90466c14df2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-14ec8312-8da9-46f5-899e-8626d04c59eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-3428cb02-0f48-4459-a5a4-f4fe15154edb,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-a2e29231-3317-4f61-98a1-c17849a867fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-52b0fe2b-04b7-43ba-8660-57318be13d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-e2d9cee0-d7c2-4546-a29b-8b44c6a030ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-ec406b1f-9545-45b6-829e-30bc0c241e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527415268-172.17.0.9-1598106811480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42237,DS-92256600-db3d-4746-9d1f-291c1a575c05,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-995f9181-f81f-48dc-9a7e-90466c14df2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-14ec8312-8da9-46f5-899e-8626d04c59eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-3428cb02-0f48-4459-a5a4-f4fe15154edb,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-a2e29231-3317-4f61-98a1-c17849a867fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-52b0fe2b-04b7-43ba-8660-57318be13d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-e2d9cee0-d7c2-4546-a29b-8b44c6a030ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-ec406b1f-9545-45b6-829e-30bc0c241e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565781299-172.17.0.9-1598107719275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43441,DS-3e2bccf6-66d1-41ec-987d-ab1f25754e28,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-63cd62d9-8020-4b22-8a11-c549bd68b9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-4a6f952a-d942-44f4-8614-04342d40fb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-aabf330a-134e-4bba-9ebc-6eb27fc0172f,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-20fd110c-0ee9-4753-be20-0749b89818c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-0eceb30e-5be5-4d9f-9842-d4af27f8a75d,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-65adbef8-c683-47ac-96f4-1d2d68c72bad,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-e441e675-7105-4cf3-ba91-68b9faa7d6ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565781299-172.17.0.9-1598107719275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43441,DS-3e2bccf6-66d1-41ec-987d-ab1f25754e28,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-63cd62d9-8020-4b22-8a11-c549bd68b9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-4a6f952a-d942-44f4-8614-04342d40fb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-aabf330a-134e-4bba-9ebc-6eb27fc0172f,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-20fd110c-0ee9-4753-be20-0749b89818c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-0eceb30e-5be5-4d9f-9842-d4af27f8a75d,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-65adbef8-c683-47ac-96f4-1d2d68c72bad,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-e441e675-7105-4cf3-ba91-68b9faa7d6ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5579
