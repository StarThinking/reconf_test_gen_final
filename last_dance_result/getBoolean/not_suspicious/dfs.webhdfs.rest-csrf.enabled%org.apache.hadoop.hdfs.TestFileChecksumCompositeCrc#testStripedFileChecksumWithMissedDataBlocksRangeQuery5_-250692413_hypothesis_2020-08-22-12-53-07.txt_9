reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839097133-172.17.0.8-1598100800985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40965,DS-9c44a661-3921-4ec7-baa5-09388ee0b737,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-6e9a6167-8ed5-451b-b9cc-476fccb1a3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-4ff5e771-87bb-4200-a6f0-68fda5619f97,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-d03305e7-0462-4fa0-b8bc-009c6c13125a,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-df7ff7f0-f1ff-4d6d-9dc5-30f592d3ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-0aa656bc-79e7-437d-b1b0-5a4d13df07b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-caa1d478-1f8f-4ae4-9bd0-8d43176c44db,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-1dd640bd-f32f-4736-aa39-6a005a13fc6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839097133-172.17.0.8-1598100800985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40965,DS-9c44a661-3921-4ec7-baa5-09388ee0b737,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-6e9a6167-8ed5-451b-b9cc-476fccb1a3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-4ff5e771-87bb-4200-a6f0-68fda5619f97,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-d03305e7-0462-4fa0-b8bc-009c6c13125a,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-df7ff7f0-f1ff-4d6d-9dc5-30f592d3ca7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-0aa656bc-79e7-437d-b1b0-5a4d13df07b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-caa1d478-1f8f-4ae4-9bd0-8d43176c44db,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-1dd640bd-f32f-4736-aa39-6a005a13fc6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028421001-172.17.0.8-1598101004128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35218,DS-6be696ac-fc00-4204-8316-8cb3d39272d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-bae3db04-03dd-4ed9-b232-403b6ccdcd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-c0661f61-4773-417b-b16e-2de2e0298fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-47f70001-dde3-48cf-bd6c-da6da4f6d6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-78b3105f-a4c3-42c6-a06f-3c4b801f95fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-9827b1e4-c7d8-43f9-9ae6-563059ade3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-4c15cfcf-2efd-43c0-b91e-f1769c975397,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-1cdd16e1-5f9b-4c37-82ff-f4e6ada887bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028421001-172.17.0.8-1598101004128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35218,DS-6be696ac-fc00-4204-8316-8cb3d39272d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-bae3db04-03dd-4ed9-b232-403b6ccdcd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-c0661f61-4773-417b-b16e-2de2e0298fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-47f70001-dde3-48cf-bd6c-da6da4f6d6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-78b3105f-a4c3-42c6-a06f-3c4b801f95fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-9827b1e4-c7d8-43f9-9ae6-563059ade3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-4c15cfcf-2efd-43c0-b91e-f1769c975397,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-1cdd16e1-5f9b-4c37-82ff-f4e6ada887bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584079026-172.17.0.8-1598101045336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38385,DS-ed6bc35e-c036-40a5-8d0b-e07188075825,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-f5685aaa-5320-4ab1-9791-fb8e231b16a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-b83c136e-25f9-491f-8b71-d774b68f0360,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-55bc9160-7c2d-425d-b2d0-dc42a0a992c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-4d08eca7-bbba-4df2-9200-7c89f10e5aea,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-3ef6e829-15a3-4cb8-945a-8ab7b63ab67e,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-a0ba8a5e-9c33-4f3b-acd4-48b51abc9a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-8d2374a6-2d1b-485a-8cf7-22f55c7c465e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584079026-172.17.0.8-1598101045336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38385,DS-ed6bc35e-c036-40a5-8d0b-e07188075825,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-f5685aaa-5320-4ab1-9791-fb8e231b16a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-b83c136e-25f9-491f-8b71-d774b68f0360,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-55bc9160-7c2d-425d-b2d0-dc42a0a992c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-4d08eca7-bbba-4df2-9200-7c89f10e5aea,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-3ef6e829-15a3-4cb8-945a-8ab7b63ab67e,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-a0ba8a5e-9c33-4f3b-acd4-48b51abc9a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-8d2374a6-2d1b-485a-8cf7-22f55c7c465e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080393053-172.17.0.8-1598101523777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38097,DS-c33a45ee-b793-4fe0-a24e-c093cb3a3ece,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-fe31f8a8-280d-467b-a083-5b5a748cf6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-1feaa8c5-ec4c-42e7-a322-ff87add228c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-af2567fa-4559-427a-a00b-90ef038fdea2,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-306af407-527e-47d6-945c-e6fe79d6faee,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-bbe59111-eb36-4df7-b5e6-19f1af43966a,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-c73e53b5-ef15-4554-9eff-56558416b01e,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-55053160-1576-4733-ad96-dab839d2b4a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080393053-172.17.0.8-1598101523777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38097,DS-c33a45ee-b793-4fe0-a24e-c093cb3a3ece,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-fe31f8a8-280d-467b-a083-5b5a748cf6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-1feaa8c5-ec4c-42e7-a322-ff87add228c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-af2567fa-4559-427a-a00b-90ef038fdea2,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-306af407-527e-47d6-945c-e6fe79d6faee,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-bbe59111-eb36-4df7-b5e6-19f1af43966a,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-c73e53b5-ef15-4554-9eff-56558416b01e,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-55053160-1576-4733-ad96-dab839d2b4a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39198063-172.17.0.8-1598101559765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40576,DS-fb7b2605-1c5a-4084-bc8b-7483ad1329ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-33ae1a9d-6f74-4893-b824-b6ee80eba958,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-2dcd8c98-fb11-4200-aebc-e57dad54d3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-b6158424-09f6-4c70-a354-f76a672d0c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-c60eacf2-4cf5-4894-9bce-111277199ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-25df5652-0cbd-4f0a-abb0-358c4aa2dfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-4c8f52bc-36b1-4ad9-9c21-91f9c792aa65,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-f352d6aa-25a9-42fb-81ac-76b00b709275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39198063-172.17.0.8-1598101559765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40576,DS-fb7b2605-1c5a-4084-bc8b-7483ad1329ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-33ae1a9d-6f74-4893-b824-b6ee80eba958,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-2dcd8c98-fb11-4200-aebc-e57dad54d3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-b6158424-09f6-4c70-a354-f76a672d0c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-c60eacf2-4cf5-4894-9bce-111277199ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-25df5652-0cbd-4f0a-abb0-358c4aa2dfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-4c8f52bc-36b1-4ad9-9c21-91f9c792aa65,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-f352d6aa-25a9-42fb-81ac-76b00b709275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821795266-172.17.0.8-1598101739057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-7753ff47-1ee7-4502-b5ae-c5c78c12d261,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-7bfce619-1482-44a3-bbb5-60be0c7302a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-bac75171-49c6-4c1b-bc25-cc01704c8f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-9b08da04-4232-4285-935b-d8ad66f50f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-bf9946cb-0f14-40c0-8dcc-e1cb6b89f648,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-fca1837b-a625-43ea-b6ce-e02b2eca6838,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-a7b48cd5-3d8f-448a-8425-2ec444cb54a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-2d42a931-68c1-4c05-9b74-95639dbe4d8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821795266-172.17.0.8-1598101739057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-7753ff47-1ee7-4502-b5ae-c5c78c12d261,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-7bfce619-1482-44a3-bbb5-60be0c7302a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-bac75171-49c6-4c1b-bc25-cc01704c8f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-9b08da04-4232-4285-935b-d8ad66f50f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-bf9946cb-0f14-40c0-8dcc-e1cb6b89f648,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-fca1837b-a625-43ea-b6ce-e02b2eca6838,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-a7b48cd5-3d8f-448a-8425-2ec444cb54a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-2d42a931-68c1-4c05-9b74-95639dbe4d8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85811041-172.17.0.8-1598102276749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46215,DS-abcce47c-a141-4d86-bae3-4fff1f9aa710,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-f239d521-8b72-4d6e-8e33-1dc6de6f4f21,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-17caea1c-9add-4a73-91ad-8f4ad18f05a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-ac14cbfe-23f4-471e-8d42-905bd79afcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-f984d620-4840-4a22-986f-bd4ecfcaa068,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-f96c0143-6396-4afb-81ca-22fe447dfa12,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-5d0f448b-1601-4f64-a9b2-65d8a8d370e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-0a84662e-2e5f-476d-8338-95e5a97e4c8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85811041-172.17.0.8-1598102276749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46215,DS-abcce47c-a141-4d86-bae3-4fff1f9aa710,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-f239d521-8b72-4d6e-8e33-1dc6de6f4f21,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-17caea1c-9add-4a73-91ad-8f4ad18f05a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-ac14cbfe-23f4-471e-8d42-905bd79afcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-f984d620-4840-4a22-986f-bd4ecfcaa068,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-f96c0143-6396-4afb-81ca-22fe447dfa12,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-5d0f448b-1601-4f64-a9b2-65d8a8d370e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-0a84662e-2e5f-476d-8338-95e5a97e4c8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046134515-172.17.0.8-1598103031485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34418,DS-a805aa8b-78f1-403f-bb0b-0b795a48c518,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-829dd8bf-48c5-46ef-9821-d2b2d7a8c34c,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-834de2bc-702f-42ff-ae00-86edaf003cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-9bd0f375-67c9-46ca-9635-7763b4bea0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-005de8aa-c7a7-4593-acf1-db888200989b,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-fbdf6545-069f-4f24-b51f-74833e48cfbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-4bb216c0-0c16-4d18-9ea0-f2a21f5a3591,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-99a295c9-258c-47be-9fc2-b300d646bf5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046134515-172.17.0.8-1598103031485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34418,DS-a805aa8b-78f1-403f-bb0b-0b795a48c518,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-829dd8bf-48c5-46ef-9821-d2b2d7a8c34c,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-834de2bc-702f-42ff-ae00-86edaf003cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-9bd0f375-67c9-46ca-9635-7763b4bea0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-005de8aa-c7a7-4593-acf1-db888200989b,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-fbdf6545-069f-4f24-b51f-74833e48cfbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-4bb216c0-0c16-4d18-9ea0-f2a21f5a3591,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-99a295c9-258c-47be-9fc2-b300d646bf5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211210506-172.17.0.8-1598103446190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40541,DS-f1499737-6826-42b5-af4a-e2266559dd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-2ffa0d43-9c36-4e6c-979a-981391b7f0be,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-550108d7-d483-4cec-b45d-7aacde4b0c89,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-f9a0fe41-cce1-4db9-bd0a-f6601a92e6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-3dbfa042-a84d-4849-ac00-6e50405bd7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-dec5eeea-a3dc-4f9f-af44-c72370606d69,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-6fc126c4-4135-46ce-924a-011d1277138b,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-90d46f07-1c0b-4467-bc7b-651d3e5b43d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211210506-172.17.0.8-1598103446190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40541,DS-f1499737-6826-42b5-af4a-e2266559dd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-2ffa0d43-9c36-4e6c-979a-981391b7f0be,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-550108d7-d483-4cec-b45d-7aacde4b0c89,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-f9a0fe41-cce1-4db9-bd0a-f6601a92e6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-3dbfa042-a84d-4849-ac00-6e50405bd7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-dec5eeea-a3dc-4f9f-af44-c72370606d69,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-6fc126c4-4135-46ce-924a-011d1277138b,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-90d46f07-1c0b-4467-bc7b-651d3e5b43d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022932486-172.17.0.8-1598103480119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41069,DS-49bcb1ee-76f1-48de-bb47-acf6b4c04436,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-df77bd7c-9959-44e8-8713-91415a6a31de,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-64edd82c-d4e7-4f37-852a-f953a5eca617,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-27c48f55-fb49-45e6-8f98-e5b465e98827,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-c5dfc33b-4c07-4c38-8315-b237dc219026,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-c35916e4-d782-44cb-a937-9ba978285c66,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-946b10e9-1f74-43cd-ae34-28dd1a718b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-a20a15d9-ad03-4a35-8bd1-e13686de707b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022932486-172.17.0.8-1598103480119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41069,DS-49bcb1ee-76f1-48de-bb47-acf6b4c04436,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-df77bd7c-9959-44e8-8713-91415a6a31de,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-64edd82c-d4e7-4f37-852a-f953a5eca617,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-27c48f55-fb49-45e6-8f98-e5b465e98827,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-c5dfc33b-4c07-4c38-8315-b237dc219026,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-c35916e4-d782-44cb-a937-9ba978285c66,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-946b10e9-1f74-43cd-ae34-28dd1a718b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-a20a15d9-ad03-4a35-8bd1-e13686de707b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1018958452-172.17.0.8-1598103737950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34056,DS-3624093d-ddd6-41d5-ab95-327f17502dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-348cb2e7-4450-4783-a877-60c08a9bdae5,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-fbb1f5be-14e7-4fb3-a53f-63d9a10e457a,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-4ea312a2-824f-4d72-87d7-d668dee74317,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-a81585e6-7027-40fc-8975-9ab6765a606c,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-47e3a1f0-70e6-466b-9b23-e7ac26d15eda,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-ee2af1fa-d64c-429a-a4ee-d0d112bd3e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-6aea77b8-ccba-48ad-b75f-c5ce7d9c5669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1018958452-172.17.0.8-1598103737950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34056,DS-3624093d-ddd6-41d5-ab95-327f17502dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-348cb2e7-4450-4783-a877-60c08a9bdae5,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-fbb1f5be-14e7-4fb3-a53f-63d9a10e457a,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-4ea312a2-824f-4d72-87d7-d668dee74317,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-a81585e6-7027-40fc-8975-9ab6765a606c,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-47e3a1f0-70e6-466b-9b23-e7ac26d15eda,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-ee2af1fa-d64c-429a-a4ee-d0d112bd3e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-6aea77b8-ccba-48ad-b75f-c5ce7d9c5669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050646336-172.17.0.8-1598104252304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37442,DS-a739686c-7988-46ce-b977-88a9be16d7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-4ea406f0-11aa-4ffe-bcd6-5c523ba218f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-b0038632-cecc-4456-99cb-b79045da54ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-a33e5677-c1a8-4f77-a4c8-a18b7431487b,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-79da9f05-5e4b-40e9-a46d-31140ee44854,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-83a06c5f-5810-4775-b988-0fca19f20b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-16b95c8a-c4ab-4780-b80e-e10b1ffa3d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-9389f563-824b-46db-814e-cd321046dc7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050646336-172.17.0.8-1598104252304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37442,DS-a739686c-7988-46ce-b977-88a9be16d7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-4ea406f0-11aa-4ffe-bcd6-5c523ba218f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-b0038632-cecc-4456-99cb-b79045da54ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-a33e5677-c1a8-4f77-a4c8-a18b7431487b,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-79da9f05-5e4b-40e9-a46d-31140ee44854,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-83a06c5f-5810-4775-b988-0fca19f20b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-16b95c8a-c4ab-4780-b80e-e10b1ffa3d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-9389f563-824b-46db-814e-cd321046dc7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093769076-172.17.0.8-1598104895435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40723,DS-4e11fdfb-ced2-4e7f-8a4a-d89974fd34eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-fc7c3b02-b2a3-49df-8ef7-cd8c069fe7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-8ed66f56-b6f8-46f4-b9b9-d6b9f1a94375,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-96ba4b97-2cfd-4f73-9ce1-18ef83ce8a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-1025dd4a-9680-4012-90ff-52d4be5c9993,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-36acf1fb-278b-4853-abdf-d905087ae747,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-771ebfe6-c23a-4e25-9f13-542afb808b91,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-669a521c-4033-4e65-be27-ccf3332368a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093769076-172.17.0.8-1598104895435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40723,DS-4e11fdfb-ced2-4e7f-8a4a-d89974fd34eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-fc7c3b02-b2a3-49df-8ef7-cd8c069fe7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-8ed66f56-b6f8-46f4-b9b9-d6b9f1a94375,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-96ba4b97-2cfd-4f73-9ce1-18ef83ce8a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-1025dd4a-9680-4012-90ff-52d4be5c9993,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-36acf1fb-278b-4853-abdf-d905087ae747,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-771ebfe6-c23a-4e25-9f13-542afb808b91,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-669a521c-4033-4e65-be27-ccf3332368a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393609492-172.17.0.8-1598105066842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36700,DS-95bde42b-3e78-492b-82e7-85868b8b7213,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-c2f0294c-814d-4178-8ea4-ee2151c06252,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-6b5b3ea6-dab7-40bf-8b03-8ab2ec2f6c15,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-022ad2c7-a530-401b-9b77-81ca001f4e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-6b539c50-1011-4d83-8951-d8fcdc43690c,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-e457b759-7066-4901-bf15-a1df47c0f4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-3ee27ce7-43e8-435f-a24a-d7e0525de718,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-bddc2c90-e673-4917-be8c-be185ae5df81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393609492-172.17.0.8-1598105066842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36700,DS-95bde42b-3e78-492b-82e7-85868b8b7213,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-c2f0294c-814d-4178-8ea4-ee2151c06252,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-6b5b3ea6-dab7-40bf-8b03-8ab2ec2f6c15,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-022ad2c7-a530-401b-9b77-81ca001f4e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-6b539c50-1011-4d83-8951-d8fcdc43690c,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-e457b759-7066-4901-bf15-a1df47c0f4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-3ee27ce7-43e8-435f-a24a-d7e0525de718,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-bddc2c90-e673-4917-be8c-be185ae5df81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742923593-172.17.0.8-1598105305795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44585,DS-b2ac4a41-8c1e-48fa-a475-1170be7db344,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-5dbd0b8a-bc1c-48f4-b70c-38e022e47209,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-1ddbe533-4ede-4d87-a1a7-43ca14424e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-8d0fc566-60dd-469d-9e50-71a6e07dbb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-79e7b273-ce77-4dd4-be81-64d4e3dd37db,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-4dd91799-6a8d-4e9d-b299-93d2f7bfcf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-0cf1c983-bf73-4c6f-8bb9-1d33479aa49e,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-a63d1425-b3c7-4856-9be9-42b2b7ec44c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742923593-172.17.0.8-1598105305795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44585,DS-b2ac4a41-8c1e-48fa-a475-1170be7db344,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-5dbd0b8a-bc1c-48f4-b70c-38e022e47209,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-1ddbe533-4ede-4d87-a1a7-43ca14424e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-8d0fc566-60dd-469d-9e50-71a6e07dbb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-79e7b273-ce77-4dd4-be81-64d4e3dd37db,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-4dd91799-6a8d-4e9d-b299-93d2f7bfcf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-0cf1c983-bf73-4c6f-8bb9-1d33479aa49e,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-a63d1425-b3c7-4856-9be9-42b2b7ec44c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941832877-172.17.0.8-1598105482645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43850,DS-cf624db6-349f-436a-9742-b59835e26921,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-0ea1ebbc-c686-4790-8110-9dee9f0af5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-336dff18-e28c-417f-8143-55d25939c90f,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-6761ca52-bdf1-4a47-b714-bc6231e9f2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-fcb2cb1e-b407-4a94-bbb0-20cf3de2ac57,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-c6f2c321-88f2-4f7e-9c39-0c1b40a0c020,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-4084d99f-b4ac-41d0-8118-5dbc4b27dab7,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-f0e9a518-8d91-4a05-9913-8edea17af9aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941832877-172.17.0.8-1598105482645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43850,DS-cf624db6-349f-436a-9742-b59835e26921,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-0ea1ebbc-c686-4790-8110-9dee9f0af5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-336dff18-e28c-417f-8143-55d25939c90f,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-6761ca52-bdf1-4a47-b714-bc6231e9f2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-fcb2cb1e-b407-4a94-bbb0-20cf3de2ac57,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-c6f2c321-88f2-4f7e-9c39-0c1b40a0c020,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-4084d99f-b4ac-41d0-8118-5dbc4b27dab7,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-f0e9a518-8d91-4a05-9913-8edea17af9aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324474355-172.17.0.8-1598105576551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45005,DS-1cc56c84-3594-4a53-b55f-422a9e2622bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-138c47bf-f864-4657-b95c-3f3baf653a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-a90b113d-fbd2-432d-85c1-c065cd564fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-bf40585b-f712-4417-8c66-bce261315481,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-2d3b310e-94c3-45fc-9345-549c8b66a3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-2db5b256-814d-4fd4-b36a-8b9ba64aca78,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-6015fd1b-875e-446e-9197-3521a6f8c091,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-7d86053b-80cd-4931-a9b5-c3b2eae1fee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324474355-172.17.0.8-1598105576551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45005,DS-1cc56c84-3594-4a53-b55f-422a9e2622bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-138c47bf-f864-4657-b95c-3f3baf653a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-a90b113d-fbd2-432d-85c1-c065cd564fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-bf40585b-f712-4417-8c66-bce261315481,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-2d3b310e-94c3-45fc-9345-549c8b66a3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-2db5b256-814d-4fd4-b36a-8b9ba64aca78,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-6015fd1b-875e-446e-9197-3521a6f8c091,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-7d86053b-80cd-4931-a9b5-c3b2eae1fee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541525374-172.17.0.8-1598105682402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34335,DS-e5fb0a9a-c845-448d-b294-adad8de457fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-04ca4c47-2cb4-481d-b5fa-bc815435b88a,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-9e8ca71a-6a0e-40a5-a665-61a4e9820238,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-e3bc2385-25af-4acb-82ad-71d7695ead2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-5309655e-1c21-4246-8724-12ca57e3d1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-6b3d6dd5-da3c-4eef-8175-da7d76e8cec7,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-bde11eb0-b53d-4bf1-b1ed-dc19673f76c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-bda66f50-74ac-4b7a-8f97-79cac878d344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541525374-172.17.0.8-1598105682402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34335,DS-e5fb0a9a-c845-448d-b294-adad8de457fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-04ca4c47-2cb4-481d-b5fa-bc815435b88a,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-9e8ca71a-6a0e-40a5-a665-61a4e9820238,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-e3bc2385-25af-4acb-82ad-71d7695ead2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-5309655e-1c21-4246-8724-12ca57e3d1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-6b3d6dd5-da3c-4eef-8175-da7d76e8cec7,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-bde11eb0-b53d-4bf1-b1ed-dc19673f76c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-bda66f50-74ac-4b7a-8f97-79cac878d344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651382468-172.17.0.8-1598105717084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40094,DS-ffc5f309-a21f-47aa-b379-e99d2c05550a,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-1ad550c6-0bc4-4b91-a875-7fc83f13bb20,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-1e732194-0022-4469-89d9-e619ca9d34a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-b96524ab-e6e0-47c2-8f27-e12320903bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-a4507b2a-4048-48e4-bbd6-b8d69d1d1687,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-c9c78f62-9ed2-454c-ac87-7227ce46457b,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-7111c404-f7cc-4154-ba46-0992d2c4eba8,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-2250c007-d509-469c-87f8-72ed62528256,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1651382468-172.17.0.8-1598105717084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40094,DS-ffc5f309-a21f-47aa-b379-e99d2c05550a,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-1ad550c6-0bc4-4b91-a875-7fc83f13bb20,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-1e732194-0022-4469-89d9-e619ca9d34a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-b96524ab-e6e0-47c2-8f27-e12320903bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-a4507b2a-4048-48e4-bbd6-b8d69d1d1687,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-c9c78f62-9ed2-454c-ac87-7227ce46457b,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-7111c404-f7cc-4154-ba46-0992d2c4eba8,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-2250c007-d509-469c-87f8-72ed62528256,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565594680-172.17.0.8-1598105979039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39780,DS-1c13c90c-c5d8-4656-9387-9c3a6f3aa035,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-5092d87e-107a-4540-8482-a89fddb00294,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-33355bba-76b3-4e31-ab3e-d1289ae65276,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-2bdbabb8-dd5e-48c9-aaad-0223f30184bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-cc45cfa7-10c3-42cf-a7d1-331eb44fa41a,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-5ef4c0a2-0b5e-41d0-aeb3-2856a11c99b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-5d6f94f1-0fc0-47f5-9463-c52fd9f438f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-45accdf8-d577-499b-9c36-562451071401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565594680-172.17.0.8-1598105979039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39780,DS-1c13c90c-c5d8-4656-9387-9c3a6f3aa035,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-5092d87e-107a-4540-8482-a89fddb00294,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-33355bba-76b3-4e31-ab3e-d1289ae65276,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-2bdbabb8-dd5e-48c9-aaad-0223f30184bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-cc45cfa7-10c3-42cf-a7d1-331eb44fa41a,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-5ef4c0a2-0b5e-41d0-aeb3-2856a11c99b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-5d6f94f1-0fc0-47f5-9463-c52fd9f438f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-45accdf8-d577-499b-9c36-562451071401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 5295
