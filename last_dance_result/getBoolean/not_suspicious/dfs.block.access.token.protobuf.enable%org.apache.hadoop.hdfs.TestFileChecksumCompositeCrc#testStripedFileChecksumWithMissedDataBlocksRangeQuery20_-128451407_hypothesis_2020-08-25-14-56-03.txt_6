reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1628240971-172.17.0.8-1598367703670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33745,DS-41b32183-db15-414e-bf38-2a8d9a6749b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-e56b52c0-acef-464d-9d13-b9c2ec5d2989,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-f501cefb-6f41-4957-98ac-a22fe56aca87,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-292e7e3a-579e-4072-aba6-a4cd01c1b96d,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-1acb84e0-f063-4308-91ed-b6a2b42e9cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-987dabd1-829f-49d3-8d3f-d81f535c3d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-5c74c0d6-18db-4ed4-8455-eb42664cbeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-58212614-8f69-4971-9481-974e39779e84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1628240971-172.17.0.8-1598367703670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33745,DS-41b32183-db15-414e-bf38-2a8d9a6749b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-e56b52c0-acef-464d-9d13-b9c2ec5d2989,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-f501cefb-6f41-4957-98ac-a22fe56aca87,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-292e7e3a-579e-4072-aba6-a4cd01c1b96d,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-1acb84e0-f063-4308-91ed-b6a2b42e9cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-987dabd1-829f-49d3-8d3f-d81f535c3d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-5c74c0d6-18db-4ed4-8455-eb42664cbeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-58212614-8f69-4971-9481-974e39779e84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271483986-172.17.0.8-1598367772575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34568,DS-09aac37e-f596-4b5d-83e3-63144cdf0f96,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-4ee75223-c7d2-4f7b-8941-ff56288e57a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-b916f7a0-32c1-4c5f-b238-a77c002d2279,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-394756bb-6558-48cc-829b-cc827b6e94cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-ed96d10d-3894-4797-8a1b-cf27af2d3cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-32f6e7db-c7e1-44c6-9324-be6cc4b8e1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-53ab8c16-e8d4-4df9-b681-8ee9d67138f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-a297ad9e-41b2-4dce-bdc8-cc07751e2790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271483986-172.17.0.8-1598367772575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34568,DS-09aac37e-f596-4b5d-83e3-63144cdf0f96,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-4ee75223-c7d2-4f7b-8941-ff56288e57a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-b916f7a0-32c1-4c5f-b238-a77c002d2279,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-394756bb-6558-48cc-829b-cc827b6e94cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-ed96d10d-3894-4797-8a1b-cf27af2d3cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-32f6e7db-c7e1-44c6-9324-be6cc4b8e1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-53ab8c16-e8d4-4df9-b681-8ee9d67138f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-a297ad9e-41b2-4dce-bdc8-cc07751e2790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607448717-172.17.0.8-1598367878860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42952,DS-a74f1630-e806-4d10-b3a1-d2a0225c54c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-bdb05982-13e9-4d7d-bc26-40de9fb747ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-c28ad25b-fea3-4ed3-a0af-f97823100764,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-10a1dd43-bb9b-4b78-98f1-6225ad6ad954,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-2eb293cf-06e0-47eb-bbb5-07f600542bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-996f122c-cbd1-42fb-be26-c7170ce24585,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-aebaa397-7f57-426d-b2a3-6c0ee7c20c40,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-7c0f48e6-e0a1-411f-9ef3-5f16bcba4d99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607448717-172.17.0.8-1598367878860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42952,DS-a74f1630-e806-4d10-b3a1-d2a0225c54c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-bdb05982-13e9-4d7d-bc26-40de9fb747ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-c28ad25b-fea3-4ed3-a0af-f97823100764,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-10a1dd43-bb9b-4b78-98f1-6225ad6ad954,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-2eb293cf-06e0-47eb-bbb5-07f600542bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-996f122c-cbd1-42fb-be26-c7170ce24585,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-aebaa397-7f57-426d-b2a3-6c0ee7c20c40,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-7c0f48e6-e0a1-411f-9ef3-5f16bcba4d99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181764529-172.17.0.8-1598368144810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43403,DS-6056c101-da24-4eae-9397-ab520d7eeb54,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-9dc87aef-5ea8-45fe-8c0f-592fb94f422b,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-22cdee15-5047-4109-ad11-4fdeb086f351,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-190012a2-b78a-42b3-8d5f-df84948e659a,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-1851d551-18cc-461d-a2fe-87d6b3deddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-e388d5b5-3afe-4f7b-8d56-d1a027bad9db,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-26306be0-2c1b-4923-bc21-5f6f7f42dd06,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-7a05dcec-d4aa-42a8-939d-0d706aecdc5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181764529-172.17.0.8-1598368144810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43403,DS-6056c101-da24-4eae-9397-ab520d7eeb54,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-9dc87aef-5ea8-45fe-8c0f-592fb94f422b,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-22cdee15-5047-4109-ad11-4fdeb086f351,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-190012a2-b78a-42b3-8d5f-df84948e659a,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-1851d551-18cc-461d-a2fe-87d6b3deddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-e388d5b5-3afe-4f7b-8d56-d1a027bad9db,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-26306be0-2c1b-4923-bc21-5f6f7f42dd06,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-7a05dcec-d4aa-42a8-939d-0d706aecdc5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469904059-172.17.0.8-1598368185691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35488,DS-2d2181ac-2e98-4926-8632-ed7c490a7bec,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-c1ac393a-2356-49fd-b50d-507ee48d6798,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-62fa2c10-1242-45e1-a160-2b96c18aa3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-c981e66b-8f99-4e99-a490-640dd61732db,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-2b89621f-6dd1-47cb-a1bc-10eb82c07934,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-334d69da-5276-40b5-84b5-1c53f5bae0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-9fcb835e-16ab-408b-a664-263ae869d64c,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-d137f1f5-ed5a-4475-b117-0f9dc98138c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469904059-172.17.0.8-1598368185691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35488,DS-2d2181ac-2e98-4926-8632-ed7c490a7bec,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-c1ac393a-2356-49fd-b50d-507ee48d6798,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-62fa2c10-1242-45e1-a160-2b96c18aa3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-c981e66b-8f99-4e99-a490-640dd61732db,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-2b89621f-6dd1-47cb-a1bc-10eb82c07934,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-334d69da-5276-40b5-84b5-1c53f5bae0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-9fcb835e-16ab-408b-a664-263ae869d64c,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-d137f1f5-ed5a-4475-b117-0f9dc98138c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453930657-172.17.0.8-1598368593515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46513,DS-c55ef9e3-532e-4a5f-bd64-93b0bf60c261,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-fe14ae8e-5668-46ac-b4c0-d1b7f07c02fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-af3e3486-4359-4f30-948c-a898ccffb198,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-c9a585d4-57ed-4cd5-a26c-6ee0a3d3b31e,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-f6175413-4cf4-4887-9314-1ec289fb5f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-58a11be3-ec56-401e-9d47-cc3f597ac248,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-b8e653a5-f81d-46be-8e15-5a487167845c,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-909d4e44-b067-4c43-acb4-0c5ad3605fa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453930657-172.17.0.8-1598368593515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46513,DS-c55ef9e3-532e-4a5f-bd64-93b0bf60c261,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-fe14ae8e-5668-46ac-b4c0-d1b7f07c02fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-af3e3486-4359-4f30-948c-a898ccffb198,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-c9a585d4-57ed-4cd5-a26c-6ee0a3d3b31e,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-f6175413-4cf4-4887-9314-1ec289fb5f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-58a11be3-ec56-401e-9d47-cc3f597ac248,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-b8e653a5-f81d-46be-8e15-5a487167845c,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-909d4e44-b067-4c43-acb4-0c5ad3605fa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1909884543-172.17.0.8-1598369439973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37967,DS-823279b3-c25a-48fc-b647-19541299be2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-a4991b04-5559-4d4f-aa50-0bdceeca8047,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-242c884e-04ae-4789-9c9d-ae5a61393395,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-dd6915bd-2416-41a2-b067-05ea900b9c19,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-1af89741-0e16-4bcc-bbe6-e104332b964c,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-358af79e-c264-4447-b0aa-d96a34e73687,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-d50c9c3e-2f82-41ec-b12e-b5ae84bc4015,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-b7f30ff4-a179-4ee7-9fcf-963d9ec5af6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1909884543-172.17.0.8-1598369439973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37967,DS-823279b3-c25a-48fc-b647-19541299be2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-a4991b04-5559-4d4f-aa50-0bdceeca8047,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-242c884e-04ae-4789-9c9d-ae5a61393395,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-dd6915bd-2416-41a2-b067-05ea900b9c19,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-1af89741-0e16-4bcc-bbe6-e104332b964c,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-358af79e-c264-4447-b0aa-d96a34e73687,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-d50c9c3e-2f82-41ec-b12e-b5ae84bc4015,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-b7f30ff4-a179-4ee7-9fcf-963d9ec5af6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867798709-172.17.0.8-1598369611079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45635,DS-280c0b11-449f-4623-a23a-f8b0837246ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-c3d05dcf-5de2-4b32-9b22-fd13747e8be3,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-34b30aa7-6399-4cdf-a7dc-4085cc6b4d20,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-b436acb7-09d7-4dce-baba-c7b9fc681454,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-f340bde0-43bd-4a36-a5fb-29ff0cb9b06a,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-835d0c49-24b5-4297-9982-21de41d32793,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-c13eebc8-9b63-40dc-b9fb-925dcf51655a,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-7b39eda0-536a-49e5-b942-4451d4c34f0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867798709-172.17.0.8-1598369611079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45635,DS-280c0b11-449f-4623-a23a-f8b0837246ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-c3d05dcf-5de2-4b32-9b22-fd13747e8be3,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-34b30aa7-6399-4cdf-a7dc-4085cc6b4d20,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-b436acb7-09d7-4dce-baba-c7b9fc681454,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-f340bde0-43bd-4a36-a5fb-29ff0cb9b06a,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-835d0c49-24b5-4297-9982-21de41d32793,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-c13eebc8-9b63-40dc-b9fb-925dcf51655a,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-7b39eda0-536a-49e5-b942-4451d4c34f0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801180697-172.17.0.8-1598369853670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34889,DS-ef980863-af50-44bf-a18c-f96199011baa,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-ce901d50-756b-4a97-9080-07ec4ff4328d,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-3a8a8d1f-a28f-45e0-bf0e-c8374242b5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-a8bc582f-dad6-4dea-9627-ac38886e20ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-2b4f6fb6-24b9-4d09-8640-da3d047a91be,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-8ee54b01-ddd9-4149-9624-90a311c4135f,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-111ff30d-2a3c-4b49-b7ee-2f3d7ebb77f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-6b88800f-dcb2-4ef5-82d7-0e3844bdce57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801180697-172.17.0.8-1598369853670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34889,DS-ef980863-af50-44bf-a18c-f96199011baa,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-ce901d50-756b-4a97-9080-07ec4ff4328d,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-3a8a8d1f-a28f-45e0-bf0e-c8374242b5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-a8bc582f-dad6-4dea-9627-ac38886e20ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-2b4f6fb6-24b9-4d09-8640-da3d047a91be,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-8ee54b01-ddd9-4149-9624-90a311c4135f,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-111ff30d-2a3c-4b49-b7ee-2f3d7ebb77f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-6b88800f-dcb2-4ef5-82d7-0e3844bdce57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-867364019-172.17.0.8-1598370076009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36124,DS-323ee8fb-fc80-45ec-bf14-49ba10ea6b96,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-729f0c57-b9d3-4f3c-83e2-804e653ff24a,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-96e6b32c-47b0-4f25-9e03-6dcf98bcfc74,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-c4c69526-3e5f-42a2-9eee-be5536688994,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-45caf351-6bdf-48ff-8a06-99b0be70db22,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-2829a224-fe1c-4091-9b84-d10472e2308d,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-30ef2634-72a1-44b2-878f-f68b6c851873,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-c3e29ada-c5b4-4ab8-be73-febec929b382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-867364019-172.17.0.8-1598370076009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36124,DS-323ee8fb-fc80-45ec-bf14-49ba10ea6b96,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-729f0c57-b9d3-4f3c-83e2-804e653ff24a,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-96e6b32c-47b0-4f25-9e03-6dcf98bcfc74,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-c4c69526-3e5f-42a2-9eee-be5536688994,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-45caf351-6bdf-48ff-8a06-99b0be70db22,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-2829a224-fe1c-4091-9b84-d10472e2308d,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-30ef2634-72a1-44b2-878f-f68b6c851873,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-c3e29ada-c5b4-4ab8-be73-febec929b382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194432269-172.17.0.8-1598370481761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42689,DS-a226f169-befc-4244-bb2e-ea3649c00589,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-19cf0154-8e24-4174-bbff-3cef66a6a716,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-4ac46dbc-997b-4c22-a449-f10467e1f9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-f17e689a-bf6e-4914-a5b8-62c0e851f236,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-2510081f-fcf6-4924-9be5-d77da7ec72dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-675adbdc-da6c-4614-9fa4-00f9c1d65867,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-21184f30-a3fd-4f4d-b5d8-70b7b7ce56ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-2e4d385a-43cb-4d60-b995-b6553b9ec43e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194432269-172.17.0.8-1598370481761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42689,DS-a226f169-befc-4244-bb2e-ea3649c00589,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-19cf0154-8e24-4174-bbff-3cef66a6a716,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-4ac46dbc-997b-4c22-a449-f10467e1f9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-f17e689a-bf6e-4914-a5b8-62c0e851f236,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-2510081f-fcf6-4924-9be5-d77da7ec72dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-675adbdc-da6c-4614-9fa4-00f9c1d65867,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-21184f30-a3fd-4f4d-b5d8-70b7b7ce56ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-2e4d385a-43cb-4d60-b995-b6553b9ec43e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-136998471-172.17.0.8-1598371245588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34341,DS-24601e65-57d2-4ea7-943b-3f4d2492250c,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-6f75751f-93b5-4add-9fbd-1d02d076f7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-503ff974-f353-48b8-948c-0ed4dcc2a706,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-284a9503-fc4b-4bc0-b831-bf3b702b7035,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-d01ba323-4499-4606-97a1-5ee452d2ec65,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-2de25d4e-0c49-42c9-a180-95b369f51a43,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-c71f0d31-5f55-4e10-b8d0-a60f9206d25c,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-fa4831d8-c5ab-4dea-8851-ceacbc21994d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-136998471-172.17.0.8-1598371245588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34341,DS-24601e65-57d2-4ea7-943b-3f4d2492250c,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-6f75751f-93b5-4add-9fbd-1d02d076f7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-503ff974-f353-48b8-948c-0ed4dcc2a706,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-284a9503-fc4b-4bc0-b831-bf3b702b7035,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-d01ba323-4499-4606-97a1-5ee452d2ec65,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-2de25d4e-0c49-42c9-a180-95b369f51a43,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-c71f0d31-5f55-4e10-b8d0-a60f9206d25c,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-fa4831d8-c5ab-4dea-8851-ceacbc21994d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094791945-172.17.0.8-1598371282662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40825,DS-113fe7a9-33cd-45e1-b246-86e0674a315d,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-d7c5f940-7caf-46e5-aefc-6fe39532b999,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-9b8fca1d-3d1e-49fc-b9bd-abac959c81d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-2815076f-23dc-4d74-9f33-039bf00f5ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-08351651-7e02-4778-ae73-fd5091c0154a,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-8d02eced-d0ba-4272-bb33-1dd4135c7072,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-c132bd3f-4f10-4ae5-bb78-926df5caeb61,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-168154d2-2e85-4964-91c4-c4f1e37b84fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094791945-172.17.0.8-1598371282662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40825,DS-113fe7a9-33cd-45e1-b246-86e0674a315d,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-d7c5f940-7caf-46e5-aefc-6fe39532b999,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-9b8fca1d-3d1e-49fc-b9bd-abac959c81d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-2815076f-23dc-4d74-9f33-039bf00f5ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-08351651-7e02-4778-ae73-fd5091c0154a,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-8d02eced-d0ba-4272-bb33-1dd4135c7072,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-c132bd3f-4f10-4ae5-bb78-926df5caeb61,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-168154d2-2e85-4964-91c4-c4f1e37b84fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1706974050-172.17.0.8-1598371426082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43813,DS-85c8a3ef-d4a4-4085-9c1f-624dbd752c08,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-c428bd72-8b11-487a-9750-9839a223d539,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-8afffe51-8a09-4e3e-913d-a4dab57cdc54,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-9fa9eb16-34f8-46ee-a780-f5bcf576e475,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-463c06c2-da97-425d-8852-8c6d2d91f348,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-a1e2420c-6bbb-41e8-9baa-504ed8a9114d,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-8cbd1a71-d3d5-4d8e-9cac-6158d4fd865e,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-52fff78e-980b-4adf-b128-fb925c2ae79f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1706974050-172.17.0.8-1598371426082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43813,DS-85c8a3ef-d4a4-4085-9c1f-624dbd752c08,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-c428bd72-8b11-487a-9750-9839a223d539,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-8afffe51-8a09-4e3e-913d-a4dab57cdc54,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-9fa9eb16-34f8-46ee-a780-f5bcf576e475,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-463c06c2-da97-425d-8852-8c6d2d91f348,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-a1e2420c-6bbb-41e8-9baa-504ed8a9114d,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-8cbd1a71-d3d5-4d8e-9cac-6158d4fd865e,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-52fff78e-980b-4adf-b128-fb925c2ae79f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542072292-172.17.0.8-1598371570349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34640,DS-fcc5a7de-9bd1-420b-8807-8116f6703699,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-6c74541f-c1f7-44c1-a983-4d955bffa4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-497ee378-0afa-4c2c-b82b-c179f1468415,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-75a7b253-384c-4dde-906f-2d7b0104dedb,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-1dea765a-dd4a-4238-9272-e5ef390b1163,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-f2a1df75-bf30-4418-abb6-ec7d1119a39f,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-a8770d47-e0c3-4194-9360-eaf8ac4618d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-5fe8547b-89e3-4a43-a052-9440da0b88b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542072292-172.17.0.8-1598371570349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34640,DS-fcc5a7de-9bd1-420b-8807-8116f6703699,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-6c74541f-c1f7-44c1-a983-4d955bffa4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-497ee378-0afa-4c2c-b82b-c179f1468415,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-75a7b253-384c-4dde-906f-2d7b0104dedb,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-1dea765a-dd4a-4238-9272-e5ef390b1163,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-f2a1df75-bf30-4418-abb6-ec7d1119a39f,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-a8770d47-e0c3-4194-9360-eaf8ac4618d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-5fe8547b-89e3-4a43-a052-9440da0b88b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1089337749-172.17.0.8-1598371610274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45165,DS-7379f559-b4b1-43ff-8c48-ad857b56de58,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-006f2534-a90b-45a4-a414-e3263faf3082,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-0a5ce327-4594-4a64-844d-6b069b2cf28e,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-ee4539ea-ddb6-48de-a247-9aec4204beb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-3558826d-de20-4f02-b687-d71a132c2a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-930542bd-4091-45cb-b13e-c20b6435742f,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-b50ca3f4-220b-48e4-a191-f5a714aa1849,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-3fef7f31-a79e-456d-b031-6f8a3dacc632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1089337749-172.17.0.8-1598371610274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45165,DS-7379f559-b4b1-43ff-8c48-ad857b56de58,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-006f2534-a90b-45a4-a414-e3263faf3082,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-0a5ce327-4594-4a64-844d-6b069b2cf28e,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-ee4539ea-ddb6-48de-a247-9aec4204beb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-3558826d-de20-4f02-b687-d71a132c2a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-930542bd-4091-45cb-b13e-c20b6435742f,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-b50ca3f4-220b-48e4-a191-f5a714aa1849,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-3fef7f31-a79e-456d-b031-6f8a3dacc632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-883549219-172.17.0.8-1598371931755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43780,DS-8b6c6892-6b40-47b9-b8ff-e52b11551fec,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-7dab3a3a-d966-44de-aa0c-5282b64a7dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-781dddf9-423e-4dfb-85a0-cccdc7e97a77,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-35832a74-596e-4ceb-979c-eac93b32c46c,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-4368483d-b951-4547-8cd0-5446bf078778,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-9161f2ec-b6bf-48a0-9be3-e5ad25995ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-1d50d918-2aa7-4f2c-af22-c47f609ee3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-1836a0b6-c003-4868-aa3a-dc6e6f437f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-883549219-172.17.0.8-1598371931755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43780,DS-8b6c6892-6b40-47b9-b8ff-e52b11551fec,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-7dab3a3a-d966-44de-aa0c-5282b64a7dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-781dddf9-423e-4dfb-85a0-cccdc7e97a77,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-35832a74-596e-4ceb-979c-eac93b32c46c,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-4368483d-b951-4547-8cd0-5446bf078778,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-9161f2ec-b6bf-48a0-9be3-e5ad25995ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-1d50d918-2aa7-4f2c-af22-c47f609ee3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-1836a0b6-c003-4868-aa3a-dc6e6f437f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821267856-172.17.0.8-1598371995301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35101,DS-dd9a62d6-ae79-4d30-924a-197a0722f3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-46ad8642-d098-479a-8cc5-74e98a166025,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-74d2d40a-8869-4ca7-984c-0d8c1c3602ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-11026bb4-63ba-42ab-8d15-338925327e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-1dd75961-5eef-4531-947c-1d282ec58b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-c81cfd85-52b0-44f3-951b-44b0ab5934b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-7557e953-3802-4e1d-91c0-f6233d460e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-5074739c-9946-4372-ae5e-dfa0f5242166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821267856-172.17.0.8-1598371995301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35101,DS-dd9a62d6-ae79-4d30-924a-197a0722f3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-46ad8642-d098-479a-8cc5-74e98a166025,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-74d2d40a-8869-4ca7-984c-0d8c1c3602ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-11026bb4-63ba-42ab-8d15-338925327e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-1dd75961-5eef-4531-947c-1d282ec58b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-c81cfd85-52b0-44f3-951b-44b0ab5934b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-7557e953-3802-4e1d-91c0-f6233d460e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-5074739c-9946-4372-ae5e-dfa0f5242166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1300553634-172.17.0.8-1598372202893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39873,DS-a174a786-9de8-400f-a6f4-a05130a64ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-a9f0e012-4d16-41e0-8a55-f7d55fd5daf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-552b29fc-9a6f-442c-9723-03d07db2f0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-c5c7c0d2-09f9-4244-95ff-63ea80e499eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-95ff8fec-f713-497f-8a33-d0a1b6ae7fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-0793c33f-0ce2-4d13-8512-1f897451238a,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-99134b13-6b6f-4c6d-b542-db8c65e7ab2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-7f1a8ffe-9a22-4e7a-89aa-afd5b3834b26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1300553634-172.17.0.8-1598372202893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39873,DS-a174a786-9de8-400f-a6f4-a05130a64ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-a9f0e012-4d16-41e0-8a55-f7d55fd5daf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-552b29fc-9a6f-442c-9723-03d07db2f0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-c5c7c0d2-09f9-4244-95ff-63ea80e499eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-95ff8fec-f713-497f-8a33-d0a1b6ae7fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-0793c33f-0ce2-4d13-8512-1f897451238a,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-99134b13-6b6f-4c6d-b542-db8c65e7ab2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-7f1a8ffe-9a22-4e7a-89aa-afd5b3834b26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5191
