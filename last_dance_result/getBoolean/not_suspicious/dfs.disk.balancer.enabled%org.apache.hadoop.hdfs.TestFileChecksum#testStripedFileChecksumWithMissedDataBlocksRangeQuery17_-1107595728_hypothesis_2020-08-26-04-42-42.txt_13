reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353292605-172.17.0.18-1598417315106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39269,DS-d68f0193-1a3c-45ca-a299-2d066bf201ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-34b83297-0a51-4bb9-97b1-a2b063d482bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-f9ffd7ad-1e3f-48cb-abc5-6ef3f014eba4,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-160d382f-63fb-49a1-b67f-862d4135b57a,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-3ce0ebbb-f7e7-4b59-b178-e2c1b247c524,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-b690a43d-48ac-49d0-889e-a569c5ad00b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-907ccd1e-7a63-4a06-91a6-08c8d48e350a,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-609b8348-479d-4411-9da1-a767035be4cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353292605-172.17.0.18-1598417315106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39269,DS-d68f0193-1a3c-45ca-a299-2d066bf201ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-34b83297-0a51-4bb9-97b1-a2b063d482bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-f9ffd7ad-1e3f-48cb-abc5-6ef3f014eba4,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-160d382f-63fb-49a1-b67f-862d4135b57a,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-3ce0ebbb-f7e7-4b59-b178-e2c1b247c524,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-b690a43d-48ac-49d0-889e-a569c5ad00b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-907ccd1e-7a63-4a06-91a6-08c8d48e350a,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-609b8348-479d-4411-9da1-a767035be4cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580512375-172.17.0.18-1598417734129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38098,DS-e6fa84c3-28d1-49cb-8042-ad47e1daa55e,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-1205081c-afa3-4f08-ae7b-72e301692660,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-ea4210a2-219b-4a3f-90a5-99e8e8a6f914,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-74c70abb-9372-4467-8fd8-375f6ad4339c,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-aaf8a782-27c5-402f-9910-0b0824268a29,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-ea5e1b88-06cc-474d-bbb0-8ed55bf8b9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-6e5102fe-225b-4ab6-a64c-f698b01bcaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-330aa5ab-07a0-4395-9291-843c7682fafb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580512375-172.17.0.18-1598417734129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38098,DS-e6fa84c3-28d1-49cb-8042-ad47e1daa55e,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-1205081c-afa3-4f08-ae7b-72e301692660,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-ea4210a2-219b-4a3f-90a5-99e8e8a6f914,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-74c70abb-9372-4467-8fd8-375f6ad4339c,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-aaf8a782-27c5-402f-9910-0b0824268a29,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-ea5e1b88-06cc-474d-bbb0-8ed55bf8b9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-6e5102fe-225b-4ab6-a64c-f698b01bcaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-330aa5ab-07a0-4395-9291-843c7682fafb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027709212-172.17.0.18-1598417873150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33477,DS-a5f2aa8b-498d-4abe-80e6-7805eeb14459,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-fa58cfc3-99a7-4403-a320-e2c83c67250d,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-0396a262-052c-4d79-9d6d-0d13ac11aa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-f08112bb-b89b-4e1c-b721-db374d2610e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-f5d82e36-d2a6-4844-822a-4c42de487674,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-0522eb61-d64f-4db2-85a8-ef87d3e02b03,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-dd3d7388-7ea2-45b8-9525-177cfea225fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-7751cdac-5f39-49b2-8b20-3d0b446d90da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027709212-172.17.0.18-1598417873150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33477,DS-a5f2aa8b-498d-4abe-80e6-7805eeb14459,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-fa58cfc3-99a7-4403-a320-e2c83c67250d,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-0396a262-052c-4d79-9d6d-0d13ac11aa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-f08112bb-b89b-4e1c-b721-db374d2610e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-f5d82e36-d2a6-4844-822a-4c42de487674,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-0522eb61-d64f-4db2-85a8-ef87d3e02b03,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-dd3d7388-7ea2-45b8-9525-177cfea225fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-7751cdac-5f39-49b2-8b20-3d0b446d90da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929087609-172.17.0.18-1598417908012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33317,DS-b5ea84b6-17cd-40b2-ac6c-810f07559660,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-f736e423-3316-42d6-9173-f65b9718635c,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-373fb352-c192-45bb-896a-aabb0b1e5208,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-b87903ff-b8ed-44d8-bedd-8072c2daa9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-71f12af4-6831-4b21-9b3b-33ef6ef91528,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-93a885bd-18f5-414c-a678-5eaabeb58772,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-7d4fafdc-bb1d-4c3a-a6bd-259b61ab72d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-a285776e-02e9-4d6e-bd45-b8fa457d5711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929087609-172.17.0.18-1598417908012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33317,DS-b5ea84b6-17cd-40b2-ac6c-810f07559660,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-f736e423-3316-42d6-9173-f65b9718635c,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-373fb352-c192-45bb-896a-aabb0b1e5208,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-b87903ff-b8ed-44d8-bedd-8072c2daa9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-71f12af4-6831-4b21-9b3b-33ef6ef91528,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-93a885bd-18f5-414c-a678-5eaabeb58772,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-7d4fafdc-bb1d-4c3a-a6bd-259b61ab72d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-a285776e-02e9-4d6e-bd45-b8fa457d5711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219314184-172.17.0.18-1598418246387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-f9bdd6cc-01f2-40af-9b74-60c0f630425a,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-70b47b09-833e-45fd-8c34-28078dd56a37,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-780de371-1dd6-4ca5-83d3-621dcc55f3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-e55d3b1b-0a32-48e9-8cfa-11fd23ce70cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-aa22fbc3-ceb3-4460-990d-c086e425bb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-e76acf9d-c95a-44ee-9a5d-cee6c66159c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-691121fe-44fe-4009-8ccf-09945c679f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-fb70d1c9-03ac-48a1-a183-51549b1028ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219314184-172.17.0.18-1598418246387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-f9bdd6cc-01f2-40af-9b74-60c0f630425a,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-70b47b09-833e-45fd-8c34-28078dd56a37,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-780de371-1dd6-4ca5-83d3-621dcc55f3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-e55d3b1b-0a32-48e9-8cfa-11fd23ce70cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-aa22fbc3-ceb3-4460-990d-c086e425bb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-e76acf9d-c95a-44ee-9a5d-cee6c66159c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-691121fe-44fe-4009-8ccf-09945c679f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-fb70d1c9-03ac-48a1-a183-51549b1028ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116331489-172.17.0.18-1598418354623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36741,DS-da82cf6c-39c0-48bd-85d0-d152b1f3c77b,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-ba8017a2-4835-470d-884b-c68c584268d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-347a8a6d-3310-4cbf-94e4-99d6f8eb7133,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-f6331a4e-1ee2-4a7f-a554-00a12424e024,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-6163b5df-1347-4a37-bbf9-f08e21f14c06,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-47c6cc7d-7278-4183-bc49-c9f4ba89bb27,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-c385a565-9911-4302-a6e3-516ba41c4b60,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-be9f76cb-3461-4b30-a8e0-11cb80d76130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116331489-172.17.0.18-1598418354623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36741,DS-da82cf6c-39c0-48bd-85d0-d152b1f3c77b,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-ba8017a2-4835-470d-884b-c68c584268d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-347a8a6d-3310-4cbf-94e4-99d6f8eb7133,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-f6331a4e-1ee2-4a7f-a554-00a12424e024,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-6163b5df-1347-4a37-bbf9-f08e21f14c06,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-47c6cc7d-7278-4183-bc49-c9f4ba89bb27,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-c385a565-9911-4302-a6e3-516ba41c4b60,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-be9f76cb-3461-4b30-a8e0-11cb80d76130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133249176-172.17.0.18-1598418884772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33467,DS-d0de86d2-e5a8-4713-971b-ef48504861d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-d1ad89e7-a39a-482b-8a51-81cc325fb355,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-56197a8b-ab95-4143-a1ba-bfcd8225619d,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-77d03429-7378-401a-a2ac-ea10af15230f,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-8df70295-42eb-4b50-8e59-8c34f7203533,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-7e2fbec6-b2b3-4ff9-a1dc-1fb8d992c6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-2c8ddcff-a824-4b38-ac79-268a0a4035d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-c19a284d-ccaa-45d7-b554-610d85ae7142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133249176-172.17.0.18-1598418884772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33467,DS-d0de86d2-e5a8-4713-971b-ef48504861d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-d1ad89e7-a39a-482b-8a51-81cc325fb355,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-56197a8b-ab95-4143-a1ba-bfcd8225619d,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-77d03429-7378-401a-a2ac-ea10af15230f,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-8df70295-42eb-4b50-8e59-8c34f7203533,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-7e2fbec6-b2b3-4ff9-a1dc-1fb8d992c6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-2c8ddcff-a824-4b38-ac79-268a0a4035d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-c19a284d-ccaa-45d7-b554-610d85ae7142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803120918-172.17.0.18-1598418976280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32928,DS-2a2a6308-3dc9-4e0c-9977-aa82206837f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-e2aa7131-e187-45cb-b171-f7491b209a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-52d4b0bb-248c-4e92-bd79-f4510405b5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-fc7fd8fc-3849-4e4a-ac6d-76ed90cca0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-ba0940be-9af5-446b-b731-2bf0540181e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-6255ec08-bb20-44d7-a610-fc890e6b6123,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-b13366da-7c68-455d-b065-8a4c9be74445,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-057e0a3b-6c13-41ef-b764-3f0050ad0caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803120918-172.17.0.18-1598418976280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32928,DS-2a2a6308-3dc9-4e0c-9977-aa82206837f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-e2aa7131-e187-45cb-b171-f7491b209a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-52d4b0bb-248c-4e92-bd79-f4510405b5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-fc7fd8fc-3849-4e4a-ac6d-76ed90cca0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-ba0940be-9af5-446b-b731-2bf0540181e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-6255ec08-bb20-44d7-a610-fc890e6b6123,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-b13366da-7c68-455d-b065-8a4c9be74445,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-057e0a3b-6c13-41ef-b764-3f0050ad0caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88048382-172.17.0.18-1598419533467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45754,DS-b60977d1-c7af-486d-a105-886e6343c218,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-34b116f5-cb1c-49ce-8e0b-6060481df558,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-fe59d4c3-c3a9-4f25-91ee-0f4080ceee18,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-204039e4-1cf3-44dd-8e3f-a750b6f63928,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-03d27bf3-9ffd-4a6e-a5e3-9eabb3d8891a,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-fa5bb21d-adb0-4df8-ab59-e4dc3712345c,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-1e184bae-2749-49ab-9ff8-7daba42b42ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-e5ae3899-8e1c-480a-819e-6ba5bcab81d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88048382-172.17.0.18-1598419533467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45754,DS-b60977d1-c7af-486d-a105-886e6343c218,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-34b116f5-cb1c-49ce-8e0b-6060481df558,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-fe59d4c3-c3a9-4f25-91ee-0f4080ceee18,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-204039e4-1cf3-44dd-8e3f-a750b6f63928,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-03d27bf3-9ffd-4a6e-a5e3-9eabb3d8891a,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-fa5bb21d-adb0-4df8-ab59-e4dc3712345c,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-1e184bae-2749-49ab-9ff8-7daba42b42ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-e5ae3899-8e1c-480a-819e-6ba5bcab81d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1950507422-172.17.0.18-1598419887855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44196,DS-46fe4130-514f-43b1-9f0d-76ddd2d08dea,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-de399476-d9c5-4513-97f4-cafb262b2b62,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-3234d367-40b6-4a31-b1cf-e13b85795a73,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-2b1f2df6-6a8a-4631-9a74-276fc974dc97,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-ef814559-1bd0-48d7-babd-01daf2be416b,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-f934be11-eb4f-4c1a-a330-5542a1b01f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-6466fbce-3483-4f63-af3a-064768fb1146,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-14e9273f-b074-49f6-8fb2-415dfa1421b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1950507422-172.17.0.18-1598419887855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44196,DS-46fe4130-514f-43b1-9f0d-76ddd2d08dea,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-de399476-d9c5-4513-97f4-cafb262b2b62,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-3234d367-40b6-4a31-b1cf-e13b85795a73,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-2b1f2df6-6a8a-4631-9a74-276fc974dc97,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-ef814559-1bd0-48d7-babd-01daf2be416b,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-f934be11-eb4f-4c1a-a330-5542a1b01f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-6466fbce-3483-4f63-af3a-064768fb1146,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-14e9273f-b074-49f6-8fb2-415dfa1421b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253369437-172.17.0.18-1598420207312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42151,DS-39150c6e-b96e-4932-b412-ef37ab4a885d,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-e7d70c5d-951b-4f19-8621-4cd29afeba83,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-07aee50a-3b8c-4c78-aeb2-3f9b884d2841,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-822a7150-da07-4cfd-823c-ea9fb69c6d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-34635bfe-f4aa-47f4-9748-5f36dc6ad49a,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-8496c85f-17c2-4f01-bac1-a5a4c731c51d,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-7945818e-ca1d-4b41-927e-98f47392a4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-b9dd0e17-34f2-4744-8bb9-c7532312817a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253369437-172.17.0.18-1598420207312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42151,DS-39150c6e-b96e-4932-b412-ef37ab4a885d,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-e7d70c5d-951b-4f19-8621-4cd29afeba83,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-07aee50a-3b8c-4c78-aeb2-3f9b884d2841,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-822a7150-da07-4cfd-823c-ea9fb69c6d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-34635bfe-f4aa-47f4-9748-5f36dc6ad49a,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-8496c85f-17c2-4f01-bac1-a5a4c731c51d,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-7945818e-ca1d-4b41-927e-98f47392a4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-b9dd0e17-34f2-4744-8bb9-c7532312817a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1404499578-172.17.0.18-1598420399458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44983,DS-79869ba1-603c-4450-81a5-3c05e3053a81,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-949c3439-0c21-40c0-a74e-fec934dceb12,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-495e9570-2255-4679-9c99-605923cc1f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-1d75f98f-1f8a-4ec1-aad1-fecef0f3e843,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-92927d70-1033-487a-a186-abd9441cb0de,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-4720013c-8cd5-48cf-a30e-1655b6698ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-644a4da4-608e-4159-85d1-ea9c609ee224,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-d50f5a87-6851-4efd-b0be-acce283774f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1404499578-172.17.0.18-1598420399458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44983,DS-79869ba1-603c-4450-81a5-3c05e3053a81,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-949c3439-0c21-40c0-a74e-fec934dceb12,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-495e9570-2255-4679-9c99-605923cc1f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-1d75f98f-1f8a-4ec1-aad1-fecef0f3e843,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-92927d70-1033-487a-a186-abd9441cb0de,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-4720013c-8cd5-48cf-a30e-1655b6698ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-644a4da4-608e-4159-85d1-ea9c609ee224,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-d50f5a87-6851-4efd-b0be-acce283774f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2087009980-172.17.0.18-1598420462054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32816,DS-336a7330-851d-4d7f-a955-a4dfda7c6b03,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-1d3b54a3-5742-4b42-99f2-a8a50f94631f,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-7ccca2c5-ad24-4693-b0fd-72a41a4af416,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-19c51163-838c-414b-81e0-d4d536709dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-48718d19-ee7e-4eff-948b-54d2bb523b49,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-8674c534-3fb1-401a-bc9b-454e4dad1b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-0864d3c7-4756-4b3e-8155-52c466971bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-60f197a1-3173-4041-bebf-2c3fa00e4826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2087009980-172.17.0.18-1598420462054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32816,DS-336a7330-851d-4d7f-a955-a4dfda7c6b03,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-1d3b54a3-5742-4b42-99f2-a8a50f94631f,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-7ccca2c5-ad24-4693-b0fd-72a41a4af416,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-19c51163-838c-414b-81e0-d4d536709dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-48718d19-ee7e-4eff-948b-54d2bb523b49,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-8674c534-3fb1-401a-bc9b-454e4dad1b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-0864d3c7-4756-4b3e-8155-52c466971bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-60f197a1-3173-4041-bebf-2c3fa00e4826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311981156-172.17.0.18-1598420675858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33866,DS-a78177b9-b8e1-4017-a513-ce3164f8af8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-aaed2eca-f4ca-457f-a7a2-960f5623be56,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-b5eddb4a-a56c-408b-a30e-4c93029aafad,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-78797e4a-638e-4ee5-99a1-f1a0a1ff85f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-4365e10b-c8aa-4fe6-907d-b819ea1508ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-a36182d1-7eda-40af-aace-439610aecb82,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-49e92ced-87b0-4c5c-b130-bc025ddf01cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-5a14a316-7369-4990-97c0-0c57916abd3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311981156-172.17.0.18-1598420675858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33866,DS-a78177b9-b8e1-4017-a513-ce3164f8af8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-aaed2eca-f4ca-457f-a7a2-960f5623be56,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-b5eddb4a-a56c-408b-a30e-4c93029aafad,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-78797e4a-638e-4ee5-99a1-f1a0a1ff85f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-4365e10b-c8aa-4fe6-907d-b819ea1508ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-a36182d1-7eda-40af-aace-439610aecb82,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-49e92ced-87b0-4c5c-b130-bc025ddf01cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-5a14a316-7369-4990-97c0-0c57916abd3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1257943462-172.17.0.18-1598420876514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36662,DS-dcc74fe3-3866-4ac2-aef9-1a1b05d046bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-8bc0449f-f233-4b3a-90f9-2c2ee8d91b53,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-9d75a101-83b2-4c38-a698-f7942117c642,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-a6cea644-1e90-4d4d-9166-7f87583a4f42,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-43feec8c-e6ea-42ab-8992-7070cea6850e,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-44571cdb-0a1a-4831-a74e-d53f81326fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-25455930-2f9b-4214-a8cb-563f46944435,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-03ab20f6-cdb2-4e56-8237-97cfad1c9044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1257943462-172.17.0.18-1598420876514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36662,DS-dcc74fe3-3866-4ac2-aef9-1a1b05d046bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-8bc0449f-f233-4b3a-90f9-2c2ee8d91b53,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-9d75a101-83b2-4c38-a698-f7942117c642,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-a6cea644-1e90-4d4d-9166-7f87583a4f42,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-43feec8c-e6ea-42ab-8992-7070cea6850e,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-44571cdb-0a1a-4831-a74e-d53f81326fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-25455930-2f9b-4214-a8cb-563f46944435,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-03ab20f6-cdb2-4e56-8237-97cfad1c9044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463541679-172.17.0.18-1598421778833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38725,DS-9621a6c8-51a9-457a-abbc-e881720ebee8,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-c6a86ad6-0e6c-40a8-8379-fb31ed120502,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-8a09e144-b426-4203-85c7-4d85c472f44b,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-fc44bc0f-e3c3-4ad3-bd7a-b2e18ddbf8da,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-118a9572-42e9-4119-8942-b3752c5bc32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-4f5e7777-e984-42f2-ab0f-bbc837d3c1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-9c5b958d-814c-4ba7-9659-2b2c28ef28a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-8fc75548-012d-4da3-817e-90cece160717,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463541679-172.17.0.18-1598421778833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38725,DS-9621a6c8-51a9-457a-abbc-e881720ebee8,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-c6a86ad6-0e6c-40a8-8379-fb31ed120502,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-8a09e144-b426-4203-85c7-4d85c472f44b,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-fc44bc0f-e3c3-4ad3-bd7a-b2e18ddbf8da,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-118a9572-42e9-4119-8942-b3752c5bc32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-4f5e7777-e984-42f2-ab0f-bbc837d3c1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-9c5b958d-814c-4ba7-9659-2b2c28ef28a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-8fc75548-012d-4da3-817e-90cece160717,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5071
