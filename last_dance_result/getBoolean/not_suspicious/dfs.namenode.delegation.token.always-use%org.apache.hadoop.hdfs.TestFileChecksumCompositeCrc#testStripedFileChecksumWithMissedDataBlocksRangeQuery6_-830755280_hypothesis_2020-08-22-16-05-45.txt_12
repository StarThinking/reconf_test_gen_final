reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52481555-172.17.0.19-1598112653775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39231,DS-de6ecc17-b6ac-49a4-8adc-34843b19d21d,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-aee562ad-2350-4197-b0ce-92848bfd67dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-814c3729-066f-459c-b6b2-08b313eda9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-8182e084-ea28-4f43-a12a-b19d0ff1dfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-9f068e21-591f-4108-8c36-76334e2025dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-afcbe840-d0e3-40a2-976d-e4da61927397,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-a03c29e1-d4f0-419f-9fec-91cee9f1a250,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-7fe47f63-3712-4c15-97a6-b70439609fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52481555-172.17.0.19-1598112653775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39231,DS-de6ecc17-b6ac-49a4-8adc-34843b19d21d,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-aee562ad-2350-4197-b0ce-92848bfd67dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-814c3729-066f-459c-b6b2-08b313eda9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-8182e084-ea28-4f43-a12a-b19d0ff1dfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-9f068e21-591f-4108-8c36-76334e2025dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-afcbe840-d0e3-40a2-976d-e4da61927397,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-a03c29e1-d4f0-419f-9fec-91cee9f1a250,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-7fe47f63-3712-4c15-97a6-b70439609fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931460148-172.17.0.19-1598112757361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41562,DS-235ff616-d0e1-43fb-bb90-af0256cd9a19,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-bde95848-c6a9-49ed-9de8-2218a8d841a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-de6b0e39-8e6f-46a8-84cf-f606fecbc773,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-639f1a08-5509-4995-befc-4666552d4477,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-013a633a-5757-479c-a4ce-ad082c35cf74,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-a9dc14cd-27d4-4821-afe2-b727dd445544,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-77224a8b-6694-481c-882f-47b2bcee1e76,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-1f51331a-7437-4e58-ae4c-5908aae602b0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931460148-172.17.0.19-1598112757361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41562,DS-235ff616-d0e1-43fb-bb90-af0256cd9a19,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-bde95848-c6a9-49ed-9de8-2218a8d841a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-de6b0e39-8e6f-46a8-84cf-f606fecbc773,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-639f1a08-5509-4995-befc-4666552d4477,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-013a633a-5757-479c-a4ce-ad082c35cf74,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-a9dc14cd-27d4-4821-afe2-b727dd445544,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-77224a8b-6694-481c-882f-47b2bcee1e76,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-1f51331a-7437-4e58-ae4c-5908aae602b0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369139921-172.17.0.19-1598112793215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42331,DS-4ddc6b1c-84de-4576-a304-f2e14c9dd457,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-0e55d7bf-2446-48ec-b05f-56570ef468c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-8a67957b-e1c3-459a-ab5a-5fede9ef64ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-d6fa05c0-724d-4d7d-b70f-9061319bfbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-397a10c6-81ca-4f10-b3f3-32c4cc70cb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-40b137d1-76ef-485b-96cf-5419b952cffd,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-fab4200b-72c8-4ca8-acde-3166ffcbbb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-92e05a54-0b5a-43f6-9003-a038c9816543,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369139921-172.17.0.19-1598112793215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42331,DS-4ddc6b1c-84de-4576-a304-f2e14c9dd457,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-0e55d7bf-2446-48ec-b05f-56570ef468c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-8a67957b-e1c3-459a-ab5a-5fede9ef64ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-d6fa05c0-724d-4d7d-b70f-9061319bfbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-397a10c6-81ca-4f10-b3f3-32c4cc70cb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-40b137d1-76ef-485b-96cf-5419b952cffd,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-fab4200b-72c8-4ca8-acde-3166ffcbbb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-92e05a54-0b5a-43f6-9003-a038c9816543,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848894298-172.17.0.19-1598112854633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33570,DS-4696c33c-59de-4605-912e-7df7ba0ae914,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-7f2b886c-8c87-4b8b-b70e-5021285fdd22,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-ab0002af-fc6b-431f-bd16-f27408958d22,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-af273d1d-a392-4584-95ce-ee43dad568b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-ba68c9aa-c57c-46ab-96f9-992c8b659857,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-8ed069b5-3cf4-44cc-8de0-6710559273f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-cf690601-09d6-4d72-ad11-f00cc68947f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-75295a05-6137-46ac-987b-ef4c396030d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848894298-172.17.0.19-1598112854633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33570,DS-4696c33c-59de-4605-912e-7df7ba0ae914,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-7f2b886c-8c87-4b8b-b70e-5021285fdd22,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-ab0002af-fc6b-431f-bd16-f27408958d22,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-af273d1d-a392-4584-95ce-ee43dad568b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-ba68c9aa-c57c-46ab-96f9-992c8b659857,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-8ed069b5-3cf4-44cc-8de0-6710559273f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-cf690601-09d6-4d72-ad11-f00cc68947f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-75295a05-6137-46ac-987b-ef4c396030d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853764846-172.17.0.19-1598113078991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38285,DS-45d4b087-60c0-4d5d-8d39-70189a349b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-a24789c1-e6aa-478c-91a7-231a9162096b,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-6e8031b2-4389-4248-9a64-248e1fce995a,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-1411ba44-b225-4a1f-bf69-94653b8adb53,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-42024706-48c2-458e-b22d-c7a07d03c89b,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-cd4bfd7b-f070-49a0-86f1-2ac963393ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-65e1c903-3f46-4765-a170-060b1c220164,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-37b61264-c3d3-47e5-b055-6a94786bc7b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853764846-172.17.0.19-1598113078991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38285,DS-45d4b087-60c0-4d5d-8d39-70189a349b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-a24789c1-e6aa-478c-91a7-231a9162096b,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-6e8031b2-4389-4248-9a64-248e1fce995a,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-1411ba44-b225-4a1f-bf69-94653b8adb53,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-42024706-48c2-458e-b22d-c7a07d03c89b,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-cd4bfd7b-f070-49a0-86f1-2ac963393ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-65e1c903-3f46-4765-a170-060b1c220164,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-37b61264-c3d3-47e5-b055-6a94786bc7b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889798492-172.17.0.19-1598113116384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35591,DS-f102ce32-0736-4bbf-8beb-f2431aee7173,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-5324222d-22fc-4b12-9c46-9b6104c7e248,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-76688c89-eef3-49e8-afb6-fe280c1256aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-7940081d-a232-4943-b03d-f17fafddcd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-97d4f1da-4e5e-477d-aaaa-68ba153db282,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-bbc22a91-1704-4fd2-8571-7a3fb2f1e156,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-c8bb9f12-4ffa-4334-81b8-101cf27596a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-cdd42bfe-de76-41eb-9186-73e57daebdb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889798492-172.17.0.19-1598113116384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35591,DS-f102ce32-0736-4bbf-8beb-f2431aee7173,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-5324222d-22fc-4b12-9c46-9b6104c7e248,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-76688c89-eef3-49e8-afb6-fe280c1256aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-7940081d-a232-4943-b03d-f17fafddcd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-97d4f1da-4e5e-477d-aaaa-68ba153db282,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-bbc22a91-1704-4fd2-8571-7a3fb2f1e156,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-c8bb9f12-4ffa-4334-81b8-101cf27596a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-cdd42bfe-de76-41eb-9186-73e57daebdb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048322402-172.17.0.19-1598113181629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42721,DS-4be537e6-8703-452a-ba25-3cb45dd5145b,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-26c4db4d-8384-402a-afdd-2e14c9703c87,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-255c7b09-6efe-4b48-9412-cf4bab7746df,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-504bbbdc-4d12-4614-ad06-3b7b958883f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-8db3895b-457d-4bd4-bce8-03b529c161fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-122ea187-9a1d-4b3d-8626-be93f0f4e1af,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-3803d9e2-251c-4eac-9bdd-5676cf97912d,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-5c336e7d-812a-4d76-a134-a84aedbbb111,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048322402-172.17.0.19-1598113181629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42721,DS-4be537e6-8703-452a-ba25-3cb45dd5145b,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-26c4db4d-8384-402a-afdd-2e14c9703c87,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-255c7b09-6efe-4b48-9412-cf4bab7746df,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-504bbbdc-4d12-4614-ad06-3b7b958883f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-8db3895b-457d-4bd4-bce8-03b529c161fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-122ea187-9a1d-4b3d-8626-be93f0f4e1af,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-3803d9e2-251c-4eac-9bdd-5676cf97912d,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-5c336e7d-812a-4d76-a134-a84aedbbb111,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-810790488-172.17.0.19-1598113209375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43581,DS-877bb1f5-16f5-4692-9af1-074363333d12,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-33f396a9-b249-4f4c-b7c7-186992835ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-0ceae1cf-cf33-41cc-91f4-c61f25fa35fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-0dbc0c17-a977-4cd9-a6ce-6715314d433d,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-2ad4d9ef-7f06-4db1-89ff-2ea5f741a1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-e88634fd-2dca-4e06-ab96-21592735f6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-f8293973-8421-4d90-b470-74d12f817729,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-a3b5d40d-2cf4-43e7-9217-35d98ad182c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-810790488-172.17.0.19-1598113209375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43581,DS-877bb1f5-16f5-4692-9af1-074363333d12,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-33f396a9-b249-4f4c-b7c7-186992835ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-0ceae1cf-cf33-41cc-91f4-c61f25fa35fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-0dbc0c17-a977-4cd9-a6ce-6715314d433d,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-2ad4d9ef-7f06-4db1-89ff-2ea5f741a1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-e88634fd-2dca-4e06-ab96-21592735f6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-f8293973-8421-4d90-b470-74d12f817729,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-a3b5d40d-2cf4-43e7-9217-35d98ad182c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584884088-172.17.0.19-1598113745924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40180,DS-8a89debd-97b1-4a50-9a4e-a61961555c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-1961078b-d2e0-4690-ac20-bc90815f9e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-9c669cc9-eaf7-4f7f-be50-eb29f4bfa524,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-b5053524-fdbe-4f7e-ad9f-2bb12127d5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-37a0bc1e-c65c-418c-b0e5-f35913d7d3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-c05d44a3-1400-4d7d-92dd-bd12ff7e21e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-963314cf-83b5-4d70-bf67-c851f746bf49,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-1b45f698-56b0-4baf-8754-3d77c63ef3e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584884088-172.17.0.19-1598113745924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40180,DS-8a89debd-97b1-4a50-9a4e-a61961555c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-1961078b-d2e0-4690-ac20-bc90815f9e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-9c669cc9-eaf7-4f7f-be50-eb29f4bfa524,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-b5053524-fdbe-4f7e-ad9f-2bb12127d5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-37a0bc1e-c65c-418c-b0e5-f35913d7d3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-c05d44a3-1400-4d7d-92dd-bd12ff7e21e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-963314cf-83b5-4d70-bf67-c851f746bf49,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-1b45f698-56b0-4baf-8754-3d77c63ef3e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535378694-172.17.0.19-1598114197231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41445,DS-5c1b6690-7d7e-4a1b-84f5-a0b0672ec1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-c96cf98d-a16c-48b7-8689-76abed769b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-2819a3d2-9d6b-4fb2-8cb0-b025fad4fcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-28dd54c4-41fc-46c2-9840-47d69251a9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-7ac8c62d-14bf-4f88-8f5f-6a8e0c375b35,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-d3a4b6c3-b53c-47de-bf12-66bd29f70e44,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-22a07443-e79a-42b3-8d83-35a5c5f8b2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-2dee16dd-494f-4390-9328-bde6d2c21e3a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535378694-172.17.0.19-1598114197231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41445,DS-5c1b6690-7d7e-4a1b-84f5-a0b0672ec1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-c96cf98d-a16c-48b7-8689-76abed769b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-2819a3d2-9d6b-4fb2-8cb0-b025fad4fcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-28dd54c4-41fc-46c2-9840-47d69251a9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-7ac8c62d-14bf-4f88-8f5f-6a8e0c375b35,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-d3a4b6c3-b53c-47de-bf12-66bd29f70e44,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-22a07443-e79a-42b3-8d83-35a5c5f8b2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-2dee16dd-494f-4390-9328-bde6d2c21e3a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207502904-172.17.0.19-1598114662148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35379,DS-9febc603-ac8a-497f-82ab-5317fd95cb38,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-378d9cb5-08e8-4dfb-9724-0378546b66ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-598edba4-5194-4706-9639-a96a4f4c481f,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-f7f766a5-f246-4499-92e7-a35d1f9616c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-8e96a063-b8f7-4868-ad2b-e6f899eb4c83,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-45e21923-ddd6-4339-b2d5-ffdd404821f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-21c65226-14cd-48a3-beb1-fc99f7bef335,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-c04bd200-3fc2-412a-8f78-9250a2dd35cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207502904-172.17.0.19-1598114662148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35379,DS-9febc603-ac8a-497f-82ab-5317fd95cb38,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-378d9cb5-08e8-4dfb-9724-0378546b66ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-598edba4-5194-4706-9639-a96a4f4c481f,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-f7f766a5-f246-4499-92e7-a35d1f9616c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-8e96a063-b8f7-4868-ad2b-e6f899eb4c83,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-45e21923-ddd6-4339-b2d5-ffdd404821f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-21c65226-14cd-48a3-beb1-fc99f7bef335,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-c04bd200-3fc2-412a-8f78-9250a2dd35cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371094301-172.17.0.19-1598114703045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35399,DS-39da62be-52de-4678-a2f0-0fec74fa9b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-d79fc87f-95eb-435c-947f-9e246ebd21bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-7bb97bad-0ef7-4a4a-af16-26962e72242e,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-f5e238ac-da4a-44e7-945c-0fb5ef147ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-3cc36df3-4854-41a5-9147-e3f9a7bdde00,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-3f38baff-1c7d-4f12-a3e8-b7b45a003d44,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-4ab8e835-732f-4005-ab16-a0e539793876,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-761c76b1-0218-4b6e-8550-8bd15b4e1234,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-371094301-172.17.0.19-1598114703045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35399,DS-39da62be-52de-4678-a2f0-0fec74fa9b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-d79fc87f-95eb-435c-947f-9e246ebd21bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-7bb97bad-0ef7-4a4a-af16-26962e72242e,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-f5e238ac-da4a-44e7-945c-0fb5ef147ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-3cc36df3-4854-41a5-9147-e3f9a7bdde00,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-3f38baff-1c7d-4f12-a3e8-b7b45a003d44,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-4ab8e835-732f-4005-ab16-a0e539793876,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-761c76b1-0218-4b6e-8550-8bd15b4e1234,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609046283-172.17.0.19-1598114870313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33599,DS-62639f5d-a60b-4ef2-8ca7-88c8b46fb85d,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-240acc3f-c91d-4e4f-b24b-26ab67df56aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-321474c5-d2c7-4b90-a7e0-f5bd7ad6d864,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-4df05490-3e3a-47ee-8958-a3fc1ed23e11,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-9b691da4-2b17-40d1-b3bc-1f35e2399fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-ef760330-3358-4645-bfa9-a3e2a6459a34,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-763db5d0-a822-48f7-b64a-dc2b710aaf79,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-06137faa-3782-4630-b54a-849af2f70a3a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609046283-172.17.0.19-1598114870313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33599,DS-62639f5d-a60b-4ef2-8ca7-88c8b46fb85d,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-240acc3f-c91d-4e4f-b24b-26ab67df56aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-321474c5-d2c7-4b90-a7e0-f5bd7ad6d864,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-4df05490-3e3a-47ee-8958-a3fc1ed23e11,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-9b691da4-2b17-40d1-b3bc-1f35e2399fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-ef760330-3358-4645-bfa9-a3e2a6459a34,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-763db5d0-a822-48f7-b64a-dc2b710aaf79,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-06137faa-3782-4630-b54a-849af2f70a3a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702126890-172.17.0.19-1598115115415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36383,DS-e2868b22-219c-4d4f-a513-e1234c70ed0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-59abfc76-d65f-49af-b571-d703f08fec6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-58370823-f070-4630-9fb0-3cf8ce720977,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-c080b89f-d050-431e-954b-669a5a8e6a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-b100cfcd-0119-48a5-b737-a7f32dc8ad24,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-94821ae1-a535-499b-a115-8b7a7aed7869,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-b4feacb7-7ca8-4cf7-829e-a26752560e34,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-04365051-dfda-4569-990e-3b4f5937e43a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702126890-172.17.0.19-1598115115415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36383,DS-e2868b22-219c-4d4f-a513-e1234c70ed0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-59abfc76-d65f-49af-b571-d703f08fec6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-58370823-f070-4630-9fb0-3cf8ce720977,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-c080b89f-d050-431e-954b-669a5a8e6a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-b100cfcd-0119-48a5-b737-a7f32dc8ad24,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-94821ae1-a535-499b-a115-8b7a7aed7869,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-b4feacb7-7ca8-4cf7-829e-a26752560e34,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-04365051-dfda-4569-990e-3b4f5937e43a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81350090-172.17.0.19-1598115215887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43715,DS-276165df-9ccf-4dd7-beb3-35184f890288,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-5fe02a4a-35b8-464f-8a55-a303cc9327b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-bee2f92b-ee54-4040-9e07-74dd4c12a87c,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-bee4c4c1-b501-4e0d-b7c7-ce85440040a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-80a02abe-857e-4f98-be3b-4168ae2f6f36,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-8155a279-4bb3-407c-bee0-6c22f440e692,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-6e03c4d9-d54a-41d0-a1fd-fcbcc9cc5026,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-6b1a9745-e5f3-4b81-81e1-6e618caf3d63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81350090-172.17.0.19-1598115215887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43715,DS-276165df-9ccf-4dd7-beb3-35184f890288,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-5fe02a4a-35b8-464f-8a55-a303cc9327b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-bee2f92b-ee54-4040-9e07-74dd4c12a87c,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-bee4c4c1-b501-4e0d-b7c7-ce85440040a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-80a02abe-857e-4f98-be3b-4168ae2f6f36,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-8155a279-4bb3-407c-bee0-6c22f440e692,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-6e03c4d9-d54a-41d0-a1fd-fcbcc9cc5026,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-6b1a9745-e5f3-4b81-81e1-6e618caf3d63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107048843-172.17.0.19-1598115351868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42733,DS-69244670-9421-4b1f-979a-7d8253de16fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-16c50ac1-18ba-4cd9-ba56-912ea581cae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-0f0d0aef-c0e7-420a-bce6-eb5e5e9d6083,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-9722257b-12b2-4a1b-86c9-9462743ea052,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-b638601e-c03b-4693-bb5f-72100f1dbc90,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-f5a788fd-b355-42f2-9717-f17886897c72,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-891f1a49-fda3-4af5-bef4-a919e547c391,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-8127ae1c-6ba3-4b25-8306-0186e13b9531,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107048843-172.17.0.19-1598115351868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42733,DS-69244670-9421-4b1f-979a-7d8253de16fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-16c50ac1-18ba-4cd9-ba56-912ea581cae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-0f0d0aef-c0e7-420a-bce6-eb5e5e9d6083,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-9722257b-12b2-4a1b-86c9-9462743ea052,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-b638601e-c03b-4693-bb5f-72100f1dbc90,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-f5a788fd-b355-42f2-9717-f17886897c72,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-891f1a49-fda3-4af5-bef4-a919e547c391,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-8127ae1c-6ba3-4b25-8306-0186e13b9531,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094333555-172.17.0.19-1598115454099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44788,DS-30ef174e-3def-4264-8474-46162a5a8b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-3b24e3bb-59c6-45c2-9f0b-a64e0d9cc4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-8f16fb4c-ab5b-405a-93c0-d7728f2bc35e,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-702de5c0-ead6-47ae-bdca-10d9cb77b026,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-d9221a96-dbd9-40f8-bb8b-58dcda71e217,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-d1b1fba1-03c9-4e3d-8d18-f8e6dacf5c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-eed8eef2-5cb4-4ac3-8772-750603fd7511,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-707352f8-7753-4bce-9342-22bc3b4a43e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094333555-172.17.0.19-1598115454099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44788,DS-30ef174e-3def-4264-8474-46162a5a8b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-3b24e3bb-59c6-45c2-9f0b-a64e0d9cc4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-8f16fb4c-ab5b-405a-93c0-d7728f2bc35e,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-702de5c0-ead6-47ae-bdca-10d9cb77b026,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-d9221a96-dbd9-40f8-bb8b-58dcda71e217,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-d1b1fba1-03c9-4e3d-8d18-f8e6dacf5c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-eed8eef2-5cb4-4ac3-8772-750603fd7511,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-707352f8-7753-4bce-9342-22bc3b4a43e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899362334-172.17.0.19-1598115486043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46719,DS-c6a1341b-f509-4149-8b8a-2dd9b7489527,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-bf43de9f-43dc-4371-a421-8ad7a29c4369,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-7becefe1-ed4b-4e2a-a198-b9716c77ccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-ef7efd73-581a-4deb-893c-187bf5b4d24c,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-f037fed3-3afb-46a8-9aa6-f1a83463383f,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-823607d5-cffe-4b94-8676-e36d04cba01b,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-811d2746-3c6d-4ef4-80ed-055ad13124fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-d35cfd22-368e-4a8e-a997-e926626742b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899362334-172.17.0.19-1598115486043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46719,DS-c6a1341b-f509-4149-8b8a-2dd9b7489527,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-bf43de9f-43dc-4371-a421-8ad7a29c4369,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-7becefe1-ed4b-4e2a-a198-b9716c77ccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-ef7efd73-581a-4deb-893c-187bf5b4d24c,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-f037fed3-3afb-46a8-9aa6-f1a83463383f,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-823607d5-cffe-4b94-8676-e36d04cba01b,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-811d2746-3c6d-4ef4-80ed-055ad13124fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-d35cfd22-368e-4a8e-a997-e926626742b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423894083-172.17.0.19-1598115843000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41155,DS-af452d21-aa79-4e64-86cf-902e92d3e68f,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-ef67ff2e-28c9-4229-8a06-c4c8c922e734,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-402059d5-28db-4ea7-93f6-55aa249c0886,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-d5f725aa-f2d5-4dc7-ac26-d0f5193097b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-5827fff7-793b-4fc9-ac15-183f82c560c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-71483f01-cace-4057-9cc2-9471d75310b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-4cee7e12-18b4-4930-9182-1acbb7cf6c49,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-fc248bf8-9bf4-4f91-9584-1715fe23af6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423894083-172.17.0.19-1598115843000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41155,DS-af452d21-aa79-4e64-86cf-902e92d3e68f,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-ef67ff2e-28c9-4229-8a06-c4c8c922e734,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-402059d5-28db-4ea7-93f6-55aa249c0886,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-d5f725aa-f2d5-4dc7-ac26-d0f5193097b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-5827fff7-793b-4fc9-ac15-183f82c560c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-71483f01-cace-4057-9cc2-9471d75310b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-4cee7e12-18b4-4930-9182-1acbb7cf6c49,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-fc248bf8-9bf4-4f91-9584-1715fe23af6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912307379-172.17.0.19-1598115974096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40546,DS-3ea62fc6-19ab-485c-90c5-02496170ac6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-9a47202e-1442-4661-b39a-be4c6c89479c,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-42e3553c-c77f-45e8-8e5f-6e96a657081b,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-e764a8b1-1005-4247-af00-35cefb1c3e32,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-0adff3a3-156f-4241-acf8-eabb7522b4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-38513742-139f-4ca3-b2dd-5e229a91e524,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-c5a57f2e-5547-4f1d-b77c-22d83e8cbb92,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-08b2f460-579f-42b5-9da3-e915f18b3f63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912307379-172.17.0.19-1598115974096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40546,DS-3ea62fc6-19ab-485c-90c5-02496170ac6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-9a47202e-1442-4661-b39a-be4c6c89479c,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-42e3553c-c77f-45e8-8e5f-6e96a657081b,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-e764a8b1-1005-4247-af00-35cefb1c3e32,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-0adff3a3-156f-4241-acf8-eabb7522b4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-38513742-139f-4ca3-b2dd-5e229a91e524,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-c5a57f2e-5547-4f1d-b77c-22d83e8cbb92,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-08b2f460-579f-42b5-9da3-e915f18b3f63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030330629-172.17.0.19-1598116179060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41722,DS-ca4c0779-522f-46d9-a7a2-611a9c746813,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-61fbc824-cfb8-4577-be54-6595a98ecfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-c1f43f61-8709-420a-8822-9e8e6a3520b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-a0d0263c-be77-472d-88d0-84ad6d0c055a,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-a08560b9-2fbb-4356-babd-63fdabe32fee,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-af531151-f178-44fb-baf0-ff725e694785,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-14b3cea3-ea18-4cef-a186-61af3697cffc,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-d887e8b4-5f70-4e28-a468-3abc6ac9ff2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030330629-172.17.0.19-1598116179060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41722,DS-ca4c0779-522f-46d9-a7a2-611a9c746813,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-61fbc824-cfb8-4577-be54-6595a98ecfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-c1f43f61-8709-420a-8822-9e8e6a3520b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-a0d0263c-be77-472d-88d0-84ad6d0c055a,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-a08560b9-2fbb-4356-babd-63fdabe32fee,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-af531151-f178-44fb-baf0-ff725e694785,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-14b3cea3-ea18-4cef-a186-61af3697cffc,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-d887e8b4-5f70-4e28-a468-3abc6ac9ff2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237828013-172.17.0.19-1598116243221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45061,DS-112e854e-b2fb-4b42-ab75-e8328c373216,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-c73af582-500d-44ba-9c84-b782f17ff260,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-7198422b-5f6f-45fc-8d43-281ff75dbe29,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-d6fbea66-36af-44ac-960b-83ae286134a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-6e75ba20-87e5-4d68-8ac5-697c701383ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-df340489-f8f5-4d61-98d3-24d5c10865f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-7b49471b-e009-4aca-9abd-b42cebd3e00a,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-ca5dc68e-e25c-49c1-a009-7002da2d51ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237828013-172.17.0.19-1598116243221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45061,DS-112e854e-b2fb-4b42-ab75-e8328c373216,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-c73af582-500d-44ba-9c84-b782f17ff260,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-7198422b-5f6f-45fc-8d43-281ff75dbe29,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-d6fbea66-36af-44ac-960b-83ae286134a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-6e75ba20-87e5-4d68-8ac5-697c701383ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-df340489-f8f5-4d61-98d3-24d5c10865f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-7b49471b-e009-4aca-9abd-b42cebd3e00a,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-ca5dc68e-e25c-49c1-a009-7002da2d51ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590735036-172.17.0.19-1598116544378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-4b984b9b-9145-430f-ac4b-5825fbe4df60,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-3a3046b8-ecd3-4bdb-abbd-25ac802f7f11,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-b4a1c9f5-42e8-4634-b7ee-d36f7a3557e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-4efba67b-a012-4f26-a914-af2f96ce2b16,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-f1d57571-ce29-42b8-93f2-ca82509b48dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-a27623c3-b22d-4641-8242-d25b5577f932,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-91bf4db3-3534-48ac-a762-9123a73faca9,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-7bb6ca52-25ac-4e43-b489-2edba10eac22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590735036-172.17.0.19-1598116544378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-4b984b9b-9145-430f-ac4b-5825fbe4df60,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-3a3046b8-ecd3-4bdb-abbd-25ac802f7f11,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-b4a1c9f5-42e8-4634-b7ee-d36f7a3557e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-4efba67b-a012-4f26-a914-af2f96ce2b16,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-f1d57571-ce29-42b8-93f2-ca82509b48dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-a27623c3-b22d-4641-8242-d25b5577f932,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-91bf4db3-3534-48ac-a762-9123a73faca9,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-7bb6ca52-25ac-4e43-b489-2edba10eac22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911175524-172.17.0.19-1598117228791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34722,DS-2322e659-8e53-4c6f-88f4-915df4752313,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-d26f5bbc-9ce1-4612-84c6-c08a3bc8d841,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-00a85d01-9085-472f-b1e7-6ae49e704d13,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-da18466c-435a-4624-9894-7d9d3230f9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-e83d51ec-cdff-44e1-ab73-73b00d07e958,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-c5f043d5-196c-4b2d-88f7-730e1318d5be,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-ccc3bcb8-a93a-47a9-8f4d-8ee24827768f,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-2a01703c-d81d-4e7f-ad9d-d7d3c07573d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911175524-172.17.0.19-1598117228791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34722,DS-2322e659-8e53-4c6f-88f4-915df4752313,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-d26f5bbc-9ce1-4612-84c6-c08a3bc8d841,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-00a85d01-9085-472f-b1e7-6ae49e704d13,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-da18466c-435a-4624-9894-7d9d3230f9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-e83d51ec-cdff-44e1-ab73-73b00d07e958,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-c5f043d5-196c-4b2d-88f7-730e1318d5be,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-ccc3bcb8-a93a-47a9-8f4d-8ee24827768f,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-2a01703c-d81d-4e7f-ad9d-d7d3c07573d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853549914-172.17.0.19-1598117288970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38870,DS-5d78d508-6691-4f38-8510-0403e269345c,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-e427f686-4ee7-476d-b2d5-4766bb02f0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-36acf49e-e84a-4bef-8d4f-5aea8a1651f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-5645542a-e7f7-4ba8-8985-d9742a53b1be,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-691c55aa-8503-4345-9d43-7452e0a9f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-fd1c47c5-269f-4eeb-800b-44a5d2182db0,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-e5d2b676-d2cc-41ea-b1da-940c4766c160,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-9e899fce-01c5-4915-aa5b-3ea111476330,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853549914-172.17.0.19-1598117288970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38870,DS-5d78d508-6691-4f38-8510-0403e269345c,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-e427f686-4ee7-476d-b2d5-4766bb02f0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-36acf49e-e84a-4bef-8d4f-5aea8a1651f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-5645542a-e7f7-4ba8-8985-d9742a53b1be,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-691c55aa-8503-4345-9d43-7452e0a9f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-fd1c47c5-269f-4eeb-800b-44a5d2182db0,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-e5d2b676-d2cc-41ea-b1da-940c4766c160,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-9e899fce-01c5-4915-aa5b-3ea111476330,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5004
