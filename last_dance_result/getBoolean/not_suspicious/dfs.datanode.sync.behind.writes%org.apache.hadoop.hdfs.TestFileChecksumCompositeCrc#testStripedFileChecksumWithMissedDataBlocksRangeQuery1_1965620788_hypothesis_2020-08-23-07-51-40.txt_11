reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835905190-172.17.0.18-1598169749324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38255,DS-57610416-ddef-4567-a453-ae4cf1805aee,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-24ce7860-0d75-411a-83f5-da9e824ece7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-59d38ab6-eae7-4c8d-b41d-5936d6f5f3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-62247545-18e9-44f4-95ab-9901f2057514,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-452a31c0-175c-4e82-9e14-23d3271d3e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-ece98ff1-ea4a-4a3c-90ac-08456b6ab7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-0e712d9c-61be-431d-b989-8c74af5f6e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-a17d5c1b-b18d-420a-8df8-225b19c4bc16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835905190-172.17.0.18-1598169749324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38255,DS-57610416-ddef-4567-a453-ae4cf1805aee,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-24ce7860-0d75-411a-83f5-da9e824ece7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-59d38ab6-eae7-4c8d-b41d-5936d6f5f3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-62247545-18e9-44f4-95ab-9901f2057514,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-452a31c0-175c-4e82-9e14-23d3271d3e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-ece98ff1-ea4a-4a3c-90ac-08456b6ab7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-0e712d9c-61be-431d-b989-8c74af5f6e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-a17d5c1b-b18d-420a-8df8-225b19c4bc16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987693740-172.17.0.18-1598169855635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38668,DS-a24f2913-8e2a-4c11-8671-64560045e213,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-9f909442-7b7a-43aa-84c7-4521602c6bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-2eede4a1-aa49-4d3f-a157-dd0ef9e4f716,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-bd902c5a-9749-45df-9f98-318f1467e12b,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-8d065221-ac83-4619-bd6b-ba56383ed072,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-c8f8f80d-7713-4581-9a2c-6bafe9d162e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-56fb30c0-793e-4456-a5fb-0503ba0d668d,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-306a11a8-c018-4405-b1f2-76494a6ef158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987693740-172.17.0.18-1598169855635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38668,DS-a24f2913-8e2a-4c11-8671-64560045e213,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-9f909442-7b7a-43aa-84c7-4521602c6bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-2eede4a1-aa49-4d3f-a157-dd0ef9e4f716,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-bd902c5a-9749-45df-9f98-318f1467e12b,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-8d065221-ac83-4619-bd6b-ba56383ed072,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-c8f8f80d-7713-4581-9a2c-6bafe9d162e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-56fb30c0-793e-4456-a5fb-0503ba0d668d,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-306a11a8-c018-4405-b1f2-76494a6ef158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460881616-172.17.0.18-1598169923939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41612,DS-c23e7991-00ab-4a17-8782-ffa91b8c823d,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-2d230f7a-8b63-46a5-a0ec-b208531989d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-17e389df-7851-45d4-ac40-0cbae65df9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-f5798b32-9d29-4476-8388-0f6b5781fb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-6f9eb8af-8b06-4e61-8f30-16037b7b796b,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-efa7b6cc-5b49-470f-b554-a3b2506b7445,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-2d48a70a-c2b8-47df-94f3-0faf364e8910,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-093fd4c7-9daa-4fea-a6e6-d4ab2142765f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460881616-172.17.0.18-1598169923939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41612,DS-c23e7991-00ab-4a17-8782-ffa91b8c823d,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-2d230f7a-8b63-46a5-a0ec-b208531989d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-17e389df-7851-45d4-ac40-0cbae65df9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-f5798b32-9d29-4476-8388-0f6b5781fb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-6f9eb8af-8b06-4e61-8f30-16037b7b796b,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-efa7b6cc-5b49-470f-b554-a3b2506b7445,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-2d48a70a-c2b8-47df-94f3-0faf364e8910,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-093fd4c7-9daa-4fea-a6e6-d4ab2142765f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913667399-172.17.0.18-1598170069274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41526,DS-4c7f2fc4-25bc-4632-9d9e-aa36928a0178,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-8d8f90cd-a9bd-4824-af82-01d413c8a1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-f2d92e54-2ce9-471f-ba27-b6b228cf1ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-cefb66f5-0ee7-4a24-bdd6-146c135d05cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-a31abe23-5b16-4456-b446-ab66bda1223a,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-565543a0-fff5-4bd5-9226-82afd9216ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-abff1310-6665-44a1-83ef-2c2c2f676351,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-ee238790-0c31-4140-bfc0-6d63035da13b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913667399-172.17.0.18-1598170069274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41526,DS-4c7f2fc4-25bc-4632-9d9e-aa36928a0178,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-8d8f90cd-a9bd-4824-af82-01d413c8a1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-f2d92e54-2ce9-471f-ba27-b6b228cf1ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-cefb66f5-0ee7-4a24-bdd6-146c135d05cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-a31abe23-5b16-4456-b446-ab66bda1223a,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-565543a0-fff5-4bd5-9226-82afd9216ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-abff1310-6665-44a1-83ef-2c2c2f676351,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-ee238790-0c31-4140-bfc0-6d63035da13b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483679992-172.17.0.18-1598170209438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37170,DS-0e3a030b-937f-4572-b96e-828b1d8029bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-86ce6778-0d4b-4c01-ae43-93279a5f2d69,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-d9b02426-8e64-4574-b476-77bd5b545e64,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-c420fa19-e84c-413d-a8bd-851c0a7e727d,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-a4c52ec3-f8e6-43bc-9cdb-e195b99b3b42,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-781894d5-1bf1-441d-8d58-a5efb7f57ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-c7e959c3-eb4a-4481-82aa-0239d2a96481,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-4a74daa1-7a56-4a8e-a727-fc79cd4ef6f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483679992-172.17.0.18-1598170209438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37170,DS-0e3a030b-937f-4572-b96e-828b1d8029bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-86ce6778-0d4b-4c01-ae43-93279a5f2d69,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-d9b02426-8e64-4574-b476-77bd5b545e64,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-c420fa19-e84c-413d-a8bd-851c0a7e727d,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-a4c52ec3-f8e6-43bc-9cdb-e195b99b3b42,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-781894d5-1bf1-441d-8d58-a5efb7f57ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-c7e959c3-eb4a-4481-82aa-0239d2a96481,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-4a74daa1-7a56-4a8e-a727-fc79cd4ef6f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243210023-172.17.0.18-1598170277403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38964,DS-9557afc1-fbd3-4cdf-b6fe-2a83120d5df8,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-5fc99e53-d4a7-47ed-b99a-23572ac6298c,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-48d81fc2-5c10-4adb-939f-1afb1b8dcb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-9a044c18-49fc-4e29-944c-26c4bc44457e,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-7255ad6f-3e54-466e-9e4a-6a8ce869e75a,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-9f7db487-8244-42ef-8389-eb24f308e97a,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-8eddb624-a3e5-4bb2-88c6-d1bae4a61d39,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-0e378643-91a7-48ae-8e27-4accea794c75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243210023-172.17.0.18-1598170277403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38964,DS-9557afc1-fbd3-4cdf-b6fe-2a83120d5df8,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-5fc99e53-d4a7-47ed-b99a-23572ac6298c,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-48d81fc2-5c10-4adb-939f-1afb1b8dcb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-9a044c18-49fc-4e29-944c-26c4bc44457e,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-7255ad6f-3e54-466e-9e4a-6a8ce869e75a,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-9f7db487-8244-42ef-8389-eb24f308e97a,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-8eddb624-a3e5-4bb2-88c6-d1bae4a61d39,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-0e378643-91a7-48ae-8e27-4accea794c75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732373790-172.17.0.18-1598170499305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34321,DS-88327aad-a0aa-48ec-b9a5-8860f8d59ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-dbddbdcc-8b54-4adf-ac4c-cbdefb409497,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-03c828b8-8c1a-4067-86c5-4df6ba19e888,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-3bab0c05-710e-4848-b97c-5e81a0ecd291,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-db5cd418-e01d-499d-a8ea-f342c22fedd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-ad4aa763-b843-4edd-b852-fb4e8ff275c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-8fda3956-7c00-4d96-9626-e2836c4abeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-aa918ec7-7d03-4cd9-b829-8e36d39b0c9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732373790-172.17.0.18-1598170499305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34321,DS-88327aad-a0aa-48ec-b9a5-8860f8d59ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-dbddbdcc-8b54-4adf-ac4c-cbdefb409497,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-03c828b8-8c1a-4067-86c5-4df6ba19e888,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-3bab0c05-710e-4848-b97c-5e81a0ecd291,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-db5cd418-e01d-499d-a8ea-f342c22fedd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-ad4aa763-b843-4edd-b852-fb4e8ff275c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-8fda3956-7c00-4d96-9626-e2836c4abeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-aa918ec7-7d03-4cd9-b829-8e36d39b0c9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371493205-172.17.0.18-1598170535475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35127,DS-4a9dfc3d-c5ce-4849-b689-c0140cec6abe,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-e24acf6b-a554-4954-afd9-144b3bed68dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-c6d5ac12-c5cc-45f0-b3ed-15593b0199d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-8b240f7d-404e-4a33-9e00-370f6bc383aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-02bbd1e0-3a97-4888-92f6-e6de46e41eef,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-d27b303e-d1d4-4be2-906c-2a99be5b0e00,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-27ed81db-1d06-4d33-a88e-38381a774a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-adc942e4-0a0b-4615-a9e9-8b6399b426ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371493205-172.17.0.18-1598170535475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35127,DS-4a9dfc3d-c5ce-4849-b689-c0140cec6abe,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-e24acf6b-a554-4954-afd9-144b3bed68dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-c6d5ac12-c5cc-45f0-b3ed-15593b0199d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-8b240f7d-404e-4a33-9e00-370f6bc383aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-02bbd1e0-3a97-4888-92f6-e6de46e41eef,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-d27b303e-d1d4-4be2-906c-2a99be5b0e00,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-27ed81db-1d06-4d33-a88e-38381a774a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-adc942e4-0a0b-4615-a9e9-8b6399b426ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483988725-172.17.0.18-1598170905999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44925,DS-9e1a838e-4b92-4bac-84b4-e5cbcba7ade7,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-4b075988-be57-4602-a92d-1e685d8ca2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-7ec3fd9e-1de1-4094-8c3f-1c77f4083b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-8b6bbb17-4721-4894-a005-b6c78eb70eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-f27d66df-1ff8-46cd-9fed-41b5aff8fa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-48cefbb6-0f28-4e78-8e6b-57137191a9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-23c2e0d6-e87c-44a5-966b-caf9f82201dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-1a4a12c9-8292-4586-9498-d34fb9921014,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483988725-172.17.0.18-1598170905999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44925,DS-9e1a838e-4b92-4bac-84b4-e5cbcba7ade7,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-4b075988-be57-4602-a92d-1e685d8ca2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-7ec3fd9e-1de1-4094-8c3f-1c77f4083b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-8b6bbb17-4721-4894-a005-b6c78eb70eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-f27d66df-1ff8-46cd-9fed-41b5aff8fa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-48cefbb6-0f28-4e78-8e6b-57137191a9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-23c2e0d6-e87c-44a5-966b-caf9f82201dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-1a4a12c9-8292-4586-9498-d34fb9921014,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426523014-172.17.0.18-1598171205024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37683,DS-9a4a9370-7148-4ae7-b02d-21b0b4f40413,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-5342051f-65d8-476c-a95d-1a5cc77623e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-102d94d1-b33f-4b24-9953-6d96aa06dbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-2b826421-e658-4d69-9dad-89014bbaa81f,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-807c7ce9-474e-47fd-99d5-60a4a4a6ab96,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-b350c713-baa7-499e-a333-653a1ac08cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-8d8343a3-65b6-4732-ae4a-ff013ea2dff8,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-68f7dfd2-bf9c-48da-ae2e-50bd2d2fffa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426523014-172.17.0.18-1598171205024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37683,DS-9a4a9370-7148-4ae7-b02d-21b0b4f40413,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-5342051f-65d8-476c-a95d-1a5cc77623e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-102d94d1-b33f-4b24-9953-6d96aa06dbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-2b826421-e658-4d69-9dad-89014bbaa81f,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-807c7ce9-474e-47fd-99d5-60a4a4a6ab96,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-b350c713-baa7-499e-a333-653a1ac08cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-8d8343a3-65b6-4732-ae4a-ff013ea2dff8,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-68f7dfd2-bf9c-48da-ae2e-50bd2d2fffa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964516515-172.17.0.18-1598171262822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36787,DS-49e49ed3-ffb2-4106-8093-18f27bb053c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-d294f410-1915-46af-9f88-35e87040b921,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-8909798c-9600-44f6-a809-3f8ce04924f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-174ee43b-7e9d-460d-a30c-0f594d05c7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-7601c3c9-a19e-4415-9616-52c35bef07e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-159873ae-d04d-403b-9255-545aa0fd674d,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-0231e91c-3ee6-47c2-a041-eba8568cb06b,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-f7e076c4-3079-4c59-ab9d-e3420ac229b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964516515-172.17.0.18-1598171262822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36787,DS-49e49ed3-ffb2-4106-8093-18f27bb053c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-d294f410-1915-46af-9f88-35e87040b921,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-8909798c-9600-44f6-a809-3f8ce04924f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-174ee43b-7e9d-460d-a30c-0f594d05c7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-7601c3c9-a19e-4415-9616-52c35bef07e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-159873ae-d04d-403b-9255-545aa0fd674d,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-0231e91c-3ee6-47c2-a041-eba8568cb06b,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-f7e076c4-3079-4c59-ab9d-e3420ac229b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488036564-172.17.0.18-1598171504210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40635,DS-05e8418f-1d30-4ad7-80e3-a5963c957ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-bfece35e-5747-4eec-beb4-d1a5b36e9f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-da3ac426-ae56-46b3-8bbb-e9244b1d180a,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-5603b56b-ed64-4fda-93f9-c0dc19726e74,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-219fae07-f4ee-4a19-9dcb-5ce14004731a,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-2b7d72f3-c093-4c8f-8b2f-03ae21ec8f81,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-34aa251a-649e-438e-924f-366ca77f4c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-a37b6147-aa06-4a7d-9226-815eff8d0414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488036564-172.17.0.18-1598171504210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40635,DS-05e8418f-1d30-4ad7-80e3-a5963c957ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-bfece35e-5747-4eec-beb4-d1a5b36e9f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-da3ac426-ae56-46b3-8bbb-e9244b1d180a,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-5603b56b-ed64-4fda-93f9-c0dc19726e74,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-219fae07-f4ee-4a19-9dcb-5ce14004731a,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-2b7d72f3-c093-4c8f-8b2f-03ae21ec8f81,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-34aa251a-649e-438e-924f-366ca77f4c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-a37b6147-aa06-4a7d-9226-815eff8d0414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261469382-172.17.0.18-1598171933193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36195,DS-d755ba5f-d99d-4c29-84ca-28f9dc5cb695,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-96868afd-14ea-4304-bc07-8db8e4bdabd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-dca70e3d-51d5-4223-b1a0-b4c101170f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-ea95f20d-a7d9-4554-ac09-ae5b135ef141,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-e33c895f-a66d-49c7-84d6-e4a1385bc13e,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-a6c4f425-6be8-4fb5-a4a0-45e576467684,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-d2bf7ac2-6afd-4fda-be63-1696509fc422,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-bb1e4ffd-18a3-4990-ac50-888c17253a75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261469382-172.17.0.18-1598171933193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36195,DS-d755ba5f-d99d-4c29-84ca-28f9dc5cb695,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-96868afd-14ea-4304-bc07-8db8e4bdabd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-dca70e3d-51d5-4223-b1a0-b4c101170f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-ea95f20d-a7d9-4554-ac09-ae5b135ef141,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-e33c895f-a66d-49c7-84d6-e4a1385bc13e,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-a6c4f425-6be8-4fb5-a4a0-45e576467684,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-d2bf7ac2-6afd-4fda-be63-1696509fc422,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-bb1e4ffd-18a3-4990-ac50-888c17253a75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113087960-172.17.0.18-1598172189374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35427,DS-5d567969-b116-4f34-a5e4-7de48edadb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-42d3ce60-eb1a-400b-9f11-6999c5860ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-98ece1a8-4556-4d54-9d34-7af7c3ffc043,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-d5357362-be3d-4b10-93bb-f661e2dad851,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-773f51b9-a220-4326-ba41-c4e0dc66dd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-a1740bf3-175b-4963-ac20-ad0e2c3c2ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-1cbb3b89-f7e4-43cd-a8a0-2f322c754e14,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-1246c284-1454-43b5-a641-32bb3fbbc0fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113087960-172.17.0.18-1598172189374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35427,DS-5d567969-b116-4f34-a5e4-7de48edadb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-42d3ce60-eb1a-400b-9f11-6999c5860ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-98ece1a8-4556-4d54-9d34-7af7c3ffc043,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-d5357362-be3d-4b10-93bb-f661e2dad851,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-773f51b9-a220-4326-ba41-c4e0dc66dd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-a1740bf3-175b-4963-ac20-ad0e2c3c2ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-1cbb3b89-f7e4-43cd-a8a0-2f322c754e14,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-1246c284-1454-43b5-a641-32bb3fbbc0fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198322248-172.17.0.18-1598172216293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33296,DS-bceeb7d1-4748-4c57-b3e6-6c7e524ab305,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-bfcd8f0e-4827-4873-9b88-7e72e52e5301,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-4d3baa17-57cc-460c-9e43-6a4a1fabccdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-eba0e5cb-5350-48fb-8971-4b9b624d7108,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-7cd5e6ed-2261-40ae-abd2-9d5488b7af46,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-cc662f16-8bf3-44ba-9ba3-8610f0c99e86,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-6df3e7e7-2947-46f0-b03b-0e8864cf065b,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-be2a5122-edf5-42e7-a994-d2f83a9f5347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198322248-172.17.0.18-1598172216293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33296,DS-bceeb7d1-4748-4c57-b3e6-6c7e524ab305,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-bfcd8f0e-4827-4873-9b88-7e72e52e5301,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-4d3baa17-57cc-460c-9e43-6a4a1fabccdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-eba0e5cb-5350-48fb-8971-4b9b624d7108,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-7cd5e6ed-2261-40ae-abd2-9d5488b7af46,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-cc662f16-8bf3-44ba-9ba3-8610f0c99e86,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-6df3e7e7-2947-46f0-b03b-0e8864cf065b,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-be2a5122-edf5-42e7-a994-d2f83a9f5347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251408192-172.17.0.18-1598172420594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46267,DS-2df7e301-8ed8-4c99-a7bd-ee30f1472eca,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-76df615e-21a9-4e8d-8151-ae21b9d8e571,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-e6e2b7bf-0eeb-4612-9815-1eb3fe2a5792,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-3c40ade3-fde4-410e-bcd7-5e25c206f35b,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-aa5d7ea0-748f-4d83-8978-8b489d560bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-0dde12a8-8d79-488b-8ef1-473e4a293838,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-73b4b68f-22e2-4fc4-b58a-425c4f206094,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-f2d68ad5-42c8-46d6-8d1d-f0b7e255a7fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251408192-172.17.0.18-1598172420594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46267,DS-2df7e301-8ed8-4c99-a7bd-ee30f1472eca,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-76df615e-21a9-4e8d-8151-ae21b9d8e571,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-e6e2b7bf-0eeb-4612-9815-1eb3fe2a5792,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-3c40ade3-fde4-410e-bcd7-5e25c206f35b,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-aa5d7ea0-748f-4d83-8978-8b489d560bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-0dde12a8-8d79-488b-8ef1-473e4a293838,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-73b4b68f-22e2-4fc4-b58a-425c4f206094,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-f2d68ad5-42c8-46d6-8d1d-f0b7e255a7fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551589283-172.17.0.18-1598172672177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38419,DS-a1c65522-9cba-4829-b558-ffdbcbe03442,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-17dcfcf4-25d1-444c-9790-1e4c6571258d,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-02ea1b4e-984c-410d-877a-2f6beb6d3454,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-d9cd5e76-3d4e-4c61-b224-f672ed160eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-4fb1d8f7-d46e-4704-8808-c3a672a612a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-38b0bb34-f433-454d-909c-6e80dbedcf75,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-f6e5e094-b6d3-489e-9733-5dc13fe70aec,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-6ea52a11-7d6c-40e1-918b-58b7d51d289e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551589283-172.17.0.18-1598172672177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38419,DS-a1c65522-9cba-4829-b558-ffdbcbe03442,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-17dcfcf4-25d1-444c-9790-1e4c6571258d,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-02ea1b4e-984c-410d-877a-2f6beb6d3454,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-d9cd5e76-3d4e-4c61-b224-f672ed160eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-4fb1d8f7-d46e-4704-8808-c3a672a612a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-38b0bb34-f433-454d-909c-6e80dbedcf75,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-f6e5e094-b6d3-489e-9733-5dc13fe70aec,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-6ea52a11-7d6c-40e1-918b-58b7d51d289e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320153155-172.17.0.18-1598172801550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44619,DS-f8be9baa-fc64-42c8-8c7c-39fdddcec809,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-9f89e715-31e2-4bf3-b8b9-69f7e81f1672,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-9e1bb744-1db7-48ec-97ee-4ea08ca6bddd,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-8996624e-e804-43b4-9691-22d1d65afdce,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-4c17922c-802d-4219-947a-aac325858da8,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-649f3a7d-e6c8-44bd-9640-149a9b239aad,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-dce795c9-8bb5-4647-96f8-e9812dcda47f,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-eb3a78b1-4a88-4f1a-a480-e764d170b7ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320153155-172.17.0.18-1598172801550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44619,DS-f8be9baa-fc64-42c8-8c7c-39fdddcec809,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-9f89e715-31e2-4bf3-b8b9-69f7e81f1672,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-9e1bb744-1db7-48ec-97ee-4ea08ca6bddd,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-8996624e-e804-43b4-9691-22d1d65afdce,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-4c17922c-802d-4219-947a-aac325858da8,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-649f3a7d-e6c8-44bd-9640-149a9b239aad,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-dce795c9-8bb5-4647-96f8-e9812dcda47f,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-eb3a78b1-4a88-4f1a-a480-e764d170b7ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914192805-172.17.0.18-1598172828134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45839,DS-d5e0681d-6759-40a5-9330-128140cb4c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-92902623-5813-4d79-9307-440b3f5ac42c,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-88fd8aed-ed77-4a23-9e9f-f113b89787eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-f02934ec-7ed5-4271-a3e1-42eb7451a88a,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-c23ea046-41f1-4edb-9d89-4b7bdbf73259,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-7c38710f-4843-4b4a-851f-d13e30284ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-167a5ed4-6860-4fbc-8617-013865793e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-1ba36ce0-5119-45de-b47e-1ef36c5d467d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914192805-172.17.0.18-1598172828134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45839,DS-d5e0681d-6759-40a5-9330-128140cb4c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-92902623-5813-4d79-9307-440b3f5ac42c,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-88fd8aed-ed77-4a23-9e9f-f113b89787eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-f02934ec-7ed5-4271-a3e1-42eb7451a88a,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-c23ea046-41f1-4edb-9d89-4b7bdbf73259,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-7c38710f-4843-4b4a-851f-d13e30284ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-167a5ed4-6860-4fbc-8617-013865793e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-1ba36ce0-5119-45de-b47e-1ef36c5d467d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305636796-172.17.0.18-1598172893791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34523,DS-07052fdd-00a4-4b00-82e3-c7b209fadc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-c1ad4a09-a766-4caa-92e3-1e20a5dd3e26,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-109f0ed4-8436-474f-8696-ea07896f93c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-ec21f962-5302-4b45-ab30-18ae881bb7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-f441c055-0491-47e9-9c55-ee1a3e9fd9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-a9c333cc-604e-4a13-a5b6-98535161690f,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-0d854cde-0101-4684-aa4e-005ead824f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-27c656d6-5b4d-4fb2-b0ef-cf7f4d7c5a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305636796-172.17.0.18-1598172893791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34523,DS-07052fdd-00a4-4b00-82e3-c7b209fadc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-c1ad4a09-a766-4caa-92e3-1e20a5dd3e26,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-109f0ed4-8436-474f-8696-ea07896f93c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-ec21f962-5302-4b45-ab30-18ae881bb7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-f441c055-0491-47e9-9c55-ee1a3e9fd9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-a9c333cc-604e-4a13-a5b6-98535161690f,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-0d854cde-0101-4684-aa4e-005ead824f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-27c656d6-5b4d-4fb2-b0ef-cf7f4d7c5a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82044028-172.17.0.18-1598173036958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35977,DS-91f2e2cf-bd1a-4f6a-823a-f312bc2b5542,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-616ce5a6-ceaa-46b3-9719-f61cb587cb02,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-f2b7e67d-9724-48d6-8a5b-4b73d5040a26,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-4fc92b59-303c-43f3-8376-4ede218c2666,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-392374fd-8214-4e26-8998-31d05b9a8e43,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-c075b962-4413-47b3-b17e-a07fd1dc5cec,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-ccd97cc1-747c-4c5a-98bc-f77df789f744,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-7b0bb1b1-f2cd-4941-8e70-46c1ac09d05c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82044028-172.17.0.18-1598173036958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35977,DS-91f2e2cf-bd1a-4f6a-823a-f312bc2b5542,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-616ce5a6-ceaa-46b3-9719-f61cb587cb02,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-f2b7e67d-9724-48d6-8a5b-4b73d5040a26,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-4fc92b59-303c-43f3-8376-4ede218c2666,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-392374fd-8214-4e26-8998-31d05b9a8e43,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-c075b962-4413-47b3-b17e-a07fd1dc5cec,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-ccd97cc1-747c-4c5a-98bc-f77df789f744,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-7b0bb1b1-f2cd-4941-8e70-46c1ac09d05c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628433994-172.17.0.18-1598173347759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35860,DS-9161b67a-67e5-4293-acd3-f657abed49d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-78750f32-1e48-4bd2-9a46-da97074437cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-2bd28924-f515-48a7-b476-14bead9cf399,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-3d56c42c-e7a8-4e66-bcf5-1bed5b5a57e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-76d8d5c5-4e06-4fd9-9ddb-453e82747c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-404f302b-76bb-495d-8ff9-e27f4487c3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-9f62b56c-ad7d-419c-affa-176aa57da981,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-325f8780-adf0-472c-a9fd-394beafbd06f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628433994-172.17.0.18-1598173347759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35860,DS-9161b67a-67e5-4293-acd3-f657abed49d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-78750f32-1e48-4bd2-9a46-da97074437cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-2bd28924-f515-48a7-b476-14bead9cf399,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-3d56c42c-e7a8-4e66-bcf5-1bed5b5a57e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-76d8d5c5-4e06-4fd9-9ddb-453e82747c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-404f302b-76bb-495d-8ff9-e27f4487c3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-9f62b56c-ad7d-419c-affa-176aa57da981,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-325f8780-adf0-472c-a9fd-394beafbd06f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158884753-172.17.0.18-1598173442773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38824,DS-f8d566cf-d79d-4045-8025-43a1d75c1201,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-f03ff21e-4bca-4e2d-bb2c-fcae7ff40862,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-4c884e77-015a-40ff-8792-7725e0628762,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-16e8c438-05c7-42c3-b11f-d5d892b1d69e,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-c17c3da5-ecf6-47b4-9ca3-ee2fc2e9681e,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-57c27bc5-51da-4018-9f1a-b7c99291bc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-5a0d0ad7-2e28-49b4-99aa-ea1824079bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-647a88b1-bbd9-4695-93dc-dcfb3fda7634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158884753-172.17.0.18-1598173442773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38824,DS-f8d566cf-d79d-4045-8025-43a1d75c1201,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-f03ff21e-4bca-4e2d-bb2c-fcae7ff40862,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-4c884e77-015a-40ff-8792-7725e0628762,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-16e8c438-05c7-42c3-b11f-d5d892b1d69e,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-c17c3da5-ecf6-47b4-9ca3-ee2fc2e9681e,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-57c27bc5-51da-4018-9f1a-b7c99291bc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-5a0d0ad7-2e28-49b4-99aa-ea1824079bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-647a88b1-bbd9-4695-93dc-dcfb3fda7634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238183272-172.17.0.18-1598173720096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35766,DS-b8d49842-50e1-4b97-8333-fbeb5fc95e10,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-975743fd-9831-4b31-b846-842f699afaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-d3e1664d-500f-4f89-8fe3-e4c47e4a947a,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-e61bce99-15dc-4cee-9f3c-b9a759091814,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-8afbb410-ea23-4434-a251-b4188d55f0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-5c2aa4e0-9c0e-44fb-94e7-c302ed399b03,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-78b19d11-b3cf-4f24-8bca-2801e95a7427,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-d9b1ba0d-a146-4e15-8fc1-47935763dc4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238183272-172.17.0.18-1598173720096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35766,DS-b8d49842-50e1-4b97-8333-fbeb5fc95e10,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-975743fd-9831-4b31-b846-842f699afaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-d3e1664d-500f-4f89-8fe3-e4c47e4a947a,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-e61bce99-15dc-4cee-9f3c-b9a759091814,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-8afbb410-ea23-4434-a251-b4188d55f0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-5c2aa4e0-9c0e-44fb-94e7-c302ed399b03,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-78b19d11-b3cf-4f24-8bca-2801e95a7427,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-d9b1ba0d-a146-4e15-8fc1-47935763dc4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996023783-172.17.0.18-1598173751935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37802,DS-906148ba-2276-43dc-9183-ae8236af1e43,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-3b0c2396-cdf6-41d2-b2e7-908e4338ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-b9d6106a-ccce-4f6b-a0fc-af54f3538b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-b8018023-c688-4b46-97b3-4216d0675539,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-5ccdb10c-0bd0-486d-bac9-c7b69c0a1c36,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-19f26d87-e35b-488b-a7d4-f1c9196fcb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-cac96efe-d2d2-48c4-949a-39da9f03ab9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-799477e9-fbb3-4653-9506-758d428ee157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996023783-172.17.0.18-1598173751935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37802,DS-906148ba-2276-43dc-9183-ae8236af1e43,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-3b0c2396-cdf6-41d2-b2e7-908e4338ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-b9d6106a-ccce-4f6b-a0fc-af54f3538b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-b8018023-c688-4b46-97b3-4216d0675539,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-5ccdb10c-0bd0-486d-bac9-c7b69c0a1c36,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-19f26d87-e35b-488b-a7d4-f1c9196fcb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-cac96efe-d2d2-48c4-949a-39da9f03ab9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-799477e9-fbb3-4653-9506-758d428ee157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462195537-172.17.0.18-1598173825301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40055,DS-2dda1c3c-ac9d-4032-94ba-cee6318426a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-6d3001f3-81de-438e-9509-63d807e9c77d,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-785968b7-7ee2-491c-b72b-9d1ad1b2d264,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-47a49a1f-225a-4bad-b4f8-201ff3ee607d,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-c02744e4-b5d5-4ab3-8ae1-8d4c1a8964ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-519f60ed-5cc5-46a3-b102-ec68fd293d21,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-3d7e7cbc-9cb3-49c5-8367-41994faea07a,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-51b7cb17-5452-461f-b8ac-d3dd38d16026,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462195537-172.17.0.18-1598173825301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40055,DS-2dda1c3c-ac9d-4032-94ba-cee6318426a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-6d3001f3-81de-438e-9509-63d807e9c77d,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-785968b7-7ee2-491c-b72b-9d1ad1b2d264,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-47a49a1f-225a-4bad-b4f8-201ff3ee607d,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-c02744e4-b5d5-4ab3-8ae1-8d4c1a8964ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-519f60ed-5cc5-46a3-b102-ec68fd293d21,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-3d7e7cbc-9cb3-49c5-8367-41994faea07a,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-51b7cb17-5452-461f-b8ac-d3dd38d16026,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058377493-172.17.0.18-1598173985240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45276,DS-5f882649-078c-4b57-bc56-c7aa0530d509,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-95936318-58f1-493d-94bd-5f06a053c7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-1b17624a-4313-4c3b-b5c1-8e00687f8ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-b602ce78-b924-4801-a29a-159006f097a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-0a4a0afd-5771-4170-b6ae-bdc053c57e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-c8b04d17-b3ae-4cba-b9f3-2ebfbb6d0fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-9e482d91-cb1f-4a2d-83ab-d1103dd5041b,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-5a593ae9-adbf-4874-ab37-fe6a83146baf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058377493-172.17.0.18-1598173985240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45276,DS-5f882649-078c-4b57-bc56-c7aa0530d509,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-95936318-58f1-493d-94bd-5f06a053c7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-1b17624a-4313-4c3b-b5c1-8e00687f8ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-b602ce78-b924-4801-a29a-159006f097a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-0a4a0afd-5771-4170-b6ae-bdc053c57e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-c8b04d17-b3ae-4cba-b9f3-2ebfbb6d0fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-9e482d91-cb1f-4a2d-83ab-d1103dd5041b,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-5a593ae9-adbf-4874-ab37-fe6a83146baf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5059
