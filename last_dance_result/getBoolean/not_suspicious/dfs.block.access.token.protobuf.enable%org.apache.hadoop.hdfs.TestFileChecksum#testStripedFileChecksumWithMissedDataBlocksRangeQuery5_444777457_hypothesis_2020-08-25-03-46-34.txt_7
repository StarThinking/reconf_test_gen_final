reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654640936-172.17.0.5-1598327499302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37978,DS-82c065c4-7a83-4dc6-a928-a5cc394e25a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-2dc947ea-d6cd-48c0-b591-b4ff6b0cb3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-30c9e31d-b771-4619-9c7b-b135b1eaed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-ee43dd2a-c1c9-47e1-bbfb-c5eda0e63bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-ff7743f3-4010-423f-88cd-92ccfddcbafc,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-f3809bf4-8bbc-4b74-91c9-c27ca84488a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-003098c0-6b53-483a-97c3-d5d678b93827,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-1a230811-57ae-417b-8711-08018034696a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654640936-172.17.0.5-1598327499302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37978,DS-82c065c4-7a83-4dc6-a928-a5cc394e25a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-2dc947ea-d6cd-48c0-b591-b4ff6b0cb3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-30c9e31d-b771-4619-9c7b-b135b1eaed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-ee43dd2a-c1c9-47e1-bbfb-c5eda0e63bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-ff7743f3-4010-423f-88cd-92ccfddcbafc,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-f3809bf4-8bbc-4b74-91c9-c27ca84488a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-003098c0-6b53-483a-97c3-d5d678b93827,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-1a230811-57ae-417b-8711-08018034696a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946301146-172.17.0.5-1598327763144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34740,DS-395f4fc7-e461-460a-8fe7-334fa4b0c76c,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-f8dae363-8db0-4704-a586-e49c3933132f,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-0936ad44-6821-4cc2-a0e5-cdb3b736ce67,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-b63ca048-f3d6-4e2a-8859-c7dd9cc856bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-6ebd6580-ddbc-49d1-8cea-ee4a41c1b0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-33433cd2-f406-4484-b6ee-0e5cae33cdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-a1d16a0c-8eae-4633-8f7b-60459f6c70c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-fe1145fb-1a11-4368-8f19-466f1056c18d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946301146-172.17.0.5-1598327763144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34740,DS-395f4fc7-e461-460a-8fe7-334fa4b0c76c,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-f8dae363-8db0-4704-a586-e49c3933132f,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-0936ad44-6821-4cc2-a0e5-cdb3b736ce67,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-b63ca048-f3d6-4e2a-8859-c7dd9cc856bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-6ebd6580-ddbc-49d1-8cea-ee4a41c1b0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-33433cd2-f406-4484-b6ee-0e5cae33cdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-a1d16a0c-8eae-4633-8f7b-60459f6c70c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-fe1145fb-1a11-4368-8f19-466f1056c18d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66965010-172.17.0.5-1598327807730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42478,DS-f7d65e1a-48a5-4cda-8ab7-325daa4bd1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-5cc4b1db-a662-4d5c-8940-9db4c9fd7251,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-aec95ba0-155f-42c6-9812-e00ce5aed06a,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-c543ef1e-e941-4752-be6e-29ee11cdb9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-01e91efc-fecc-4aea-847f-b32d7f790601,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-f4bef5b4-892d-4ecc-8ff3-d485fd397025,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-efd8548c-cb71-4298-af53-42f0fe972556,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-d27db8a8-c332-4a1a-8709-c4e2972612cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66965010-172.17.0.5-1598327807730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42478,DS-f7d65e1a-48a5-4cda-8ab7-325daa4bd1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-5cc4b1db-a662-4d5c-8940-9db4c9fd7251,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-aec95ba0-155f-42c6-9812-e00ce5aed06a,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-c543ef1e-e941-4752-be6e-29ee11cdb9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-01e91efc-fecc-4aea-847f-b32d7f790601,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-f4bef5b4-892d-4ecc-8ff3-d485fd397025,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-efd8548c-cb71-4298-af53-42f0fe972556,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-d27db8a8-c332-4a1a-8709-c4e2972612cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961973709-172.17.0.5-1598328419837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33290,DS-f304bd4b-4179-4028-b347-32ae2d466288,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-d6cf82dd-ae91-4dc7-8674-98156a960f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-d444c553-557c-4e44-92c0-aae04cf3a093,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-d3143011-254a-4344-8d6f-cba9ab5ba9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-0d4aacef-b4e1-4bfc-baaf-02aa724abd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-1cad68a5-22ab-4388-89ee-b8493fae2042,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-142fe481-c46e-4f82-88e7-7e3a53c73ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-139da2a5-78db-44de-bf17-9f407d5085d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961973709-172.17.0.5-1598328419837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33290,DS-f304bd4b-4179-4028-b347-32ae2d466288,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-d6cf82dd-ae91-4dc7-8674-98156a960f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-d444c553-557c-4e44-92c0-aae04cf3a093,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-d3143011-254a-4344-8d6f-cba9ab5ba9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-0d4aacef-b4e1-4bfc-baaf-02aa724abd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-1cad68a5-22ab-4388-89ee-b8493fae2042,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-142fe481-c46e-4f82-88e7-7e3a53c73ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-139da2a5-78db-44de-bf17-9f407d5085d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547978422-172.17.0.5-1598328497633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40789,DS-1cc85c90-8894-4e92-8ab3-b6f7015db396,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-7ced0ff4-2a92-4455-b320-b0d4bb444c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-0f55eaf2-fb4c-47ef-b7ae-5a753c3c5654,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-893dedba-8b56-4665-af7d-34229d14ba83,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-04b8953d-b399-4bc5-a5f0-62308ba2af5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-bc341304-a0e7-49fe-ba4e-330acf36cd25,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-35fd5855-93cb-4a01-bd49-d80383cbb48f,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-cb238c29-c529-4424-bf28-f48d6becff5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547978422-172.17.0.5-1598328497633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40789,DS-1cc85c90-8894-4e92-8ab3-b6f7015db396,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-7ced0ff4-2a92-4455-b320-b0d4bb444c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-0f55eaf2-fb4c-47ef-b7ae-5a753c3c5654,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-893dedba-8b56-4665-af7d-34229d14ba83,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-04b8953d-b399-4bc5-a5f0-62308ba2af5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-bc341304-a0e7-49fe-ba4e-330acf36cd25,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-35fd5855-93cb-4a01-bd49-d80383cbb48f,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-cb238c29-c529-4424-bf28-f48d6becff5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800118030-172.17.0.5-1598329051178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41979,DS-5c6f36bd-a7ff-4c60-b2f9-c4d16acef552,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-1e9fb0f2-f696-406e-99a3-908c7316c1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-032b2579-1154-4fc8-87c2-1b0616596c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-d857fcfe-7fee-4037-8ac2-502ad1234694,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-21b96159-a165-491f-9feb-bfd3b6e51cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-f1a350d1-ed58-497b-9b55-a8f353efe502,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-a4f50b26-b55f-49ca-b149-41c47a2418b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-f7c1822b-8d9a-4ff0-aa8a-1d8040891740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1800118030-172.17.0.5-1598329051178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41979,DS-5c6f36bd-a7ff-4c60-b2f9-c4d16acef552,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-1e9fb0f2-f696-406e-99a3-908c7316c1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-032b2579-1154-4fc8-87c2-1b0616596c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-d857fcfe-7fee-4037-8ac2-502ad1234694,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-21b96159-a165-491f-9feb-bfd3b6e51cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-f1a350d1-ed58-497b-9b55-a8f353efe502,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-a4f50b26-b55f-49ca-b149-41c47a2418b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-f7c1822b-8d9a-4ff0-aa8a-1d8040891740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755873211-172.17.0.5-1598329367533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41785,DS-4962fe71-20a8-4389-877c-6d25458153fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-f405af51-4b88-4967-9d21-d5232712d146,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-85d06a32-9fb9-447b-a2b4-863d63e40683,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-4ed55352-38f4-48fd-a5cd-7f60650dc3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-0b8621cc-6d3e-45db-a75b-894b5b1d390f,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-ffab8d29-bbeb-4ed3-83cd-96cf9cf16fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-b5d767c1-12a5-4382-8c7b-a87a48b2357e,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-66991b5f-17dc-4cd2-9f01-44949d6c4105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755873211-172.17.0.5-1598329367533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41785,DS-4962fe71-20a8-4389-877c-6d25458153fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-f405af51-4b88-4967-9d21-d5232712d146,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-85d06a32-9fb9-447b-a2b4-863d63e40683,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-4ed55352-38f4-48fd-a5cd-7f60650dc3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-0b8621cc-6d3e-45db-a75b-894b5b1d390f,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-ffab8d29-bbeb-4ed3-83cd-96cf9cf16fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-b5d767c1-12a5-4382-8c7b-a87a48b2357e,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-66991b5f-17dc-4cd2-9f01-44949d6c4105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108626365-172.17.0.5-1598329548531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37991,DS-c6e67640-3536-4c90-94e6-855073ce01ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-e0ff3607-bfa3-4add-b57d-2a5009f31e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-d7ca5de0-83b8-472b-abac-fcb7afdfd7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-b4d302de-fdce-48e6-b532-52e47e6068e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-206aea66-0852-4313-a0bd-7d15363916f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-976714f9-209a-4084-8526-e28cc4267c32,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-5779ab85-4668-43ec-9ab5-42638d66eab1,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-2809d1cc-fae6-42ea-af11-60d760c6aab0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108626365-172.17.0.5-1598329548531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37991,DS-c6e67640-3536-4c90-94e6-855073ce01ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-e0ff3607-bfa3-4add-b57d-2a5009f31e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-d7ca5de0-83b8-472b-abac-fcb7afdfd7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-b4d302de-fdce-48e6-b532-52e47e6068e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-206aea66-0852-4313-a0bd-7d15363916f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-976714f9-209a-4084-8526-e28cc4267c32,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-5779ab85-4668-43ec-9ab5-42638d66eab1,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-2809d1cc-fae6-42ea-af11-60d760c6aab0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42144197-172.17.0.5-1598330015088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40318,DS-16570a4e-0c19-4dce-8f6e-795041317400,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-328802c1-e282-4ccf-820d-989dd9a6c6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-01ce84ea-3a73-46b5-a95a-b8d8b5df82e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-51827fa1-fcbf-45cc-b730-af2d023fc760,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-b222da60-bde6-47a9-810e-83bf0cb447aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-81155944-99fe-48a0-ba6b-d600553dd07c,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-e1966110-b11c-48ef-9203-8dd541df8f22,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-f8d3d90f-8913-44ce-b9e3-04fcf4b5dd12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42144197-172.17.0.5-1598330015088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40318,DS-16570a4e-0c19-4dce-8f6e-795041317400,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-328802c1-e282-4ccf-820d-989dd9a6c6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-01ce84ea-3a73-46b5-a95a-b8d8b5df82e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-51827fa1-fcbf-45cc-b730-af2d023fc760,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-b222da60-bde6-47a9-810e-83bf0cb447aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-81155944-99fe-48a0-ba6b-d600553dd07c,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-e1966110-b11c-48ef-9203-8dd541df8f22,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-f8d3d90f-8913-44ce-b9e3-04fcf4b5dd12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035292818-172.17.0.5-1598330886964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44667,DS-fb98335e-a28f-4bbd-929c-0331555f76ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-960d8603-d8ad-49cd-bebc-6dfb76d302a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-6363b48c-77f0-4268-96aa-c13111f2038e,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-6aebe6c9-3133-43fc-97b5-6f1a743b739a,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-b9fd58b5-55de-481f-8812-cef65d2c0cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-6bc028af-1de7-4399-95b7-8a5b42bc15c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-c7a18e42-ccea-451b-bc70-882412468abb,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-692867f7-1f56-48b9-b2c0-87b6791a747c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035292818-172.17.0.5-1598330886964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44667,DS-fb98335e-a28f-4bbd-929c-0331555f76ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-960d8603-d8ad-49cd-bebc-6dfb76d302a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-6363b48c-77f0-4268-96aa-c13111f2038e,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-6aebe6c9-3133-43fc-97b5-6f1a743b739a,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-b9fd58b5-55de-481f-8812-cef65d2c0cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-6bc028af-1de7-4399-95b7-8a5b42bc15c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-c7a18e42-ccea-451b-bc70-882412468abb,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-692867f7-1f56-48b9-b2c0-87b6791a747c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559774039-172.17.0.5-1598331505004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41450,DS-0dc5b0de-9cec-4b18-b8a4-2561ce0e89a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-03f4f492-4403-4f44-b578-02ea4c2bf72d,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-38490e59-167c-43eb-bb98-811ed437d585,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-dc7abba4-94bc-4695-8448-ccdd46e980cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-f97362ba-9e14-4a1d-9cac-c180d84ba027,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-748fc6a0-28c2-4dbb-832b-c1bca475e661,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-4d21c182-afad-44e9-a491-397baffa3c82,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-612fd74f-7bb6-486e-a83f-02c6f2305416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559774039-172.17.0.5-1598331505004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41450,DS-0dc5b0de-9cec-4b18-b8a4-2561ce0e89a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-03f4f492-4403-4f44-b578-02ea4c2bf72d,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-38490e59-167c-43eb-bb98-811ed437d585,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-dc7abba4-94bc-4695-8448-ccdd46e980cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-f97362ba-9e14-4a1d-9cac-c180d84ba027,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-748fc6a0-28c2-4dbb-832b-c1bca475e661,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-4d21c182-afad-44e9-a491-397baffa3c82,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-612fd74f-7bb6-486e-a83f-02c6f2305416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307243677-172.17.0.5-1598332609586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36055,DS-4ddbff1c-5e23-4562-b419-b65a50fddcee,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-b399ee46-ed07-4b20-9f40-441d52ff2a20,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-a9c1b284-b9ca-4180-9297-eb38964dbf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-6af582fc-32f1-4107-91cf-aca091962473,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-dbee53b4-88fc-45f8-bf74-727d1eed958a,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-84370ffb-5557-4093-a0ac-41a075cda223,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-27d2a1f7-8488-4f52-9641-fe86b7f2f681,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-f8877908-ba3e-41d4-ba7d-7b916991cbe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307243677-172.17.0.5-1598332609586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36055,DS-4ddbff1c-5e23-4562-b419-b65a50fddcee,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-b399ee46-ed07-4b20-9f40-441d52ff2a20,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-a9c1b284-b9ca-4180-9297-eb38964dbf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-6af582fc-32f1-4107-91cf-aca091962473,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-dbee53b4-88fc-45f8-bf74-727d1eed958a,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-84370ffb-5557-4093-a0ac-41a075cda223,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-27d2a1f7-8488-4f52-9641-fe86b7f2f681,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-f8877908-ba3e-41d4-ba7d-7b916991cbe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5478
