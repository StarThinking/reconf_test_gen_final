reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859831514-172.17.0.11-1598394734862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33779,DS-dfc6d49e-0ddb-4916-a88b-658909cb5ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-f1b4d8b3-85e0-4a00-8f58-cf28987d9021,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-be279a48-4417-4ae4-a185-42d399fd3417,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-7438cd98-9011-4670-980d-352bbaa3064b,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-fe67ed32-c36c-49b3-8484-95b5368d5583,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-1befbd1a-5367-4698-b4ff-63c61ad0d799,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-ce5defab-9deb-4ca3-b615-066fe45879fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-e677dae2-197a-4918-b872-d6232e788b29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859831514-172.17.0.11-1598394734862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33779,DS-dfc6d49e-0ddb-4916-a88b-658909cb5ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-f1b4d8b3-85e0-4a00-8f58-cf28987d9021,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-be279a48-4417-4ae4-a185-42d399fd3417,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-7438cd98-9011-4670-980d-352bbaa3064b,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-fe67ed32-c36c-49b3-8484-95b5368d5583,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-1befbd1a-5367-4698-b4ff-63c61ad0d799,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-ce5defab-9deb-4ca3-b615-066fe45879fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-e677dae2-197a-4918-b872-d6232e788b29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465396170-172.17.0.11-1598394810807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43270,DS-8ca977ed-d24c-425a-a12e-58d26e4a88d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-8ec8dae3-5e1e-49c4-971a-5393e8ce6ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-f6f216de-d935-40f1-aa7a-705f3bcad517,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-fe5c6fa8-2b26-4dca-9ec7-f2b05f21b5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-ef34e658-9ba5-408b-8295-9593a46030cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-ddeacdd7-3ab7-4803-8f07-7e696771665f,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-0509bd5e-8ef1-4259-aec2-b0788dd00fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-aa2e85a7-40bb-4309-a644-e6f2b76df06e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465396170-172.17.0.11-1598394810807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43270,DS-8ca977ed-d24c-425a-a12e-58d26e4a88d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-8ec8dae3-5e1e-49c4-971a-5393e8ce6ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-f6f216de-d935-40f1-aa7a-705f3bcad517,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-fe5c6fa8-2b26-4dca-9ec7-f2b05f21b5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-ef34e658-9ba5-408b-8295-9593a46030cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-ddeacdd7-3ab7-4803-8f07-7e696771665f,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-0509bd5e-8ef1-4259-aec2-b0788dd00fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-aa2e85a7-40bb-4309-a644-e6f2b76df06e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339490550-172.17.0.11-1598394997791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40182,DS-7c71b416-aa18-4127-81ae-1cfd516f4510,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-43fb8330-bd1c-43b4-be3c-3491048286b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-db58c9ea-f88e-4a6b-8b2f-59d774b1359f,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-cbf21058-494d-4051-9211-a1710ad2a365,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-3f0e729a-aa06-4f7c-8560-581a44d685a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-94b363c8-5ff5-4c20-bc29-3386591742ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-f5d9fe28-a6fe-4862-8540-e12a60575390,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-499c17b7-97ee-455e-972b-58046cf36719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339490550-172.17.0.11-1598394997791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40182,DS-7c71b416-aa18-4127-81ae-1cfd516f4510,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-43fb8330-bd1c-43b4-be3c-3491048286b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-db58c9ea-f88e-4a6b-8b2f-59d774b1359f,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-cbf21058-494d-4051-9211-a1710ad2a365,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-3f0e729a-aa06-4f7c-8560-581a44d685a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-94b363c8-5ff5-4c20-bc29-3386591742ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-f5d9fe28-a6fe-4862-8540-e12a60575390,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-499c17b7-97ee-455e-972b-58046cf36719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188943431-172.17.0.11-1598395265684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43047,DS-15f74ffb-9013-4176-bfe0-e555f3d67719,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-0a4232eb-874a-4566-b94b-d868f9ff85cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-b26fbf32-d4ec-4063-a399-b6cfb3c7a628,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-43f0a3cc-0748-48b8-97d7-a62cb05b38d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-ba29ae58-198b-4bb5-a0e4-bd8e1d4c17f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-5145b391-6955-407d-ab7d-b0d05979ece1,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-3ccdebef-3da7-4d35-9f9c-2e9f8eafe7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-63a93832-5261-4de4-85f3-bcceada595b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188943431-172.17.0.11-1598395265684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43047,DS-15f74ffb-9013-4176-bfe0-e555f3d67719,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-0a4232eb-874a-4566-b94b-d868f9ff85cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-b26fbf32-d4ec-4063-a399-b6cfb3c7a628,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-43f0a3cc-0748-48b8-97d7-a62cb05b38d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-ba29ae58-198b-4bb5-a0e4-bd8e1d4c17f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-5145b391-6955-407d-ab7d-b0d05979ece1,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-3ccdebef-3da7-4d35-9f9c-2e9f8eafe7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-63a93832-5261-4de4-85f3-bcceada595b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351079575-172.17.0.11-1598395820429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36841,DS-e8db69c7-d1f8-47a1-bf70-cc1a4429a8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-1f5ff047-a1d1-4f46-af00-4c745c7463a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-16126553-fce1-4463-b077-8742293b465e,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-d9306789-e036-4167-8287-ac983acd7522,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-fe3748b8-972c-4790-84cb-103cdb8a0823,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-05a2eb1b-e29b-478d-979d-382c9394bef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-d886e52a-9f85-4d91-b585-c927ef693ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-ffc41bc0-5597-4c55-8b75-7fb28a5e7551,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351079575-172.17.0.11-1598395820429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36841,DS-e8db69c7-d1f8-47a1-bf70-cc1a4429a8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-1f5ff047-a1d1-4f46-af00-4c745c7463a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-16126553-fce1-4463-b077-8742293b465e,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-d9306789-e036-4167-8287-ac983acd7522,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-fe3748b8-972c-4790-84cb-103cdb8a0823,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-05a2eb1b-e29b-478d-979d-382c9394bef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-d886e52a-9f85-4d91-b585-c927ef693ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-ffc41bc0-5597-4c55-8b75-7fb28a5e7551,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516849801-172.17.0.11-1598397349067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36290,DS-0917629b-0e30-4592-a46f-a4a5dc317485,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-acad242d-2473-4f8b-be69-91fb99d679af,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-9c713e05-4c45-42b3-b19f-53c8de9c2463,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-91cadb9a-d119-4979-89ff-218a51f9176b,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-95aa4f44-1887-47a9-b7d3-736334cfcfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-09f397f9-8173-46ed-b822-8486318bd4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-f4a58eac-0ec4-4b3a-9029-0531b8447709,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-241f8de5-72bf-43cc-bb67-5b942d95c3d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516849801-172.17.0.11-1598397349067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36290,DS-0917629b-0e30-4592-a46f-a4a5dc317485,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-acad242d-2473-4f8b-be69-91fb99d679af,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-9c713e05-4c45-42b3-b19f-53c8de9c2463,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-91cadb9a-d119-4979-89ff-218a51f9176b,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-95aa4f44-1887-47a9-b7d3-736334cfcfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-09f397f9-8173-46ed-b822-8486318bd4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-f4a58eac-0ec4-4b3a-9029-0531b8447709,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-241f8de5-72bf-43cc-bb67-5b942d95c3d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170226579-172.17.0.11-1598397593345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38708,DS-d3e59835-51ff-44d8-b023-f2409c51e331,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-e0345b54-6044-4afe-9d1f-fbfed2b0f831,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-68420bb3-f0db-41cb-b6b7-a0e4d7116fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-1b6d1033-4810-430b-b192-d4bdcebb9ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-b7f25d30-90f7-4a98-bd05-2795a718128c,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-d67d8789-0c0e-4c90-87f5-5866655f0944,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-9805c560-fea5-4a01-a456-bab41f76c407,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-f7bc389e-1c13-4a92-bf21-0c1ad9249fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170226579-172.17.0.11-1598397593345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38708,DS-d3e59835-51ff-44d8-b023-f2409c51e331,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-e0345b54-6044-4afe-9d1f-fbfed2b0f831,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-68420bb3-f0db-41cb-b6b7-a0e4d7116fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-1b6d1033-4810-430b-b192-d4bdcebb9ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-b7f25d30-90f7-4a98-bd05-2795a718128c,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-d67d8789-0c0e-4c90-87f5-5866655f0944,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-9805c560-fea5-4a01-a456-bab41f76c407,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-f7bc389e-1c13-4a92-bf21-0c1ad9249fa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427512329-172.17.0.11-1598397966298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42103,DS-2d1ca7f7-5764-4d26-b013-b59034033284,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-a589cc78-3809-4fb1-9a15-f92b1c0906dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-75976ebe-6fb5-4da0-9fc9-58bac9ffe615,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-a586d7b5-b2d6-4248-b1d2-15902b6ff637,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-70b52d08-67cd-4674-9a15-6e7c34a429ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-2ee010ac-1430-43ac-8cf9-cbbeb33da050,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-d99d7a6e-3c78-4e7b-b3c4-801bb9d4e9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-ea87bb1c-124d-406a-a8f6-1c32d0655e7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427512329-172.17.0.11-1598397966298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42103,DS-2d1ca7f7-5764-4d26-b013-b59034033284,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-a589cc78-3809-4fb1-9a15-f92b1c0906dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-75976ebe-6fb5-4da0-9fc9-58bac9ffe615,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-a586d7b5-b2d6-4248-b1d2-15902b6ff637,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-70b52d08-67cd-4674-9a15-6e7c34a429ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-2ee010ac-1430-43ac-8cf9-cbbeb33da050,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-d99d7a6e-3c78-4e7b-b3c4-801bb9d4e9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-ea87bb1c-124d-406a-a8f6-1c32d0655e7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1443387389-172.17.0.11-1598398101135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43874,DS-50e2bef3-835f-4b3c-9aaf-16e5573a25da,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-04fa3307-2656-4f0f-aa83-296e5b505935,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-20f25b95-a8d0-4f6d-a09a-94ff62fe559e,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-cb0b2b11-5e63-4307-b433-f5bc687da26c,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-e8c107b0-112d-4b50-b186-5d782b30299d,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-88cc8110-8eef-4341-9d4c-16bc0d0c1d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-e9baa1dc-6822-4df1-99ca-e5731c1eb203,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-37bed4c8-bf23-4bd3-9300-9d1cbe376d73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1443387389-172.17.0.11-1598398101135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43874,DS-50e2bef3-835f-4b3c-9aaf-16e5573a25da,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-04fa3307-2656-4f0f-aa83-296e5b505935,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-20f25b95-a8d0-4f6d-a09a-94ff62fe559e,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-cb0b2b11-5e63-4307-b433-f5bc687da26c,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-e8c107b0-112d-4b50-b186-5d782b30299d,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-88cc8110-8eef-4341-9d4c-16bc0d0c1d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-e9baa1dc-6822-4df1-99ca-e5731c1eb203,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-37bed4c8-bf23-4bd3-9300-9d1cbe376d73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913490480-172.17.0.11-1598398273813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41310,DS-645ea3c9-40eb-4374-934d-540f221567e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-432a1e4b-a287-4a57-a303-2166f48b18c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-bbe90da6-2fe8-4e7e-98d1-15ee484f623d,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-3bfbd64f-7603-4b1b-a20c-afa6a8cc6c34,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-e806d9a4-fe67-4881-b87e-a23efb78f5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-86789773-1187-48d6-b09b-f4b6baf51e34,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-01e05520-8bbf-4b4f-a1bd-0b8390fbc694,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-570f6baf-dbb4-4e62-a975-eb58051e7686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913490480-172.17.0.11-1598398273813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41310,DS-645ea3c9-40eb-4374-934d-540f221567e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-432a1e4b-a287-4a57-a303-2166f48b18c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-bbe90da6-2fe8-4e7e-98d1-15ee484f623d,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-3bfbd64f-7603-4b1b-a20c-afa6a8cc6c34,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-e806d9a4-fe67-4881-b87e-a23efb78f5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-86789773-1187-48d6-b09b-f4b6baf51e34,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-01e05520-8bbf-4b4f-a1bd-0b8390fbc694,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-570f6baf-dbb4-4e62-a975-eb58051e7686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-848887494-172.17.0.11-1598398310474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41031,DS-dae15bed-abe8-4a7a-bded-34c815635aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-639df9aa-28bf-46a7-b768-9ff56761bb53,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-7c3ab6c2-c2b6-4b1f-a96f-314d9ea7d2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-83d054a2-9e9a-4b0c-a779-3ca4ca865eab,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-9462c329-f94e-4165-8756-aca02c41351c,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-52054bb3-cf7a-47e2-af93-52b2a3c880d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-0103b2fa-9022-4e95-a67c-859dabcadedc,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-f022b59b-e005-4ce4-b481-f27549057ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-848887494-172.17.0.11-1598398310474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41031,DS-dae15bed-abe8-4a7a-bded-34c815635aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-639df9aa-28bf-46a7-b768-9ff56761bb53,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-7c3ab6c2-c2b6-4b1f-a96f-314d9ea7d2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-83d054a2-9e9a-4b0c-a779-3ca4ca865eab,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-9462c329-f94e-4165-8756-aca02c41351c,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-52054bb3-cf7a-47e2-af93-52b2a3c880d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-0103b2fa-9022-4e95-a67c-859dabcadedc,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-f022b59b-e005-4ce4-b481-f27549057ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958494286-172.17.0.11-1598398386918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40946,DS-0b9bdbe2-522f-421f-ae78-c936ee5e7f34,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-09c0c136-a4c9-4b63-90eb-e5eac32abc17,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-07a11fd8-2422-48cf-9937-25fa41fa0800,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-525bfa86-c2b8-4bc4-834b-f00e6a9f6ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-560663ef-504b-4e57-bd8d-87d72597e9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-51f594f5-a5db-4fac-a84d-c88f229481af,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-cc0c9024-cb38-43a3-8e23-01cd5516ac44,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-2fef8955-5b43-4d05-884b-646e6d9ddfe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958494286-172.17.0.11-1598398386918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40946,DS-0b9bdbe2-522f-421f-ae78-c936ee5e7f34,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-09c0c136-a4c9-4b63-90eb-e5eac32abc17,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-07a11fd8-2422-48cf-9937-25fa41fa0800,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-525bfa86-c2b8-4bc4-834b-f00e6a9f6ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-560663ef-504b-4e57-bd8d-87d72597e9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-51f594f5-a5db-4fac-a84d-c88f229481af,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-cc0c9024-cb38-43a3-8e23-01cd5516ac44,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-2fef8955-5b43-4d05-884b-646e6d9ddfe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935406108-172.17.0.11-1598398768254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38109,DS-8adc16b5-c218-4a99-a0e3-2988ff1b1f38,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-44ec4abf-fc19-496e-8dd2-3072d24e805f,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-7b33c5a4-6458-42da-8cb3-39447445d622,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-3f1e12e6-dcb9-47cd-99ef-52140fa8a501,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-832e01ab-9e6d-4e0b-bae2-abaaa685f312,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-a693e9c1-1dad-4c17-8d68-c95dcd9509a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-8b5e1cfe-7d59-4922-a579-ee91d60aa09b,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-6168c006-bdeb-4a9f-ad63-a0fc83e95f5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935406108-172.17.0.11-1598398768254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38109,DS-8adc16b5-c218-4a99-a0e3-2988ff1b1f38,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-44ec4abf-fc19-496e-8dd2-3072d24e805f,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-7b33c5a4-6458-42da-8cb3-39447445d622,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-3f1e12e6-dcb9-47cd-99ef-52140fa8a501,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-832e01ab-9e6d-4e0b-bae2-abaaa685f312,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-a693e9c1-1dad-4c17-8d68-c95dcd9509a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-8b5e1cfe-7d59-4922-a579-ee91d60aa09b,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-6168c006-bdeb-4a9f-ad63-a0fc83e95f5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421159046-172.17.0.11-1598398913076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33570,DS-05850933-8bb0-4fd1-9dc7-5334f61d39a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-01c8f128-e03f-4d8a-9d6c-fa8f7e728274,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-2d441b56-6258-436a-bc14-d5a1145d7a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-3c4efda6-b531-4c39-8d9e-372f80953719,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-b04dc1af-1a2e-4c75-a9b4-00b679b629ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-92ee9681-1e6e-47a3-bdab-273c4de6e3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-45bc9616-dbe4-40c9-adff-9231264da00f,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-75dd9a23-6ddc-4878-a585-877f2eec69dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421159046-172.17.0.11-1598398913076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33570,DS-05850933-8bb0-4fd1-9dc7-5334f61d39a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-01c8f128-e03f-4d8a-9d6c-fa8f7e728274,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-2d441b56-6258-436a-bc14-d5a1145d7a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-3c4efda6-b531-4c39-8d9e-372f80953719,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-b04dc1af-1a2e-4c75-a9b4-00b679b629ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-92ee9681-1e6e-47a3-bdab-273c4de6e3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-45bc9616-dbe4-40c9-adff-9231264da00f,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-75dd9a23-6ddc-4878-a585-877f2eec69dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399612143-172.17.0.11-1598399091369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-ab0d5f5a-2d9a-475b-a7b1-0bbedb38f19e,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-a8c82511-596f-472c-82fd-c342ce45c894,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-bf336ff9-f1b7-456d-b71b-8402290646cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-87bdb349-02fb-48a5-a336-1df665bff66c,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-414b27a3-533e-47b0-8107-686fe3f6d764,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-c193d84d-5180-49ad-b249-ebf4b3c1a15d,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-9f04d3d1-87b3-47a8-8945-26adcfb51fab,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-45cdf5a7-0bdb-4069-b9ca-9b1706d438e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399612143-172.17.0.11-1598399091369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-ab0d5f5a-2d9a-475b-a7b1-0bbedb38f19e,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-a8c82511-596f-472c-82fd-c342ce45c894,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-bf336ff9-f1b7-456d-b71b-8402290646cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-87bdb349-02fb-48a5-a336-1df665bff66c,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-414b27a3-533e-47b0-8107-686fe3f6d764,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-c193d84d-5180-49ad-b249-ebf4b3c1a15d,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-9f04d3d1-87b3-47a8-8945-26adcfb51fab,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-45cdf5a7-0bdb-4069-b9ca-9b1706d438e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-82064217-172.17.0.11-1598399267868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46264,DS-9e2e8d12-33b8-4d93-8eb9-e782835b981b,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-6adefd8a-bf57-47da-9762-103f7defec83,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-d748d64c-a194-4f34-89ab-b170866b7511,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-4f8820ad-4f32-48ac-912a-baa67122bbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-06460f0d-8405-41f1-aeed-05df45a1bbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-826ebd83-1afc-4beb-8672-a57e86634044,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-892620d9-829f-4ad3-a200-8f1e434b16fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-5961d9db-6d0e-43f5-bd67-2d007d615d0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-82064217-172.17.0.11-1598399267868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46264,DS-9e2e8d12-33b8-4d93-8eb9-e782835b981b,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-6adefd8a-bf57-47da-9762-103f7defec83,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-d748d64c-a194-4f34-89ab-b170866b7511,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-4f8820ad-4f32-48ac-912a-baa67122bbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-06460f0d-8405-41f1-aeed-05df45a1bbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-826ebd83-1afc-4beb-8672-a57e86634044,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-892620d9-829f-4ad3-a200-8f1e434b16fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-5961d9db-6d0e-43f5-bd67-2d007d615d0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722180719-172.17.0.11-1598399455458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39433,DS-e643945c-36ed-4822-b722-ae014aaa5c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-2ee165cd-022d-4f1b-9341-1c15cae517ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-74683e3b-61a8-4bbf-abe7-4d47a5a0fe76,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-58f20120-d481-4367-b032-e5b609b433f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-cc2767f0-ae35-4a47-98df-402eaa3a167e,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-64fac7de-2e38-4e48-ac9a-69638d28b985,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-fb1069cb-cc74-4d13-8609-e8f7282fdd35,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-b47cc16f-dcd1-424f-9ef5-38bfc379c864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722180719-172.17.0.11-1598399455458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39433,DS-e643945c-36ed-4822-b722-ae014aaa5c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-2ee165cd-022d-4f1b-9341-1c15cae517ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-74683e3b-61a8-4bbf-abe7-4d47a5a0fe76,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-58f20120-d481-4367-b032-e5b609b433f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-cc2767f0-ae35-4a47-98df-402eaa3a167e,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-64fac7de-2e38-4e48-ac9a-69638d28b985,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-fb1069cb-cc74-4d13-8609-e8f7282fdd35,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-b47cc16f-dcd1-424f-9ef5-38bfc379c864,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1786410615-172.17.0.11-1598399910363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45152,DS-3cdd836e-40c6-4a3f-923b-63a6634bec06,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-cd0b23de-149a-4844-bba4-2ab608b1b25e,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-a2fe6bc8-162c-4360-a381-4557f4bb818b,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-6eb192b2-81a4-4027-a791-11163fa03d60,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-a9b859a1-d08c-42ce-8248-73d168dd8728,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-bbee98aa-2334-4115-b7d1-06a6d96009f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-b414acee-bb53-4fae-98ba-382b59dc3cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-6479dff7-5631-4eec-9be3-9695353ac935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1786410615-172.17.0.11-1598399910363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45152,DS-3cdd836e-40c6-4a3f-923b-63a6634bec06,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-cd0b23de-149a-4844-bba4-2ab608b1b25e,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-a2fe6bc8-162c-4360-a381-4557f4bb818b,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-6eb192b2-81a4-4027-a791-11163fa03d60,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-a9b859a1-d08c-42ce-8248-73d168dd8728,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-bbee98aa-2334-4115-b7d1-06a6d96009f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-b414acee-bb53-4fae-98ba-382b59dc3cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-6479dff7-5631-4eec-9be3-9695353ac935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5244
