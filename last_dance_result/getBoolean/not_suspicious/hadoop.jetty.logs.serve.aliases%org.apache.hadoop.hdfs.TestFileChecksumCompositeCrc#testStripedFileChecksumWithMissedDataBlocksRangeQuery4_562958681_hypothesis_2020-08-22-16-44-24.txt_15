reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470958849-172.17.0.5-1598114956176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36735,DS-9e56a7fd-cfb6-4422-ad9e-957f29cf8a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-c4d86dbc-22ed-4e00-a1e9-6eafc5244507,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-200386f3-4f76-4a9f-9f21-e1d0e31251e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-1b787d96-ff12-4947-9270-71d211905117,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-97326826-29a3-4848-8c55-32567830e444,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-b2ea404a-077e-4154-945f-8f09be8a8ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-2f6050f6-d76f-4a2a-abef-651fc92ce474,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-e0732cc8-15e2-49b6-b395-f92aaf7d2274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470958849-172.17.0.5-1598114956176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36735,DS-9e56a7fd-cfb6-4422-ad9e-957f29cf8a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-c4d86dbc-22ed-4e00-a1e9-6eafc5244507,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-200386f3-4f76-4a9f-9f21-e1d0e31251e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-1b787d96-ff12-4947-9270-71d211905117,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-97326826-29a3-4848-8c55-32567830e444,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-b2ea404a-077e-4154-945f-8f09be8a8ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-2f6050f6-d76f-4a2a-abef-651fc92ce474,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-e0732cc8-15e2-49b6-b395-f92aaf7d2274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575204170-172.17.0.5-1598115515170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46339,DS-9a1e1ca3-2c4c-4336-a624-e381c3f64231,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-a94f6597-8ad1-4101-a5d0-83d0ac7060e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-d778eaf7-cb02-4f48-8db0-360cb9f5f5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-8eb44181-3825-4422-a314-a1ae887a553a,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-aa5fcdd2-ca5c-4d06-8ea4-a693f957e5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-b96a7628-c023-4a38-aa7a-4972b297c30f,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-ff6b05c2-6306-4f3f-bac5-b063ec96fdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-88a348c7-056c-4e7a-9d28-cf732e56503b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575204170-172.17.0.5-1598115515170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46339,DS-9a1e1ca3-2c4c-4336-a624-e381c3f64231,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-a94f6597-8ad1-4101-a5d0-83d0ac7060e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-d778eaf7-cb02-4f48-8db0-360cb9f5f5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-8eb44181-3825-4422-a314-a1ae887a553a,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-aa5fcdd2-ca5c-4d06-8ea4-a693f957e5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-b96a7628-c023-4a38-aa7a-4972b297c30f,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-ff6b05c2-6306-4f3f-bac5-b063ec96fdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-88a348c7-056c-4e7a-9d28-cf732e56503b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854484277-172.17.0.5-1598115674766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35730,DS-535fdf5d-24f4-4dcc-a778-5e0e737f18b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-9bbdf758-0846-446f-8205-121df3e8c75d,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-22a74140-3ada-46de-865a-02ea36c19ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-b460f4d2-a8a9-44f7-8db2-0c2fc0c34ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-207fa193-fe31-437e-83d4-23a4eaacc895,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-6fc95cd8-ce4a-4a29-ae5a-8dc0d6d8b12e,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-49368093-0272-4483-a4bb-9ed2d2946898,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-ac5029ad-7fa6-4eb4-b7db-1ba8ea646d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854484277-172.17.0.5-1598115674766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35730,DS-535fdf5d-24f4-4dcc-a778-5e0e737f18b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-9bbdf758-0846-446f-8205-121df3e8c75d,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-22a74140-3ada-46de-865a-02ea36c19ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-b460f4d2-a8a9-44f7-8db2-0c2fc0c34ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-207fa193-fe31-437e-83d4-23a4eaacc895,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-6fc95cd8-ce4a-4a29-ae5a-8dc0d6d8b12e,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-49368093-0272-4483-a4bb-9ed2d2946898,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-ac5029ad-7fa6-4eb4-b7db-1ba8ea646d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425698922-172.17.0.5-1598115706631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33342,DS-8f62a0d7-5686-48b7-90a1-2d3bb838f19e,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-510d8842-837e-4e14-bc60-0591b28e9dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-5d77aaaf-0166-4678-93a7-f5d083b93d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-dc4d0487-2d4b-4ea9-ba8a-619ba02b50af,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-59b6ecf4-882a-4f10-9507-ed2ed8300a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-0c4e2450-1a2f-4319-8700-416b686cac65,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-4b150ef0-e4f7-4613-81bc-e1506bfda24e,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-f00073ab-9776-4474-a307-30f957e196bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425698922-172.17.0.5-1598115706631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33342,DS-8f62a0d7-5686-48b7-90a1-2d3bb838f19e,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-510d8842-837e-4e14-bc60-0591b28e9dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-5d77aaaf-0166-4678-93a7-f5d083b93d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-dc4d0487-2d4b-4ea9-ba8a-619ba02b50af,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-59b6ecf4-882a-4f10-9507-ed2ed8300a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-0c4e2450-1a2f-4319-8700-416b686cac65,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-4b150ef0-e4f7-4613-81bc-e1506bfda24e,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-f00073ab-9776-4474-a307-30f957e196bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006731796-172.17.0.5-1598116096409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42733,DS-909dc0a7-e848-4ab0-a461-c6d344baadd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-e3869d66-482d-4b5f-8421-43ac54ed8500,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-126cec2b-6228-49f8-a23a-aec661b364fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-d868ec0b-cd7b-485e-9691-ec2c8b164575,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-0f3b8873-caf7-40cb-8e48-1f001de053b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-19f803d0-94d2-4a9c-8968-b512da8639ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-f94d1591-0c12-4b13-94ec-d1a97c5a3489,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-0378d473-261c-4ff4-b31d-2d56893adc8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006731796-172.17.0.5-1598116096409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42733,DS-909dc0a7-e848-4ab0-a461-c6d344baadd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-e3869d66-482d-4b5f-8421-43ac54ed8500,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-126cec2b-6228-49f8-a23a-aec661b364fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-d868ec0b-cd7b-485e-9691-ec2c8b164575,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-0f3b8873-caf7-40cb-8e48-1f001de053b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-19f803d0-94d2-4a9c-8968-b512da8639ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-f94d1591-0c12-4b13-94ec-d1a97c5a3489,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-0378d473-261c-4ff4-b31d-2d56893adc8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710503767-172.17.0.5-1598116347553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33316,DS-948ff6fb-91ff-4ba4-aaeb-0af56e10393c,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-7f4247f6-f1c3-4c7b-ad2d-d06ad6d18534,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-37bc6a5d-7369-4d20-828e-b8baf8a3cbba,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-bdd6db48-7dfc-485c-a5b0-ff183af3bce1,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-79802350-f2aa-4f41-b047-9b9cea9b9b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-28a0d401-7a3a-4cab-b26b-2b0db02418a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-cd97d89b-85ec-4842-a9f8-fd8f8ec748ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-c944ae18-6d0c-4f60-a40a-8b842ef3e701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710503767-172.17.0.5-1598116347553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33316,DS-948ff6fb-91ff-4ba4-aaeb-0af56e10393c,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-7f4247f6-f1c3-4c7b-ad2d-d06ad6d18534,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-37bc6a5d-7369-4d20-828e-b8baf8a3cbba,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-bdd6db48-7dfc-485c-a5b0-ff183af3bce1,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-79802350-f2aa-4f41-b047-9b9cea9b9b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-28a0d401-7a3a-4cab-b26b-2b0db02418a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-cd97d89b-85ec-4842-a9f8-fd8f8ec748ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-c944ae18-6d0c-4f60-a40a-8b842ef3e701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090747208-172.17.0.5-1598116508779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41368,DS-a9050f4f-0192-49c4-b60e-7731df80cc19,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-2685e888-0cf1-45f1-be51-1c434741d866,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-3cc3ab45-f96d-480c-adf7-410a6b459fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-811cb5b1-a3c9-474f-ade9-78814ddf3e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-37961b97-ddfd-4255-ba88-3529491aaac7,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-2f83b23f-fab6-48a3-8992-6b218dcd4124,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-fa249a6c-6d16-45b8-98e0-d3ce8057cdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-b1d99d7d-8a20-4912-952c-b9fa0d59872b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090747208-172.17.0.5-1598116508779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41368,DS-a9050f4f-0192-49c4-b60e-7731df80cc19,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-2685e888-0cf1-45f1-be51-1c434741d866,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-3cc3ab45-f96d-480c-adf7-410a6b459fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-811cb5b1-a3c9-474f-ade9-78814ddf3e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-37961b97-ddfd-4255-ba88-3529491aaac7,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-2f83b23f-fab6-48a3-8992-6b218dcd4124,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-fa249a6c-6d16-45b8-98e0-d3ce8057cdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-b1d99d7d-8a20-4912-952c-b9fa0d59872b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-429785711-172.17.0.5-1598117689629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33005,DS-b418f224-ea69-4e39-9c39-d00f8d64d121,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-bce4ed23-3ab2-4497-af64-be3082ef0640,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-dd2bc44c-be74-4a0e-a0f5-cc42df21a798,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-d6e7a37e-fafd-449b-9cc0-9586bf4b8ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-08dbfd72-790b-4d36-86f0-072bc99dc920,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-546f7c1e-043b-4c36-912d-1434276a8492,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-bba7d2db-5219-4b63-85d7-379a13173087,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-936f2008-eeb5-45e7-bce3-94e8e745a70d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-429785711-172.17.0.5-1598117689629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33005,DS-b418f224-ea69-4e39-9c39-d00f8d64d121,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-bce4ed23-3ab2-4497-af64-be3082ef0640,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-dd2bc44c-be74-4a0e-a0f5-cc42df21a798,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-d6e7a37e-fafd-449b-9cc0-9586bf4b8ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-08dbfd72-790b-4d36-86f0-072bc99dc920,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-546f7c1e-043b-4c36-912d-1434276a8492,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-bba7d2db-5219-4b63-85d7-379a13173087,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-936f2008-eeb5-45e7-bce3-94e8e745a70d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510351935-172.17.0.5-1598117770222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35212,DS-f2b91ab7-e387-4c7e-a067-488734704fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-a029af57-2aa3-4cdc-8eb0-2792a5861497,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-a479e06c-5d4f-4ec4-97e5-29a82f0f7b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-88ed9ea6-5ad0-4728-85f6-5f2c712c9ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-42f6b155-5fe6-40d3-841e-47c858f12296,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-def0ce84-8a79-4a0f-9a3e-b2af9c99f412,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-22580657-5b8d-4b02-85cd-bee564e43cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-b77053da-0aee-4911-83dc-3115d082626c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510351935-172.17.0.5-1598117770222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35212,DS-f2b91ab7-e387-4c7e-a067-488734704fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-a029af57-2aa3-4cdc-8eb0-2792a5861497,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-a479e06c-5d4f-4ec4-97e5-29a82f0f7b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-88ed9ea6-5ad0-4728-85f6-5f2c712c9ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-42f6b155-5fe6-40d3-841e-47c858f12296,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-def0ce84-8a79-4a0f-9a3e-b2af9c99f412,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-22580657-5b8d-4b02-85cd-bee564e43cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-b77053da-0aee-4911-83dc-3115d082626c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783557490-172.17.0.5-1598118012672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39740,DS-c5dc7887-f4a1-4302-984f-f4a45a251990,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-5062fefd-594a-41f1-8c48-ccb7e8fa90f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-6ead8166-b8a8-48e9-b348-a434b8a3de2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-9adf54c3-78dc-4278-930d-262223b58399,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-f12bbcc9-1482-48aa-b1d1-1a752aca91d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-7492e5e8-97ff-41bc-9d0c-954eb5379bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-564098a0-33dc-4d20-9cbd-72c91267911d,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-846c15d8-2a9d-4d41-b2bb-6f479c668667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783557490-172.17.0.5-1598118012672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39740,DS-c5dc7887-f4a1-4302-984f-f4a45a251990,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-5062fefd-594a-41f1-8c48-ccb7e8fa90f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-6ead8166-b8a8-48e9-b348-a434b8a3de2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-9adf54c3-78dc-4278-930d-262223b58399,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-f12bbcc9-1482-48aa-b1d1-1a752aca91d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-7492e5e8-97ff-41bc-9d0c-954eb5379bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-564098a0-33dc-4d20-9cbd-72c91267911d,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-846c15d8-2a9d-4d41-b2bb-6f479c668667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-116795825-172.17.0.5-1598118367677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33018,DS-1eef21fb-8232-47d5-8695-1c2e3c03bb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-06d5e246-c391-43cf-bfe0-1e6ab0bee72b,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-0886d18a-9f49-4477-92a2-4d1c06840fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-a2a2d194-4bab-464d-a337-ec529dc6b3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-16548025-dce0-41a7-a6cd-d41a468f43a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-72e94ebe-80dc-484c-88f3-ab01e0066923,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-27bc83e6-211d-41b4-ae4b-4f5d79a3a771,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-049245c5-ef59-4ccf-94e7-98e9a5b14587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-116795825-172.17.0.5-1598118367677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33018,DS-1eef21fb-8232-47d5-8695-1c2e3c03bb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-06d5e246-c391-43cf-bfe0-1e6ab0bee72b,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-0886d18a-9f49-4477-92a2-4d1c06840fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-a2a2d194-4bab-464d-a337-ec529dc6b3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-16548025-dce0-41a7-a6cd-d41a468f43a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-72e94ebe-80dc-484c-88f3-ab01e0066923,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-27bc83e6-211d-41b4-ae4b-4f5d79a3a771,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-049245c5-ef59-4ccf-94e7-98e9a5b14587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019585945-172.17.0.5-1598118448491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40008,DS-532b1049-6cfd-4f44-92b8-97c2254a1290,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-8ab0ebb5-181a-422f-bcb8-a0768d6f41d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-56bfc434-fd7e-421e-a5bd-bb3e20c46d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-8e5cdb4f-7c42-402f-807f-92ae2da83472,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-c2123064-41ad-4a13-8f22-57427701fe24,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-f2348efb-68d9-4955-b984-7f630d95fed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-a63c59f7-f149-4e58-98ce-374e0bd86fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-621efcae-5c25-4406-9b4d-ef3d579b520e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019585945-172.17.0.5-1598118448491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40008,DS-532b1049-6cfd-4f44-92b8-97c2254a1290,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-8ab0ebb5-181a-422f-bcb8-a0768d6f41d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-56bfc434-fd7e-421e-a5bd-bb3e20c46d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-8e5cdb4f-7c42-402f-807f-92ae2da83472,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-c2123064-41ad-4a13-8f22-57427701fe24,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-f2348efb-68d9-4955-b984-7f630d95fed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-a63c59f7-f149-4e58-98ce-374e0bd86fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-621efcae-5c25-4406-9b4d-ef3d579b520e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835475839-172.17.0.5-1598118594573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43359,DS-b5822ad4-8d83-44ad-8e85-f44a9974361d,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-934e0345-efbd-4a15-b7ac-20aa68b19eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-74375db1-9aec-4e35-8418-a178de70a9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-9ab99895-3d1e-4bbf-b58a-6bbf5c5ad669,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-d0bba4a1-d14e-4004-bd72-1b3d92a7c494,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-b3e40970-b32a-46d5-8a6f-37c95b602e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-be78ac91-33c5-4b98-9555-5e5d4581dafa,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-2a462e49-5f0f-473e-b894-d292eaf40012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835475839-172.17.0.5-1598118594573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43359,DS-b5822ad4-8d83-44ad-8e85-f44a9974361d,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-934e0345-efbd-4a15-b7ac-20aa68b19eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-74375db1-9aec-4e35-8418-a178de70a9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-9ab99895-3d1e-4bbf-b58a-6bbf5c5ad669,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-d0bba4a1-d14e-4004-bd72-1b3d92a7c494,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-b3e40970-b32a-46d5-8a6f-37c95b602e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-be78ac91-33c5-4b98-9555-5e5d4581dafa,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-2a462e49-5f0f-473e-b894-d292eaf40012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896238293-172.17.0.5-1598119352831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42212,DS-621cdbf7-14b8-4781-b280-7953d4feb5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-a554b587-260e-419c-b0e5-d44f453a61b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-6367c4b4-ebbc-49b5-9188-4753eab1c226,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-73b4c694-4d26-45df-9adc-6d9913bbfd71,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-44db2435-7415-4b75-b422-6e6e2e81199a,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-dc8b6d0e-eebd-469a-9274-3a8af831892a,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-38d961fd-27f0-4c9f-a013-940d029a149a,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-37f0842c-e28f-4ee6-b6bd-0d7d7b821d9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896238293-172.17.0.5-1598119352831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42212,DS-621cdbf7-14b8-4781-b280-7953d4feb5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-a554b587-260e-419c-b0e5-d44f453a61b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-6367c4b4-ebbc-49b5-9188-4753eab1c226,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-73b4c694-4d26-45df-9adc-6d9913bbfd71,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-44db2435-7415-4b75-b422-6e6e2e81199a,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-dc8b6d0e-eebd-469a-9274-3a8af831892a,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-38d961fd-27f0-4c9f-a013-940d029a149a,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-37f0842c-e28f-4ee6-b6bd-0d7d7b821d9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596836201-172.17.0.5-1598119659483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35748,DS-71dc4372-61dc-4687-8f7a-c540056bbef9,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-7402d794-89e3-463a-b845-15f67d608c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-bfcb0b65-9e5a-4fb0-be8b-65a461514507,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-cec69066-eb6e-4a5d-952f-0cc94cfed5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-576a5886-f7a7-4a9b-b51f-99d452f2bc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-27ce0c13-8725-41ac-ab64-cb65ed99792c,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-ac60c313-b802-404d-855b-5d8d08dec966,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-d7571a76-df04-419c-a3c6-a23b7958a087,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596836201-172.17.0.5-1598119659483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35748,DS-71dc4372-61dc-4687-8f7a-c540056bbef9,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-7402d794-89e3-463a-b845-15f67d608c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-bfcb0b65-9e5a-4fb0-be8b-65a461514507,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-cec69066-eb6e-4a5d-952f-0cc94cfed5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-576a5886-f7a7-4a9b-b51f-99d452f2bc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-27ce0c13-8725-41ac-ab64-cb65ed99792c,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-ac60c313-b802-404d-855b-5d8d08dec966,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-d7571a76-df04-419c-a3c6-a23b7958a087,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648207797-172.17.0.5-1598120040704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45678,DS-49017cd7-eb88-4e75-9ab3-e93fecb8d58a,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-c2f2d9dc-03f9-4bc1-9d76-20afca634750,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-1c958e80-83f8-4d98-a5c0-3817de192810,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-af105c22-f0b7-4e38-869e-2f2ff7d68f73,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-dd208f36-f970-49a4-977c-72e8d735e0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-d149c52f-0428-445b-b9a4-332fbf1e725c,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-6c30363d-01cc-4e86-ad3a-0886c5b84c55,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-e319bca5-80c3-40b6-a5ca-487d0f358cc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648207797-172.17.0.5-1598120040704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45678,DS-49017cd7-eb88-4e75-9ab3-e93fecb8d58a,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-c2f2d9dc-03f9-4bc1-9d76-20afca634750,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-1c958e80-83f8-4d98-a5c0-3817de192810,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-af105c22-f0b7-4e38-869e-2f2ff7d68f73,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-dd208f36-f970-49a4-977c-72e8d735e0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-d149c52f-0428-445b-b9a4-332fbf1e725c,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-6c30363d-01cc-4e86-ad3a-0886c5b84c55,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-e319bca5-80c3-40b6-a5ca-487d0f358cc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925365078-172.17.0.5-1598120194428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43953,DS-5b70d212-ccc4-464c-8a36-4c0ac009a933,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-f3179f1a-18c5-4f61-978a-2f5544ee50bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-f2a417c4-cd62-4ca3-98fb-a901fe6d6da6,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-487ed020-cc97-456c-99fe-b4015739682d,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-dd4d787d-11ba-4b8c-97b1-13006f984b68,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-b2588c92-851f-4953-99af-9d76ac515864,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-07779b39-0d0a-433c-b1e9-268817e388ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-5966fa9d-3958-4395-ba5a-4aa8c12a4935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925365078-172.17.0.5-1598120194428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43953,DS-5b70d212-ccc4-464c-8a36-4c0ac009a933,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-f3179f1a-18c5-4f61-978a-2f5544ee50bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-f2a417c4-cd62-4ca3-98fb-a901fe6d6da6,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-487ed020-cc97-456c-99fe-b4015739682d,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-dd4d787d-11ba-4b8c-97b1-13006f984b68,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-b2588c92-851f-4953-99af-9d76ac515864,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-07779b39-0d0a-433c-b1e9-268817e388ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-5966fa9d-3958-4395-ba5a-4aa8c12a4935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850039574-172.17.0.5-1598120234825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40417,DS-0b58ebb5-5cf2-42f5-af6b-cb9fb3fde479,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-87fc315e-bb58-498c-b90e-c3f0ff9c0700,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-ab6930ff-6258-4801-9de9-f53833ecab49,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-bcb620f3-87bf-49d8-974c-593273234d90,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-468d0b0f-e42f-4c01-b5b6-3b262f22258c,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-ad939b08-94fc-4de6-b6d4-a7e4e5615c80,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-925c4d78-04d1-4708-b9bf-e7699b3ef9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-cb015b8f-4291-431b-939d-7a8c4e5e1671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850039574-172.17.0.5-1598120234825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40417,DS-0b58ebb5-5cf2-42f5-af6b-cb9fb3fde479,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-87fc315e-bb58-498c-b90e-c3f0ff9c0700,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-ab6930ff-6258-4801-9de9-f53833ecab49,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-bcb620f3-87bf-49d8-974c-593273234d90,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-468d0b0f-e42f-4c01-b5b6-3b262f22258c,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-ad939b08-94fc-4de6-b6d4-a7e4e5615c80,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-925c4d78-04d1-4708-b9bf-e7699b3ef9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-cb015b8f-4291-431b-939d-7a8c4e5e1671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5589
