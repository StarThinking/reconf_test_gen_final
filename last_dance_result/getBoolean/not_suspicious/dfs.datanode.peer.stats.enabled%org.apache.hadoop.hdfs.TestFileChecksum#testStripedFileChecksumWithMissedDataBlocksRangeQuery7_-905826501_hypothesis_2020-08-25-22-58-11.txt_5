reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912283156-172.17.0.18-1598396308157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37127,DS-24993965-3a04-46d1-9542-83f0e8d8c9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-8dfb3a8d-d0c3-4a79-b302-c6f0af347563,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-11cfe0ac-cdd3-41de-a93b-44e962200476,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-56759d88-7469-4881-978e-c84675fa1b34,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-0cb1c8a7-d533-4e69-84da-709a0931dbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-33976968-fee6-49ff-8fab-2066a6757530,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-ceefad78-6e08-4d06-ae45-ba76eead1b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-6f65b1c3-c3dd-4058-81e8-468acfd1e48b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912283156-172.17.0.18-1598396308157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37127,DS-24993965-3a04-46d1-9542-83f0e8d8c9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-8dfb3a8d-d0c3-4a79-b302-c6f0af347563,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-11cfe0ac-cdd3-41de-a93b-44e962200476,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-56759d88-7469-4881-978e-c84675fa1b34,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-0cb1c8a7-d533-4e69-84da-709a0931dbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-33976968-fee6-49ff-8fab-2066a6757530,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-ceefad78-6e08-4d06-ae45-ba76eead1b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-6f65b1c3-c3dd-4058-81e8-468acfd1e48b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138108237-172.17.0.18-1598396341141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45108,DS-6f09d3a0-27cd-40a3-90f2-5ab5910e461c,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-dee7bda6-d6b3-4b2c-a3c0-44ed77c535ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-605df557-d82e-4091-9f6b-a8b72805b5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-f13190da-e406-4288-8a91-440abefb10d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-0abc4a3d-465d-4b73-ad81-5355c97710ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-df5bb2f6-e339-49a9-8b0a-09441f4e006e,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-3593b610-6de0-4e0a-8364-1bbb546056d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-30b19f60-81c0-42f3-b2e8-de2dede9fc05,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138108237-172.17.0.18-1598396341141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45108,DS-6f09d3a0-27cd-40a3-90f2-5ab5910e461c,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-dee7bda6-d6b3-4b2c-a3c0-44ed77c535ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-605df557-d82e-4091-9f6b-a8b72805b5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-f13190da-e406-4288-8a91-440abefb10d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-0abc4a3d-465d-4b73-ad81-5355c97710ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-df5bb2f6-e339-49a9-8b0a-09441f4e006e,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-3593b610-6de0-4e0a-8364-1bbb546056d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-30b19f60-81c0-42f3-b2e8-de2dede9fc05,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897564060-172.17.0.18-1598396413673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40848,DS-ee9e92b0-0a4c-46f7-b271-3e04567a4b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-14f581a1-85f2-4d18-8f1b-3787aa093eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-e4c28ec2-626f-4f6e-8a0e-48fd013cd403,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-47a41764-22a5-4b4d-8953-09f4e1b207de,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-b63942d6-2223-4455-adb8-f01bb1f33b54,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-1933f8d9-da42-4e54-9dd8-e54623acf3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-ef2fcd6a-8c41-4b29-bd92-dbbea18fc1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-20a644cb-f6a0-4d2c-af90-f4a5cbf96656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897564060-172.17.0.18-1598396413673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40848,DS-ee9e92b0-0a4c-46f7-b271-3e04567a4b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-14f581a1-85f2-4d18-8f1b-3787aa093eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-e4c28ec2-626f-4f6e-8a0e-48fd013cd403,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-47a41764-22a5-4b4d-8953-09f4e1b207de,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-b63942d6-2223-4455-adb8-f01bb1f33b54,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-1933f8d9-da42-4e54-9dd8-e54623acf3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-ef2fcd6a-8c41-4b29-bd92-dbbea18fc1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-20a644cb-f6a0-4d2c-af90-f4a5cbf96656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560054977-172.17.0.18-1598396558720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40435,DS-a346cad1-f731-4f8b-bcf9-ba6cd1d8a7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-ca6cb83d-5a42-4c4d-8564-1fadab98ca7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-e56d0313-ec6d-4815-9e6e-7f141e61c406,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-914af30d-68a6-4209-ae68-ab7e07813ace,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-0123e86a-b6e5-49e8-a360-4ec82c6f40a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-7dfe09bb-06ef-46d1-a1d8-c1f7c2fd325c,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-9d133b3e-0603-45db-b1ab-bcfb7e21bb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-5a2bd310-33ce-4fd4-b238-62eca6048549,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560054977-172.17.0.18-1598396558720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40435,DS-a346cad1-f731-4f8b-bcf9-ba6cd1d8a7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-ca6cb83d-5a42-4c4d-8564-1fadab98ca7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-e56d0313-ec6d-4815-9e6e-7f141e61c406,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-914af30d-68a6-4209-ae68-ab7e07813ace,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-0123e86a-b6e5-49e8-a360-4ec82c6f40a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-7dfe09bb-06ef-46d1-a1d8-c1f7c2fd325c,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-9d133b3e-0603-45db-b1ab-bcfb7e21bb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-5a2bd310-33ce-4fd4-b238-62eca6048549,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828541289-172.17.0.18-1598396667555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39314,DS-75a0f974-9677-4144-8412-8772d71cd146,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-334ba382-7137-495e-a8ae-38ebb9810af9,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-d74b1252-c6b7-47d7-b92f-dd8c80ae728f,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-64fea2f2-9221-484b-ad38-aba2a8793e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-4ef3612c-05dd-4e23-a3f9-3c8a1a7cdd46,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-f923d021-f5a6-4aaf-b2e5-34952adca015,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-ad4e459a-ea74-46d1-a262-37a6ca06fb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-981ac5f5-fe3c-4a02-8ade-09ca998d9283,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828541289-172.17.0.18-1598396667555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39314,DS-75a0f974-9677-4144-8412-8772d71cd146,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-334ba382-7137-495e-a8ae-38ebb9810af9,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-d74b1252-c6b7-47d7-b92f-dd8c80ae728f,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-64fea2f2-9221-484b-ad38-aba2a8793e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-4ef3612c-05dd-4e23-a3f9-3c8a1a7cdd46,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-f923d021-f5a6-4aaf-b2e5-34952adca015,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-ad4e459a-ea74-46d1-a262-37a6ca06fb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-981ac5f5-fe3c-4a02-8ade-09ca998d9283,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032021748-172.17.0.18-1598397061341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45423,DS-728dbdb7-1615-413b-83cc-00cdbda699e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-f13aab4e-0623-4906-beb2-07f963ae327f,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-6084ef10-546c-41dd-9f3e-06e1397185e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-d73f815e-6d60-468d-80af-a9e3458fad6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-31229fe1-393a-40fd-a314-651bd6d61d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-bd26caf7-c1b0-494a-bd1c-173da8a27554,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-a9e29aef-ec53-49bf-9d07-62265536614e,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-d4e230b5-ece5-4b84-8bad-43520ba3b705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032021748-172.17.0.18-1598397061341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45423,DS-728dbdb7-1615-413b-83cc-00cdbda699e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-f13aab4e-0623-4906-beb2-07f963ae327f,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-6084ef10-546c-41dd-9f3e-06e1397185e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-d73f815e-6d60-468d-80af-a9e3458fad6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-31229fe1-393a-40fd-a314-651bd6d61d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-bd26caf7-c1b0-494a-bd1c-173da8a27554,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-a9e29aef-ec53-49bf-9d07-62265536614e,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-d4e230b5-ece5-4b84-8bad-43520ba3b705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350723291-172.17.0.18-1598397093262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42824,DS-61ac4728-f4e6-4fff-ad00-e1879ffaf624,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-9c58ae6c-0b07-4254-8dd0-c2060bb75e57,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-8d9db1f3-f665-4359-8790-e58ea1a53eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-51a79d57-ce5c-41b6-936a-ad9b1e855a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-ab142713-7d5a-44b9-a029-a5c455323b42,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-6276c9b1-911e-4205-9aad-735a437926c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-88b5f117-8808-479b-9acd-46bb36f3a143,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-74e4c5e7-d984-4e9f-914d-5ed9e32451e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350723291-172.17.0.18-1598397093262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42824,DS-61ac4728-f4e6-4fff-ad00-e1879ffaf624,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-9c58ae6c-0b07-4254-8dd0-c2060bb75e57,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-8d9db1f3-f665-4359-8790-e58ea1a53eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-51a79d57-ce5c-41b6-936a-ad9b1e855a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-ab142713-7d5a-44b9-a029-a5c455323b42,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-6276c9b1-911e-4205-9aad-735a437926c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-88b5f117-8808-479b-9acd-46bb36f3a143,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-74e4c5e7-d984-4e9f-914d-5ed9e32451e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20332062-172.17.0.18-1598397289000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36704,DS-182f226a-734c-4c74-a37a-8442363197be,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-eb62b9fe-0a65-44fb-9c10-a511b05ab6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-ed4489c2-0f84-44aa-9849-3e367a1732bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-5fd73d3a-7c4e-41c2-a312-362293d76e90,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-8020a415-1252-4a31-a31b-65bacf2c4186,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-0b161254-fef0-4a63-8f24-4b1f2f98bc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-177ea875-7f31-40a1-a07e-c8981dee8bba,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-f7f3f90e-2faa-44b6-92f8-484a47ee0aae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20332062-172.17.0.18-1598397289000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36704,DS-182f226a-734c-4c74-a37a-8442363197be,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-eb62b9fe-0a65-44fb-9c10-a511b05ab6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-ed4489c2-0f84-44aa-9849-3e367a1732bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-5fd73d3a-7c4e-41c2-a312-362293d76e90,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-8020a415-1252-4a31-a31b-65bacf2c4186,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-0b161254-fef0-4a63-8f24-4b1f2f98bc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-177ea875-7f31-40a1-a07e-c8981dee8bba,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-f7f3f90e-2faa-44b6-92f8-484a47ee0aae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572075194-172.17.0.18-1598397560400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44686,DS-0c235793-372d-4202-ba5f-cee8f5c99db0,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-ce7de1c1-2f68-41d1-94b9-e8e147a6c2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-6294a9b8-23d0-4429-9f54-8229960c7df0,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-cef7f143-484b-4675-8c25-1eb7d8097401,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-0e7c4ec4-1768-4ec4-a030-aebff6e804c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-426edf5c-f844-4975-9283-c23216af4bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-0f0df6a8-78f7-49b6-98b5-f54ccdd94baf,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-02259b55-1bc3-4bd9-9a6d-0bb4020d7769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572075194-172.17.0.18-1598397560400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44686,DS-0c235793-372d-4202-ba5f-cee8f5c99db0,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-ce7de1c1-2f68-41d1-94b9-e8e147a6c2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-6294a9b8-23d0-4429-9f54-8229960c7df0,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-cef7f143-484b-4675-8c25-1eb7d8097401,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-0e7c4ec4-1768-4ec4-a030-aebff6e804c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-426edf5c-f844-4975-9283-c23216af4bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-0f0df6a8-78f7-49b6-98b5-f54ccdd94baf,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-02259b55-1bc3-4bd9-9a6d-0bb4020d7769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951718929-172.17.0.18-1598397619774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43785,DS-235ad537-8c8b-4994-aa6a-0a80d01bf71d,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-95b18f66-1d75-4a59-8bb4-7c90877a56c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-f770aa81-4660-4918-a20c-f165cb710b20,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-87b8f6c2-3612-4060-98e7-62e8b8bc9ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-ded5da58-c304-481a-a7f3-26767b84faf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-7e9476de-a2b1-4c31-8b3d-4a17af2f5b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-cc531b00-3b35-43f4-b74f-fcb73b67e471,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-9015b7c6-18d9-4bf6-967a-81ebe4851a03,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951718929-172.17.0.18-1598397619774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43785,DS-235ad537-8c8b-4994-aa6a-0a80d01bf71d,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-95b18f66-1d75-4a59-8bb4-7c90877a56c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-f770aa81-4660-4918-a20c-f165cb710b20,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-87b8f6c2-3612-4060-98e7-62e8b8bc9ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-ded5da58-c304-481a-a7f3-26767b84faf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-7e9476de-a2b1-4c31-8b3d-4a17af2f5b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-cc531b00-3b35-43f4-b74f-fcb73b67e471,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-9015b7c6-18d9-4bf6-967a-81ebe4851a03,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762176475-172.17.0.18-1598397649793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33395,DS-f42a9fe8-03d7-4e21-b6e9-e29bd8ed8070,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-74565391-4dc5-4b16-81b4-3583ef7574cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-391fceab-f895-47dc-ba24-9a237e971fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-a192d367-e18e-4155-b873-14a7d58f8d89,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-28da1e20-e4db-405c-966c-df402661a7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-3ec7c94a-2c8f-4f4c-af6c-01f8b5af1eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-c6d68375-b009-442d-9056-c375a70bf3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-cde90239-b70e-406c-b132-ed7eb47aeae9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762176475-172.17.0.18-1598397649793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33395,DS-f42a9fe8-03d7-4e21-b6e9-e29bd8ed8070,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-74565391-4dc5-4b16-81b4-3583ef7574cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-391fceab-f895-47dc-ba24-9a237e971fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-a192d367-e18e-4155-b873-14a7d58f8d89,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-28da1e20-e4db-405c-966c-df402661a7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-3ec7c94a-2c8f-4f4c-af6c-01f8b5af1eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-c6d68375-b009-442d-9056-c375a70bf3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-cde90239-b70e-406c-b132-ed7eb47aeae9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467267487-172.17.0.18-1598397875702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46357,DS-5b2b958d-e32b-4b5c-a1a7-d5ac8d80bce9,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-e7ac1a0b-2813-4c11-b8d6-3a72f64aeb48,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-db795631-0db8-423c-94a8-31e11e6f3b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-8042b5e3-f871-41e9-a39a-54f077791169,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-1bd031e7-e02c-48ab-a897-b070784ce4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-93eddff6-b653-456d-b76f-9867e33b63e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-42d47181-9268-4a27-9491-4bcc942bff3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-ebddbe23-1081-4294-8ccd-2f909eb9e7c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467267487-172.17.0.18-1598397875702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46357,DS-5b2b958d-e32b-4b5c-a1a7-d5ac8d80bce9,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-e7ac1a0b-2813-4c11-b8d6-3a72f64aeb48,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-db795631-0db8-423c-94a8-31e11e6f3b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-8042b5e3-f871-41e9-a39a-54f077791169,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-1bd031e7-e02c-48ab-a897-b070784ce4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-93eddff6-b653-456d-b76f-9867e33b63e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-42d47181-9268-4a27-9491-4bcc942bff3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-ebddbe23-1081-4294-8ccd-2f909eb9e7c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185883017-172.17.0.18-1598397999864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-04151389-caed-48b3-99e2-6cbacad27d57,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-37f29d83-2505-4641-b7fd-5f9d576b100f,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-e493e0ba-4efd-4215-8709-bd13f71b81f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-0a3ffdc1-9bf4-44b3-a23a-851e43d01111,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-3c59d708-7fb3-4b58-bc24-676d4f7d5c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-da44a7ef-8dc6-44b1-9877-7ec021f2ab10,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-215a2843-8331-47b8-bff9-d2302c70085e,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-a6e85f12-5c65-4a00-903f-fd9921e80144,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185883017-172.17.0.18-1598397999864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-04151389-caed-48b3-99e2-6cbacad27d57,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-37f29d83-2505-4641-b7fd-5f9d576b100f,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-e493e0ba-4efd-4215-8709-bd13f71b81f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-0a3ffdc1-9bf4-44b3-a23a-851e43d01111,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-3c59d708-7fb3-4b58-bc24-676d4f7d5c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-da44a7ef-8dc6-44b1-9877-7ec021f2ab10,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-215a2843-8331-47b8-bff9-d2302c70085e,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-a6e85f12-5c65-4a00-903f-fd9921e80144,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027922305-172.17.0.18-1598398067868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37489,DS-f8c87bfd-67a3-4451-93bc-acfac6a43ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-d9eaf139-107b-417e-84ab-5399b33debef,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-50954789-8781-4a57-93a8-444bee0bac01,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-6df323d6-08d1-460d-a983-ccd192aea787,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-0608b49e-65e2-4d51-9c5e-39f557de1e39,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-6e1cfae6-bc92-4806-b50e-1c0e21029342,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-57f0c22e-443a-4d33-9539-0308f39cf6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-4ec569fe-6c2c-4676-935d-5ea302521ff5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027922305-172.17.0.18-1598398067868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37489,DS-f8c87bfd-67a3-4451-93bc-acfac6a43ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-d9eaf139-107b-417e-84ab-5399b33debef,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-50954789-8781-4a57-93a8-444bee0bac01,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-6df323d6-08d1-460d-a983-ccd192aea787,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-0608b49e-65e2-4d51-9c5e-39f557de1e39,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-6e1cfae6-bc92-4806-b50e-1c0e21029342,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-57f0c22e-443a-4d33-9539-0308f39cf6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-4ec569fe-6c2c-4676-935d-5ea302521ff5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663193345-172.17.0.18-1598398123059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34102,DS-6c3bb2ae-e6ce-41fa-abaf-479117660b71,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-826b639f-c7fc-4d40-8bc9-5f9b9a18882e,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-ec776398-9238-4a2e-8903-2e08794e5984,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-0044b902-79dc-44ac-a477-e5bd92eb37ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-66bfa338-9da1-4a0b-9bf1-6073c022b46c,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-65b85459-fe7d-4938-a274-617091641061,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-47007f8f-b536-474c-9946-fdc603ffe272,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-983a80ed-5d1f-4dd5-b9be-d6cc5308d168,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663193345-172.17.0.18-1598398123059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34102,DS-6c3bb2ae-e6ce-41fa-abaf-479117660b71,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-826b639f-c7fc-4d40-8bc9-5f9b9a18882e,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-ec776398-9238-4a2e-8903-2e08794e5984,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-0044b902-79dc-44ac-a477-e5bd92eb37ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-66bfa338-9da1-4a0b-9bf1-6073c022b46c,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-65b85459-fe7d-4938-a274-617091641061,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-47007f8f-b536-474c-9946-fdc603ffe272,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-983a80ed-5d1f-4dd5-b9be-d6cc5308d168,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430546113-172.17.0.18-1598398527184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34593,DS-4d5dd882-f850-420c-b4f4-a96f3751a3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-dab5d1cc-ed69-4fb5-b1e7-60331f40def0,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-bc4099c4-b0ec-4985-b4f4-3fdd58e32c15,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-aa7891c6-ce95-4909-b85f-2dd56ab7dba9,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-266b3368-9c10-4cb2-bb68-654d8a7d077c,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-f043c7cb-c48b-48e1-b2ca-3b06430caa44,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-b2a1de97-34e0-45b8-9df3-a7324dafeb57,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-7ceeff7d-40f1-4627-9c3b-b13606345aa2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430546113-172.17.0.18-1598398527184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34593,DS-4d5dd882-f850-420c-b4f4-a96f3751a3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-dab5d1cc-ed69-4fb5-b1e7-60331f40def0,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-bc4099c4-b0ec-4985-b4f4-3fdd58e32c15,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-aa7891c6-ce95-4909-b85f-2dd56ab7dba9,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-266b3368-9c10-4cb2-bb68-654d8a7d077c,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-f043c7cb-c48b-48e1-b2ca-3b06430caa44,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-b2a1de97-34e0-45b8-9df3-a7324dafeb57,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-7ceeff7d-40f1-4627-9c3b-b13606345aa2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652445247-172.17.0.18-1598398750823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40415,DS-2a319211-61fb-406f-ae48-687992c078b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-52fd2c9c-1b35-4bc7-96df-aef97be19f70,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-92b63edf-510f-474c-9936-5d6669f4808e,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-446e3560-eaf7-4502-8075-8b91eac81f61,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-8aa9fa8c-4689-47c1-914c-0d4b5eeccc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-7babeb15-d008-4a6b-a553-cd9eaff48bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-829abb0e-cf7b-4506-912c-2bff6615a5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-bd9f1a51-8c17-443c-8a13-343d8f81d420,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652445247-172.17.0.18-1598398750823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40415,DS-2a319211-61fb-406f-ae48-687992c078b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-52fd2c9c-1b35-4bc7-96df-aef97be19f70,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-92b63edf-510f-474c-9936-5d6669f4808e,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-446e3560-eaf7-4502-8075-8b91eac81f61,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-8aa9fa8c-4689-47c1-914c-0d4b5eeccc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-7babeb15-d008-4a6b-a553-cd9eaff48bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-829abb0e-cf7b-4506-912c-2bff6615a5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-bd9f1a51-8c17-443c-8a13-343d8f81d420,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528710030-172.17.0.18-1598398896367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42705,DS-516f0724-a49e-4186-92dc-7277bfdf850d,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-ccb4cf02-20a0-43f6-be40-9d43d67f1470,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-da01c74e-4d85-4239-972e-428708af1c08,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-568fa142-7cad-4542-b4ef-f63e3f370368,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-7efa1a32-bd93-46d0-9457-14ba19b63e92,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-a3977dcd-b069-4659-926b-a0178721d5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-5dd68019-6a1b-4890-9702-71dbe1a30aff,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-983694d2-95ec-4f2f-83fa-3905d78d93f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528710030-172.17.0.18-1598398896367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42705,DS-516f0724-a49e-4186-92dc-7277bfdf850d,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-ccb4cf02-20a0-43f6-be40-9d43d67f1470,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-da01c74e-4d85-4239-972e-428708af1c08,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-568fa142-7cad-4542-b4ef-f63e3f370368,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-7efa1a32-bd93-46d0-9457-14ba19b63e92,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-a3977dcd-b069-4659-926b-a0178721d5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-5dd68019-6a1b-4890-9702-71dbe1a30aff,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-983694d2-95ec-4f2f-83fa-3905d78d93f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250439283-172.17.0.18-1598398960848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40529,DS-6bf8b4c3-97e4-4590-9f4b-4760164bc23d,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-7b6dfa51-a673-44e2-951a-83981b5ccb01,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-334aab2f-da78-4437-8d4a-e44dfba30c86,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-e3647d80-7136-45cd-9f0c-f56e3d6aa9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-19c05aea-cbb9-4c88-9bc9-84a38057f2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-45c4f9ba-c481-4d5c-adca-b6ed4d602706,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-ba412835-7e86-472e-8b17-77ff4f882611,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-1fcc9997-2c81-4f58-9dbc-744776d88d58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250439283-172.17.0.18-1598398960848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40529,DS-6bf8b4c3-97e4-4590-9f4b-4760164bc23d,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-7b6dfa51-a673-44e2-951a-83981b5ccb01,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-334aab2f-da78-4437-8d4a-e44dfba30c86,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-e3647d80-7136-45cd-9f0c-f56e3d6aa9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-19c05aea-cbb9-4c88-9bc9-84a38057f2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-45c4f9ba-c481-4d5c-adca-b6ed4d602706,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-ba412835-7e86-472e-8b17-77ff4f882611,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-1fcc9997-2c81-4f58-9dbc-744776d88d58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386672827-172.17.0.18-1598399096246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45349,DS-c21ed2cb-5110-40e0-aea4-2aee184589b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-3299ab25-49bf-455f-a662-b8d736fd158d,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-33931ee3-ee95-4e40-aeca-a2b86bea2715,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-4f98ede7-4b8b-4e61-819f-0b92e22b4a21,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-57e21bc7-9d42-4adb-8954-99e256cac100,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-bbfefb97-8413-4072-a8cf-7098a6ffd118,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-bdc07d87-a4f6-4432-b156-9b227b21aaab,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-2e0b3506-61b9-4109-8293-1edf296ca1ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386672827-172.17.0.18-1598399096246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45349,DS-c21ed2cb-5110-40e0-aea4-2aee184589b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-3299ab25-49bf-455f-a662-b8d736fd158d,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-33931ee3-ee95-4e40-aeca-a2b86bea2715,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-4f98ede7-4b8b-4e61-819f-0b92e22b4a21,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-57e21bc7-9d42-4adb-8954-99e256cac100,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-bbfefb97-8413-4072-a8cf-7098a6ffd118,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-bdc07d87-a4f6-4432-b156-9b227b21aaab,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-2e0b3506-61b9-4109-8293-1edf296ca1ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379863276-172.17.0.18-1598399166610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42370,DS-2f612ee1-b97c-4faf-84c4-b0a2066f95ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-c40988c1-2087-4689-b176-392ff656757b,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-9b17df4f-9ca4-49b4-81e2-423f9bada2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-80fba886-4ee7-4ae8-9ed5-28fa1f139227,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-2b2d3e69-a7aa-4ffc-9d16-c22b5e2c57b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-b1284b51-9f50-4292-bce4-3f38894420fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-f1bdaee1-f7a7-4368-9897-df5f6aa3e9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-08d6f469-916d-415a-8794-4288c3543af6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379863276-172.17.0.18-1598399166610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42370,DS-2f612ee1-b97c-4faf-84c4-b0a2066f95ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-c40988c1-2087-4689-b176-392ff656757b,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-9b17df4f-9ca4-49b4-81e2-423f9bada2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-80fba886-4ee7-4ae8-9ed5-28fa1f139227,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-2b2d3e69-a7aa-4ffc-9d16-c22b5e2c57b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-b1284b51-9f50-4292-bce4-3f38894420fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-f1bdaee1-f7a7-4368-9897-df5f6aa3e9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-08d6f469-916d-415a-8794-4288c3543af6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948396835-172.17.0.18-1598399198850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42393,DS-f92c2851-250e-4693-8de4-a1eca3ffbae0,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-be30e12d-8464-4be9-b3db-344b8df53c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-b3d1738a-867d-4057-a69b-9f52b0a326bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-caf30ae2-9689-437f-a450-5b875b05306d,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-94b7f239-dac6-4d14-846a-abb304c39099,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-5ceeb99d-0625-4ae1-abfb-38db4e74461d,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-ecdd93a7-7589-4f87-a5f9-18ba5e32ce20,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-4c2704c4-a31c-4207-bdc2-d4b6f24e5604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948396835-172.17.0.18-1598399198850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42393,DS-f92c2851-250e-4693-8de4-a1eca3ffbae0,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-be30e12d-8464-4be9-b3db-344b8df53c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-b3d1738a-867d-4057-a69b-9f52b0a326bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-caf30ae2-9689-437f-a450-5b875b05306d,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-94b7f239-dac6-4d14-846a-abb304c39099,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-5ceeb99d-0625-4ae1-abfb-38db4e74461d,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-ecdd93a7-7589-4f87-a5f9-18ba5e32ce20,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-4c2704c4-a31c-4207-bdc2-d4b6f24e5604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813789883-172.17.0.18-1598399262384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33106,DS-6d3f5c35-1a62-4548-bfb1-6feeb656d8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-36095df8-c80c-4f22-9f99-92316cb1b8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-260d97ad-8fd2-49d3-a3b8-346ce8b26f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-cb958ef9-7b61-4312-8b0a-e64926be9fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-e5ffa5ef-1e6a-4618-94ec-9d31ac083c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-10374cab-138d-4d4f-973f-cca03e4ac5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-6bdebb1d-4045-47d8-9b74-a2df907d3b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-1c347645-5a2b-4258-9786-ec8297da39e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813789883-172.17.0.18-1598399262384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33106,DS-6d3f5c35-1a62-4548-bfb1-6feeb656d8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-36095df8-c80c-4f22-9f99-92316cb1b8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-260d97ad-8fd2-49d3-a3b8-346ce8b26f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-cb958ef9-7b61-4312-8b0a-e64926be9fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-e5ffa5ef-1e6a-4618-94ec-9d31ac083c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-10374cab-138d-4d4f-973f-cca03e4ac5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-6bdebb1d-4045-47d8-9b74-a2df907d3b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-1c347645-5a2b-4258-9786-ec8297da39e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522708041-172.17.0.18-1598399455167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42065,DS-6eeb658d-5f4b-4af7-aab0-87cdc19fd968,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-ab9da7e7-7f70-4b26-841c-02901bcb504c,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-7b1f26cb-9812-4b06-a0df-ecb7c489868a,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-2a0d80ec-bb04-4f33-a91d-00e0e7edc41a,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-1d3d4ab2-610c-4a1d-a17b-1011e5c567b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-25222c24-e48a-49f7-b278-4cc9a7e33dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-7efe53b2-76b8-43e3-89a9-2f8e6a92c57c,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-2d50c867-9365-411d-9962-74a3551283e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522708041-172.17.0.18-1598399455167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42065,DS-6eeb658d-5f4b-4af7-aab0-87cdc19fd968,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-ab9da7e7-7f70-4b26-841c-02901bcb504c,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-7b1f26cb-9812-4b06-a0df-ecb7c489868a,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-2a0d80ec-bb04-4f33-a91d-00e0e7edc41a,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-1d3d4ab2-610c-4a1d-a17b-1011e5c567b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-25222c24-e48a-49f7-b278-4cc9a7e33dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-7efe53b2-76b8-43e3-89a9-2f8e6a92c57c,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-2d50c867-9365-411d-9962-74a3551283e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003511039-172.17.0.18-1598399487807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40167,DS-2b9cbb67-9bd5-43c0-a2ef-8416884070af,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-6603d865-1170-4a4e-bd6e-693cc5e5a032,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-e1b060a6-520d-40fb-af51-352a6580e417,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-2a1cdd58-aad8-42ff-91d3-2e7eab0f7604,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-168b2253-b680-4d84-8d53-01972bd65651,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-6b6c063d-8075-4b0e-ab47-fde107955ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-4483bc43-8878-4d81-93fb-5fd5b5fb371a,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-92c4a2b5-9ad8-4007-981a-b60d7ddc13b0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003511039-172.17.0.18-1598399487807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40167,DS-2b9cbb67-9bd5-43c0-a2ef-8416884070af,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-6603d865-1170-4a4e-bd6e-693cc5e5a032,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-e1b060a6-520d-40fb-af51-352a6580e417,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-2a1cdd58-aad8-42ff-91d3-2e7eab0f7604,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-168b2253-b680-4d84-8d53-01972bd65651,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-6b6c063d-8075-4b0e-ab47-fde107955ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-4483bc43-8878-4d81-93fb-5fd5b5fb371a,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-92c4a2b5-9ad8-4007-981a-b60d7ddc13b0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-490447708-172.17.0.18-1598399525627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41877,DS-859d2e26-bddb-4b8b-a532-6aecb290f7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-ad209124-0bce-46b3-8ec8-c1bc37084d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-6379cca9-6404-4f68-87ab-9f5359e9ae70,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-dab7575e-6133-4608-b4a7-0d8c8421544e,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-6df8a0f1-a9b2-444c-9b49-7187713cd428,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-b064d172-07c2-409c-8d00-3f92fe4cd05d,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-2fc63ad9-be28-49c6-b33f-abcfbac35d90,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-b89726dd-a3cc-4405-baef-a590b23ad884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-490447708-172.17.0.18-1598399525627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41877,DS-859d2e26-bddb-4b8b-a532-6aecb290f7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-ad209124-0bce-46b3-8ec8-c1bc37084d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-6379cca9-6404-4f68-87ab-9f5359e9ae70,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-dab7575e-6133-4608-b4a7-0d8c8421544e,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-6df8a0f1-a9b2-444c-9b49-7187713cd428,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-b064d172-07c2-409c-8d00-3f92fe4cd05d,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-2fc63ad9-be28-49c6-b33f-abcfbac35d90,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-b89726dd-a3cc-4405-baef-a590b23ad884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587184000-172.17.0.18-1598399694160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39451,DS-cc96c709-a9c2-47f8-ac9b-ce23ecb1c91b,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-d5d16cb8-b856-4796-adc0-9a66a8678515,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-0b45afed-17cd-42d9-8c7f-e650d2efa48d,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-a0f51d3c-5882-4767-95a1-fd218df5bf74,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-fc13b669-eadc-4a15-b453-e40c955b9e76,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-d48265b4-ea23-413a-9a95-2aa1402d3346,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-7c2b56be-add5-494e-a841-904c360f4705,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-2bf7da83-1c30-4de4-a849-567b9c1e1338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587184000-172.17.0.18-1598399694160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39451,DS-cc96c709-a9c2-47f8-ac9b-ce23ecb1c91b,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-d5d16cb8-b856-4796-adc0-9a66a8678515,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-0b45afed-17cd-42d9-8c7f-e650d2efa48d,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-a0f51d3c-5882-4767-95a1-fd218df5bf74,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-fc13b669-eadc-4a15-b453-e40c955b9e76,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-d48265b4-ea23-413a-9a95-2aa1402d3346,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-7c2b56be-add5-494e-a841-904c360f4705,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-2bf7da83-1c30-4de4-a849-567b9c1e1338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266440538-172.17.0.18-1598399796107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33822,DS-48ee8ac8-6db1-40ba-8431-f9ae28e63e30,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-00b444f6-7032-4ecc-abb2-887b146c9430,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-bc96a18d-02cc-44f2-979c-266e2105c6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-07c0bf85-1a44-48fe-b193-e1f1ec8233a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-d5ba984d-ca8e-4c61-89d6-945a028bfcce,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-15040605-f199-45bd-a504-c941711f406f,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-1834daab-304e-4c81-b0a3-5f0bd6a74a19,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-e679f08c-91c4-4b4e-9cc7-96f455704545,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266440538-172.17.0.18-1598399796107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33822,DS-48ee8ac8-6db1-40ba-8431-f9ae28e63e30,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-00b444f6-7032-4ecc-abb2-887b146c9430,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-bc96a18d-02cc-44f2-979c-266e2105c6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-07c0bf85-1a44-48fe-b193-e1f1ec8233a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-d5ba984d-ca8e-4c61-89d6-945a028bfcce,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-15040605-f199-45bd-a504-c941711f406f,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-1834daab-304e-4c81-b0a3-5f0bd6a74a19,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-e679f08c-91c4-4b4e-9cc7-96f455704545,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904425886-172.17.0.18-1598399886710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33955,DS-9cfd7d0b-c376-4485-9f14-cd7d4e2dc953,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-a1851f6c-9ee9-4937-90cb-35196812066a,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-3182a89f-49de-451b-bd66-9280a7f51857,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-50b9047e-6afb-4171-9361-caf76635db04,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-ff4ea44f-f491-44d1-b9e2-6b6b2b22a23c,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-a07f843b-3f8b-48aa-9a1a-826b5c0d0df5,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-853e9cf8-8ce7-4465-98a1-c708b19de964,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-d987e770-3723-40a3-9bfc-92ea1fd0f3b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904425886-172.17.0.18-1598399886710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33955,DS-9cfd7d0b-c376-4485-9f14-cd7d4e2dc953,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-a1851f6c-9ee9-4937-90cb-35196812066a,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-3182a89f-49de-451b-bd66-9280a7f51857,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-50b9047e-6afb-4171-9361-caf76635db04,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-ff4ea44f-f491-44d1-b9e2-6b6b2b22a23c,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-a07f843b-3f8b-48aa-9a1a-826b5c0d0df5,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-853e9cf8-8ce7-4465-98a1-c708b19de964,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-d987e770-3723-40a3-9bfc-92ea1fd0f3b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958645084-172.17.0.18-1598399925297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33134,DS-470f9894-2262-44af-b644-d6e040d7ae00,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-0c3e89bf-7618-4e6e-ab7c-2a5cda8d0436,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-35812f65-29d9-46f5-8b7d-eb3cccd22db9,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-4052a18f-2845-4f68-9fca-699aa9dd9bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-b6125f1c-7174-4a7e-b697-38eae49497b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-3b466292-cd35-4a28-a707-9d1866617fca,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-eadcbc70-e391-44fd-b145-749016ae8b45,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-028f15b9-29bb-47e3-bf91-5b528b73e8f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958645084-172.17.0.18-1598399925297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33134,DS-470f9894-2262-44af-b644-d6e040d7ae00,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-0c3e89bf-7618-4e6e-ab7c-2a5cda8d0436,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-35812f65-29d9-46f5-8b7d-eb3cccd22db9,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-4052a18f-2845-4f68-9fca-699aa9dd9bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-b6125f1c-7174-4a7e-b697-38eae49497b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-3b466292-cd35-4a28-a707-9d1866617fca,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-eadcbc70-e391-44fd-b145-749016ae8b45,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-028f15b9-29bb-47e3-bf91-5b528b73e8f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-216251425-172.17.0.18-1598399957324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33534,DS-b7cf8abf-28f3-421a-80b5-9791409aa04a,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-0ad56e57-e1d7-477b-8953-964299dcf671,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-57124703-c478-42a2-8f7e-cbfbde91ef4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-fac27158-9ea4-440a-9c6d-25e0c0111425,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-6ea82316-b0ff-4cf4-8465-5c92056d1325,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-f514641a-d72e-4002-85c6-fa89b98bc5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-6f18ba69-46ad-4bba-874b-abd647181d28,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-84ac4763-3a81-4a6d-a16c-81042827902d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-216251425-172.17.0.18-1598399957324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33534,DS-b7cf8abf-28f3-421a-80b5-9791409aa04a,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-0ad56e57-e1d7-477b-8953-964299dcf671,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-57124703-c478-42a2-8f7e-cbfbde91ef4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-fac27158-9ea4-440a-9c6d-25e0c0111425,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-6ea82316-b0ff-4cf4-8465-5c92056d1325,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-f514641a-d72e-4002-85c6-fa89b98bc5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-6f18ba69-46ad-4bba-874b-abd647181d28,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-84ac4763-3a81-4a6d-a16c-81042827902d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133966205-172.17.0.18-1598400227446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45474,DS-560e93a9-0305-4b78-8a50-4e490d9b7c07,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-945007ee-be78-449a-94af-e7121376f155,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-f05c3d7b-5642-4bf1-833b-18651cf22884,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-afe6dbeb-c3af-4fcf-83fd-4154529615b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-30804d7a-caee-4c46-9069-13a4544f4da9,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-61b1bf4a-50a3-4922-82b9-45b77c49c509,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-ef4a273c-4cdb-4bc5-bb01-2dbfcc5576fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-eee0a7c9-baa3-49fa-ba03-d77f2badd5a3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133966205-172.17.0.18-1598400227446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45474,DS-560e93a9-0305-4b78-8a50-4e490d9b7c07,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-945007ee-be78-449a-94af-e7121376f155,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-f05c3d7b-5642-4bf1-833b-18651cf22884,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-afe6dbeb-c3af-4fcf-83fd-4154529615b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-30804d7a-caee-4c46-9069-13a4544f4da9,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-61b1bf4a-50a3-4922-82b9-45b77c49c509,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-ef4a273c-4cdb-4bc5-bb01-2dbfcc5576fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-eee0a7c9-baa3-49fa-ba03-d77f2badd5a3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213802527-172.17.0.18-1598400260320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46233,DS-1cd1914f-c4fc-44a4-abf6-ad7bbb759f02,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-ed42cde7-39e6-4029-a536-a2f89e2330b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-1d20bd54-315d-4ad4-b20a-d701f9ddec10,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-cce2c554-a04d-446a-b59b-dc1aaa0053b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-f59f2031-8f34-49c4-b7f6-b51d2ba4e9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-21fc8a45-5c27-434e-a9ec-116ca6606e71,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-d674ac5b-da85-4642-822a-23a92506c0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-4d587a43-4c3f-48e9-a20d-d5e2e63a0731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213802527-172.17.0.18-1598400260320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46233,DS-1cd1914f-c4fc-44a4-abf6-ad7bbb759f02,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-ed42cde7-39e6-4029-a536-a2f89e2330b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-1d20bd54-315d-4ad4-b20a-d701f9ddec10,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-cce2c554-a04d-446a-b59b-dc1aaa0053b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-f59f2031-8f34-49c4-b7f6-b51d2ba4e9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-21fc8a45-5c27-434e-a9ec-116ca6606e71,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-d674ac5b-da85-4642-822a-23a92506c0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-4d587a43-4c3f-48e9-a20d-d5e2e63a0731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035497347-172.17.0.18-1598400368198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45125,DS-03290fd1-4727-4c0d-8d6c-01ee667b0d32,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-f9bbce72-49c7-42bc-bbdc-8eb9e458e06d,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-b61afb29-f5a0-4bc8-950b-203891d97314,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-5a92c0dc-af47-4daa-87ab-af0ab26c320b,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-948f80c7-e98b-405c-9357-851a6af5bdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-c421b723-9131-4154-b842-01f9eabe8ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-3914ef3c-678a-4795-815e-a000fa03e094,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-692d481f-0de1-4ddb-8684-70f5663e0f62,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035497347-172.17.0.18-1598400368198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45125,DS-03290fd1-4727-4c0d-8d6c-01ee667b0d32,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-f9bbce72-49c7-42bc-bbdc-8eb9e458e06d,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-b61afb29-f5a0-4bc8-950b-203891d97314,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-5a92c0dc-af47-4daa-87ab-af0ab26c320b,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-948f80c7-e98b-405c-9357-851a6af5bdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-c421b723-9131-4154-b842-01f9eabe8ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-3914ef3c-678a-4795-815e-a000fa03e094,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-692d481f-0de1-4ddb-8684-70f5663e0f62,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334361789-172.17.0.18-1598400600255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32859,DS-03070248-95ef-4baf-82b6-987357378995,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-e0a6db06-3d3e-49f0-ad49-cd83aeb0d37c,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-1b0ac031-83a3-4004-88c1-02c29bb645d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-efc97b38-5607-4862-b799-20af29005fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-7ea1e29a-86e8-4165-9765-9ee8dca1274e,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-95c915d1-ead0-4a24-812a-2b7cd17cfee4,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-3f0f91b9-efd9-49c0-aad7-1daf9b94a5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-02f24d3c-8191-46fd-b39c-ba53b2e99e24,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334361789-172.17.0.18-1598400600255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32859,DS-03070248-95ef-4baf-82b6-987357378995,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-e0a6db06-3d3e-49f0-ad49-cd83aeb0d37c,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-1b0ac031-83a3-4004-88c1-02c29bb645d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-efc97b38-5607-4862-b799-20af29005fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-7ea1e29a-86e8-4165-9765-9ee8dca1274e,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-95c915d1-ead0-4a24-812a-2b7cd17cfee4,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-3f0f91b9-efd9-49c0-aad7-1daf9b94a5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-02f24d3c-8191-46fd-b39c-ba53b2e99e24,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707352933-172.17.0.18-1598400779594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-00353a97-b045-4efe-911e-00252b50e3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-915b4553-f72c-473f-ac68-6831b46e6b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-64369e27-b880-4158-bb96-46ea37ba5aca,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-536664dc-0140-4c07-89cf-f79bb7ce84e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-c263b5db-2902-4fb5-989b-7a5ae3e59f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-368e3f1d-4f19-4a9a-91be-15988913edc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-7062ac17-67c6-4339-aa13-059617d94cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-e3f52077-dad5-42d5-872f-8bd69a2a534c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707352933-172.17.0.18-1598400779594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-00353a97-b045-4efe-911e-00252b50e3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-915b4553-f72c-473f-ac68-6831b46e6b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-64369e27-b880-4158-bb96-46ea37ba5aca,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-536664dc-0140-4c07-89cf-f79bb7ce84e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-c263b5db-2902-4fb5-989b-7a5ae3e59f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-368e3f1d-4f19-4a9a-91be-15988913edc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-7062ac17-67c6-4339-aa13-059617d94cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-e3f52077-dad5-42d5-872f-8bd69a2a534c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160686522-172.17.0.18-1598400814006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44987,DS-bdd85e3b-9da3-44e8-ba61-30a520bf9ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-c3dac05b-a520-44ee-99cc-be897ba04a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-663815b1-164d-4af8-9f3e-3a56a29c75f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-253d0039-4db9-474d-90bf-8de183d7d6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-6c70c42c-6dc4-4e50-8346-ce8b5b165307,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-b9cdc9da-aee1-4107-99f3-08bf5d516350,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-8a0307cc-5dc5-4cb7-bda4-c953cb18d087,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-19c32495-01e7-42db-884c-2bf646bf3307,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160686522-172.17.0.18-1598400814006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44987,DS-bdd85e3b-9da3-44e8-ba61-30a520bf9ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-c3dac05b-a520-44ee-99cc-be897ba04a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-663815b1-164d-4af8-9f3e-3a56a29c75f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-253d0039-4db9-474d-90bf-8de183d7d6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-6c70c42c-6dc4-4e50-8346-ce8b5b165307,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-b9cdc9da-aee1-4107-99f3-08bf5d516350,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-8a0307cc-5dc5-4cb7-bda4-c953cb18d087,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-19c32495-01e7-42db-884c-2bf646bf3307,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432631995-172.17.0.18-1598400919320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42575,DS-a314e4da-e042-4626-835d-1f254a4f1c28,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-8f859ac9-87e0-4cb4-9f97-636ecda6a2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-c6c61989-0821-401f-872b-1439c9d317a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-a4dcf025-17b0-4704-aeab-d81fb364d916,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-8d7e47e0-9e58-4a1b-b02a-6db7a3bcbac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-c4b80907-e4f0-486c-a597-1ee94d680772,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-17301105-9831-4359-b371-bef6b1dbdf55,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-09d1ee21-9e88-4609-9851-9a0e8b6b7b5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432631995-172.17.0.18-1598400919320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42575,DS-a314e4da-e042-4626-835d-1f254a4f1c28,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-8f859ac9-87e0-4cb4-9f97-636ecda6a2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-c6c61989-0821-401f-872b-1439c9d317a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-a4dcf025-17b0-4704-aeab-d81fb364d916,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-8d7e47e0-9e58-4a1b-b02a-6db7a3bcbac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-c4b80907-e4f0-486c-a597-1ee94d680772,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-17301105-9831-4359-b371-bef6b1dbdf55,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-09d1ee21-9e88-4609-9851-9a0e8b6b7b5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347083728-172.17.0.18-1598401042261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36659,DS-29b4dc34-8589-4eff-825c-57f78cd6aef6,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-6c35b846-4020-43f1-a288-afdf2fc732df,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-00447f5f-1c41-4eba-b27d-ad0fab200a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-75f9f81e-0f31-4c4a-8244-b6a468518cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-e16e4da6-cee2-4f6a-bf31-001c032e16c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-42f998cd-a7da-4301-bbbd-eedbd2252ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-0b8c3f81-8993-4538-a907-1fc9b86cab46,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-c2afa835-9248-4932-a4ad-cb1b9deaab48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347083728-172.17.0.18-1598401042261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36659,DS-29b4dc34-8589-4eff-825c-57f78cd6aef6,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-6c35b846-4020-43f1-a288-afdf2fc732df,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-00447f5f-1c41-4eba-b27d-ad0fab200a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-75f9f81e-0f31-4c4a-8244-b6a468518cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-e16e4da6-cee2-4f6a-bf31-001c032e16c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-42f998cd-a7da-4301-bbbd-eedbd2252ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-0b8c3f81-8993-4538-a907-1fc9b86cab46,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-c2afa835-9248-4932-a4ad-cb1b9deaab48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 23 out of 50
result: false positive !!!
Total execution time in seconds : 4973
