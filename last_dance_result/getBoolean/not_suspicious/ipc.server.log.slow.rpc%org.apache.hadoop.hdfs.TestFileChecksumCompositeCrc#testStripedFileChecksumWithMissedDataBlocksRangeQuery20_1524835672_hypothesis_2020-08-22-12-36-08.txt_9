reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148100114-172.17.0.2-1598100006413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41986,DS-39676fcc-95ad-4f04-abcf-871c088da65a,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-322a73e8-2905-40f8-94c7-7c26dac72fca,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-14d54080-ab7c-41d7-b567-31098291d9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-715a3de3-12e7-4310-9268-2a3d69c1849a,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-27b48979-cd60-451c-b00a-e086b423f3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-41c7bdab-cac3-4e9d-97a5-00c29f3f483a,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-4d9061cd-3484-4c40-bd8c-e6914896a266,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-705efacf-6c68-4197-8a9f-f7cda8877b94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148100114-172.17.0.2-1598100006413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41986,DS-39676fcc-95ad-4f04-abcf-871c088da65a,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-322a73e8-2905-40f8-94c7-7c26dac72fca,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-14d54080-ab7c-41d7-b567-31098291d9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-715a3de3-12e7-4310-9268-2a3d69c1849a,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-27b48979-cd60-451c-b00a-e086b423f3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-41c7bdab-cac3-4e9d-97a5-00c29f3f483a,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-4d9061cd-3484-4c40-bd8c-e6914896a266,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-705efacf-6c68-4197-8a9f-f7cda8877b94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2121279991-172.17.0.2-1598100480873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38131,DS-41e1e82f-b22c-4b3c-877a-de9207b655d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-a92de21c-27b9-44f0-9a2f-22790881d5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-e479cd4f-9c01-4ba8-a675-64b16f757852,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-447eff6d-9c21-43dd-a844-339336a0080f,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-74bce441-0550-4517-8ff4-6f1398114a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-59c91402-4115-4332-8683-e0baeeebd17a,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-e1bad5af-74f3-43e5-b704-5a533f670284,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-b16a1b7f-a57c-42aa-8fb7-3949bc31b1ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2121279991-172.17.0.2-1598100480873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38131,DS-41e1e82f-b22c-4b3c-877a-de9207b655d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-a92de21c-27b9-44f0-9a2f-22790881d5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-e479cd4f-9c01-4ba8-a675-64b16f757852,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-447eff6d-9c21-43dd-a844-339336a0080f,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-74bce441-0550-4517-8ff4-6f1398114a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-59c91402-4115-4332-8683-e0baeeebd17a,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-e1bad5af-74f3-43e5-b704-5a533f670284,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-b16a1b7f-a57c-42aa-8fb7-3949bc31b1ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521592012-172.17.0.2-1598101418321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33802,DS-ae0b7907-8085-4180-a670-c8a243126410,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-8cad47e7-4372-443b-9537-e303d52865ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-8684cb4a-b4c7-46be-87e2-4dc81e9b02bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-1e01fcd6-ba47-4f79-8828-7cfe48a5f142,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-9474be29-0d3c-477c-bbae-893b3cb93144,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-e2ca2f97-dd7d-4710-bc9a-94dfea0d554b,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-cd3945a4-dd64-4576-892b-e28813fe2206,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-4763e3b2-6484-46f3-ba58-1f9f663980ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521592012-172.17.0.2-1598101418321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33802,DS-ae0b7907-8085-4180-a670-c8a243126410,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-8cad47e7-4372-443b-9537-e303d52865ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-8684cb4a-b4c7-46be-87e2-4dc81e9b02bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-1e01fcd6-ba47-4f79-8828-7cfe48a5f142,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-9474be29-0d3c-477c-bbae-893b3cb93144,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-e2ca2f97-dd7d-4710-bc9a-94dfea0d554b,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-cd3945a4-dd64-4576-892b-e28813fe2206,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-4763e3b2-6484-46f3-ba58-1f9f663980ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788595252-172.17.0.2-1598101976363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42144,DS-bd963085-d6de-48e4-8749-7f3d28a52a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-2a328cd8-100c-486a-9d95-14c55d4198b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-52392de8-c782-45fb-a7c9-76bddd2d02c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-ed4508a6-2248-480a-9f86-adade44f362e,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-f0e3ecce-a15f-40c2-95f4-ab01d8db9e09,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-76eb9df6-e61b-41c2-9e80-849a8df70420,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-9ce18e93-26e2-499d-a31f-258c4e50adb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-c31c6905-db40-46d1-82c5-fd51bb348aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788595252-172.17.0.2-1598101976363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42144,DS-bd963085-d6de-48e4-8749-7f3d28a52a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-2a328cd8-100c-486a-9d95-14c55d4198b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-52392de8-c782-45fb-a7c9-76bddd2d02c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-ed4508a6-2248-480a-9f86-adade44f362e,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-f0e3ecce-a15f-40c2-95f4-ab01d8db9e09,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-76eb9df6-e61b-41c2-9e80-849a8df70420,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-9ce18e93-26e2-499d-a31f-258c4e50adb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-c31c6905-db40-46d1-82c5-fd51bb348aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970658587-172.17.0.2-1598102058849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40306,DS-6815c40a-9331-4826-9362-ef59fd45d1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-dac9a877-c6b3-46a9-8533-e4405b955a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-5dfe77de-74d6-4c2d-9bb0-9b8b34d305ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-bb63863b-7d3b-4fa0-86ef-c85636d12241,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-8c26f345-2824-4207-9a16-e2086d35af76,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-e6fa3201-1e1c-46f4-8f66-dbdc5074298c,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-26350a04-cb3d-4a81-9dcf-31569382c03e,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-2094d8dc-46f6-4847-93e1-e56bd5ce6111,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970658587-172.17.0.2-1598102058849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40306,DS-6815c40a-9331-4826-9362-ef59fd45d1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-dac9a877-c6b3-46a9-8533-e4405b955a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-5dfe77de-74d6-4c2d-9bb0-9b8b34d305ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-bb63863b-7d3b-4fa0-86ef-c85636d12241,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-8c26f345-2824-4207-9a16-e2086d35af76,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-e6fa3201-1e1c-46f4-8f66-dbdc5074298c,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-26350a04-cb3d-4a81-9dcf-31569382c03e,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-2094d8dc-46f6-4847-93e1-e56bd5ce6111,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1578515457-172.17.0.2-1598102118230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45284,DS-93963aef-927a-471c-9d20-e5bf51addd33,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-bd69016d-543a-4286-9bcb-984545bc31a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-e14b89e3-7b00-4d31-8cee-f9933333876c,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-8bc327e0-448d-4080-ac1b-c7bc8d322043,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-96a38e55-4ef3-40df-bc42-0d18a28c4c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-ab840f06-6bc7-4ad1-b195-a4138962e5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-cd88bf70-def6-47a2-9f19-90d28f7c5745,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-e0b549d3-348e-48fc-b7b6-f919ae172575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1578515457-172.17.0.2-1598102118230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45284,DS-93963aef-927a-471c-9d20-e5bf51addd33,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-bd69016d-543a-4286-9bcb-984545bc31a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-e14b89e3-7b00-4d31-8cee-f9933333876c,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-8bc327e0-448d-4080-ac1b-c7bc8d322043,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-96a38e55-4ef3-40df-bc42-0d18a28c4c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-ab840f06-6bc7-4ad1-b195-a4138962e5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-cd88bf70-def6-47a2-9f19-90d28f7c5745,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-e0b549d3-348e-48fc-b7b6-f919ae172575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066530366-172.17.0.2-1598102150957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38881,DS-70bf1b62-275c-4ca7-8f4f-199998baf658,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-824aef68-f226-473c-894f-39965e048a66,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-5db73a80-171f-4cfa-a735-763854bc7de9,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-f4d098be-9469-43e1-8432-df808c44c629,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-a9e90edc-deee-42b9-827d-2d7978db4ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-8e04d366-8a49-4abb-a473-427b0965eb77,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-b815ec45-ad2c-4f6d-a328-40b77d661e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-f03228e0-5a25-4200-8d99-3e7912d54753,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066530366-172.17.0.2-1598102150957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38881,DS-70bf1b62-275c-4ca7-8f4f-199998baf658,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-824aef68-f226-473c-894f-39965e048a66,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-5db73a80-171f-4cfa-a735-763854bc7de9,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-f4d098be-9469-43e1-8432-df808c44c629,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-a9e90edc-deee-42b9-827d-2d7978db4ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-8e04d366-8a49-4abb-a473-427b0965eb77,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-b815ec45-ad2c-4f6d-a328-40b77d661e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-f03228e0-5a25-4200-8d99-3e7912d54753,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862753300-172.17.0.2-1598102223060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37882,DS-39fbbd4d-50c3-45b4-b473-40b8a4917daa,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-73813b90-1e16-4992-822e-f7798900184d,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-24b9877e-6049-4dac-80c0-da6f6d9ea200,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-eb99b74a-65cb-4596-a37c-938019c5eafd,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-d5c60f99-296a-444d-8f37-3f93ef468cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-4edb1357-eff9-4c32-9e86-7700eb1c3a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-98fe696a-bbd9-410b-80d6-6822687db39a,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-1ef6f397-cf50-46ae-8238-d7402f059ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862753300-172.17.0.2-1598102223060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37882,DS-39fbbd4d-50c3-45b4-b473-40b8a4917daa,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-73813b90-1e16-4992-822e-f7798900184d,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-24b9877e-6049-4dac-80c0-da6f6d9ea200,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-eb99b74a-65cb-4596-a37c-938019c5eafd,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-d5c60f99-296a-444d-8f37-3f93ef468cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-4edb1357-eff9-4c32-9e86-7700eb1c3a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-98fe696a-bbd9-410b-80d6-6822687db39a,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-1ef6f397-cf50-46ae-8238-d7402f059ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1445997501-172.17.0.2-1598102392329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35436,DS-bafc8b4b-49b1-474e-9c6e-12d768b70a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-69fabc54-d915-4c4e-a570-a4bee70a2c29,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-e9778fe8-d03b-4ffd-8680-fb6e07e0462b,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-41da49e6-d5bf-4d9b-8d53-05d3153a2c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-32ef3044-2037-48bd-8971-cc4b7e5dec89,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-fcbe2c51-173b-47d7-a772-a3dcae4f4015,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-a9204ec9-4c40-4517-8835-0ffd59ffb368,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-ea6221c6-8a0f-40eb-9841-3c6e5869ab81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1445997501-172.17.0.2-1598102392329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35436,DS-bafc8b4b-49b1-474e-9c6e-12d768b70a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-69fabc54-d915-4c4e-a570-a4bee70a2c29,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-e9778fe8-d03b-4ffd-8680-fb6e07e0462b,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-41da49e6-d5bf-4d9b-8d53-05d3153a2c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-32ef3044-2037-48bd-8971-cc4b7e5dec89,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-fcbe2c51-173b-47d7-a772-a3dcae4f4015,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-a9204ec9-4c40-4517-8835-0ffd59ffb368,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-ea6221c6-8a0f-40eb-9841-3c6e5869ab81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116819745-172.17.0.2-1598102531595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40595,DS-3e9fb293-2d35-4b2a-a83e-921533aca34c,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-a55d2c26-df76-487e-9cff-bd1717a2e1da,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-c4ef84c5-f53a-4c11-9b0c-fa91edea0793,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-f2066178-70fd-428a-ba13-2249ca2c73bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-6f34811a-0aa3-4d62-b1f0-4d3577d3636f,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-ad2a80b2-3907-4eab-a95b-b2cc3e54e74a,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-e893aa15-c762-4053-85a7-f734d34ad409,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-cb6de5b3-f1b2-4171-8d6b-3c28dd9805c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116819745-172.17.0.2-1598102531595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40595,DS-3e9fb293-2d35-4b2a-a83e-921533aca34c,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-a55d2c26-df76-487e-9cff-bd1717a2e1da,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-c4ef84c5-f53a-4c11-9b0c-fa91edea0793,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-f2066178-70fd-428a-ba13-2249ca2c73bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-6f34811a-0aa3-4d62-b1f0-4d3577d3636f,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-ad2a80b2-3907-4eab-a95b-b2cc3e54e74a,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-e893aa15-c762-4053-85a7-f734d34ad409,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-cb6de5b3-f1b2-4171-8d6b-3c28dd9805c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132093163-172.17.0.2-1598103371857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40057,DS-8f739fa8-fc12-4d16-b2ef-911e3be26961,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-a798e5f5-603c-4755-802b-f5ec13a89146,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-408f91c7-cd22-4426-97c4-68482d37528b,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-f06122e9-e600-40fa-b1fc-10d5268da2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-2ce799ab-ba9a-4a53-9201-9dee2c4ed4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-d24f5d4a-5d83-4796-9833-6728445d7012,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-e9108320-4fc3-44fd-b280-b455e8a93f78,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-f06c8558-3b2a-4b8f-b0ef-51fba8cab4cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132093163-172.17.0.2-1598103371857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40057,DS-8f739fa8-fc12-4d16-b2ef-911e3be26961,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-a798e5f5-603c-4755-802b-f5ec13a89146,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-408f91c7-cd22-4426-97c4-68482d37528b,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-f06122e9-e600-40fa-b1fc-10d5268da2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-2ce799ab-ba9a-4a53-9201-9dee2c4ed4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-d24f5d4a-5d83-4796-9833-6728445d7012,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-e9108320-4fc3-44fd-b280-b455e8a93f78,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-f06c8558-3b2a-4b8f-b0ef-51fba8cab4cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475876809-172.17.0.2-1598103481794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36774,DS-e8ee76aa-c055-40c0-959c-d26e22e59805,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-3e10750e-40c9-4b54-a095-e1c74de9a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-f0180a34-fe74-4d54-9518-54a5ce6d1c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-257a4b23-e132-4a0b-9b69-a460a4c8007f,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-50ce89e5-0695-4d80-af63-9a8330236028,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-09fe9350-d4b9-4651-bf7e-2210b8890a41,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-54cc2396-ed1e-402f-8d7c-c9fbca579507,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-427b852e-9b97-4cc4-b6a4-0725c95cd8f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475876809-172.17.0.2-1598103481794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36774,DS-e8ee76aa-c055-40c0-959c-d26e22e59805,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-3e10750e-40c9-4b54-a095-e1c74de9a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-f0180a34-fe74-4d54-9518-54a5ce6d1c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-257a4b23-e132-4a0b-9b69-a460a4c8007f,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-50ce89e5-0695-4d80-af63-9a8330236028,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-09fe9350-d4b9-4651-bf7e-2210b8890a41,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-54cc2396-ed1e-402f-8d7c-c9fbca579507,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-427b852e-9b97-4cc4-b6a4-0725c95cd8f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-472342619-172.17.0.2-1598103553953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37831,DS-34d96bb2-f8a8-4501-89f3-4397642601fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-93e3739a-d382-46b1-9fa8-310b8d83eb27,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-47b7af00-5266-49c6-93c2-350b93dfe704,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-f2c28ad5-101a-4bc7-a2c2-765656de5866,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-1d2ee6ce-99d0-45eb-85b3-ff8be28e19e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-bb9b6046-f4e1-472f-b94d-98d072ad29a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-e49b45c8-a044-4271-8edd-8f9ba27138e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-12e9a77e-4aad-4cf4-b598-064ee3224715,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-472342619-172.17.0.2-1598103553953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37831,DS-34d96bb2-f8a8-4501-89f3-4397642601fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-93e3739a-d382-46b1-9fa8-310b8d83eb27,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-47b7af00-5266-49c6-93c2-350b93dfe704,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-f2c28ad5-101a-4bc7-a2c2-765656de5866,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-1d2ee6ce-99d0-45eb-85b3-ff8be28e19e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-bb9b6046-f4e1-472f-b94d-98d072ad29a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-e49b45c8-a044-4271-8edd-8f9ba27138e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-12e9a77e-4aad-4cf4-b598-064ee3224715,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487711510-172.17.0.2-1598104227621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35279,DS-70de6829-8ef9-4069-a5b4-e5ab6708c602,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-60e34bbd-a597-40a2-8f33-dcab85646203,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-8a30f914-d182-4f65-bdab-109e403bf780,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-ace6f138-20b0-498a-810d-b28ecb0482cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-d2686f1e-e2b6-47b4-8f0b-afdce94759cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-0aec30e1-47c5-4c7d-91b3-5b6ea5452cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-b34fd0c2-3b95-47a9-8cee-db9c0050c474,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-68a09e7f-2234-4e28-8538-8813fe1254ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487711510-172.17.0.2-1598104227621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35279,DS-70de6829-8ef9-4069-a5b4-e5ab6708c602,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-60e34bbd-a597-40a2-8f33-dcab85646203,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-8a30f914-d182-4f65-bdab-109e403bf780,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-ace6f138-20b0-498a-810d-b28ecb0482cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-d2686f1e-e2b6-47b4-8f0b-afdce94759cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-0aec30e1-47c5-4c7d-91b3-5b6ea5452cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-b34fd0c2-3b95-47a9-8cee-db9c0050c474,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-68a09e7f-2234-4e28-8538-8813fe1254ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806660062-172.17.0.2-1598104620355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37356,DS-694fd087-fdaf-41ab-8689-a4b1a7ac283e,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-d2181f87-668f-4e22-b4f5-b40d1b825749,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-1a7fb400-51e5-4d21-af71-8ba35c8b5fed,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-c687fe83-873a-4665-85d6-755d3dfae09a,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-e5db1abc-d0bc-4aba-aa6f-bf1bb9a378bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-aebaf94a-ae46-465e-8667-f77e15d659e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-cac10f1c-d29c-475d-a5b3-93225e3d7b29,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-0c0d1ac8-4d4d-435b-b2d5-b77bb439f2bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806660062-172.17.0.2-1598104620355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37356,DS-694fd087-fdaf-41ab-8689-a4b1a7ac283e,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-d2181f87-668f-4e22-b4f5-b40d1b825749,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-1a7fb400-51e5-4d21-af71-8ba35c8b5fed,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-c687fe83-873a-4665-85d6-755d3dfae09a,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-e5db1abc-d0bc-4aba-aa6f-bf1bb9a378bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-aebaf94a-ae46-465e-8667-f77e15d659e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-cac10f1c-d29c-475d-a5b3-93225e3d7b29,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-0c0d1ac8-4d4d-435b-b2d5-b77bb439f2bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1175360171-172.17.0.2-1598104658885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43339,DS-cd617aa1-b508-494e-8354-dd65852bea08,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-4dc06a0a-54c9-419b-ac5e-099d446bc87f,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-aec3ca8c-cde4-4d51-beb2-42b28bb65340,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-ce8f8978-7a19-4c8f-90c8-b6ee3729f76d,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-76aa27da-5558-4ee0-9cc1-87c115287328,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-de540fcf-36b9-4a2d-8bbe-92a153da3b96,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-b95b2a63-b9e1-4e48-9cef-bf89139368eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-77f49274-c210-4007-a02f-0fdd5694ec20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1175360171-172.17.0.2-1598104658885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43339,DS-cd617aa1-b508-494e-8354-dd65852bea08,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-4dc06a0a-54c9-419b-ac5e-099d446bc87f,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-aec3ca8c-cde4-4d51-beb2-42b28bb65340,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-ce8f8978-7a19-4c8f-90c8-b6ee3729f76d,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-76aa27da-5558-4ee0-9cc1-87c115287328,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-de540fcf-36b9-4a2d-8bbe-92a153da3b96,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-b95b2a63-b9e1-4e48-9cef-bf89139368eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-77f49274-c210-4007-a02f-0fdd5694ec20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048475581-172.17.0.2-1598104696916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33781,DS-131b11d4-4870-4e99-8aa2-d15671c583ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-eff1d827-dd04-4d7b-b108-9986fb7ba072,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-0fe7a3a6-fc8e-4b3c-b03c-780a42927ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-f567a5f4-ab66-461d-88b6-89b7a2f9bd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-e20cadfb-2de2-4dc1-bdbf-307402e04ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-3b54732d-9d66-4b45-a8f7-750c6fe96a84,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-04ee9b91-3456-47a2-809f-7ca799cf9e78,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-6a0c6655-83b5-4ad2-b4e2-d72de007fa94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048475581-172.17.0.2-1598104696916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33781,DS-131b11d4-4870-4e99-8aa2-d15671c583ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-eff1d827-dd04-4d7b-b108-9986fb7ba072,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-0fe7a3a6-fc8e-4b3c-b03c-780a42927ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-f567a5f4-ab66-461d-88b6-89b7a2f9bd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-e20cadfb-2de2-4dc1-bdbf-307402e04ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-3b54732d-9d66-4b45-a8f7-750c6fe96a84,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-04ee9b91-3456-47a2-809f-7ca799cf9e78,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-6a0c6655-83b5-4ad2-b4e2-d72de007fa94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5338
