reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334957042-172.17.0.20-1598138870316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46565,DS-9b10373c-907c-4a72-addb-6b26d09eee4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-3b04c84f-7030-425f-919d-c7dd7ef52dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-f2b997b7-91c4-4079-b309-c2f3801184af,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-e42ef7c8-b7c4-4c71-8c03-3631369b8203,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-d8e07d05-1b9e-4007-b988-55ae71871f16,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-22c82f88-5e9f-4e10-a48b-d5dd87cd0a17,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-10ccb684-beac-4fa9-89e0-74a93425135a,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-5167fa6f-b3a4-4e6e-88bc-169c28646a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334957042-172.17.0.20-1598138870316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46565,DS-9b10373c-907c-4a72-addb-6b26d09eee4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-3b04c84f-7030-425f-919d-c7dd7ef52dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-f2b997b7-91c4-4079-b309-c2f3801184af,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-e42ef7c8-b7c4-4c71-8c03-3631369b8203,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-d8e07d05-1b9e-4007-b988-55ae71871f16,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-22c82f88-5e9f-4e10-a48b-d5dd87cd0a17,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-10ccb684-beac-4fa9-89e0-74a93425135a,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-5167fa6f-b3a4-4e6e-88bc-169c28646a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-276098057-172.17.0.20-1598138908669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40631,DS-2a1ea393-6d4c-45b4-9321-2b25f31ee247,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-69d4bda3-21b6-406f-b754-fcdf116b14ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-3e305436-fd8f-4ce7-8297-9addd28f4c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-7e354fef-9b8f-4c00-ae62-2553c9f1656b,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-4860c9f2-4416-4900-9169-d79b9c6cc6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-731b17d3-d4b3-4a14-821d-ec2e37f56a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-6729f3c9-77f3-42ba-a6f8-6e6c5d680bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-f7159f24-853f-44e0-b93d-1d321b58c2e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-276098057-172.17.0.20-1598138908669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40631,DS-2a1ea393-6d4c-45b4-9321-2b25f31ee247,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-69d4bda3-21b6-406f-b754-fcdf116b14ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-3e305436-fd8f-4ce7-8297-9addd28f4c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-7e354fef-9b8f-4c00-ae62-2553c9f1656b,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-4860c9f2-4416-4900-9169-d79b9c6cc6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-731b17d3-d4b3-4a14-821d-ec2e37f56a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-6729f3c9-77f3-42ba-a6f8-6e6c5d680bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-f7159f24-853f-44e0-b93d-1d321b58c2e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740633146-172.17.0.20-1598138940537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39605,DS-eb35afaa-a36d-4249-a804-3215e76ed159,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-375ab212-931d-4464-8f68-7657ac03a628,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-d515f73c-1148-4a6c-9481-56c470d2157d,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-ebe77097-c03e-4c0d-9e42-334ff5f4d850,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-928e53d6-c1b8-4daa-88d3-78b8e7f63fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-a2d9061a-1f6f-4bc3-9b8f-2390e53b79ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-f9de1bbf-c3a4-4b98-89a0-52ce4c1cbbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-270ca50f-8559-4f2d-b307-93d45b3c2132,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740633146-172.17.0.20-1598138940537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39605,DS-eb35afaa-a36d-4249-a804-3215e76ed159,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-375ab212-931d-4464-8f68-7657ac03a628,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-d515f73c-1148-4a6c-9481-56c470d2157d,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-ebe77097-c03e-4c0d-9e42-334ff5f4d850,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-928e53d6-c1b8-4daa-88d3-78b8e7f63fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-a2d9061a-1f6f-4bc3-9b8f-2390e53b79ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-f9de1bbf-c3a4-4b98-89a0-52ce4c1cbbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-270ca50f-8559-4f2d-b307-93d45b3c2132,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050252532-172.17.0.20-1598139267887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39493,DS-165347a6-5366-40d8-a616-48cbe6c1e2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-efddee67-f1fc-4d8f-b23d-e3f3ed10fa06,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-aa79fa62-f65b-44ad-96b6-9538d5914831,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-70f5a6a6-cb80-433c-9800-85904a94cb03,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-b99ba3f4-b81b-405c-8cba-4b495627efca,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-c3b9a4b8-a79a-4a86-89e8-0fd468234437,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-c42b39c5-78e2-41b1-9175-8997cd5913a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-5c1db608-af88-4555-b028-3a6dc6b5e272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050252532-172.17.0.20-1598139267887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39493,DS-165347a6-5366-40d8-a616-48cbe6c1e2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-efddee67-f1fc-4d8f-b23d-e3f3ed10fa06,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-aa79fa62-f65b-44ad-96b6-9538d5914831,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-70f5a6a6-cb80-433c-9800-85904a94cb03,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-b99ba3f4-b81b-405c-8cba-4b495627efca,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-c3b9a4b8-a79a-4a86-89e8-0fd468234437,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-c42b39c5-78e2-41b1-9175-8997cd5913a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-5c1db608-af88-4555-b028-3a6dc6b5e272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479339029-172.17.0.20-1598139530883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44053,DS-ed93ad1b-0276-470d-9ddb-4d25c7b81d14,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-410d9fa4-ac61-4d88-9714-85afdad1e81b,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-57dc6d18-3e62-4603-a538-e42340ebb7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-4c616207-36d1-4934-8eef-e5866a4e443b,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-c9614afe-007a-4ef7-adde-ebe045529264,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-d6566f31-1e6b-460a-b88e-a766dcbd82bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-55542ab5-57a4-40d0-94cc-dac9d5291a88,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-ca52bca7-9883-4364-be74-49042666ba87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479339029-172.17.0.20-1598139530883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44053,DS-ed93ad1b-0276-470d-9ddb-4d25c7b81d14,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-410d9fa4-ac61-4d88-9714-85afdad1e81b,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-57dc6d18-3e62-4603-a538-e42340ebb7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-4c616207-36d1-4934-8eef-e5866a4e443b,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-c9614afe-007a-4ef7-adde-ebe045529264,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-d6566f31-1e6b-460a-b88e-a766dcbd82bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-55542ab5-57a4-40d0-94cc-dac9d5291a88,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-ca52bca7-9883-4364-be74-49042666ba87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668657842-172.17.0.20-1598139701386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40442,DS-4a1883af-ea7f-4fcf-8cb4-ec096b9c4c19,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-848ded1f-c649-4196-a487-f255bfd5126a,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-1bf4d433-56b2-43e2-8b7c-c6b2cbf15e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-5d9f4005-83d2-4781-b59f-e02cd2957e94,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-0c38f40e-6c55-4c0a-9300-81624f415afa,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-444398c7-9a73-49ec-8dbe-be48502d4e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-3e42a014-7b7c-4ab4-9ff6-3ff0c36dce67,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-85a3befe-c767-4fc7-b69a-e4367ed057cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668657842-172.17.0.20-1598139701386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40442,DS-4a1883af-ea7f-4fcf-8cb4-ec096b9c4c19,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-848ded1f-c649-4196-a487-f255bfd5126a,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-1bf4d433-56b2-43e2-8b7c-c6b2cbf15e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-5d9f4005-83d2-4781-b59f-e02cd2957e94,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-0c38f40e-6c55-4c0a-9300-81624f415afa,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-444398c7-9a73-49ec-8dbe-be48502d4e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-3e42a014-7b7c-4ab4-9ff6-3ff0c36dce67,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-85a3befe-c767-4fc7-b69a-e4367ed057cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488033244-172.17.0.20-1598139794178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46689,DS-b55997f2-de4e-488e-a812-b4901a9d6042,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-32e1c7e0-a8c8-4ec9-a980-7a4e178ae77a,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-76b172df-dc3f-4475-b3c6-8ed8717efe44,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-7c69f553-3aae-487c-ae2a-002a66077872,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-60ba6a08-ab2f-4103-a597-56f168aa0cae,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-c534e51f-767b-444c-9e39-9b7bac40a005,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-fbcefc21-f533-40cf-b857-4502eacfb13f,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-8b49e1f4-8c5e-4f5c-aa66-051c36de3fcb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488033244-172.17.0.20-1598139794178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46689,DS-b55997f2-de4e-488e-a812-b4901a9d6042,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-32e1c7e0-a8c8-4ec9-a980-7a4e178ae77a,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-76b172df-dc3f-4475-b3c6-8ed8717efe44,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-7c69f553-3aae-487c-ae2a-002a66077872,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-60ba6a08-ab2f-4103-a597-56f168aa0cae,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-c534e51f-767b-444c-9e39-9b7bac40a005,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-fbcefc21-f533-40cf-b857-4502eacfb13f,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-8b49e1f4-8c5e-4f5c-aa66-051c36de3fcb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896949174-172.17.0.20-1598139967882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38317,DS-5f764277-f88e-46e4-8b00-e6f8e2174be6,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-7b08d740-87b5-4291-b062-a779c0810334,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-6f769d17-c977-46dd-b331-6249dd690b45,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-f2f962ee-c86a-4393-a55e-496235eff4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-5cfd6e35-d799-4711-b458-2f2a77e47704,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-7c363f61-f65a-4d67-bf16-c117a5e0babe,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-0e914878-3209-4735-b133-570bbdce39b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-20235947-09a3-4b8c-8966-d10a5de88b76,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896949174-172.17.0.20-1598139967882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38317,DS-5f764277-f88e-46e4-8b00-e6f8e2174be6,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-7b08d740-87b5-4291-b062-a779c0810334,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-6f769d17-c977-46dd-b331-6249dd690b45,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-f2f962ee-c86a-4393-a55e-496235eff4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-5cfd6e35-d799-4711-b458-2f2a77e47704,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-7c363f61-f65a-4d67-bf16-c117a5e0babe,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-0e914878-3209-4735-b133-570bbdce39b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-20235947-09a3-4b8c-8966-d10a5de88b76,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678896195-172.17.0.20-1598140260588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40081,DS-22c5029a-0943-4a4e-977c-96d3ecd2d8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-8f32abfb-f834-4a66-8005-971927772ede,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-96233238-d119-4f83-bffc-0808c0b1f711,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-785a8725-7866-4551-99f8-a21e4cd265b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-20b0f0b2-148a-4254-9b1b-7ad14cd8c083,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-68816f85-ee52-44b2-b4d8-35bad829662b,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-75eb2f06-8568-4512-84b9-9fab0748313a,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-6cd67490-fe5b-4af2-9632-dfa89c45a9c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678896195-172.17.0.20-1598140260588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40081,DS-22c5029a-0943-4a4e-977c-96d3ecd2d8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-8f32abfb-f834-4a66-8005-971927772ede,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-96233238-d119-4f83-bffc-0808c0b1f711,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-785a8725-7866-4551-99f8-a21e4cd265b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-20b0f0b2-148a-4254-9b1b-7ad14cd8c083,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-68816f85-ee52-44b2-b4d8-35bad829662b,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-75eb2f06-8568-4512-84b9-9fab0748313a,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-6cd67490-fe5b-4af2-9632-dfa89c45a9c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952761918-172.17.0.20-1598140481417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37064,DS-b82eadd6-7e28-4632-9563-81ef8a0397c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-00ab8d15-17b1-4e3b-a057-881c64eb4515,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-ce1a9682-4ab9-45a8-a723-2939d1517521,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-79e111a8-2e69-498a-a370-2f19e68b9ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-2dfa6206-3a30-45d6-bd4f-96767664c739,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-f4fc2123-5d60-43f8-b310-6d2e6f199295,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-f42911e8-f71c-43f5-8d88-38766e12cb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-4eb3419e-fbc1-4729-8926-921c5866481f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952761918-172.17.0.20-1598140481417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37064,DS-b82eadd6-7e28-4632-9563-81ef8a0397c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-00ab8d15-17b1-4e3b-a057-881c64eb4515,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-ce1a9682-4ab9-45a8-a723-2939d1517521,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-79e111a8-2e69-498a-a370-2f19e68b9ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-2dfa6206-3a30-45d6-bd4f-96767664c739,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-f4fc2123-5d60-43f8-b310-6d2e6f199295,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-f42911e8-f71c-43f5-8d88-38766e12cb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-4eb3419e-fbc1-4729-8926-921c5866481f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546893593-172.17.0.20-1598140776116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36102,DS-e3740cb0-1a64-4bda-8110-a978452938fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-780e4933-ef3f-4865-b58a-175cfcae1c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-388c8f1d-f0bf-4968-933e-436174574d75,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-269b472b-52f2-4387-ab82-5317edb68ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-36cf1fe7-8c81-4814-96e2-b7e27f6f08ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-71533555-6a8e-4157-8cda-fe89ffeca176,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-f9bf330d-920c-4c07-8b9f-132015dfaa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-b018933d-8750-40c7-b0ef-233d791f12ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546893593-172.17.0.20-1598140776116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36102,DS-e3740cb0-1a64-4bda-8110-a978452938fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-780e4933-ef3f-4865-b58a-175cfcae1c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-388c8f1d-f0bf-4968-933e-436174574d75,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-269b472b-52f2-4387-ab82-5317edb68ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-36cf1fe7-8c81-4814-96e2-b7e27f6f08ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-71533555-6a8e-4157-8cda-fe89ffeca176,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-f9bf330d-920c-4c07-8b9f-132015dfaa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-b018933d-8750-40c7-b0ef-233d791f12ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404720608-172.17.0.20-1598140830182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42414,DS-9157c00e-90a0-45f0-a83b-c78aa435d489,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-324c7957-af62-4309-a6ed-59f041a31558,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-0939fa82-cc16-4eb5-a8e7-d788c8591943,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-0f1e71c8-c3eb-40d6-9bf8-a3911511dac3,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-879f6b5e-a6c3-4618-9a25-16c3c354d1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-c8dd327f-35b4-42a7-b814-45e2b166952f,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-92fc1b53-09a4-47a1-aac0-f5b536a572c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-5ad6d01f-82e3-4d45-9cc3-c07ae4a614fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404720608-172.17.0.20-1598140830182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42414,DS-9157c00e-90a0-45f0-a83b-c78aa435d489,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-324c7957-af62-4309-a6ed-59f041a31558,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-0939fa82-cc16-4eb5-a8e7-d788c8591943,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-0f1e71c8-c3eb-40d6-9bf8-a3911511dac3,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-879f6b5e-a6c3-4618-9a25-16c3c354d1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-c8dd327f-35b4-42a7-b814-45e2b166952f,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-92fc1b53-09a4-47a1-aac0-f5b536a572c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-5ad6d01f-82e3-4d45-9cc3-c07ae4a614fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747661735-172.17.0.20-1598141004259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37618,DS-35567535-39ab-4de9-993b-4831ba1fe06b,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-88ffa942-0282-4c9d-a646-4779791b743a,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-5c8ea5ab-ddbc-42cb-9b10-c47794da47c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-450811d3-998b-48c4-adcf-ddf7e2da68b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-1ae7fd05-4550-4685-856c-c480235a42f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-a4b2756d-8d5a-449f-b1fa-49464599522f,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-1d491b3c-1603-4424-853f-8c9398311693,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-7c3b8481-2277-437a-b3db-7447ea8fb5bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747661735-172.17.0.20-1598141004259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37618,DS-35567535-39ab-4de9-993b-4831ba1fe06b,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-88ffa942-0282-4c9d-a646-4779791b743a,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-5c8ea5ab-ddbc-42cb-9b10-c47794da47c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-450811d3-998b-48c4-adcf-ddf7e2da68b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-1ae7fd05-4550-4685-856c-c480235a42f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-a4b2756d-8d5a-449f-b1fa-49464599522f,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-1d491b3c-1603-4424-853f-8c9398311693,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-7c3b8481-2277-437a-b3db-7447ea8fb5bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549802681-172.17.0.20-1598141183494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37552,DS-66218c3b-6f0d-48f7-92fb-c9c35f0d2505,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-89c43be1-e669-4ddc-915c-fec0625f0798,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-970292e3-d912-4691-a824-fc0abdd5576b,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-d2608e66-ce8e-4f7d-9337-48a8196dcbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-cbf528cc-f6bd-4b5c-95d5-1e298564ab2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-0bf6b463-02f4-4f85-bd21-ecebc7830c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-43ce96d2-434e-4ca3-b3be-184fced00dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-2866314b-1e9c-45ff-9832-0ef97c813532,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549802681-172.17.0.20-1598141183494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37552,DS-66218c3b-6f0d-48f7-92fb-c9c35f0d2505,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-89c43be1-e669-4ddc-915c-fec0625f0798,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-970292e3-d912-4691-a824-fc0abdd5576b,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-d2608e66-ce8e-4f7d-9337-48a8196dcbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-cbf528cc-f6bd-4b5c-95d5-1e298564ab2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-0bf6b463-02f4-4f85-bd21-ecebc7830c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-43ce96d2-434e-4ca3-b3be-184fced00dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-2866314b-1e9c-45ff-9832-0ef97c813532,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769834203-172.17.0.20-1598141267358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41364,DS-94d36048-a34f-4724-82ae-928886ed4723,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-fafe89de-cba0-4ea4-a073-149839e473fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-2c0d41e4-178d-42ce-b9bf-d8067a23af36,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-65bad7c3-7910-4ed4-a1b8-329491a2093a,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-9c918272-dc42-4f56-905d-6a59f4ac957f,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-93506566-8bac-4dcd-b13a-5e2201dcc090,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-1c531168-7755-4d93-95bb-e3773a462979,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-57e56a99-2e43-4eef-a61d-75e91a1394d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769834203-172.17.0.20-1598141267358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41364,DS-94d36048-a34f-4724-82ae-928886ed4723,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-fafe89de-cba0-4ea4-a073-149839e473fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-2c0d41e4-178d-42ce-b9bf-d8067a23af36,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-65bad7c3-7910-4ed4-a1b8-329491a2093a,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-9c918272-dc42-4f56-905d-6a59f4ac957f,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-93506566-8bac-4dcd-b13a-5e2201dcc090,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-1c531168-7755-4d93-95bb-e3773a462979,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-57e56a99-2e43-4eef-a61d-75e91a1394d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992843720-172.17.0.20-1598141435375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42793,DS-2c38b7e3-9e09-41f7-b63e-0ef353adffea,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-779e889b-6b85-4a08-af59-0cc98138b7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-ae01e0eb-7597-4020-979e-372ec0ac3742,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-54569e1d-f785-4024-97cc-0a9a69fbbebe,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-cd3e5796-aedd-483f-998d-bdc2e2977b04,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-850524c2-5f8c-4c0e-a1fd-09d5886d6700,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-bc51ee5a-fd10-4d39-89f0-18984471c032,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-8c2a0875-3a92-46f8-9945-8b12ef3dde57,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992843720-172.17.0.20-1598141435375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42793,DS-2c38b7e3-9e09-41f7-b63e-0ef353adffea,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-779e889b-6b85-4a08-af59-0cc98138b7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-ae01e0eb-7597-4020-979e-372ec0ac3742,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-54569e1d-f785-4024-97cc-0a9a69fbbebe,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-cd3e5796-aedd-483f-998d-bdc2e2977b04,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-850524c2-5f8c-4c0e-a1fd-09d5886d6700,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-bc51ee5a-fd10-4d39-89f0-18984471c032,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-8c2a0875-3a92-46f8-9945-8b12ef3dde57,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605375742-172.17.0.20-1598141560258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35587,DS-6040e8cb-4c83-4256-8b75-31c4f0da370b,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-982f7f34-e642-4df6-ace8-f1b8fa46bd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-f78f2707-be9e-409d-927a-25011f44ce45,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-3cb1838c-f39f-4e6c-b7ae-cd41ce583546,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-afe32763-d120-414f-9499-bfd78ca21ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-a056a5c5-df1a-45b4-a234-1f51ba471a82,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-a585379c-4108-4988-8554-4307f18f622f,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-a6cd7f9c-9fff-4cc3-9566-bde27309cce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605375742-172.17.0.20-1598141560258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35587,DS-6040e8cb-4c83-4256-8b75-31c4f0da370b,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-982f7f34-e642-4df6-ace8-f1b8fa46bd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-f78f2707-be9e-409d-927a-25011f44ce45,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-3cb1838c-f39f-4e6c-b7ae-cd41ce583546,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-afe32763-d120-414f-9499-bfd78ca21ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-a056a5c5-df1a-45b4-a234-1f51ba471a82,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-a585379c-4108-4988-8554-4307f18f622f,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-a6cd7f9c-9fff-4cc3-9566-bde27309cce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101855129-172.17.0.20-1598141607021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46658,DS-835f42ab-717e-43cd-86fa-fc3c910da68d,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-efbd3e5f-b833-42fb-a6c7-01f47314f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-c02ec09c-6a47-4778-a02e-0faf7b759286,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-468fa9bf-e2eb-4fcd-a088-a5d3aea70e30,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-6d678a6a-6085-4fcf-8a5e-66daa502bef7,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-873dd8a9-150b-438a-8385-5c32f1b42871,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-e17d2039-db9c-444e-a24d-28df268bc26d,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-58b13f00-1c03-4746-aed9-af23f4a5fb7d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101855129-172.17.0.20-1598141607021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46658,DS-835f42ab-717e-43cd-86fa-fc3c910da68d,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-efbd3e5f-b833-42fb-a6c7-01f47314f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-c02ec09c-6a47-4778-a02e-0faf7b759286,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-468fa9bf-e2eb-4fcd-a088-a5d3aea70e30,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-6d678a6a-6085-4fcf-8a5e-66daa502bef7,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-873dd8a9-150b-438a-8385-5c32f1b42871,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-e17d2039-db9c-444e-a24d-28df268bc26d,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-58b13f00-1c03-4746-aed9-af23f4a5fb7d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958722653-172.17.0.20-1598141863632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33475,DS-307fbbad-def0-460a-8437-24af1e8d8d90,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-be8ccd1a-208a-4147-a5a7-90cae9f416b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-2103cafe-b764-48b4-86df-038eb3c4d060,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-d1071448-4dd5-4990-9db6-19781cbb24e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-47047c1b-b40f-4de4-afa8-b7964ab70e93,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-3ecf7bc2-32c9-4585-ac6c-c0f0007d131c,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-0b9265d8-c501-4bb4-8dbd-857e2fc8dd13,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-9a27d1d5-0bea-42f0-81b0-098bed8a10c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958722653-172.17.0.20-1598141863632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33475,DS-307fbbad-def0-460a-8437-24af1e8d8d90,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-be8ccd1a-208a-4147-a5a7-90cae9f416b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-2103cafe-b764-48b4-86df-038eb3c4d060,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-d1071448-4dd5-4990-9db6-19781cbb24e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-47047c1b-b40f-4de4-afa8-b7964ab70e93,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-3ecf7bc2-32c9-4585-ac6c-c0f0007d131c,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-0b9265d8-c501-4bb4-8dbd-857e2fc8dd13,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-9a27d1d5-0bea-42f0-81b0-098bed8a10c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875530773-172.17.0.20-1598142212992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33532,DS-e6d0e980-c3d0-47a1-a781-bf866a2d58c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-072fcc3d-8cd3-431d-9b18-303b4896b687,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-52770864-f8bd-4bce-9d8b-ec0a001f6886,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-956381c3-3a78-45af-824b-05a7a39ae0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-0a5de223-1515-4050-914f-e37fc1fccab8,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-87ec76d9-a373-4f42-a0ef-045e31c9ec0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-9eb46f02-53f0-4833-97e0-a68d042f8b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-ed66e21f-1cea-46ab-ac0b-9d3672a22e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875530773-172.17.0.20-1598142212992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33532,DS-e6d0e980-c3d0-47a1-a781-bf866a2d58c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-072fcc3d-8cd3-431d-9b18-303b4896b687,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-52770864-f8bd-4bce-9d8b-ec0a001f6886,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-956381c3-3a78-45af-824b-05a7a39ae0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-0a5de223-1515-4050-914f-e37fc1fccab8,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-87ec76d9-a373-4f42-a0ef-045e31c9ec0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-9eb46f02-53f0-4833-97e0-a68d042f8b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-ed66e21f-1cea-46ab-ac0b-9d3672a22e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658377298-172.17.0.20-1598142381234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34629,DS-c12fabb8-3e14-43cc-868e-635596527afa,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-452bd97c-8470-42d0-8aea-749ba0b6bf27,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-025e5a4c-fca5-4bd3-b30d-5de75aa9084d,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-60a54872-6901-4252-923e-6f4c7799b448,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-1924b3ba-568b-4094-9440-6072280c49fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-1f2bdf69-f907-4493-84df-e93580cae317,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-7f6b3978-9185-4b5f-ae5e-18662f6cc11b,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-b7486360-d1ea-45c5-b9d5-90798ec33298,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658377298-172.17.0.20-1598142381234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34629,DS-c12fabb8-3e14-43cc-868e-635596527afa,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-452bd97c-8470-42d0-8aea-749ba0b6bf27,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-025e5a4c-fca5-4bd3-b30d-5de75aa9084d,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-60a54872-6901-4252-923e-6f4c7799b448,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-1924b3ba-568b-4094-9440-6072280c49fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-1f2bdf69-f907-4493-84df-e93580cae317,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-7f6b3978-9185-4b5f-ae5e-18662f6cc11b,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-b7486360-d1ea-45c5-b9d5-90798ec33298,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018428399-172.17.0.20-1598142814177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46252,DS-d238efe7-36dc-40a1-a69f-e789fd0da207,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-a942bd8d-b9ff-4726-b84c-8a6aa0a8ee5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-74b93ca3-de45-4051-8d88-303ebc06ddc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-b73350a3-f549-4b03-8f37-d00c56741897,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-2ff727a2-1a02-489b-b8c0-cac38aefc818,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-36dc0d68-2283-47d8-9115-4163500603ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-3ca6c315-dffc-4a7b-bd70-c5620a69d083,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-c43ef340-a385-4453-9e64-f96ac0dbd2f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018428399-172.17.0.20-1598142814177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46252,DS-d238efe7-36dc-40a1-a69f-e789fd0da207,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-a942bd8d-b9ff-4726-b84c-8a6aa0a8ee5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-74b93ca3-de45-4051-8d88-303ebc06ddc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-b73350a3-f549-4b03-8f37-d00c56741897,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-2ff727a2-1a02-489b-b8c0-cac38aefc818,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-36dc0d68-2283-47d8-9115-4163500603ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-3ca6c315-dffc-4a7b-bd70-c5620a69d083,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-c43ef340-a385-4453-9e64-f96ac0dbd2f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507286102-172.17.0.20-1598142903415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39054,DS-b5e30cf4-c256-4563-9853-39b8a03ceaed,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-53e8e94d-ecaa-4268-a31f-3852afdda1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-e41606b1-825f-4b09-81bf-998503737ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-eba37c60-c557-47a1-abd8-edb55e41fff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-5b0ebfa7-7213-46b6-95e0-6f0ceca3482a,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-3ea8ab36-8f35-4f31-80f3-65f8b0eef485,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-3abc41fb-b489-491c-bc17-4175b80b7376,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-5610cffb-40de-414c-9482-4efc7cb5f445,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507286102-172.17.0.20-1598142903415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39054,DS-b5e30cf4-c256-4563-9853-39b8a03ceaed,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-53e8e94d-ecaa-4268-a31f-3852afdda1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-e41606b1-825f-4b09-81bf-998503737ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-eba37c60-c557-47a1-abd8-edb55e41fff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-5b0ebfa7-7213-46b6-95e0-6f0ceca3482a,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-3ea8ab36-8f35-4f31-80f3-65f8b0eef485,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-3abc41fb-b489-491c-bc17-4175b80b7376,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-5610cffb-40de-414c-9482-4efc7cb5f445,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628953783-172.17.0.20-1598143114630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-0a0fcf2d-e1e0-4915-a4e5-53dd4fcc064c,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-26eef228-a9bd-4f0a-b019-0eab9e9bebf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-c9359a09-a6c8-45e0-9ef5-eedaadc9a927,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-04975a83-8b95-4e78-80f5-cf56de640b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-4d0e68d0-2471-4475-aef8-c32b1c30d911,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-a9f8a45a-599d-49a1-9269-b10ad4ed2da8,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-1fb06607-3ab0-4bb2-94c6-53a161f5c2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-8469bda6-e216-47e3-807d-f807b1878a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628953783-172.17.0.20-1598143114630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-0a0fcf2d-e1e0-4915-a4e5-53dd4fcc064c,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-26eef228-a9bd-4f0a-b019-0eab9e9bebf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-c9359a09-a6c8-45e0-9ef5-eedaadc9a927,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-04975a83-8b95-4e78-80f5-cf56de640b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-4d0e68d0-2471-4475-aef8-c32b1c30d911,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-a9f8a45a-599d-49a1-9269-b10ad4ed2da8,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-1fb06607-3ab0-4bb2-94c6-53a161f5c2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-8469bda6-e216-47e3-807d-f807b1878a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091490121-172.17.0.20-1598143286122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40813,DS-dae91818-220d-4a2b-bdc4-664d681163af,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-0000e6f7-5e02-4e49-b033-d0593532d343,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-40299439-ef26-47d0-80df-9f9aff0accf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-e5458d1f-4781-48ca-bf8d-d6907ac61c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-53eb0311-dd18-4ce0-a679-e9af92c20983,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-ba8997a0-b63c-4266-a116-5cfa02c93f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-696aebd4-61b6-4673-a5e6-00f19ce43653,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-2e96adad-f9ab-4673-b99f-2248938f7d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091490121-172.17.0.20-1598143286122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40813,DS-dae91818-220d-4a2b-bdc4-664d681163af,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-0000e6f7-5e02-4e49-b033-d0593532d343,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-40299439-ef26-47d0-80df-9f9aff0accf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-e5458d1f-4781-48ca-bf8d-d6907ac61c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-53eb0311-dd18-4ce0-a679-e9af92c20983,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-ba8997a0-b63c-4266-a116-5cfa02c93f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-696aebd4-61b6-4673-a5e6-00f19ce43653,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-2e96adad-f9ab-4673-b99f-2248938f7d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391620999-172.17.0.20-1598143416377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42715,DS-bb6a3fba-7c61-44a3-be23-5e82018dea98,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-948c959d-cc27-4d78-aa5c-980b593b1d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-e979c084-0da9-427c-bf21-973508e5dd48,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-0893946c-d4a2-4606-82bd-2eca8056de80,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-feb32ab3-c1e8-45bf-8322-055dad186872,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-11bc584e-dee9-4ee3-83e6-bc0d4609b403,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-906c2fb8-e205-4a0d-9a0d-b9bff541ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-255adffd-06b0-4557-808d-766327856e5d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391620999-172.17.0.20-1598143416377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42715,DS-bb6a3fba-7c61-44a3-be23-5e82018dea98,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-948c959d-cc27-4d78-aa5c-980b593b1d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-e979c084-0da9-427c-bf21-973508e5dd48,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-0893946c-d4a2-4606-82bd-2eca8056de80,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-feb32ab3-c1e8-45bf-8322-055dad186872,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-11bc584e-dee9-4ee3-83e6-bc0d4609b403,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-906c2fb8-e205-4a0d-9a0d-b9bff541ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-255adffd-06b0-4557-808d-766327856e5d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034088821-172.17.0.20-1598143674810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35469,DS-77deaff4-3075-42f9-b932-b052b2c05ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-4c9a9898-f448-4886-87d4-97c3bc123df0,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-9fd5d9bc-2d2a-4a14-a6b3-e0c36c99a65c,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-a1f64366-414f-4e3b-82a9-9ff8e2457b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-6564b121-a3f4-4d61-a8f7-e4bf658c229d,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-a0cc526d-98f6-445f-a394-4c5aef286a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-cc365eb0-2b32-4a5d-a7f0-0b549e643f10,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-8519b666-2933-4d87-9ec0-3d07d06c2da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034088821-172.17.0.20-1598143674810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35469,DS-77deaff4-3075-42f9-b932-b052b2c05ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-4c9a9898-f448-4886-87d4-97c3bc123df0,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-9fd5d9bc-2d2a-4a14-a6b3-e0c36c99a65c,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-a1f64366-414f-4e3b-82a9-9ff8e2457b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-6564b121-a3f4-4d61-a8f7-e4bf658c229d,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-a0cc526d-98f6-445f-a394-4c5aef286a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-cc365eb0-2b32-4a5d-a7f0-0b549e643f10,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-8519b666-2933-4d87-9ec0-3d07d06c2da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840674111-172.17.0.20-1598144316725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35794,DS-24b9ce0c-ac38-4888-8ae9-f5aebc42cff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-7bbad943-b7d3-4138-865e-fa539df28d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-dcf3a6b8-6b30-4820-af33-86b880e1f500,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-edc3776e-659b-4043-a333-fe5f7203e43a,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-c18f0e2d-7bfc-44ed-b1ac-280af72c5754,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-e5c31dc1-32cb-445b-9e15-8c826db6bcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-f0302c4d-7b24-48c2-8845-dfa8334ff67b,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-3eb1d096-6b1f-4e3d-82ef-fe8018242e61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840674111-172.17.0.20-1598144316725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35794,DS-24b9ce0c-ac38-4888-8ae9-f5aebc42cff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-7bbad943-b7d3-4138-865e-fa539df28d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-dcf3a6b8-6b30-4820-af33-86b880e1f500,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-edc3776e-659b-4043-a333-fe5f7203e43a,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-c18f0e2d-7bfc-44ed-b1ac-280af72c5754,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-e5c31dc1-32cb-445b-9e15-8c826db6bcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-f0302c4d-7b24-48c2-8845-dfa8334ff67b,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-3eb1d096-6b1f-4e3d-82ef-fe8018242e61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958247696-172.17.0.20-1598144693047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41462,DS-1ac82abf-e022-4f21-b6f5-596306f66e86,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-b182041a-4235-4479-ba08-57ade9450dca,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-6890cc0b-f01f-42cb-96d4-6cfdcd221ede,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-5fb97701-13cf-4012-8aa6-5df8cc77ed67,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-172f985a-57ea-45b3-bee2-7b07a22ac1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-f85f2237-47fc-45eb-8759-34b0a5d7eeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-ee507303-9411-48a9-b5fc-c09a7d97f64d,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-467605e0-e6db-4351-a920-01705050981c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958247696-172.17.0.20-1598144693047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41462,DS-1ac82abf-e022-4f21-b6f5-596306f66e86,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-b182041a-4235-4479-ba08-57ade9450dca,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-6890cc0b-f01f-42cb-96d4-6cfdcd221ede,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-5fb97701-13cf-4012-8aa6-5df8cc77ed67,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-172f985a-57ea-45b3-bee2-7b07a22ac1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-f85f2237-47fc-45eb-8759-34b0a5d7eeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-ee507303-9411-48a9-b5fc-c09a7d97f64d,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-467605e0-e6db-4351-a920-01705050981c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 6433
