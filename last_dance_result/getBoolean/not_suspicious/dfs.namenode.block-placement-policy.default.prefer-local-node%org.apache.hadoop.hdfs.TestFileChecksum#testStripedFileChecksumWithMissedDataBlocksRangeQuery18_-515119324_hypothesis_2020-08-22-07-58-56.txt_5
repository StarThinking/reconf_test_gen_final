reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1150829010-172.17.0.20-1598083454931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44361,DS-621cc397-d925-49b2-94f5-ca301d62d235,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-0b4d609d-f85c-4f77-94b4-35591aa376ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-e554f218-7d4a-4aec-8f14-31450bf23b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-0cf23866-7de5-44d6-a40a-78de271481cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-2ee12efc-b051-4b9e-9c44-64e1efc86f39,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-295fe91a-c0b2-4b56-92b5-99803e818cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-25a39a4d-b940-4197-b080-42f740be8f67,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-ebb10382-030d-4086-9c09-c09473ebb690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1150829010-172.17.0.20-1598083454931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44361,DS-621cc397-d925-49b2-94f5-ca301d62d235,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-0b4d609d-f85c-4f77-94b4-35591aa376ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-e554f218-7d4a-4aec-8f14-31450bf23b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-0cf23866-7de5-44d6-a40a-78de271481cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-2ee12efc-b051-4b9e-9c44-64e1efc86f39,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-295fe91a-c0b2-4b56-92b5-99803e818cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-25a39a4d-b940-4197-b080-42f740be8f67,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-ebb10382-030d-4086-9c09-c09473ebb690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942225983-172.17.0.20-1598083704706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45899,DS-aa3933ce-a803-48f4-93cf-f6b3f905d19b,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-baaff720-62dc-42b3-a8df-c935f12474eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-ccb9a423-74e3-471e-b330-6f3a76acfb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-311001b3-0b43-4fd5-97cd-9901715e3736,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-8e823e54-15c2-4c15-95d4-ed36e21fac46,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-bf19f01c-58b4-49b9-bb12-eb8613e368ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-9477b59f-e577-4bf8-91f3-873c95e9571d,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-e7b6a401-5abc-4939-9ab6-24de69a6c9ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942225983-172.17.0.20-1598083704706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45899,DS-aa3933ce-a803-48f4-93cf-f6b3f905d19b,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-baaff720-62dc-42b3-a8df-c935f12474eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-ccb9a423-74e3-471e-b330-6f3a76acfb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-311001b3-0b43-4fd5-97cd-9901715e3736,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-8e823e54-15c2-4c15-95d4-ed36e21fac46,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-bf19f01c-58b4-49b9-bb12-eb8613e368ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-9477b59f-e577-4bf8-91f3-873c95e9571d,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-e7b6a401-5abc-4939-9ab6-24de69a6c9ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009205338-172.17.0.20-1598084434285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43920,DS-de92fa70-6fd8-4b19-8dd3-451b98cb751c,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-8c43707e-bde2-4c1a-81f7-0835e74cd62f,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-aa2f6160-b4a5-40f1-8b3d-216b31edbdde,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-417ce085-5d6e-4ed2-9905-916813c8b456,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-cb7f5887-c30c-4963-9440-b8e7865fb529,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-3743e9ad-028b-48b3-971f-d65b7e7b70f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-40d29f15-0801-4f54-898d-bc190d06efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-1420887a-9614-45d5-b908-37f72368c2cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009205338-172.17.0.20-1598084434285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43920,DS-de92fa70-6fd8-4b19-8dd3-451b98cb751c,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-8c43707e-bde2-4c1a-81f7-0835e74cd62f,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-aa2f6160-b4a5-40f1-8b3d-216b31edbdde,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-417ce085-5d6e-4ed2-9905-916813c8b456,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-cb7f5887-c30c-4963-9440-b8e7865fb529,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-3743e9ad-028b-48b3-971f-d65b7e7b70f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-40d29f15-0801-4f54-898d-bc190d06efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-1420887a-9614-45d5-b908-37f72368c2cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1713733975-172.17.0.20-1598084543851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42305,DS-c7cc159f-77cf-4f60-a336-5dfe3a5ce7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-977fc6d5-34de-4a03-aa7d-a4921561eb51,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-2222b626-3a81-441e-b7fa-457ee2bd673d,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-d56fec4a-3c87-4bde-95d0-441759edf0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-480fbe88-23d8-4573-8fa7-9c15c70200b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-8f087a71-f8c5-44db-a903-d86ac908d59d,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-9023a9a9-479b-4dde-9eca-0792e035fe07,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-54be8bd8-a6b7-4cbc-9a8c-431464ff054e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1713733975-172.17.0.20-1598084543851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42305,DS-c7cc159f-77cf-4f60-a336-5dfe3a5ce7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-977fc6d5-34de-4a03-aa7d-a4921561eb51,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-2222b626-3a81-441e-b7fa-457ee2bd673d,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-d56fec4a-3c87-4bde-95d0-441759edf0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-480fbe88-23d8-4573-8fa7-9c15c70200b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-8f087a71-f8c5-44db-a903-d86ac908d59d,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-9023a9a9-479b-4dde-9eca-0792e035fe07,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-54be8bd8-a6b7-4cbc-9a8c-431464ff054e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1298937814-172.17.0.20-1598084725417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38050,DS-b5107238-4ce8-467f-ad37-6db7c8ff4156,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-44469093-d906-489a-b6fb-cd5dded9fb35,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-af9c3c5b-b888-4b22-a8c8-a524f69a801f,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-c3703742-5744-4ebb-a040-97046783a025,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-3b99f571-9f78-4efd-947b-7be7b719c770,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-cacce9d1-9e46-47b7-b1a4-f662e67c169e,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-f7a988b4-6dcc-4a56-88e1-821ee750601f,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-a8c5ad7e-d6c9-43db-99fc-5b22c1b6747c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1298937814-172.17.0.20-1598084725417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38050,DS-b5107238-4ce8-467f-ad37-6db7c8ff4156,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-44469093-d906-489a-b6fb-cd5dded9fb35,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-af9c3c5b-b888-4b22-a8c8-a524f69a801f,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-c3703742-5744-4ebb-a040-97046783a025,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-3b99f571-9f78-4efd-947b-7be7b719c770,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-cacce9d1-9e46-47b7-b1a4-f662e67c169e,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-f7a988b4-6dcc-4a56-88e1-821ee750601f,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-a8c5ad7e-d6c9-43db-99fc-5b22c1b6747c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929229457-172.17.0.20-1598084926837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36266,DS-9190ece0-d030-43ec-9c6e-ef38edc3f56a,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-d739c165-4dee-47fb-9d47-3ea6a04c30a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-8f6f0c90-625a-419c-b948-64d732b95a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-979c9f75-702a-4d15-ac08-ba362afa897d,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-9098c680-f9b0-48bc-b32b-9ace14a3dc46,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-c399f54b-aa39-4cb7-ab87-77dcaab43a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-4cc1336f-a06c-4e18-802a-cd06016713bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-31b1b2ad-ad15-4884-b84f-0f7c615eefdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929229457-172.17.0.20-1598084926837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36266,DS-9190ece0-d030-43ec-9c6e-ef38edc3f56a,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-d739c165-4dee-47fb-9d47-3ea6a04c30a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-8f6f0c90-625a-419c-b948-64d732b95a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-979c9f75-702a-4d15-ac08-ba362afa897d,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-9098c680-f9b0-48bc-b32b-9ace14a3dc46,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-c399f54b-aa39-4cb7-ab87-77dcaab43a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-4cc1336f-a06c-4e18-802a-cd06016713bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-31b1b2ad-ad15-4884-b84f-0f7c615eefdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647151722-172.17.0.20-1598085869488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34827,DS-faabf7ae-b3f9-413b-b7c7-19e5a96fd46d,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-a5ed8e26-72fe-406e-91e1-763b079b1882,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-d11279ff-4345-41f2-b400-f0a6eb779ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-4745698a-8dfa-427e-81c3-58fa61a032cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-ea24700a-5535-4566-9dde-f6595b754644,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-a802821a-cbce-4524-a32b-6b993fc21a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-b95cbb61-4759-4787-9a7e-12985f822d79,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-110529fe-8ead-447a-b886-8312bb2c15f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647151722-172.17.0.20-1598085869488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34827,DS-faabf7ae-b3f9-413b-b7c7-19e5a96fd46d,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-a5ed8e26-72fe-406e-91e1-763b079b1882,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-d11279ff-4345-41f2-b400-f0a6eb779ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-4745698a-8dfa-427e-81c3-58fa61a032cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-ea24700a-5535-4566-9dde-f6595b754644,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-a802821a-cbce-4524-a32b-6b993fc21a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-b95cbb61-4759-4787-9a7e-12985f822d79,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-110529fe-8ead-447a-b886-8312bb2c15f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1127105971-172.17.0.20-1598086197078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38583,DS-7f01f79b-e1ca-413c-97c4-83b5da2a0e96,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-05305461-c403-45d0-8053-41d6e5c9cff6,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-9aa15bb5-c14e-4718-87e7-633c4e3fe1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-4cc1a48f-0d2f-497d-9321-41780c86fdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-e6ee3f62-4be6-4eb1-9d08-3ab342fc0731,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-40066e87-f54c-47c4-be59-0b5389bc9436,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-4b54aa5d-4428-4827-9484-165a3cc7309c,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-8062ee92-c837-4f02-8ba4-c2d9f014b30d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1127105971-172.17.0.20-1598086197078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38583,DS-7f01f79b-e1ca-413c-97c4-83b5da2a0e96,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-05305461-c403-45d0-8053-41d6e5c9cff6,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-9aa15bb5-c14e-4718-87e7-633c4e3fe1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-4cc1a48f-0d2f-497d-9321-41780c86fdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-e6ee3f62-4be6-4eb1-9d08-3ab342fc0731,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-40066e87-f54c-47c4-be59-0b5389bc9436,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-4b54aa5d-4428-4827-9484-165a3cc7309c,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-8062ee92-c837-4f02-8ba4-c2d9f014b30d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909130485-172.17.0.20-1598086365104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40859,DS-4044f87b-2205-4260-857c-8e0413bc06c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-71ed15d4-5831-40e3-a819-4d2b7fa519cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-90efc173-3efe-46dd-9c11-625fb27c02d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-26a656f4-01a2-485b-9298-e91795f2ab8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-00ee5f5f-d790-465a-802a-beabca146956,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-8d9064c3-7fec-449e-8695-746602f0ccfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-8a6f94c5-9f06-4798-aa5d-2f79bc2b0020,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-f9ac9131-ba82-49ce-a002-ed3e5156442f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909130485-172.17.0.20-1598086365104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40859,DS-4044f87b-2205-4260-857c-8e0413bc06c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-71ed15d4-5831-40e3-a819-4d2b7fa519cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-90efc173-3efe-46dd-9c11-625fb27c02d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-26a656f4-01a2-485b-9298-e91795f2ab8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-00ee5f5f-d790-465a-802a-beabca146956,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-8d9064c3-7fec-449e-8695-746602f0ccfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-8a6f94c5-9f06-4798-aa5d-2f79bc2b0020,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-f9ac9131-ba82-49ce-a002-ed3e5156442f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271393365-172.17.0.20-1598086893043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33358,DS-5af462e8-dd83-447b-8a4a-0825468b6c38,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-48ce1bec-d1b5-43f4-b3c0-07393012452d,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-bd4464a1-089a-43d0-88ec-ef059727674c,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-52919fd5-faed-4940-ac0f-5482cee57ced,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-82d69a53-0351-4d97-97e5-55fd93cd8b05,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-09986270-33d1-4819-bbc4-9853d5372ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-9879869a-47ad-4cb0-a5d7-1149494307d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-51b87e72-82b7-401d-8d9f-16b0ab1f8387,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271393365-172.17.0.20-1598086893043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33358,DS-5af462e8-dd83-447b-8a4a-0825468b6c38,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-48ce1bec-d1b5-43f4-b3c0-07393012452d,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-bd4464a1-089a-43d0-88ec-ef059727674c,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-52919fd5-faed-4940-ac0f-5482cee57ced,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-82d69a53-0351-4d97-97e5-55fd93cd8b05,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-09986270-33d1-4819-bbc4-9853d5372ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-9879869a-47ad-4cb0-a5d7-1149494307d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-51b87e72-82b7-401d-8d9f-16b0ab1f8387,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712203380-172.17.0.20-1598087204080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45043,DS-e75aeaa6-c066-448e-b895-2e789c910de7,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-a1004a39-5256-405c-88e0-fdf14431f90b,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-235bf027-6750-4ad6-adeb-2ee8a5dde695,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-52baa380-ab7c-41c1-b3e8-172a87bf32db,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-57c7a22e-2e9e-41c5-b255-bed9878f375f,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-766bc7cd-7a78-41ab-8fb2-6e2a98660e50,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-1fa6d276-bf62-4d48-8343-da70a40b50fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-7e5a8ed4-cb72-4e7e-aa27-ca16e089652c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712203380-172.17.0.20-1598087204080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45043,DS-e75aeaa6-c066-448e-b895-2e789c910de7,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-a1004a39-5256-405c-88e0-fdf14431f90b,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-235bf027-6750-4ad6-adeb-2ee8a5dde695,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-52baa380-ab7c-41c1-b3e8-172a87bf32db,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-57c7a22e-2e9e-41c5-b255-bed9878f375f,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-766bc7cd-7a78-41ab-8fb2-6e2a98660e50,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-1fa6d276-bf62-4d48-8343-da70a40b50fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-7e5a8ed4-cb72-4e7e-aa27-ca16e089652c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554750658-172.17.0.20-1598087349194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35870,DS-3bd20a6b-9fe5-4472-bc8e-c0dcf414055b,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-8fe2301c-38ac-45b1-af0a-5c16a979cd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-ece96c72-f355-4a18-be3a-12871b58d5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-3982be85-91e1-45ef-9d6d-c740e1b0cd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-22dcc237-0d2d-46c0-952e-07f77f9f820f,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-7c4a4214-897d-49d3-b695-eb6ee252d463,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-f9c10eae-df35-4e04-b668-c8eaba5f950f,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-3dfa5634-1b09-49ec-8858-e9bbb75ed2c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554750658-172.17.0.20-1598087349194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35870,DS-3bd20a6b-9fe5-4472-bc8e-c0dcf414055b,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-8fe2301c-38ac-45b1-af0a-5c16a979cd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-ece96c72-f355-4a18-be3a-12871b58d5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-3982be85-91e1-45ef-9d6d-c740e1b0cd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-22dcc237-0d2d-46c0-952e-07f77f9f820f,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-7c4a4214-897d-49d3-b695-eb6ee252d463,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-f9c10eae-df35-4e04-b668-c8eaba5f950f,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-3dfa5634-1b09-49ec-8858-e9bbb75ed2c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139174813-172.17.0.20-1598087631252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46037,DS-ef97a1b6-b2e0-48aa-8122-83ffb1a61a13,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-f5ba3822-f84c-489a-81d5-ccbc7672c272,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-cbe0f4da-0769-4c43-8a46-642c30a2c6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-baa9b4bd-c122-4ffa-9380-55c18ce74022,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-a8a55256-3845-4f69-bf7a-85068b36cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-8d057057-3eb3-4b7f-9098-31d0d65da2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-9c0e63c1-8890-4508-95cc-fe6bf4f27e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-eb19ec60-02e9-4edc-8c54-7c232a7c92b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139174813-172.17.0.20-1598087631252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46037,DS-ef97a1b6-b2e0-48aa-8122-83ffb1a61a13,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-f5ba3822-f84c-489a-81d5-ccbc7672c272,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-cbe0f4da-0769-4c43-8a46-642c30a2c6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-baa9b4bd-c122-4ffa-9380-55c18ce74022,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-a8a55256-3845-4f69-bf7a-85068b36cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-8d057057-3eb3-4b7f-9098-31d0d65da2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-9c0e63c1-8890-4508-95cc-fe6bf4f27e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-eb19ec60-02e9-4edc-8c54-7c232a7c92b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631212501-172.17.0.20-1598087832021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37169,DS-29eb76b0-0bdd-407e-9c1e-70e51e77f11c,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-21b9ffba-6987-404c-bcdf-12c0e5e50d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-76e975ba-0b97-4298-bed9-ddb1f51defb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-f618581a-8947-4901-a54b-a5dc7a210d51,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-bc10d9d0-67f4-4358-ba8f-b8bd8a93846f,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-5af6099d-1c3d-4886-b529-f7f0fa69276e,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-269948f1-4eb7-4f92-8b87-0c06f2d36e95,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-82a8fc75-5486-4d46-a81d-affea6966743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631212501-172.17.0.20-1598087832021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37169,DS-29eb76b0-0bdd-407e-9c1e-70e51e77f11c,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-21b9ffba-6987-404c-bcdf-12c0e5e50d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-76e975ba-0b97-4298-bed9-ddb1f51defb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-f618581a-8947-4901-a54b-a5dc7a210d51,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-bc10d9d0-67f4-4358-ba8f-b8bd8a93846f,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-5af6099d-1c3d-4886-b529-f7f0fa69276e,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-269948f1-4eb7-4f92-8b87-0c06f2d36e95,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-82a8fc75-5486-4d46-a81d-affea6966743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1854751471-172.17.0.20-1598088242583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43753,DS-67ac07bd-d5ec-4e0a-9e31-86c9e100b7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-6c6e0872-e6d5-43f0-9f42-e1aa9d0a226c,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-c7c10b16-13e8-484a-a0d9-bb55ac1b1df1,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-f07974a1-3b07-45e3-b76c-95656f64469f,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-08567089-d99a-41b5-b5bc-d53a97ea6d43,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-f03de877-7f3e-480c-ac0c-18ed01301905,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-17f41cc5-6314-4e4b-84b9-8750374d970a,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-c6cae7e0-4eb0-4540-a759-d187acffacd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1854751471-172.17.0.20-1598088242583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43753,DS-67ac07bd-d5ec-4e0a-9e31-86c9e100b7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-6c6e0872-e6d5-43f0-9f42-e1aa9d0a226c,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-c7c10b16-13e8-484a-a0d9-bb55ac1b1df1,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-f07974a1-3b07-45e3-b76c-95656f64469f,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-08567089-d99a-41b5-b5bc-d53a97ea6d43,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-f03de877-7f3e-480c-ac0c-18ed01301905,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-17f41cc5-6314-4e4b-84b9-8750374d970a,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-c6cae7e0-4eb0-4540-a759-d187acffacd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5361
