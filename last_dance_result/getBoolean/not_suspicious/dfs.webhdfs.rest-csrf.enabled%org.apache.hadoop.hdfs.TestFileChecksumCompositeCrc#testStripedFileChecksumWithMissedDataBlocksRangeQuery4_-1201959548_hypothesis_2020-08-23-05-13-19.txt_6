reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877358670-172.17.0.3-1598159801743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39257,DS-929f5c40-94ad-4da4-88b4-3a70b502dbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-d329dee6-38cc-4736-9d35-a97cb1845232,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-314e52bc-3c57-45be-8d2d-fa566277a978,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-e16ad046-25ae-4e91-a43c-b294e82b01c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-7cf56d25-a250-41a0-bc88-8b53ecd7b68a,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-c3b73a39-2416-4eb7-932c-fc064a208a16,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-2566719e-1bf4-4673-aa20-265caa7bbc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-6c9d03f0-6ee9-43d8-bdf9-49255d6aacca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877358670-172.17.0.3-1598159801743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39257,DS-929f5c40-94ad-4da4-88b4-3a70b502dbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-d329dee6-38cc-4736-9d35-a97cb1845232,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-314e52bc-3c57-45be-8d2d-fa566277a978,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-e16ad046-25ae-4e91-a43c-b294e82b01c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-7cf56d25-a250-41a0-bc88-8b53ecd7b68a,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-c3b73a39-2416-4eb7-932c-fc064a208a16,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-2566719e-1bf4-4673-aa20-265caa7bbc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-6c9d03f0-6ee9-43d8-bdf9-49255d6aacca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930476370-172.17.0.3-1598160068851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41498,DS-cb27d206-51e1-400d-b396-4e63c2b9f6de,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-b05f7a21-170d-4aa4-860a-1198ae92db53,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-96bc98a6-cc5c-4aea-a8c2-9e26d73e59ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-c486ecb7-0742-4300-9e68-c570b2db4bea,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-f9458d41-654c-469e-9fa7-48e704f18318,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-989c8b53-ff0b-4e01-b93c-0a20aaf4dea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-215b0c7a-0316-4873-a148-9f881be7eb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-12c6232f-20ff-43b8-8a7c-5da565bde3fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930476370-172.17.0.3-1598160068851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41498,DS-cb27d206-51e1-400d-b396-4e63c2b9f6de,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-b05f7a21-170d-4aa4-860a-1198ae92db53,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-96bc98a6-cc5c-4aea-a8c2-9e26d73e59ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-c486ecb7-0742-4300-9e68-c570b2db4bea,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-f9458d41-654c-469e-9fa7-48e704f18318,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-989c8b53-ff0b-4e01-b93c-0a20aaf4dea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-215b0c7a-0316-4873-a148-9f881be7eb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-12c6232f-20ff-43b8-8a7c-5da565bde3fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383270965-172.17.0.3-1598160295228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40148,DS-6d27271f-89bb-411a-9082-056d7eb9498c,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-8b207514-2b8a-4892-b436-3a01a87f25b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-17f468b0-9eb9-4ae1-ba4f-e9e86ede04fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-0fcc424b-f376-404b-9b61-af93e19e9815,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-4732eaa0-2ed5-40f6-999d-1ef2a12f8953,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-60915c5d-4853-4391-a342-2645244aed83,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-38061036-9595-44bb-8129-3522cf080e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-ff3a4f1d-84c1-478d-95eb-664bb4de2e44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383270965-172.17.0.3-1598160295228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40148,DS-6d27271f-89bb-411a-9082-056d7eb9498c,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-8b207514-2b8a-4892-b436-3a01a87f25b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-17f468b0-9eb9-4ae1-ba4f-e9e86ede04fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-0fcc424b-f376-404b-9b61-af93e19e9815,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-4732eaa0-2ed5-40f6-999d-1ef2a12f8953,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-60915c5d-4853-4391-a342-2645244aed83,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-38061036-9595-44bb-8129-3522cf080e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-ff3a4f1d-84c1-478d-95eb-664bb4de2e44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319229121-172.17.0.3-1598160338518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39255,DS-0c8f04d3-e7aa-4171-9ca6-8612b827f56c,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-3a3d2336-eddd-40fd-ae59-181015590248,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-56b91833-a2bb-4126-b22c-a9af7f35e235,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-8ce1fd5c-ca02-4353-a565-9206a40670ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-c9d0d857-25d5-483c-a0e0-689e77893717,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-44ed59f7-2f3c-4f11-ae01-efb73c649e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-d9929b31-788a-40f3-b33c-9861213d1e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-56b85a49-4cae-4202-b417-94fffa217d4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319229121-172.17.0.3-1598160338518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39255,DS-0c8f04d3-e7aa-4171-9ca6-8612b827f56c,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-3a3d2336-eddd-40fd-ae59-181015590248,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-56b91833-a2bb-4126-b22c-a9af7f35e235,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-8ce1fd5c-ca02-4353-a565-9206a40670ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-c9d0d857-25d5-483c-a0e0-689e77893717,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-44ed59f7-2f3c-4f11-ae01-efb73c649e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-d9929b31-788a-40f3-b33c-9861213d1e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-56b85a49-4cae-4202-b417-94fffa217d4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379319102-172.17.0.3-1598160577915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40933,DS-b58070b6-2458-4117-a0b6-edd43fc7dc35,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-f1b10fac-4714-4800-a1e1-f5f528fdbc04,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-4b9a96bf-880a-4832-b47b-ee9c5976611b,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-6b36273a-80ab-4d3a-b3ad-6bf7cdfae774,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-cae4a1cf-ce73-4f18-9212-3dd977c6c62c,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-f922700c-e75f-43f8-9af5-3d3b96935133,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-d7422a5b-4678-4cdc-a595-e1737ab8e434,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-68049613-f1d9-4548-8c7d-17f666e4fd99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379319102-172.17.0.3-1598160577915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40933,DS-b58070b6-2458-4117-a0b6-edd43fc7dc35,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-f1b10fac-4714-4800-a1e1-f5f528fdbc04,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-4b9a96bf-880a-4832-b47b-ee9c5976611b,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-6b36273a-80ab-4d3a-b3ad-6bf7cdfae774,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-cae4a1cf-ce73-4f18-9212-3dd977c6c62c,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-f922700c-e75f-43f8-9af5-3d3b96935133,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-d7422a5b-4678-4cdc-a595-e1737ab8e434,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-68049613-f1d9-4548-8c7d-17f666e4fd99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028093731-172.17.0.3-1598160689384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46625,DS-9c7133d8-6107-4fab-bd5d-d2e86f251445,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-f98b4ef9-abca-477b-9d7d-7d7c5108ff80,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-afbc9e05-2250-42a1-ae5a-5b900a377a96,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-c5367d9a-4731-4fc7-bbb3-2a91c6c5d465,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-b953e1f6-f288-4cb7-a5f8-1fa07d696d48,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-f6bef93b-17d2-4ee2-aff0-ed681872e6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-e1ccb77a-fbd7-4135-a990-962799eeacb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-d9d31ad7-25e3-4569-94db-a2f01c3a0407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028093731-172.17.0.3-1598160689384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46625,DS-9c7133d8-6107-4fab-bd5d-d2e86f251445,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-f98b4ef9-abca-477b-9d7d-7d7c5108ff80,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-afbc9e05-2250-42a1-ae5a-5b900a377a96,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-c5367d9a-4731-4fc7-bbb3-2a91c6c5d465,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-b953e1f6-f288-4cb7-a5f8-1fa07d696d48,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-f6bef93b-17d2-4ee2-aff0-ed681872e6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-e1ccb77a-fbd7-4135-a990-962799eeacb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-d9d31ad7-25e3-4569-94db-a2f01c3a0407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683503131-172.17.0.3-1598160732475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34597,DS-91ea20d8-8ab9-4613-a874-a64f8f66e40c,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-b7d87cde-826c-4d1e-b7fc-487533816913,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-12da6262-8fed-4a3f-a232-b29521a382fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-1002cde7-59c8-4062-ac41-acd31b779925,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-d24b10ae-dc1d-471f-89db-55c724c06988,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-ee0cef8b-3de8-4077-b745-d5304713fd51,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-01928dc4-17bb-4b8e-a97f-a015052dfb70,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-7be60212-7cd5-4527-8b56-95526e7b02c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683503131-172.17.0.3-1598160732475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34597,DS-91ea20d8-8ab9-4613-a874-a64f8f66e40c,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-b7d87cde-826c-4d1e-b7fc-487533816913,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-12da6262-8fed-4a3f-a232-b29521a382fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-1002cde7-59c8-4062-ac41-acd31b779925,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-d24b10ae-dc1d-471f-89db-55c724c06988,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-ee0cef8b-3de8-4077-b745-d5304713fd51,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-01928dc4-17bb-4b8e-a97f-a015052dfb70,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-7be60212-7cd5-4527-8b56-95526e7b02c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809403260-172.17.0.3-1598161005718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43215,DS-9d482a39-5496-4326-8206-880cb4f4d523,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-33212510-0b82-4a4c-9998-fa4ad09ab95c,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-c3e97d59-2d8b-44aa-8717-eedb171f146c,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-e2acda0b-be85-430e-a2cd-94a1c74ca22d,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-997daba0-6981-41bf-9719-84c8312dad63,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-0aef2888-0283-4aba-a949-8cefff484402,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-4bf01f50-324a-4167-92a2-5456d786a59f,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-9b6963a6-04b4-4888-beab-9d41f136fa14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809403260-172.17.0.3-1598161005718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43215,DS-9d482a39-5496-4326-8206-880cb4f4d523,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-33212510-0b82-4a4c-9998-fa4ad09ab95c,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-c3e97d59-2d8b-44aa-8717-eedb171f146c,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-e2acda0b-be85-430e-a2cd-94a1c74ca22d,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-997daba0-6981-41bf-9719-84c8312dad63,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-0aef2888-0283-4aba-a949-8cefff484402,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-4bf01f50-324a-4167-92a2-5456d786a59f,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-9b6963a6-04b4-4888-beab-9d41f136fa14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827873610-172.17.0.3-1598161227336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38106,DS-232d2e4a-9f23-483c-b45a-36c15b1e01bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-453fc6af-dd6c-4673-9654-f429a1f9f0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-9809ccbe-2b88-4104-80f1-0d4ca3ec64a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-a383a3c1-9068-4a78-a5ed-2635adbcbfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-1d38443b-7c09-438d-8fdd-7722f8dbbfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-ae7888dd-99f1-4e92-a4bb-f0fa8a9c8e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-f7ea97f0-4714-4245-a36c-f2f5da4bc7da,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-55083874-8b2c-4ce3-aaa0-24ac4825f6c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827873610-172.17.0.3-1598161227336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38106,DS-232d2e4a-9f23-483c-b45a-36c15b1e01bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-453fc6af-dd6c-4673-9654-f429a1f9f0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-9809ccbe-2b88-4104-80f1-0d4ca3ec64a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-a383a3c1-9068-4a78-a5ed-2635adbcbfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-1d38443b-7c09-438d-8fdd-7722f8dbbfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-ae7888dd-99f1-4e92-a4bb-f0fa8a9c8e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-f7ea97f0-4714-4245-a36c-f2f5da4bc7da,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-55083874-8b2c-4ce3-aaa0-24ac4825f6c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698429238-172.17.0.3-1598161335872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37225,DS-47fc38b2-e5af-4071-a2e0-f940399cd07e,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-06d51736-912d-4bf0-88af-ebc1a028828b,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-69c1bb12-079a-4f95-bc4e-2ee2033d7fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-bd8aea8d-bc5d-4529-9581-25b80d73bb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-6fdd0636-1174-4415-9ae9-3440b7ce409c,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-09a9d41e-438b-4e98-8a50-53def0dbc5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-939b8ce8-a938-48d9-9f5b-8b8976e0491c,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-6af38b70-c400-4c4b-8725-8c47f464974a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698429238-172.17.0.3-1598161335872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37225,DS-47fc38b2-e5af-4071-a2e0-f940399cd07e,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-06d51736-912d-4bf0-88af-ebc1a028828b,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-69c1bb12-079a-4f95-bc4e-2ee2033d7fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-bd8aea8d-bc5d-4529-9581-25b80d73bb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-6fdd0636-1174-4415-9ae9-3440b7ce409c,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-09a9d41e-438b-4e98-8a50-53def0dbc5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-939b8ce8-a938-48d9-9f5b-8b8976e0491c,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-6af38b70-c400-4c4b-8725-8c47f464974a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084476134-172.17.0.3-1598162078933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43955,DS-847a3a53-848c-49ca-abbc-ba57828c298f,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-79d6b7ba-5003-4f81-beee-436697256a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-3e6ef6f4-e83a-4275-b490-91426f8975b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-3538c175-57cc-44a9-9caf-05aa5053adb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-d2981b39-c5bc-4eb2-96d3-862c5691329c,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-af263c95-7351-48ec-abc3-f4c2b2bf486d,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-a7c8aab4-a988-4235-b030-1a7fa7b820f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-91021477-b0ef-4061-b536-fc1aebd37e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084476134-172.17.0.3-1598162078933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43955,DS-847a3a53-848c-49ca-abbc-ba57828c298f,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-79d6b7ba-5003-4f81-beee-436697256a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-3e6ef6f4-e83a-4275-b490-91426f8975b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-3538c175-57cc-44a9-9caf-05aa5053adb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-d2981b39-c5bc-4eb2-96d3-862c5691329c,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-af263c95-7351-48ec-abc3-f4c2b2bf486d,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-a7c8aab4-a988-4235-b030-1a7fa7b820f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-91021477-b0ef-4061-b536-fc1aebd37e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153280074-172.17.0.3-1598162233114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34562,DS-14330b2a-e236-454a-8548-b34a8314614c,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-c24cf1bd-d3ff-4bab-a860-755c7a4cc5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-976d826a-a415-430a-9455-936f06b5b534,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-68f63954-4284-42a1-8dfd-1ec19515df62,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-f0d7621a-5272-4360-8506-c2d99f455a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-6122440b-15fb-4e47-8f7a-f337866b4a10,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-7c97ef54-2e28-4cd1-b266-eba9ea597551,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-4748fcf0-7ff2-41d1-834f-4acf7264c392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153280074-172.17.0.3-1598162233114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34562,DS-14330b2a-e236-454a-8548-b34a8314614c,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-c24cf1bd-d3ff-4bab-a860-755c7a4cc5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-976d826a-a415-430a-9455-936f06b5b534,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-68f63954-4284-42a1-8dfd-1ec19515df62,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-f0d7621a-5272-4360-8506-c2d99f455a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-6122440b-15fb-4e47-8f7a-f337866b4a10,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-7c97ef54-2e28-4cd1-b266-eba9ea597551,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-4748fcf0-7ff2-41d1-834f-4acf7264c392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35684812-172.17.0.3-1598162839159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46538,DS-6d983301-4b8c-4ae5-9c4a-23cef54856af,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-4d02910b-ce96-406f-b7e6-b63d950b3a06,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-224f8a03-f74b-4812-a46d-def750837187,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-e1bc9392-cfcb-4008-8d10-493bcc0f0f78,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-d431ccfa-6c4d-4b57-812a-fe6083ac3e22,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-828b75c2-8946-43de-a123-f7cc3851ca3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-29d62073-1191-4aee-94df-10beed4b7181,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-5d222f24-49b2-43c8-8acd-4043b48aebd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35684812-172.17.0.3-1598162839159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46538,DS-6d983301-4b8c-4ae5-9c4a-23cef54856af,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-4d02910b-ce96-406f-b7e6-b63d950b3a06,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-224f8a03-f74b-4812-a46d-def750837187,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-e1bc9392-cfcb-4008-8d10-493bcc0f0f78,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-d431ccfa-6c4d-4b57-812a-fe6083ac3e22,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-828b75c2-8946-43de-a123-f7cc3851ca3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-29d62073-1191-4aee-94df-10beed4b7181,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-5d222f24-49b2-43c8-8acd-4043b48aebd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128187264-172.17.0.3-1598163823955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46478,DS-ca6f1bf5-e257-423c-9448-465c93fdcda8,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-bafd4b6c-8952-4691-ae08-8e1e3c277c63,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-e92a598d-4216-4521-b685-70d4797f627d,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-17599df5-2c8b-4a72-888b-9d6eb7e7201b,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-40e97cb0-0b1f-4abd-8b07-9546c0babff2,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-32dbf8f9-a14b-4797-b862-a7fe6668f320,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-573e38a6-c8d7-44d4-b74b-4bbd3e4d64cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-09a0d697-d1db-46da-b063-a4e4d445d4ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128187264-172.17.0.3-1598163823955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46478,DS-ca6f1bf5-e257-423c-9448-465c93fdcda8,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-bafd4b6c-8952-4691-ae08-8e1e3c277c63,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-e92a598d-4216-4521-b685-70d4797f627d,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-17599df5-2c8b-4a72-888b-9d6eb7e7201b,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-40e97cb0-0b1f-4abd-8b07-9546c0babff2,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-32dbf8f9-a14b-4797-b862-a7fe6668f320,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-573e38a6-c8d7-44d4-b74b-4bbd3e4d64cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-09a0d697-d1db-46da-b063-a4e4d445d4ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1463904022-172.17.0.3-1598164013454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36622,DS-49d4ac21-49a1-4953-852e-2e284edee6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-0fa27749-3099-48c8-9fc0-94e536c021d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-23184117-2415-46f2-9cc2-0348b07f2012,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-865a13f2-22a3-4878-9fb4-ae4343a57ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-b6b52219-e34c-4edd-b9e7-9e4cb8bb2cca,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-44cc381b-5e41-45bc-83f0-57000ce00c28,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-8af6c053-baaa-49ec-a46c-72f8d7cd46c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-70360aad-5f11-4147-b756-eee8b7067ec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1463904022-172.17.0.3-1598164013454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36622,DS-49d4ac21-49a1-4953-852e-2e284edee6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-0fa27749-3099-48c8-9fc0-94e536c021d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-23184117-2415-46f2-9cc2-0348b07f2012,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-865a13f2-22a3-4878-9fb4-ae4343a57ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-b6b52219-e34c-4edd-b9e7-9e4cb8bb2cca,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-44cc381b-5e41-45bc-83f0-57000ce00c28,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-8af6c053-baaa-49ec-a46c-72f8d7cd46c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-70360aad-5f11-4147-b756-eee8b7067ec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199653392-172.17.0.3-1598164051913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36324,DS-94b10a10-e3c9-4b93-b636-46d478940163,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-ee1aeac3-1cd1-494d-b7a0-2397b8b5f10d,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-753a1da5-5e5a-4259-8f7c-f4bb9226a606,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-461962ac-8d21-4045-a19a-d5f82028c380,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-302352fb-bbc1-455e-b8ab-158f917bd9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-15d25adc-ec24-451c-a98a-5e875ba8b602,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-d7438689-369c-4177-ba60-9c553e573861,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-69c71fd9-4f6f-472c-9533-c84bfd3d0f48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199653392-172.17.0.3-1598164051913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36324,DS-94b10a10-e3c9-4b93-b636-46d478940163,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-ee1aeac3-1cd1-494d-b7a0-2397b8b5f10d,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-753a1da5-5e5a-4259-8f7c-f4bb9226a606,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-461962ac-8d21-4045-a19a-d5f82028c380,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-302352fb-bbc1-455e-b8ab-158f917bd9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-15d25adc-ec24-451c-a98a-5e875ba8b602,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-d7438689-369c-4177-ba60-9c553e573861,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-69c71fd9-4f6f-472c-9533-c84bfd3d0f48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700191681-172.17.0.3-1598164197844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39816,DS-1bbefe8e-5245-4219-bb3a-e02c410f6e32,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-9d272b1c-7b36-473a-9bfc-9f14a5c34d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-f05c8f41-63ce-49e5-88c7-2a9f41eb72b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-0dbc16f6-dcea-491e-a51d-2c8dc2239820,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-f44a8d2b-af75-43dc-9a3f-ade2efc83cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-a68008c1-b3e8-4ed8-b84b-23214041cf59,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-9176819b-e8a9-4129-8ed4-14f13b7f5a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-d3282d13-7e37-4d3f-b3d3-43efac70d30f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700191681-172.17.0.3-1598164197844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39816,DS-1bbefe8e-5245-4219-bb3a-e02c410f6e32,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-9d272b1c-7b36-473a-9bfc-9f14a5c34d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-f05c8f41-63ce-49e5-88c7-2a9f41eb72b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-0dbc16f6-dcea-491e-a51d-2c8dc2239820,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-f44a8d2b-af75-43dc-9a3f-ade2efc83cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-a68008c1-b3e8-4ed8-b84b-23214041cf59,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-9176819b-e8a9-4129-8ed4-14f13b7f5a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-d3282d13-7e37-4d3f-b3d3-43efac70d30f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868319684-172.17.0.3-1598164305339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41072,DS-57074acd-2104-4bbd-baa3-02137b032de6,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-e3f1841f-e1f4-470c-8b1c-09cbf1661f63,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-387c5bf6-008e-4ad8-b82d-7a0b8b184ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-fbd8ce15-409d-4f62-81a8-e291d9786fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-96981b84-6472-4b44-b10c-b71a15c69a72,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-1cfa8e64-6e09-4554-8684-e3c375499c45,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-d07dddb4-a2f8-4b21-a06b-36798212778b,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-4fabab5a-7350-4b25-810f-ddf2c9a347cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868319684-172.17.0.3-1598164305339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41072,DS-57074acd-2104-4bbd-baa3-02137b032de6,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-e3f1841f-e1f4-470c-8b1c-09cbf1661f63,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-387c5bf6-008e-4ad8-b82d-7a0b8b184ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-fbd8ce15-409d-4f62-81a8-e291d9786fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-96981b84-6472-4b44-b10c-b71a15c69a72,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-1cfa8e64-6e09-4554-8684-e3c375499c45,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-d07dddb4-a2f8-4b21-a06b-36798212778b,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-4fabab5a-7350-4b25-810f-ddf2c9a347cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570835765-172.17.0.3-1598164481954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41053,DS-4249196c-c245-4ff4-9205-10c3e2151f88,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-b8e09998-8e87-4705-92c9-cc74504dd127,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-761df13b-d4a5-4156-a704-17c48bbc7813,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-546cea19-53a7-4063-89c8-edcc7ed49996,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-19d2bb7b-47da-48a8-8f7b-923fd1b52c21,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-c8b37675-84ed-4441-9069-3f60ffd7dad4,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-daaa1adf-9a14-4107-9dd5-8d54cb3d3016,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-a3c3b0fe-23f4-454c-baad-8397ca27a23f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570835765-172.17.0.3-1598164481954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41053,DS-4249196c-c245-4ff4-9205-10c3e2151f88,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-b8e09998-8e87-4705-92c9-cc74504dd127,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-761df13b-d4a5-4156-a704-17c48bbc7813,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-546cea19-53a7-4063-89c8-edcc7ed49996,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-19d2bb7b-47da-48a8-8f7b-923fd1b52c21,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-c8b37675-84ed-4441-9069-3f60ffd7dad4,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-daaa1adf-9a14-4107-9dd5-8d54cb3d3016,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-a3c3b0fe-23f4-454c-baad-8397ca27a23f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838741948-172.17.0.3-1598165272429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45729,DS-cae8ae8a-7d90-435a-acd1-bce36e54d252,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-2ce756c5-93a0-41d7-830c-6d278a5d5ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-876ea6f9-54db-474b-973e-a6e9929675b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-9bf0b972-a9b9-4299-85a5-eac461c1b1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-9da296af-07a8-4ec4-a0fa-05f011bbeefd,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-c815dae6-ba68-4cbe-ab82-b996317c2a68,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-65001995-36c8-404e-b2dc-749434bcffc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-b0c56ecb-eac2-4c64-8b3a-cbdec36c0088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838741948-172.17.0.3-1598165272429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45729,DS-cae8ae8a-7d90-435a-acd1-bce36e54d252,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-2ce756c5-93a0-41d7-830c-6d278a5d5ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-876ea6f9-54db-474b-973e-a6e9929675b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-9bf0b972-a9b9-4299-85a5-eac461c1b1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-9da296af-07a8-4ec4-a0fa-05f011bbeefd,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-c815dae6-ba68-4cbe-ab82-b996317c2a68,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-65001995-36c8-404e-b2dc-749434bcffc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-b0c56ecb-eac2-4c64-8b3a-cbdec36c0088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024169294-172.17.0.3-1598165355575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42233,DS-605c4d99-b438-4c3d-a2de-a7221a5f02dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-ca5eb6ca-977a-4be6-b237-24f265acafdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-961c8179-0152-4f92-8280-f45fbeef0232,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-09db7687-d5eb-427d-9cab-6ec9062845d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-64cacb1b-7bfb-45dd-9e9b-88d4622b7edd,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-5795014c-7461-4ea5-ac27-06cbdb235615,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-558e0d43-0f50-490f-9894-22dd6eb8a3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-d60b1672-7cd2-4e83-be63-5305f79f4cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024169294-172.17.0.3-1598165355575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42233,DS-605c4d99-b438-4c3d-a2de-a7221a5f02dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-ca5eb6ca-977a-4be6-b237-24f265acafdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-961c8179-0152-4f92-8280-f45fbeef0232,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-09db7687-d5eb-427d-9cab-6ec9062845d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-64cacb1b-7bfb-45dd-9e9b-88d4622b7edd,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-5795014c-7461-4ea5-ac27-06cbdb235615,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-558e0d43-0f50-490f-9894-22dd6eb8a3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-d60b1672-7cd2-4e83-be63-5305f79f4cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5782
