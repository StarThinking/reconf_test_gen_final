reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996649090-172.17.0.11-1598192713943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45239,DS-bb4de6cf-acf1-4068-970b-a4dfa93f407a,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-f6464b60-dbe1-4578-a83c-778de5c781c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-31fb20ee-a52e-4319-b992-85abffbcb40f,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-fac74593-426f-4015-a04a-2e147cab9e62,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-b1eae7e8-5370-41e7-93bf-d36d36670c41,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-82c71771-bb3e-443b-9060-73dd78752a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-b676cfe8-203f-48e5-b7f1-87a384f1edb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-5d6a8209-b26e-4c8f-b2b7-223afd8af3ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996649090-172.17.0.11-1598192713943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45239,DS-bb4de6cf-acf1-4068-970b-a4dfa93f407a,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-f6464b60-dbe1-4578-a83c-778de5c781c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-31fb20ee-a52e-4319-b992-85abffbcb40f,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-fac74593-426f-4015-a04a-2e147cab9e62,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-b1eae7e8-5370-41e7-93bf-d36d36670c41,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-82c71771-bb3e-443b-9060-73dd78752a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-b676cfe8-203f-48e5-b7f1-87a384f1edb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-5d6a8209-b26e-4c8f-b2b7-223afd8af3ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-772060847-172.17.0.11-1598192786348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42376,DS-b7801533-ac4b-4f4b-9a05-11c9c69044f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-f8c97d38-66be-4471-ba81-573c2491ed8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-eb27205d-dd56-42ce-904c-5941a279d177,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-edea1d7a-d948-4073-bcb2-c952cca06351,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-7f9b73de-fd62-40ee-94f1-e5cd2cfb72dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-a40f7a10-9bc2-4c2f-b846-44a4119530c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-cb18784a-343b-4630-a469-c2a67f024dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-9f1e90cc-d5ff-499f-8716-2add1b90d66b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-772060847-172.17.0.11-1598192786348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42376,DS-b7801533-ac4b-4f4b-9a05-11c9c69044f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-f8c97d38-66be-4471-ba81-573c2491ed8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-eb27205d-dd56-42ce-904c-5941a279d177,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-edea1d7a-d948-4073-bcb2-c952cca06351,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-7f9b73de-fd62-40ee-94f1-e5cd2cfb72dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-a40f7a10-9bc2-4c2f-b846-44a4119530c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-cb18784a-343b-4630-a469-c2a67f024dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-9f1e90cc-d5ff-499f-8716-2add1b90d66b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1571150867-172.17.0.11-1598192971353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41468,DS-4a316d82-60f1-4382-9a0a-dc1d340c1841,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-62362c63-6842-4fb9-8cd1-6416c376e4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-23bb3123-366f-439f-8321-45f99c1cdcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-a662f27d-d830-4703-93ec-6aa3a60bcc26,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-f5f34a49-eb2b-47bb-b0e8-3773e8e47250,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-5bb26fee-8158-4717-af4e-ff38f9b7a4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-851fc668-6e32-4d53-8d8c-2539e885d2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-6eff1b5f-35e4-4e4a-b57f-e75bae4fc818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1571150867-172.17.0.11-1598192971353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41468,DS-4a316d82-60f1-4382-9a0a-dc1d340c1841,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-62362c63-6842-4fb9-8cd1-6416c376e4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-23bb3123-366f-439f-8321-45f99c1cdcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-a662f27d-d830-4703-93ec-6aa3a60bcc26,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-f5f34a49-eb2b-47bb-b0e8-3773e8e47250,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-5bb26fee-8158-4717-af4e-ff38f9b7a4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-851fc668-6e32-4d53-8d8c-2539e885d2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-6eff1b5f-35e4-4e4a-b57f-e75bae4fc818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1122474804-172.17.0.11-1598193075128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38359,DS-3531a8b3-5902-4474-91f5-3186640bac01,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-f96245cf-31c2-49a0-adcd-c07a874d1047,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-d05b83f3-0366-4280-bb50-8d8d41ab815c,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-60c1e0f2-9289-4270-a5af-31b45ee84719,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-6e5f56eb-bf55-40bc-9108-7a3705ed1057,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-d48e8b2c-42ce-448f-b8eb-e6cfdb6f9938,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-59fa1db3-7b9d-4827-afbc-804e5ef18e79,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-464aaa78-f9fa-4d25-9e45-f7087c86820f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1122474804-172.17.0.11-1598193075128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38359,DS-3531a8b3-5902-4474-91f5-3186640bac01,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-f96245cf-31c2-49a0-adcd-c07a874d1047,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-d05b83f3-0366-4280-bb50-8d8d41ab815c,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-60c1e0f2-9289-4270-a5af-31b45ee84719,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-6e5f56eb-bf55-40bc-9108-7a3705ed1057,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-d48e8b2c-42ce-448f-b8eb-e6cfdb6f9938,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-59fa1db3-7b9d-4827-afbc-804e5ef18e79,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-464aaa78-f9fa-4d25-9e45-f7087c86820f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2004436060-172.17.0.11-1598194077972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35472,DS-9fd2e4a0-ea29-4477-aa5f-f9ff645c4e29,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-c96af752-591b-41f9-8672-276e25717d41,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-115c8ffb-e38a-4ae9-a605-4bd9149b1f80,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-4db2d338-3567-4a73-8445-3ee9525b53f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-4c196e4b-e8fd-4701-b58b-ee49896e10c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-eae2b364-6789-415b-963c-eeb16670ed4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-732ae86b-f981-4467-abd5-3a4dcc324e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-6215bc21-d74e-44a6-ab41-ce1b777b9299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2004436060-172.17.0.11-1598194077972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35472,DS-9fd2e4a0-ea29-4477-aa5f-f9ff645c4e29,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-c96af752-591b-41f9-8672-276e25717d41,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-115c8ffb-e38a-4ae9-a605-4bd9149b1f80,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-4db2d338-3567-4a73-8445-3ee9525b53f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-4c196e4b-e8fd-4701-b58b-ee49896e10c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-eae2b364-6789-415b-963c-eeb16670ed4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-732ae86b-f981-4467-abd5-3a4dcc324e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-6215bc21-d74e-44a6-ab41-ce1b777b9299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521577915-172.17.0.11-1598194294102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39780,DS-2bd5fc05-1c2d-4694-9954-d83b2f6d2133,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-2e99dde5-298c-4953-9001-78e4ad8e2542,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-91e092a5-3b89-4587-a22e-54878e2a05da,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-9e2f9a75-88ee-45a0-ae04-70a4da3188cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-7c69b713-5765-469a-aaeb-c25f6814b348,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-a13221d3-a739-44ad-8eea-dfe179809f51,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-e31335c3-f3b2-4542-ba97-1b3a3be52ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-bb373a91-0d28-497c-86df-ab0d1401072d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521577915-172.17.0.11-1598194294102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39780,DS-2bd5fc05-1c2d-4694-9954-d83b2f6d2133,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-2e99dde5-298c-4953-9001-78e4ad8e2542,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-91e092a5-3b89-4587-a22e-54878e2a05da,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-9e2f9a75-88ee-45a0-ae04-70a4da3188cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-7c69b713-5765-469a-aaeb-c25f6814b348,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-a13221d3-a739-44ad-8eea-dfe179809f51,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-e31335c3-f3b2-4542-ba97-1b3a3be52ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-bb373a91-0d28-497c-86df-ab0d1401072d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268909247-172.17.0.11-1598194679918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46007,DS-f8576bbc-69d5-4475-98c3-eed5bf72e2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-cb10e4be-f875-497e-94a5-8dc0e0d6768c,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-9f0e5384-c727-4d40-b048-748935cb301b,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-11b6a6a6-e2bc-41c4-bb12-521e0051faf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-d560dc2f-91b2-4b9a-b197-1cff80c7a49f,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-2fdd4f3c-e1b9-41d4-9194-ae0840934b07,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-e3c060cc-af9b-4667-901f-55f109f19ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-08a51dac-5a38-41ba-bf07-d159548109f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268909247-172.17.0.11-1598194679918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46007,DS-f8576bbc-69d5-4475-98c3-eed5bf72e2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-cb10e4be-f875-497e-94a5-8dc0e0d6768c,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-9f0e5384-c727-4d40-b048-748935cb301b,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-11b6a6a6-e2bc-41c4-bb12-521e0051faf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-d560dc2f-91b2-4b9a-b197-1cff80c7a49f,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-2fdd4f3c-e1b9-41d4-9194-ae0840934b07,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-e3c060cc-af9b-4667-901f-55f109f19ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-08a51dac-5a38-41ba-bf07-d159548109f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-592932816-172.17.0.11-1598195061467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37731,DS-3b894bcd-bc05-4b6f-bb45-72178ed2eacf,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-c233eadd-1f74-4b67-b603-e517ef459be8,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-1b4cf105-2fea-4c02-8075-b4e6ae34cdce,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-f5c70527-c83b-40fc-8b75-699be5a37fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-cf24041e-409f-4cf0-96ac-0382556bfa36,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-ce6eaa43-5257-498f-a909-c4d0762532ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-9a2ac534-bed6-4ba8-8ed0-4b391abb1ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-f4312884-fa1d-4b10-bc2c-6d9e079dfcd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-592932816-172.17.0.11-1598195061467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37731,DS-3b894bcd-bc05-4b6f-bb45-72178ed2eacf,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-c233eadd-1f74-4b67-b603-e517ef459be8,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-1b4cf105-2fea-4c02-8075-b4e6ae34cdce,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-f5c70527-c83b-40fc-8b75-699be5a37fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-cf24041e-409f-4cf0-96ac-0382556bfa36,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-ce6eaa43-5257-498f-a909-c4d0762532ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-9a2ac534-bed6-4ba8-8ed0-4b391abb1ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-f4312884-fa1d-4b10-bc2c-6d9e079dfcd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014226041-172.17.0.11-1598195124117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37376,DS-3fc82ea6-c518-4f12-b017-4d631293c3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-0a163edb-6196-4837-a52b-8d6859104fea,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-45db1f8a-fd86-41d4-a606-b68b64a2ac32,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-18cc9ffb-8f94-459b-bbf1-3e9e8eda5394,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-ffad1838-beab-4799-b627-85942f421a25,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-6386c333-eeba-4cd7-8189-2c42b8cc3080,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-4c880e7b-2f2b-403d-8763-49699d915c90,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-e2cc5953-d214-48da-baf4-c13283a0e592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014226041-172.17.0.11-1598195124117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37376,DS-3fc82ea6-c518-4f12-b017-4d631293c3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-0a163edb-6196-4837-a52b-8d6859104fea,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-45db1f8a-fd86-41d4-a606-b68b64a2ac32,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-18cc9ffb-8f94-459b-bbf1-3e9e8eda5394,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-ffad1838-beab-4799-b627-85942f421a25,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-6386c333-eeba-4cd7-8189-2c42b8cc3080,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-4c880e7b-2f2b-403d-8763-49699d915c90,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-e2cc5953-d214-48da-baf4-c13283a0e592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-40240024-172.17.0.11-1598195160768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39300,DS-a6404995-d439-4d59-a1ed-28ac30bfe52e,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-3addd48b-d018-4ac0-9cca-43b860a8172b,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-d207fa2b-5ef6-418d-9145-9f1095b703aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-9d4f5dcf-5479-4559-a0cf-eceb24d7c8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-c5d2a5ce-2f65-41e9-874e-3e49215ec865,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-aa348c9f-e367-420e-a764-abaa5bdcdce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-70fd1418-2523-4bdc-85da-312f50df4b51,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-75c624ff-0c20-47f3-b2e0-f0e2b30f41fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-40240024-172.17.0.11-1598195160768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39300,DS-a6404995-d439-4d59-a1ed-28ac30bfe52e,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-3addd48b-d018-4ac0-9cca-43b860a8172b,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-d207fa2b-5ef6-418d-9145-9f1095b703aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-9d4f5dcf-5479-4559-a0cf-eceb24d7c8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-c5d2a5ce-2f65-41e9-874e-3e49215ec865,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-aa348c9f-e367-420e-a764-abaa5bdcdce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-70fd1418-2523-4bdc-85da-312f50df4b51,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-75c624ff-0c20-47f3-b2e0-f0e2b30f41fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864872002-172.17.0.11-1598195689092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32897,DS-4b6a6ac5-ef16-41d5-ab71-9f180da09d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-2761b4c0-e0a4-4d12-9f15-e7a97f1adcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-8f9b0620-6c99-4032-80d9-305fd40fda39,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-2ad0f539-8a61-4fb8-9660-a3d1a31d8df4,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-5e6a96ee-d20c-48b6-bbf1-ca8635be28e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-b787936d-42a1-46fe-8f01-2f816871f501,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-1623b1d8-a9ea-4b0e-adee-10d1e3ee6fce,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-199e9648-30a5-471c-8793-22661b8c35e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864872002-172.17.0.11-1598195689092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32897,DS-4b6a6ac5-ef16-41d5-ab71-9f180da09d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-2761b4c0-e0a4-4d12-9f15-e7a97f1adcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-8f9b0620-6c99-4032-80d9-305fd40fda39,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-2ad0f539-8a61-4fb8-9660-a3d1a31d8df4,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-5e6a96ee-d20c-48b6-bbf1-ca8635be28e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-b787936d-42a1-46fe-8f01-2f816871f501,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-1623b1d8-a9ea-4b0e-adee-10d1e3ee6fce,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-199e9648-30a5-471c-8793-22661b8c35e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411429367-172.17.0.11-1598195726463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45671,DS-136ce764-5e53-4cb6-9a9a-1d2cb0a21b40,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-5139f164-3c9e-41bd-85d2-b6015bfc761d,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-88b66dbf-3e48-42b0-beec-5b71be86bff2,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-0e44555f-7e16-4c6f-8441-6b099b2adc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-4be81096-953c-4d6e-aab1-dce309686e92,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-699feb3a-4ded-414f-b4d2-6f3b569fe6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-239adb33-73d4-4573-9863-c6b6bf4f56a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-19906551-ccf9-48a6-b0c6-163961d574cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411429367-172.17.0.11-1598195726463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45671,DS-136ce764-5e53-4cb6-9a9a-1d2cb0a21b40,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-5139f164-3c9e-41bd-85d2-b6015bfc761d,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-88b66dbf-3e48-42b0-beec-5b71be86bff2,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-0e44555f-7e16-4c6f-8441-6b099b2adc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-4be81096-953c-4d6e-aab1-dce309686e92,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-699feb3a-4ded-414f-b4d2-6f3b569fe6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-239adb33-73d4-4573-9863-c6b6bf4f56a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-19906551-ccf9-48a6-b0c6-163961d574cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2007450878-172.17.0.11-1598195832637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36183,DS-b66891aa-4bf3-4a72-8c78-34312e7b3fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-fa6b578f-b63b-4173-9c33-622275c83be3,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-87939a77-67c8-4651-92fe-a8deee0e6b74,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-c0c3f31c-6824-4222-8eee-ac71d5cf74a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-37b83d33-a439-4192-bb38-48ab2f7ef32e,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-1a425537-8d53-4895-a2ce-975e5294688f,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-a638cb64-79ac-41a6-9959-01aad8414297,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-8fac7809-951c-4571-925a-0be7a15dfc4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2007450878-172.17.0.11-1598195832637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36183,DS-b66891aa-4bf3-4a72-8c78-34312e7b3fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-fa6b578f-b63b-4173-9c33-622275c83be3,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-87939a77-67c8-4651-92fe-a8deee0e6b74,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-c0c3f31c-6824-4222-8eee-ac71d5cf74a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-37b83d33-a439-4192-bb38-48ab2f7ef32e,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-1a425537-8d53-4895-a2ce-975e5294688f,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-a638cb64-79ac-41a6-9959-01aad8414297,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-8fac7809-951c-4571-925a-0be7a15dfc4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231336616-172.17.0.11-1598196279481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-06d04c85-e455-47e4-ab4d-31c6593d5ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-11b7c415-6e56-42a3-b97f-fd9846b690e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-bc1a4a3e-adbf-454a-9458-5cc7bfe012d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-897700a1-00f4-4470-9da0-73890b079cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-a05579bc-b62d-4330-8d79-b9e242214d65,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-d487cccd-41f1-4f53-be36-8ea7e6fba13b,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-1e88bc7c-ecea-403d-83cc-8244023d82bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-f4a78b67-c220-4520-af06-52d1e1f45f70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231336616-172.17.0.11-1598196279481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-06d04c85-e455-47e4-ab4d-31c6593d5ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-11b7c415-6e56-42a3-b97f-fd9846b690e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-bc1a4a3e-adbf-454a-9458-5cc7bfe012d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-897700a1-00f4-4470-9da0-73890b079cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-a05579bc-b62d-4330-8d79-b9e242214d65,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-d487cccd-41f1-4f53-be36-8ea7e6fba13b,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-1e88bc7c-ecea-403d-83cc-8244023d82bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-f4a78b67-c220-4520-af06-52d1e1f45f70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188235654-172.17.0.11-1598197020937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38321,DS-076995da-c32d-414a-b48d-79176311afb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-25e6b21a-9384-4571-9fe8-8dc692a1d593,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-9f2b142d-01f6-4c31-b84f-44a6267db3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-e855b079-f982-4be7-8e0c-9e3e11dd4d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-022358ea-03c1-4313-b4a5-e37fcf7e2a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-78aca0d1-9974-412d-9ef9-ad4fdfc94d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-e3eadcfc-a372-49ce-acfc-e7e9e0d2b41e,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-1a46ae3d-49b4-478e-99e0-37b8f2cbd6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188235654-172.17.0.11-1598197020937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38321,DS-076995da-c32d-414a-b48d-79176311afb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-25e6b21a-9384-4571-9fe8-8dc692a1d593,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-9f2b142d-01f6-4c31-b84f-44a6267db3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-e855b079-f982-4be7-8e0c-9e3e11dd4d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-022358ea-03c1-4313-b4a5-e37fcf7e2a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-78aca0d1-9974-412d-9ef9-ad4fdfc94d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-e3eadcfc-a372-49ce-acfc-e7e9e0d2b41e,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-1a46ae3d-49b4-478e-99e0-37b8f2cbd6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-543388458-172.17.0.11-1598197097716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46034,DS-b5383a54-b835-4519-bb8a-da1f6b2ac922,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-043f88d4-f61f-4436-8ae9-418c22c6c863,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-75bbb3be-641a-4f3f-8571-f57ad7bccc36,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-b3dbdbb1-045d-4078-b7d3-19e5ec599ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-d6c009e9-bc66-4861-b4c9-81f30f343dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-5db0acb0-fb8f-4522-88b4-7bc3f2961ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-3c278a8a-419e-4bc9-8fe2-4a22ce2c9ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-fa3b5021-6d87-4ce0-bbee-75cea61d3ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-543388458-172.17.0.11-1598197097716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46034,DS-b5383a54-b835-4519-bb8a-da1f6b2ac922,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-043f88d4-f61f-4436-8ae9-418c22c6c863,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-75bbb3be-641a-4f3f-8571-f57ad7bccc36,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-b3dbdbb1-045d-4078-b7d3-19e5ec599ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-d6c009e9-bc66-4861-b4c9-81f30f343dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-5db0acb0-fb8f-4522-88b4-7bc3f2961ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-3c278a8a-419e-4bc9-8fe2-4a22ce2c9ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-fa3b5021-6d87-4ce0-bbee-75cea61d3ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910002601-172.17.0.11-1598197581156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43435,DS-73ba9d4c-02d9-4905-810e-e4a69d58bd84,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-e9c46c21-8a5e-4289-b503-ee3e7c97712f,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-feabfc06-bb1a-4038-b258-e935135926a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-a09b5505-ed96-479b-a48e-d406aaa8d5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-af3af8c6-4157-4084-b5ad-566fee6558d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-17c02583-6ef7-4873-804b-109b02ded4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-51322d9c-e2e6-4a55-8203-2d45037d4e11,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-22aa8518-88a6-46a4-8268-7b545fadcb24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910002601-172.17.0.11-1598197581156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43435,DS-73ba9d4c-02d9-4905-810e-e4a69d58bd84,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-e9c46c21-8a5e-4289-b503-ee3e7c97712f,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-feabfc06-bb1a-4038-b258-e935135926a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-a09b5505-ed96-479b-a48e-d406aaa8d5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-af3af8c6-4157-4084-b5ad-566fee6558d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-17c02583-6ef7-4873-804b-109b02ded4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-51322d9c-e2e6-4a55-8203-2d45037d4e11,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-22aa8518-88a6-46a4-8268-7b545fadcb24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5253
