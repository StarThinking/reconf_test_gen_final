reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-114717240-172.17.0.12-1598183281958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36256,DS-1d31c3a5-5fcd-4299-aee5-f67cf637abe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-b5d46974-cb4b-431a-9962-d6cdd7bd996d,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-0cd9405c-b72d-4f45-94f7-4a1bb94f566c,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-34448990-219d-40f0-9414-9a70fae75990,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-92a78afa-0b50-447f-9e1b-d03c834f2a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-abe13916-f4cf-4606-ba93-904a6c5e3cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-08a5f3b9-00c4-4937-8a7e-7c5f58fc10da,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-9e7007a6-f100-4da8-8c5d-b1549a817ec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-114717240-172.17.0.12-1598183281958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36256,DS-1d31c3a5-5fcd-4299-aee5-f67cf637abe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-b5d46974-cb4b-431a-9962-d6cdd7bd996d,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-0cd9405c-b72d-4f45-94f7-4a1bb94f566c,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-34448990-219d-40f0-9414-9a70fae75990,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-92a78afa-0b50-447f-9e1b-d03c834f2a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-abe13916-f4cf-4606-ba93-904a6c5e3cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-08a5f3b9-00c4-4937-8a7e-7c5f58fc10da,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-9e7007a6-f100-4da8-8c5d-b1549a817ec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-131576652-172.17.0.12-1598183312768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40511,DS-51da9389-8d2c-4578-b5b0-9bb86d830877,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-2bfafcdf-19dc-4622-a48e-70a68620ead1,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-2fba0d1d-c737-40ab-ae2d-68748b81613b,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-e5d3be5b-b21c-4322-91d0-af4111015092,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-9ad66e63-90fb-40a1-937c-efc3c160ce68,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-9dfec182-a70c-4315-a896-0d3acb123c17,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-e47499c4-9e79-40d9-ace7-e459a0326c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-895b6c73-372c-4266-8412-a98062eeaf6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-131576652-172.17.0.12-1598183312768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40511,DS-51da9389-8d2c-4578-b5b0-9bb86d830877,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-2bfafcdf-19dc-4622-a48e-70a68620ead1,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-2fba0d1d-c737-40ab-ae2d-68748b81613b,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-e5d3be5b-b21c-4322-91d0-af4111015092,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-9ad66e63-90fb-40a1-937c-efc3c160ce68,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-9dfec182-a70c-4315-a896-0d3acb123c17,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-e47499c4-9e79-40d9-ace7-e459a0326c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-895b6c73-372c-4266-8412-a98062eeaf6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106993107-172.17.0.12-1598183615521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35734,DS-9a0b5aad-99a9-41e5-b21e-1cd4fa195df4,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-dd2f6ba2-4207-468f-aa55-72f2ee32ed06,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-5a0bf0ef-16e3-4ed6-aa88-25b78b165af6,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-f8e15b3e-5a5d-4642-a381-dc883a231c61,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-2961b3d8-c0cc-4104-89e1-7fbeb116b424,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-172b5f81-6bf3-4031-bee4-83e128342957,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-5de063a6-442c-4ef1-911e-678443f45231,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-26312f09-60aa-4fe3-9698-3fbc12af19cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106993107-172.17.0.12-1598183615521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35734,DS-9a0b5aad-99a9-41e5-b21e-1cd4fa195df4,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-dd2f6ba2-4207-468f-aa55-72f2ee32ed06,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-5a0bf0ef-16e3-4ed6-aa88-25b78b165af6,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-f8e15b3e-5a5d-4642-a381-dc883a231c61,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-2961b3d8-c0cc-4104-89e1-7fbeb116b424,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-172b5f81-6bf3-4031-bee4-83e128342957,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-5de063a6-442c-4ef1-911e-678443f45231,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-26312f09-60aa-4fe3-9698-3fbc12af19cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847409738-172.17.0.12-1598184241271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41853,DS-e52f167d-7702-4d36-84e8-b72a3c0dd487,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-541564f1-fac3-41d6-9519-bed7599d8189,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-2b3e9b67-017a-494f-98e5-17ea44e58183,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-72f5c604-9683-465b-be9f-a6361dc326ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-dcddd0f8-dacc-4acc-987c-5513460caca8,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-974c4c69-08f5-4f1d-9508-0a696ffa0c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-e457269a-f6f9-48f8-b4fd-eddb79fccb24,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-56bbed22-3163-4707-a23d-358b23e168d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847409738-172.17.0.12-1598184241271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41853,DS-e52f167d-7702-4d36-84e8-b72a3c0dd487,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-541564f1-fac3-41d6-9519-bed7599d8189,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-2b3e9b67-017a-494f-98e5-17ea44e58183,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-72f5c604-9683-465b-be9f-a6361dc326ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-dcddd0f8-dacc-4acc-987c-5513460caca8,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-974c4c69-08f5-4f1d-9508-0a696ffa0c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-e457269a-f6f9-48f8-b4fd-eddb79fccb24,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-56bbed22-3163-4707-a23d-358b23e168d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829104195-172.17.0.12-1598184442423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45348,DS-74fcb0a9-95f6-48cb-b081-b23709c607bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-95ab10f5-2d7a-49bf-9fcf-3339c6623104,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-0466b40f-6fa9-4bc4-abf2-44d611a9c879,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-e0638c69-27e6-43f6-86d0-000e4ae963ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-01b37a91-0e6d-4cfe-83d7-c47a3a503c76,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-726f68a5-34dd-40ff-ae4d-7d67d7383d85,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-de4e0e3d-13ab-4993-a117-d8023646db86,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-1f36430a-b4f8-49a2-9989-04db0b748e3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829104195-172.17.0.12-1598184442423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45348,DS-74fcb0a9-95f6-48cb-b081-b23709c607bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-95ab10f5-2d7a-49bf-9fcf-3339c6623104,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-0466b40f-6fa9-4bc4-abf2-44d611a9c879,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-e0638c69-27e6-43f6-86d0-000e4ae963ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-01b37a91-0e6d-4cfe-83d7-c47a3a503c76,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-726f68a5-34dd-40ff-ae4d-7d67d7383d85,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-de4e0e3d-13ab-4993-a117-d8023646db86,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-1f36430a-b4f8-49a2-9989-04db0b748e3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079177354-172.17.0.12-1598185114731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42779,DS-cd54d020-361e-40a6-bd18-b3b49f9985cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-3871f98c-777c-4c80-9f48-a728993ca774,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-2f1f5c97-44d6-4c98-99e7-d03923433446,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-80de3cd2-a344-49eb-96d4-99e6ed85e25b,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-99ca53e2-bb35-4214-9220-af16569800c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-eae17bdf-cbe5-4233-9212-02a5af9b1fda,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-3cd21e2f-2892-488b-889f-cfa69d1297b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-32702a79-44a8-47ad-996f-a16ed32b0ebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079177354-172.17.0.12-1598185114731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42779,DS-cd54d020-361e-40a6-bd18-b3b49f9985cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-3871f98c-777c-4c80-9f48-a728993ca774,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-2f1f5c97-44d6-4c98-99e7-d03923433446,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-80de3cd2-a344-49eb-96d4-99e6ed85e25b,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-99ca53e2-bb35-4214-9220-af16569800c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-eae17bdf-cbe5-4233-9212-02a5af9b1fda,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-3cd21e2f-2892-488b-889f-cfa69d1297b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-32702a79-44a8-47ad-996f-a16ed32b0ebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558452489-172.17.0.12-1598185452346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32957,DS-065ec015-e0a9-476f-bbf7-4ae6677b7165,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-59cc91d6-14bc-4ec7-8127-878b557a84c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-fe61698a-0b50-438b-978d-12f1268b85c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-30e616ad-b2d1-428f-aa79-95c39f79ae47,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-98fb7787-7dfa-4c1c-9446-ed834d907693,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-3c7b1e43-1268-4b16-a8fc-895e46924d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-b6479db7-3195-420a-bd49-36fb52f49cab,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-d8b37f22-da26-48ff-b9fd-3139974b550f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558452489-172.17.0.12-1598185452346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32957,DS-065ec015-e0a9-476f-bbf7-4ae6677b7165,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-59cc91d6-14bc-4ec7-8127-878b557a84c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-fe61698a-0b50-438b-978d-12f1268b85c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-30e616ad-b2d1-428f-aa79-95c39f79ae47,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-98fb7787-7dfa-4c1c-9446-ed834d907693,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-3c7b1e43-1268-4b16-a8fc-895e46924d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-b6479db7-3195-420a-bd49-36fb52f49cab,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-d8b37f22-da26-48ff-b9fd-3139974b550f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537377379-172.17.0.12-1598185525397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44725,DS-d77d78dc-b6c2-479d-816f-643288448c26,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-c71f87a0-cd95-4d0e-9f65-7444300b4a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-eb2bbed5-8ee3-460c-b71a-abd327e4422c,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-bea9bd14-cb18-4dc7-b8e9-91a25e2fed90,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-2ba4e8df-0a33-4b41-8239-625c93e70d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-69dc1986-26c6-420c-bfc8-9f88a84de694,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-13b6cc5f-9210-4990-89d8-2be13c2bed64,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-94bc650e-a7d7-4ffb-a9d0-c00e156f7f0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537377379-172.17.0.12-1598185525397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44725,DS-d77d78dc-b6c2-479d-816f-643288448c26,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-c71f87a0-cd95-4d0e-9f65-7444300b4a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-eb2bbed5-8ee3-460c-b71a-abd327e4422c,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-bea9bd14-cb18-4dc7-b8e9-91a25e2fed90,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-2ba4e8df-0a33-4b41-8239-625c93e70d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-69dc1986-26c6-420c-bfc8-9f88a84de694,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-13b6cc5f-9210-4990-89d8-2be13c2bed64,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-94bc650e-a7d7-4ffb-a9d0-c00e156f7f0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2011244126-172.17.0.12-1598185599710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37709,DS-92a8dd2f-1dcf-457e-896d-c79cc0cbf9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-b0289a82-ac17-4116-bcee-7dd462f8d542,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-506c74f2-7641-4956-a66e-a2087f3dcfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-93ee6775-d53b-4db2-9290-64eb284406fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-1a85a0b3-c362-477d-9893-b6fb9a27489e,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-09f2d283-238e-4b7b-94e1-5f6a30f6d742,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-4ddc33b6-bb4f-4a4a-a2a9-8b6f10bfcac7,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-8bca70e6-81af-43ce-bdbb-e4d74d53ca01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2011244126-172.17.0.12-1598185599710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37709,DS-92a8dd2f-1dcf-457e-896d-c79cc0cbf9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-b0289a82-ac17-4116-bcee-7dd462f8d542,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-506c74f2-7641-4956-a66e-a2087f3dcfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-93ee6775-d53b-4db2-9290-64eb284406fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-1a85a0b3-c362-477d-9893-b6fb9a27489e,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-09f2d283-238e-4b7b-94e1-5f6a30f6d742,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-4ddc33b6-bb4f-4a4a-a2a9-8b6f10bfcac7,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-8bca70e6-81af-43ce-bdbb-e4d74d53ca01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863334037-172.17.0.12-1598185940428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34129,DS-e70aac3a-25de-4388-aee5-a64675f6a66c,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-b3426fc9-3c8f-4234-a430-0880e266e41d,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-dcde132a-d806-46cd-ac60-063bbd19c3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-e511f81a-02c0-4cf6-bfcf-640f069feee6,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-801c2056-c6f2-4f32-b91f-dafad1250949,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-8609c5d1-1641-4cef-8b3f-2cd3f4cf6307,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-0e5997b1-f1b4-4b44-a6d3-d0caee467d01,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-d8b16d0c-6e13-4d7b-8777-4a1aa0050f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863334037-172.17.0.12-1598185940428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34129,DS-e70aac3a-25de-4388-aee5-a64675f6a66c,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-b3426fc9-3c8f-4234-a430-0880e266e41d,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-dcde132a-d806-46cd-ac60-063bbd19c3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-e511f81a-02c0-4cf6-bfcf-640f069feee6,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-801c2056-c6f2-4f32-b91f-dafad1250949,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-8609c5d1-1641-4cef-8b3f-2cd3f4cf6307,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-0e5997b1-f1b4-4b44-a6d3-d0caee467d01,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-d8b16d0c-6e13-4d7b-8777-4a1aa0050f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2075352420-172.17.0.12-1598186350908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46393,DS-ae203a22-165f-4b3b-86a9-c576c8ab5044,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-b930cc9c-4a27-4b2c-a37c-45003a431c55,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-68523892-d4ab-47d6-b110-db6286323574,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-57157480-f79e-4e17-a9d2-c93751475e91,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-0fd0832e-3ad0-4398-af15-4f54c7c28459,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-fb5c8034-0738-4084-8c6a-f3cfc451f8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-4de15c70-fd73-479c-a697-a51b4cc9404b,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-bb07f49a-764e-485c-97f3-23b4cf55e97f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2075352420-172.17.0.12-1598186350908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46393,DS-ae203a22-165f-4b3b-86a9-c576c8ab5044,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-b930cc9c-4a27-4b2c-a37c-45003a431c55,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-68523892-d4ab-47d6-b110-db6286323574,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-57157480-f79e-4e17-a9d2-c93751475e91,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-0fd0832e-3ad0-4398-af15-4f54c7c28459,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-fb5c8034-0738-4084-8c6a-f3cfc451f8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-4de15c70-fd73-479c-a697-a51b4cc9404b,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-bb07f49a-764e-485c-97f3-23b4cf55e97f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666513615-172.17.0.12-1598186605148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37842,DS-281f39a6-8514-443a-b387-ad8755fa0e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-b97faf62-2ab4-4228-b03d-6e5a4276f2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-3eee9e8b-0b5e-47b2-83ee-6844da07a5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-039e6bd3-a9e4-47c7-9713-7ebbabc335c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-5c9c1ce6-5709-4bb2-907a-d56a81d58454,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-a44cc9fb-983d-4a09-824e-0f0fff56e3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-d4ebad4a-32f5-48e6-a8f3-7d9e849ea53c,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-a1391621-d9da-4a21-9dbf-65603fa9a707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666513615-172.17.0.12-1598186605148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37842,DS-281f39a6-8514-443a-b387-ad8755fa0e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-b97faf62-2ab4-4228-b03d-6e5a4276f2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-3eee9e8b-0b5e-47b2-83ee-6844da07a5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-039e6bd3-a9e4-47c7-9713-7ebbabc335c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-5c9c1ce6-5709-4bb2-907a-d56a81d58454,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-a44cc9fb-983d-4a09-824e-0f0fff56e3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-d4ebad4a-32f5-48e6-a8f3-7d9e849ea53c,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-a1391621-d9da-4a21-9dbf-65603fa9a707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668385505-172.17.0.12-1598186633273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38726,DS-006000a8-38be-4aa0-b003-21ea2602cab5,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-b8fc8dcc-50c7-4c86-bcae-b8fd83f8010d,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-36082f0e-bcc1-41fc-afe1-284f25306488,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-faa6aae4-3345-491c-bdf9-0218cc7902b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-4e9006d0-9e31-4970-be3c-f6ffd834dde1,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-b72f0f21-0fa7-4c9e-9575-e0e53bb24912,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-d71dafc8-4770-4967-93f8-4c5a78fbbfac,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-26ee00a1-6ee8-4dec-ab95-71efda13db6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668385505-172.17.0.12-1598186633273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38726,DS-006000a8-38be-4aa0-b003-21ea2602cab5,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-b8fc8dcc-50c7-4c86-bcae-b8fd83f8010d,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-36082f0e-bcc1-41fc-afe1-284f25306488,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-faa6aae4-3345-491c-bdf9-0218cc7902b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-4e9006d0-9e31-4970-be3c-f6ffd834dde1,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-b72f0f21-0fa7-4c9e-9575-e0e53bb24912,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-d71dafc8-4770-4967-93f8-4c5a78fbbfac,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-26ee00a1-6ee8-4dec-ab95-71efda13db6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468234981-172.17.0.12-1598187104675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46367,DS-afdb066e-648d-4ad1-a80b-03ec7b1ba67a,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-893ec5d8-7752-4ac5-a5a1-68b68bdc0704,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-ed9a8a10-dac9-46c3-8363-9cb871881e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-f44823a3-64a0-414b-b872-0312977569b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-b7ad09f4-46b7-4d16-969c-ccf9f83f7d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-de1f2af0-3038-40fe-9d1d-4058ea443292,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-2416af3e-6e15-4c53-bb1e-362caf19e7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-136210eb-07db-41e5-adf6-1ad6767cec83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468234981-172.17.0.12-1598187104675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46367,DS-afdb066e-648d-4ad1-a80b-03ec7b1ba67a,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-893ec5d8-7752-4ac5-a5a1-68b68bdc0704,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-ed9a8a10-dac9-46c3-8363-9cb871881e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-f44823a3-64a0-414b-b872-0312977569b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-b7ad09f4-46b7-4d16-969c-ccf9f83f7d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-de1f2af0-3038-40fe-9d1d-4058ea443292,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-2416af3e-6e15-4c53-bb1e-362caf19e7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-136210eb-07db-41e5-adf6-1ad6767cec83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564512969-172.17.0.12-1598187310129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35979,DS-b89940a6-3606-4373-8c89-4e100f1f10be,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-5360d9e9-c0b2-43c2-a370-9cba8544b842,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-e8167d2e-4fb4-485b-b989-6e0809379f27,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-460c05ff-327d-4ce9-8a08-bc41d6d174b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-780aec53-9ce6-4c53-ac5c-d189b82ac5da,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-0c7de719-8a67-4c7c-accf-16578aa55717,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-2ca8ab52-eb73-4749-ab70-fa7768637966,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-61af67c5-85c8-4dc4-8949-e9cff0390ce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564512969-172.17.0.12-1598187310129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35979,DS-b89940a6-3606-4373-8c89-4e100f1f10be,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-5360d9e9-c0b2-43c2-a370-9cba8544b842,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-e8167d2e-4fb4-485b-b989-6e0809379f27,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-460c05ff-327d-4ce9-8a08-bc41d6d174b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-780aec53-9ce6-4c53-ac5c-d189b82ac5da,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-0c7de719-8a67-4c7c-accf-16578aa55717,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-2ca8ab52-eb73-4749-ab70-fa7768637966,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-61af67c5-85c8-4dc4-8949-e9cff0390ce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1802374968-172.17.0.12-1598187483494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39452,DS-98abd8f3-76d3-407c-aa14-d13369df08fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-3f8fbd95-ad78-4858-8a3c-143e5bc1bd32,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-d77599ef-cc43-4c37-acf3-7a3d40928c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-1d820a20-6649-4cff-abcf-cf2a62d09f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-747b1747-5d62-474e-8fc7-9c1fec41081a,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-e5b9c255-dd63-4370-af78-7f88c12b164b,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-01b3a67b-7714-4042-b26b-80056717cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-8a6ca08b-325f-492d-bea5-1c82b61e8dc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1802374968-172.17.0.12-1598187483494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39452,DS-98abd8f3-76d3-407c-aa14-d13369df08fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-3f8fbd95-ad78-4858-8a3c-143e5bc1bd32,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-d77599ef-cc43-4c37-acf3-7a3d40928c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-1d820a20-6649-4cff-abcf-cf2a62d09f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-747b1747-5d62-474e-8fc7-9c1fec41081a,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-e5b9c255-dd63-4370-af78-7f88c12b164b,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-01b3a67b-7714-4042-b26b-80056717cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-8a6ca08b-325f-492d-bea5-1c82b61e8dc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-328111151-172.17.0.12-1598187755427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35095,DS-402338b1-05ca-4ae4-a22e-bd1765e7ea8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-d070d59a-fabb-432d-9d56-bf25c088593a,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-7cd8b7ef-5cd6-402f-a8ac-2804fc4a30d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-e76bf6dd-739e-4c1f-adff-59542c1ca7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-321cf5f9-4caa-41ff-ab0f-1db174205a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-5e9af2cf-f3e4-46f8-944f-5a7021a9bc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-a3691a7d-fad9-438f-a7de-6672e0746769,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-edf2c26b-dca5-4a03-933a-f3732be445e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-328111151-172.17.0.12-1598187755427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35095,DS-402338b1-05ca-4ae4-a22e-bd1765e7ea8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-d070d59a-fabb-432d-9d56-bf25c088593a,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-7cd8b7ef-5cd6-402f-a8ac-2804fc4a30d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-e76bf6dd-739e-4c1f-adff-59542c1ca7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-321cf5f9-4caa-41ff-ab0f-1db174205a61,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-5e9af2cf-f3e4-46f8-944f-5a7021a9bc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-a3691a7d-fad9-438f-a7de-6672e0746769,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-edf2c26b-dca5-4a03-933a-f3732be445e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795056226-172.17.0.12-1598187923140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34764,DS-1a44262f-b1d6-4ab7-a42b-beb71fb6e554,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-eddd1477-ac12-45b7-9cec-ac38e7dbcf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-234e35e3-298c-4df6-bcb8-1354894ff8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-7fe4b5e8-ab2c-45fb-9b12-695c12494cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-86edceec-2921-42f9-88e9-7b720c8a0dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-fea026ac-8798-42b4-93f0-10fb343be27d,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-18f8395f-d617-4acb-8de4-18e3691cd6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-e581bfd4-bda7-4216-a9ab-26f722b763f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795056226-172.17.0.12-1598187923140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34764,DS-1a44262f-b1d6-4ab7-a42b-beb71fb6e554,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-eddd1477-ac12-45b7-9cec-ac38e7dbcf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-234e35e3-298c-4df6-bcb8-1354894ff8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-7fe4b5e8-ab2c-45fb-9b12-695c12494cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-86edceec-2921-42f9-88e9-7b720c8a0dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-fea026ac-8798-42b4-93f0-10fb343be27d,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-18f8395f-d617-4acb-8de4-18e3691cd6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-e581bfd4-bda7-4216-a9ab-26f722b763f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479113935-172.17.0.12-1598188048882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34151,DS-c8e1c385-68a4-435c-b8e1-32ad921f6cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-367281d1-45dc-46d0-a012-cfddfc01636e,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-b4c19ab4-d132-49f0-b23a-0c7ba92e48d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-f66d949a-fe41-4a7f-a96e-a573ae4ab50e,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-3e90b952-f0ec-4b8a-ace0-59f789a10381,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-6ce2c2b5-cd0c-40dd-9e9c-91c9f56f7215,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-02fcd8cb-ae47-4399-94bf-c9a0090065d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-af1be7e5-32c2-48e5-bb95-d032866823f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479113935-172.17.0.12-1598188048882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34151,DS-c8e1c385-68a4-435c-b8e1-32ad921f6cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-367281d1-45dc-46d0-a012-cfddfc01636e,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-b4c19ab4-d132-49f0-b23a-0c7ba92e48d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-f66d949a-fe41-4a7f-a96e-a573ae4ab50e,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-3e90b952-f0ec-4b8a-ace0-59f789a10381,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-6ce2c2b5-cd0c-40dd-9e9c-91c9f56f7215,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-02fcd8cb-ae47-4399-94bf-c9a0090065d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-af1be7e5-32c2-48e5-bb95-d032866823f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5093
