reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964987363-172.17.0.3-1598165250773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-76c9e793-8f16-4bd7-9cc0-6d0d6662d361,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-422a933b-5988-4df4-ae53-8b5b63de6d16,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-aef80b54-eee0-4510-ae2d-fff7c1db6e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-353a57f2-dfba-4c18-9ffb-00c014f627fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-c7340c3b-93cf-4ff5-a116-ba6ecb8d9aca,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-3f9d34d2-0ba6-41f0-9321-63a407addcee,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-48f55735-352a-4be9-b271-0b109c1807f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-11b56755-535f-4774-bbaa-dfa4ba4a7c1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964987363-172.17.0.3-1598165250773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-76c9e793-8f16-4bd7-9cc0-6d0d6662d361,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-422a933b-5988-4df4-ae53-8b5b63de6d16,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-aef80b54-eee0-4510-ae2d-fff7c1db6e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-353a57f2-dfba-4c18-9ffb-00c014f627fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-c7340c3b-93cf-4ff5-a116-ba6ecb8d9aca,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-3f9d34d2-0ba6-41f0-9321-63a407addcee,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-48f55735-352a-4be9-b271-0b109c1807f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-11b56755-535f-4774-bbaa-dfa4ba4a7c1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364799246-172.17.0.3-1598165510351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40803,DS-10ec7ae3-2df4-4f56-9b02-4b09d57eabf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-db9bdc31-0048-40f0-ad6e-eae4cc310f54,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-c9c1a021-680a-47be-8fc2-dcb4465676f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-6eb531ad-ce26-45bf-ba25-74d087c99162,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-63c9153a-8945-4baf-b7d6-adaa95b585fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-14722a47-67a1-4c46-8a41-1dee555bffad,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-675c0453-a75f-4cef-8631-21622446eaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-4ae47ef0-57a9-440f-9015-7df6d42f4239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364799246-172.17.0.3-1598165510351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40803,DS-10ec7ae3-2df4-4f56-9b02-4b09d57eabf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-db9bdc31-0048-40f0-ad6e-eae4cc310f54,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-c9c1a021-680a-47be-8fc2-dcb4465676f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-6eb531ad-ce26-45bf-ba25-74d087c99162,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-63c9153a-8945-4baf-b7d6-adaa95b585fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-14722a47-67a1-4c46-8a41-1dee555bffad,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-675c0453-a75f-4cef-8631-21622446eaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-4ae47ef0-57a9-440f-9015-7df6d42f4239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876261643-172.17.0.3-1598165644961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36351,DS-420605bb-fe9c-4fd3-8c0f-f2207a63fd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-6f17650c-2ab4-47e0-8929-25c4ce685dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-d3e4d7cb-7419-4c2f-814a-2ed2f86ce93b,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-c7197abc-4523-463a-9998-5d2cb983a97f,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-2f62d622-aa7c-4f8a-bc42-6673559b9b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-7d68a9b2-8713-4441-b015-93a4cd356892,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-c3b7d4ce-3524-4b0f-be5b-85da940142ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-7ab3dc65-fe01-46a6-a979-f325079331ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876261643-172.17.0.3-1598165644961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36351,DS-420605bb-fe9c-4fd3-8c0f-f2207a63fd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-6f17650c-2ab4-47e0-8929-25c4ce685dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-d3e4d7cb-7419-4c2f-814a-2ed2f86ce93b,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-c7197abc-4523-463a-9998-5d2cb983a97f,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-2f62d622-aa7c-4f8a-bc42-6673559b9b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-7d68a9b2-8713-4441-b015-93a4cd356892,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-c3b7d4ce-3524-4b0f-be5b-85da940142ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-7ab3dc65-fe01-46a6-a979-f325079331ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950734278-172.17.0.3-1598165744751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42604,DS-7c9b846c-b22e-43b3-a1f6-3dc2c89a7159,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-1e1f41bb-773f-4279-ab4b-9f75a2e35108,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-1e2d1c72-73be-42f0-b53f-08c2dda8a2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-b43d217b-c5cf-4b68-b66a-3dc54fb2117d,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-24ee4b06-b3ac-41b9-a6d7-30d93adb6940,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-7ee0f3d0-bd6c-40b5-a9a3-87bb0b727b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-d8712c95-b390-4db1-bac1-972f90f8ddd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-7f90e684-8099-4f2e-a075-ac7dbc5b4787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950734278-172.17.0.3-1598165744751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42604,DS-7c9b846c-b22e-43b3-a1f6-3dc2c89a7159,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-1e1f41bb-773f-4279-ab4b-9f75a2e35108,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-1e2d1c72-73be-42f0-b53f-08c2dda8a2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-b43d217b-c5cf-4b68-b66a-3dc54fb2117d,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-24ee4b06-b3ac-41b9-a6d7-30d93adb6940,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-7ee0f3d0-bd6c-40b5-a9a3-87bb0b727b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-d8712c95-b390-4db1-bac1-972f90f8ddd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-7f90e684-8099-4f2e-a075-ac7dbc5b4787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67559641-172.17.0.3-1598165929017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36148,DS-39c337aa-a032-4147-b13a-c4d775b60027,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-e654d07a-d8c7-4674-91f1-33fa6d281ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-d7de65b0-0c9e-4ff7-acad-5855d373cf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-188d7334-5899-4d3f-b06a-254137c1818b,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-467588ba-e7ec-4d09-a1f6-679b5c091ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-acc15de3-105f-4509-9ba6-54cbe5080d95,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-e5eeb75b-524f-43b7-96f8-aa6ddc668b20,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-29f8af6b-1818-4f08-82ba-35e91b79eb3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67559641-172.17.0.3-1598165929017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36148,DS-39c337aa-a032-4147-b13a-c4d775b60027,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-e654d07a-d8c7-4674-91f1-33fa6d281ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-d7de65b0-0c9e-4ff7-acad-5855d373cf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-188d7334-5899-4d3f-b06a-254137c1818b,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-467588ba-e7ec-4d09-a1f6-679b5c091ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-acc15de3-105f-4509-9ba6-54cbe5080d95,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-e5eeb75b-524f-43b7-96f8-aa6ddc668b20,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-29f8af6b-1818-4f08-82ba-35e91b79eb3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109156678-172.17.0.3-1598166533512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39393,DS-52dabd29-e066-497e-858c-bff529ef174f,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-e98a3ea2-c7a5-4534-a54d-480a4fd8579b,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-1e0078e9-7cd9-490f-aac5-121856a03a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-acad8b14-7f99-4ad1-951c-9ca955f9abfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-f5f33561-ada9-4616-93e4-66d419f280f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-c251f1ca-7a4f-4f1b-b8e3-7ef4bac17252,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-52d426e1-41f4-4d35-a231-6e33e7a0af38,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-94178ccc-2a21-456c-8642-3d4556fd4f68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109156678-172.17.0.3-1598166533512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39393,DS-52dabd29-e066-497e-858c-bff529ef174f,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-e98a3ea2-c7a5-4534-a54d-480a4fd8579b,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-1e0078e9-7cd9-490f-aac5-121856a03a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-acad8b14-7f99-4ad1-951c-9ca955f9abfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-f5f33561-ada9-4616-93e4-66d419f280f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-c251f1ca-7a4f-4f1b-b8e3-7ef4bac17252,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-52d426e1-41f4-4d35-a231-6e33e7a0af38,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-94178ccc-2a21-456c-8642-3d4556fd4f68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161387206-172.17.0.3-1598166645869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43871,DS-dfb5b9db-7f2b-40be-a602-d6c48f8cc7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-c191cda9-d295-4bf0-a59b-66ddbad28536,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-e46618d8-a25f-4a40-840e-076ff68a583e,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-29c360b5-d192-4d17-bd23-cae8c7f70d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-6c3be21d-babb-415d-86ab-8bda42b291d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-63a1b581-afb2-43c2-8b55-fc79f1324e60,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-4b42adbe-c39c-4882-b403-10921a79b305,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-9225dd2a-d60c-4f65-80d4-d08d8eb5647c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161387206-172.17.0.3-1598166645869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43871,DS-dfb5b9db-7f2b-40be-a602-d6c48f8cc7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-c191cda9-d295-4bf0-a59b-66ddbad28536,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-e46618d8-a25f-4a40-840e-076ff68a583e,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-29c360b5-d192-4d17-bd23-cae8c7f70d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-6c3be21d-babb-415d-86ab-8bda42b291d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-63a1b581-afb2-43c2-8b55-fc79f1324e60,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-4b42adbe-c39c-4882-b403-10921a79b305,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-9225dd2a-d60c-4f65-80d4-d08d8eb5647c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140267505-172.17.0.3-1598166709972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40067,DS-466e1a87-7ce6-44c1-acae-93f0770a2289,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-ab367d24-eca1-4d5a-bc0d-940c34d99684,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-474d7d13-ac70-45e4-8391-8914f78eaf71,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-7c65deb3-dbdb-4258-be2f-75b080601d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-8a0f9a6e-7237-45d5-b09f-2602c26f69dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-ea066d62-91ef-4a1d-bdcd-6071df5cdf86,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-416b4db5-fec6-4b8e-bdec-0bbcf06f2b56,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-311fd6c5-06cd-4ab3-a667-a94e01843d79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140267505-172.17.0.3-1598166709972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40067,DS-466e1a87-7ce6-44c1-acae-93f0770a2289,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-ab367d24-eca1-4d5a-bc0d-940c34d99684,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-474d7d13-ac70-45e4-8391-8914f78eaf71,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-7c65deb3-dbdb-4258-be2f-75b080601d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-8a0f9a6e-7237-45d5-b09f-2602c26f69dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-ea066d62-91ef-4a1d-bdcd-6071df5cdf86,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-416b4db5-fec6-4b8e-bdec-0bbcf06f2b56,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-311fd6c5-06cd-4ab3-a667-a94e01843d79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155807714-172.17.0.3-1598166858514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45677,DS-70748375-4d08-4a43-9083-2a4de9759cca,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-1d963cf2-8073-4f5a-b7e3-635d604081e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-3cc9958a-f921-42fc-b187-b53035092252,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-c4a9caf2-d4d4-44df-82ac-56271d34736b,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-15f6741e-5410-4fee-8e28-1d8a59d65bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-32abdf02-e10c-4a48-86fa-3f586c85506c,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-a0220022-a168-4365-ba8f-f207c0b78ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-f7712e1f-766c-4dae-b587-9344c0152c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155807714-172.17.0.3-1598166858514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45677,DS-70748375-4d08-4a43-9083-2a4de9759cca,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-1d963cf2-8073-4f5a-b7e3-635d604081e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-3cc9958a-f921-42fc-b187-b53035092252,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-c4a9caf2-d4d4-44df-82ac-56271d34736b,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-15f6741e-5410-4fee-8e28-1d8a59d65bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-32abdf02-e10c-4a48-86fa-3f586c85506c,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-a0220022-a168-4365-ba8f-f207c0b78ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-f7712e1f-766c-4dae-b587-9344c0152c95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751790322-172.17.0.3-1598166935082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43332,DS-fde7b19a-d938-4e37-96d2-c409c7bc163a,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-02e35678-0a89-4c89-8d23-dba892254d87,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-348e1250-fb1d-41ea-823b-25e34ef9fe45,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-036c438d-c342-4065-a840-3fcd89031d62,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-f8ebe67d-7220-4b51-bdba-a265cb11a79f,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-7a3c0003-ab76-455d-a779-546109cf609d,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-d9ec71be-44b5-4e53-964b-f1ad90428534,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-cf25e8ba-d4cd-40a0-ae7d-0044d0057798,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751790322-172.17.0.3-1598166935082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43332,DS-fde7b19a-d938-4e37-96d2-c409c7bc163a,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-02e35678-0a89-4c89-8d23-dba892254d87,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-348e1250-fb1d-41ea-823b-25e34ef9fe45,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-036c438d-c342-4065-a840-3fcd89031d62,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-f8ebe67d-7220-4b51-bdba-a265cb11a79f,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-7a3c0003-ab76-455d-a779-546109cf609d,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-d9ec71be-44b5-4e53-964b-f1ad90428534,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-cf25e8ba-d4cd-40a0-ae7d-0044d0057798,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942909155-172.17.0.3-1598166995390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43400,DS-c8396c78-d73d-4f16-9171-f3caee2ebf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-174106bb-4777-41ce-aa5d-9499afe87e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-b31627af-8576-45e8-b72b-82774db64cca,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-e4885914-774f-46e3-aefc-74710c1abb44,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-ce758ffc-501f-4bac-b8c7-c52bdc5f1cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-f1bddcef-e482-4299-9771-38c7c316b29c,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-46f3f51c-97ac-44d5-88aa-55dfb6c940a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-b044a5c1-ecc5-4c83-b669-67d900fa3589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942909155-172.17.0.3-1598166995390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43400,DS-c8396c78-d73d-4f16-9171-f3caee2ebf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-174106bb-4777-41ce-aa5d-9499afe87e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-b31627af-8576-45e8-b72b-82774db64cca,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-e4885914-774f-46e3-aefc-74710c1abb44,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-ce758ffc-501f-4bac-b8c7-c52bdc5f1cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-f1bddcef-e482-4299-9771-38c7c316b29c,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-46f3f51c-97ac-44d5-88aa-55dfb6c940a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-b044a5c1-ecc5-4c83-b669-67d900fa3589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182098103-172.17.0.3-1598167985831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37763,DS-42d3727b-f93b-412f-8ff6-4c04f86a1952,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-924a31c0-1023-4e4b-ac23-3f6d2b38c286,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-9ac978ae-e769-46ea-be76-02bb450b84e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-8cb2ef6a-2058-4ce9-8c7f-3b26064d24a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-723d01fc-fdfb-4ff4-879e-d206cde06d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-79efb3f8-e866-4274-970c-0a1b2d3489cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-45070b05-bfba-4b0d-b6d6-bf19da575128,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-9287658b-24d4-4d61-bc41-49c218be9308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182098103-172.17.0.3-1598167985831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37763,DS-42d3727b-f93b-412f-8ff6-4c04f86a1952,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-924a31c0-1023-4e4b-ac23-3f6d2b38c286,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-9ac978ae-e769-46ea-be76-02bb450b84e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-8cb2ef6a-2058-4ce9-8c7f-3b26064d24a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-723d01fc-fdfb-4ff4-879e-d206cde06d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-79efb3f8-e866-4274-970c-0a1b2d3489cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-45070b05-bfba-4b0d-b6d6-bf19da575128,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-9287658b-24d4-4d61-bc41-49c218be9308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180838554-172.17.0.3-1598168321777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44441,DS-86a911ff-9020-45c8-839b-e0105dbf4b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-6afa852c-f0d8-4eb3-bcf5-7d6f10ef7ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-29b78746-b9a7-4a87-b0da-5eaacb366d43,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-b18db9d0-8f41-48f6-b525-0e1ebf16706e,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-2ab9dc5e-def0-4b5f-a8f9-6267aa50389d,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-69dbe18b-36f4-47b1-9abc-e7f144c8bbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-c942a9f8-8018-4e88-b7fa-3c6d9edde3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-bff0f0a3-bf23-481d-a217-d41e3093c664,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180838554-172.17.0.3-1598168321777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44441,DS-86a911ff-9020-45c8-839b-e0105dbf4b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-6afa852c-f0d8-4eb3-bcf5-7d6f10ef7ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-29b78746-b9a7-4a87-b0da-5eaacb366d43,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-b18db9d0-8f41-48f6-b525-0e1ebf16706e,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-2ab9dc5e-def0-4b5f-a8f9-6267aa50389d,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-69dbe18b-36f4-47b1-9abc-e7f144c8bbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-c942a9f8-8018-4e88-b7fa-3c6d9edde3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-bff0f0a3-bf23-481d-a217-d41e3093c664,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-402902952-172.17.0.3-1598168393893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35118,DS-37d13034-9c87-488b-8d72-12ea61d9cd48,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-aa3aae88-8eaf-47ae-a4f3-517653eaab94,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-0f3b1000-fae5-4b74-adc3-080d622c5a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-b7f0e22d-6249-40b6-8939-b6e345cad53d,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-607d5d55-3def-4722-89ec-c9edbd37d379,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-6d654a84-93bb-47b6-b6c2-4420048c42b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-447a2d42-863d-4fed-8ef4-a2cf9a1f0b52,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-f644b00b-94f4-417f-b26d-4642fae10a87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-402902952-172.17.0.3-1598168393893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35118,DS-37d13034-9c87-488b-8d72-12ea61d9cd48,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-aa3aae88-8eaf-47ae-a4f3-517653eaab94,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-0f3b1000-fae5-4b74-adc3-080d622c5a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-b7f0e22d-6249-40b6-8939-b6e345cad53d,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-607d5d55-3def-4722-89ec-c9edbd37d379,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-6d654a84-93bb-47b6-b6c2-4420048c42b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-447a2d42-863d-4fed-8ef4-a2cf9a1f0b52,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-f644b00b-94f4-417f-b26d-4642fae10a87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087818914-172.17.0.3-1598168906701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42274,DS-ebc1e7aa-4d23-44e3-ade0-e9c88e0d9984,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-3e7b2784-6a01-46f3-95a8-5b79727eea3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-87de1896-83d2-4e40-bd7e-cff37f4e9960,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-c34eaf5a-81d7-4e9f-bc7a-2239fc1f16f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-5f14e66b-ccbe-40bc-8957-9329b568579c,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-e52662b3-2215-4b24-b2d0-5fb38652a96d,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-0f477cd0-ecff-41fb-83ce-218145bc4295,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-760f8fa8-ff5c-4b7c-a883-1b1bfff1aec4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087818914-172.17.0.3-1598168906701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42274,DS-ebc1e7aa-4d23-44e3-ade0-e9c88e0d9984,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-3e7b2784-6a01-46f3-95a8-5b79727eea3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-87de1896-83d2-4e40-bd7e-cff37f4e9960,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-c34eaf5a-81d7-4e9f-bc7a-2239fc1f16f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-5f14e66b-ccbe-40bc-8957-9329b568579c,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-e52662b3-2215-4b24-b2d0-5fb38652a96d,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-0f477cd0-ecff-41fb-83ce-218145bc4295,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-760f8fa8-ff5c-4b7c-a883-1b1bfff1aec4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960685122-172.17.0.3-1598169917760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41750,DS-f1f782c1-d102-4db7-80e2-aba558dbf8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-eb2f022a-6a1f-4b8d-b981-93beed3358e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-e0f6cd29-65e7-4f6a-8fff-7c1b80961e48,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-bf72be1d-9596-41aa-9291-dc37ed51a808,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-f5d16afc-a489-4c71-85c4-d28fbd9a0fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-af440e43-547e-4cb8-b01c-1ba86d5a0552,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-432c9eaf-6dc7-4f96-84ce-116391657f93,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-13aab27c-20f2-437e-920b-fe2d25830f3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960685122-172.17.0.3-1598169917760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41750,DS-f1f782c1-d102-4db7-80e2-aba558dbf8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-eb2f022a-6a1f-4b8d-b981-93beed3358e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-e0f6cd29-65e7-4f6a-8fff-7c1b80961e48,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-bf72be1d-9596-41aa-9291-dc37ed51a808,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-f5d16afc-a489-4c71-85c4-d28fbd9a0fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-af440e43-547e-4cb8-b01c-1ba86d5a0552,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-432c9eaf-6dc7-4f96-84ce-116391657f93,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-13aab27c-20f2-437e-920b-fe2d25830f3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975959239-172.17.0.3-1598169991075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46442,DS-5d2b5ed8-4e10-4ee2-8460-30d3d46b11b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-167afa32-25a2-44df-9937-df9871bc33ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-dcb74524-cc42-42a1-834f-ab0c04c5af83,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-fda38d14-45fc-4415-a463-0764bfc69384,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-284817b3-22f1-4b06-91ba-8081874b23d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-f62daec4-7f80-45c6-a1f5-f081c5b1724e,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-99356067-e010-4c60-926c-677b308be838,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-54604a28-5ed3-4153-9ed5-154456145236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975959239-172.17.0.3-1598169991075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46442,DS-5d2b5ed8-4e10-4ee2-8460-30d3d46b11b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-167afa32-25a2-44df-9937-df9871bc33ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-dcb74524-cc42-42a1-834f-ab0c04c5af83,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-fda38d14-45fc-4415-a463-0764bfc69384,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-284817b3-22f1-4b06-91ba-8081874b23d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-f62daec4-7f80-45c6-a1f5-f081c5b1724e,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-99356067-e010-4c60-926c-677b308be838,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-54604a28-5ed3-4153-9ed5-154456145236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5236
