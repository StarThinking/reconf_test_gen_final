reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269687346-172.17.0.5-1598119740704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34102,DS-20e48e81-75d0-40d9-bf4c-12b5a5d8d51c,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-52d99bda-eca6-4764-a78b-5256eb5b33ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-2c17b021-f666-4185-9d7e-d102c7f5b6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-e43237f8-51db-4865-b056-1c27e2645ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-f65f9688-b928-473a-8c37-b886218fd241,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-45ee8e1b-b825-4f55-b7d6-4a214b521235,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-54f1df53-7b01-4eab-b023-dffa35c1e841,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-5205b07e-16e8-4ed8-8751-f3ca14eb0d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269687346-172.17.0.5-1598119740704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34102,DS-20e48e81-75d0-40d9-bf4c-12b5a5d8d51c,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-52d99bda-eca6-4764-a78b-5256eb5b33ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-2c17b021-f666-4185-9d7e-d102c7f5b6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-e43237f8-51db-4865-b056-1c27e2645ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-f65f9688-b928-473a-8c37-b886218fd241,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-45ee8e1b-b825-4f55-b7d6-4a214b521235,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-54f1df53-7b01-4eab-b023-dffa35c1e841,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-5205b07e-16e8-4ed8-8751-f3ca14eb0d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238537790-172.17.0.5-1598120492428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33180,DS-e59c70a0-7bf1-4847-8bdc-4ca8232c4c47,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-6623e9e4-69df-4996-b6fa-3db7f49d3e15,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-cf50937c-0325-4e95-ae75-7845838dc0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-f8c1b369-27d2-4732-9dc8-694677fc1f03,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-87df866b-500a-412a-b7d2-0b456926c130,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-0390ae78-6656-4715-9d8c-e72c6b44a019,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-14606498-b0e7-4765-907b-3709bd838298,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-8fb8e2ee-3147-4d81-ac63-6cd7ca31bc5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238537790-172.17.0.5-1598120492428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33180,DS-e59c70a0-7bf1-4847-8bdc-4ca8232c4c47,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-6623e9e4-69df-4996-b6fa-3db7f49d3e15,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-cf50937c-0325-4e95-ae75-7845838dc0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-f8c1b369-27d2-4732-9dc8-694677fc1f03,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-87df866b-500a-412a-b7d2-0b456926c130,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-0390ae78-6656-4715-9d8c-e72c6b44a019,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-14606498-b0e7-4765-907b-3709bd838298,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-8fb8e2ee-3147-4d81-ac63-6cd7ca31bc5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506251066-172.17.0.5-1598120576542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40906,DS-6ac26b72-5e08-4460-a756-f694e49ea521,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-b70b45c0-6077-45b4-9c85-ed9dd1ca930b,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-0462e572-beee-4bf2-8bcb-a31d5a79964c,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-b7458eed-fcea-4a82-8324-000c3be3e80e,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-12040ca3-de95-4d89-a5e7-53c60982c1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-be37ff1d-c90e-42a5-a6f0-64dea6398f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-ffe9d199-0b33-4834-a670-bbad3b4fc7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-60a657c6-7c9a-449f-a7c2-138393c730d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506251066-172.17.0.5-1598120576542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40906,DS-6ac26b72-5e08-4460-a756-f694e49ea521,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-b70b45c0-6077-45b4-9c85-ed9dd1ca930b,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-0462e572-beee-4bf2-8bcb-a31d5a79964c,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-b7458eed-fcea-4a82-8324-000c3be3e80e,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-12040ca3-de95-4d89-a5e7-53c60982c1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-be37ff1d-c90e-42a5-a6f0-64dea6398f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-ffe9d199-0b33-4834-a670-bbad3b4fc7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-60a657c6-7c9a-449f-a7c2-138393c730d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020921856-172.17.0.5-1598121431966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38996,DS-b20f9231-2261-4198-9c4f-bf713e9f4eed,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-7ec1615e-1058-487f-a0a0-af211952afe5,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-605d3ace-54da-4ef1-96f9-dfff4cac6930,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-aeb7d0f3-64d1-49b4-83ba-eb04a74cbda0,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-aeda76da-38fb-484e-8dd0-ea73b27c57d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-a93976ee-4c6e-40df-95f0-ee1b0eb7294f,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-0b0c1aec-e473-4ea2-b604-c6794a81439c,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-1b8b471b-d41a-43d2-aeb6-cf7447626833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020921856-172.17.0.5-1598121431966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38996,DS-b20f9231-2261-4198-9c4f-bf713e9f4eed,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-7ec1615e-1058-487f-a0a0-af211952afe5,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-605d3ace-54da-4ef1-96f9-dfff4cac6930,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-aeb7d0f3-64d1-49b4-83ba-eb04a74cbda0,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-aeda76da-38fb-484e-8dd0-ea73b27c57d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-a93976ee-4c6e-40df-95f0-ee1b0eb7294f,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-0b0c1aec-e473-4ea2-b604-c6794a81439c,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-1b8b471b-d41a-43d2-aeb6-cf7447626833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1226517413-172.17.0.5-1598121790207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38878,DS-7c838255-1742-4c4b-8e06-47d795e5b7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-a7024fc3-5c50-4f42-ac2e-e3d54ed7dc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-8cae2d56-2ba7-49a6-a1c7-8a0ce077e061,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-24b53b3d-97e9-49f1-9b1a-48f57a0bfb81,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-7a2ca823-f231-4a70-b12a-2ca8f2a444ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-ca323262-349b-4f8f-b042-cbbfd0c94f34,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-88707fb5-4a2f-46ac-bb4d-741ca784ed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-059e91e6-6798-4a84-b139-88c037a439bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1226517413-172.17.0.5-1598121790207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38878,DS-7c838255-1742-4c4b-8e06-47d795e5b7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-a7024fc3-5c50-4f42-ac2e-e3d54ed7dc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-8cae2d56-2ba7-49a6-a1c7-8a0ce077e061,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-24b53b3d-97e9-49f1-9b1a-48f57a0bfb81,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-7a2ca823-f231-4a70-b12a-2ca8f2a444ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-ca323262-349b-4f8f-b042-cbbfd0c94f34,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-88707fb5-4a2f-46ac-bb4d-741ca784ed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-059e91e6-6798-4a84-b139-88c037a439bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-914177993-172.17.0.5-1598122498922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39022,DS-2983c15e-1b8f-4782-bfe4-e9a758c6e7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-41e36807-0d4e-470e-81bf-45f8a0774975,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-6f05f626-183c-4b79-9344-664432b35fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-4dbc505a-a552-45eb-82e1-078c83f227b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-010f76d6-fb4a-4382-9642-c21125bc4ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-78c6c312-7288-4609-a2dd-06e26a98f270,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-ed1aa63c-25ec-4fd2-847f-320025a1ca98,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-9f00d256-3a84-43e6-8a58-3e0620467ab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-914177993-172.17.0.5-1598122498922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39022,DS-2983c15e-1b8f-4782-bfe4-e9a758c6e7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-41e36807-0d4e-470e-81bf-45f8a0774975,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-6f05f626-183c-4b79-9344-664432b35fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-4dbc505a-a552-45eb-82e1-078c83f227b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-010f76d6-fb4a-4382-9642-c21125bc4ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-78c6c312-7288-4609-a2dd-06e26a98f270,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-ed1aa63c-25ec-4fd2-847f-320025a1ca98,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-9f00d256-3a84-43e6-8a58-3e0620467ab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1853821134-172.17.0.5-1598122625531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44009,DS-8e0a9145-c4a5-476e-9be8-21709f60713b,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-6eca9f62-8613-4f15-b646-000507383812,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-1dbfa9c2-d8b7-4c15-8767-902c3e357dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-c07dae9d-3bc0-4114-9ac7-3390d3394d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-54ba068d-ba86-4e63-8e14-e406864a82e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-d26290bd-85be-44bb-ad53-80b3e273a68c,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-afe7eeb9-77d9-48f5-8378-25c373ff24f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-ddbc5398-5661-447b-be20-f33da7507ed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1853821134-172.17.0.5-1598122625531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44009,DS-8e0a9145-c4a5-476e-9be8-21709f60713b,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-6eca9f62-8613-4f15-b646-000507383812,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-1dbfa9c2-d8b7-4c15-8767-902c3e357dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-c07dae9d-3bc0-4114-9ac7-3390d3394d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-54ba068d-ba86-4e63-8e14-e406864a82e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-d26290bd-85be-44bb-ad53-80b3e273a68c,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-afe7eeb9-77d9-48f5-8378-25c373ff24f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-ddbc5398-5661-447b-be20-f33da7507ed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504672043-172.17.0.5-1598123618596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46484,DS-2a1fb4b1-25f2-4404-9215-dcdb44a39e04,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-6e56e8e6-ae26-4e6c-84ff-73b609547d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-3502bf02-0039-4191-a902-7f9d33121a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-1d768149-28e7-4019-a4f0-e87110be3be7,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-8cac00d8-18d5-4670-8e27-e1ff85471072,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-44593375-0682-4ba0-a502-e3a8d35d5ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-488e7b23-a045-418c-ba74-9d3527bd593f,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-38a138fd-bbf2-4e1d-ace9-60bf377aa405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504672043-172.17.0.5-1598123618596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46484,DS-2a1fb4b1-25f2-4404-9215-dcdb44a39e04,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-6e56e8e6-ae26-4e6c-84ff-73b609547d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-3502bf02-0039-4191-a902-7f9d33121a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-1d768149-28e7-4019-a4f0-e87110be3be7,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-8cac00d8-18d5-4670-8e27-e1ff85471072,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-44593375-0682-4ba0-a502-e3a8d35d5ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-488e7b23-a045-418c-ba74-9d3527bd593f,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-38a138fd-bbf2-4e1d-ace9-60bf377aa405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-852546193-172.17.0.5-1598124199201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43618,DS-62eab614-8e7e-4f1a-8f9f-2e11d80a4692,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-abfe4b86-f254-49c8-9d2b-4790308313da,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-580b3612-d3e1-4c78-ad9c-333c4bd920f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-4334c61e-b956-41a6-a323-2366e5316d34,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-26a3ce3c-152c-4790-bc9b-3de33b4bc8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-96040f9c-89c9-431a-a498-f0ac4e817180,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-08049982-18bd-4249-a867-62048476f48b,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-0929d0d5-acf4-4465-9fe1-f9f1ac372a8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-852546193-172.17.0.5-1598124199201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43618,DS-62eab614-8e7e-4f1a-8f9f-2e11d80a4692,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-abfe4b86-f254-49c8-9d2b-4790308313da,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-580b3612-d3e1-4c78-ad9c-333c4bd920f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-4334c61e-b956-41a6-a323-2366e5316d34,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-26a3ce3c-152c-4790-bc9b-3de33b4bc8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-96040f9c-89c9-431a-a498-f0ac4e817180,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-08049982-18bd-4249-a867-62048476f48b,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-0929d0d5-acf4-4465-9fe1-f9f1ac372a8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765273934-172.17.0.5-1598124388132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44705,DS-5552cc12-dbb0-4302-8235-2b2f98eb3b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-359975d6-2a37-44a1-a954-c7a4960ae8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-940745ba-aa2e-41b5-af4e-c4ea01bcb857,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-2ad13d84-d7de-40ae-ad41-8d1464449c04,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-f32ec190-e291-4529-bc1e-012b080f47ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-67d4687c-7b93-4123-80fa-36193093d3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-1fbc0c70-dc04-4c6e-9533-ef63fc38b26b,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-7275d8bc-3aff-4326-8b75-29acaaf24277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765273934-172.17.0.5-1598124388132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44705,DS-5552cc12-dbb0-4302-8235-2b2f98eb3b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-359975d6-2a37-44a1-a954-c7a4960ae8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-940745ba-aa2e-41b5-af4e-c4ea01bcb857,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-2ad13d84-d7de-40ae-ad41-8d1464449c04,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-f32ec190-e291-4529-bc1e-012b080f47ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-67d4687c-7b93-4123-80fa-36193093d3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-1fbc0c70-dc04-4c6e-9533-ef63fc38b26b,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-7275d8bc-3aff-4326-8b75-29acaaf24277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305193732-172.17.0.5-1598124671762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36662,DS-87da9a54-0169-4388-9bee-8fb3fa7577ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-f8b67729-f8fa-49d3-87e7-5200e36a35ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-6b0ac0ef-7f18-44e3-af0c-2cef7b85bffc,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-733deb70-20cb-497e-8ae5-dccc6cc444ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-d75c6c48-3606-49af-b877-28dbaf695472,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-c31a42b4-0eda-4200-ac66-255cf93a8c08,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-fdb36006-9eb8-402b-894e-fb7c816e73a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-0cac274d-0ebe-45c9-b7ae-aa0d6d1e5da3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305193732-172.17.0.5-1598124671762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36662,DS-87da9a54-0169-4388-9bee-8fb3fa7577ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-f8b67729-f8fa-49d3-87e7-5200e36a35ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-6b0ac0ef-7f18-44e3-af0c-2cef7b85bffc,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-733deb70-20cb-497e-8ae5-dccc6cc444ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-d75c6c48-3606-49af-b877-28dbaf695472,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-c31a42b4-0eda-4200-ac66-255cf93a8c08,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-fdb36006-9eb8-402b-894e-fb7c816e73a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-0cac274d-0ebe-45c9-b7ae-aa0d6d1e5da3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701937593-172.17.0.5-1598124719693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35310,DS-73209ed0-f3ac-417d-b517-6c54781b9d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-49d51000-0f2d-4636-9ac8-b2aed1d6d731,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-17b5995a-e101-4e6e-ab4e-6ace35d08b32,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-235dc27b-e92b-41f3-9f17-634bf14c6b21,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-de87842c-663b-4935-b78d-635b39de327e,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-1c20013c-fbec-4126-8e2d-848b35aa7756,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-6a3a0b4f-c505-47b4-aa35-c42018480f52,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-f1ec4a6a-d03c-4fce-beb5-77d2e3c1e1e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701937593-172.17.0.5-1598124719693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35310,DS-73209ed0-f3ac-417d-b517-6c54781b9d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-49d51000-0f2d-4636-9ac8-b2aed1d6d731,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-17b5995a-e101-4e6e-ab4e-6ace35d08b32,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-235dc27b-e92b-41f3-9f17-634bf14c6b21,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-de87842c-663b-4935-b78d-635b39de327e,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-1c20013c-fbec-4126-8e2d-848b35aa7756,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-6a3a0b4f-c505-47b4-aa35-c42018480f52,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-f1ec4a6a-d03c-4fce-beb5-77d2e3c1e1e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763133585-172.17.0.5-1598124808323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33439,DS-451ebb89-415f-4825-87a8-d0a8e3680afe,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-d62bdb11-f190-4deb-a18f-b6e50487ca59,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-2ee4e503-b7eb-400e-bce5-35e137a10eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-c4b8f307-f4bb-4454-8338-b6dec69327e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-4882bee1-3cce-4c00-9b97-f2a534ad769d,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-48cd8a8f-661e-4f7f-b147-df91a6b6bda1,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-7aceb1e1-7bf4-4429-b1f6-400089d1a817,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-3e8e3c6d-dbd7-44da-b21e-66b6b0c342c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763133585-172.17.0.5-1598124808323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33439,DS-451ebb89-415f-4825-87a8-d0a8e3680afe,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-d62bdb11-f190-4deb-a18f-b6e50487ca59,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-2ee4e503-b7eb-400e-bce5-35e137a10eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-c4b8f307-f4bb-4454-8338-b6dec69327e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-4882bee1-3cce-4c00-9b97-f2a534ad769d,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-48cd8a8f-661e-4f7f-b147-df91a6b6bda1,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-7aceb1e1-7bf4-4429-b1f6-400089d1a817,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-3e8e3c6d-dbd7-44da-b21e-66b6b0c342c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.async
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-379177162-172.17.0.5-1598125024499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33110,DS-38680e97-c7d0-42ce-9b34-654875c364ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-a0a7736e-380a-49f0-b398-36fae1767d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-6e2a51fe-721e-4f09-b80b-10ddb49e52a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-e2402a95-4cca-4149-8ed8-ea5ef88f59f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-829797dd-eaf2-4657-8c07-0fade201ac85,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-9b0f84eb-59e3-4078-9225-39efe9138dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-38e0fd38-a7b2-436c-9c7a-c2c3a4ca6cef,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-6c744133-b829-455f-bb4c-783e4ca3fc6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-379177162-172.17.0.5-1598125024499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33110,DS-38680e97-c7d0-42ce-9b34-654875c364ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-a0a7736e-380a-49f0-b398-36fae1767d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-6e2a51fe-721e-4f09-b80b-10ddb49e52a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-e2402a95-4cca-4149-8ed8-ea5ef88f59f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-829797dd-eaf2-4657-8c07-0fade201ac85,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-9b0f84eb-59e3-4078-9225-39efe9138dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-38e0fd38-a7b2-436c-9c7a-c2c3a4ca6cef,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-6c744133-b829-455f-bb4c-783e4ca3fc6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6592
