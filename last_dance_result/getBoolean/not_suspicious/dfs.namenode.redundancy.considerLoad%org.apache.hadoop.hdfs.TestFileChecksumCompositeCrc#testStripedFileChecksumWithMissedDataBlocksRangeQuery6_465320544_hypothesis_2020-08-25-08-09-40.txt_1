reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190462569-172.17.0.7-1598343065894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35357,DS-ab39c678-28e9-420f-bdca-0b0b91c98d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-24d12114-2d6e-4ec7-b3c9-4e3dba04aca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-a8f0a804-aa8f-40a9-8646-5cfa2e99b82e,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-a9b3e402-79a1-4bfd-a566-71510334832d,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-4dd14ae1-630e-4365-b393-96b57f4306d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-a86c4236-d330-44fc-8f54-f6958e58b3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-64eef038-7d32-4f52-b53f-204ebe724afe,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-3804d468-3096-4aea-8753-969ccecc33c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190462569-172.17.0.7-1598343065894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35357,DS-ab39c678-28e9-420f-bdca-0b0b91c98d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-24d12114-2d6e-4ec7-b3c9-4e3dba04aca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-a8f0a804-aa8f-40a9-8646-5cfa2e99b82e,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-a9b3e402-79a1-4bfd-a566-71510334832d,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-4dd14ae1-630e-4365-b393-96b57f4306d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-a86c4236-d330-44fc-8f54-f6958e58b3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-64eef038-7d32-4f52-b53f-204ebe724afe,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-3804d468-3096-4aea-8753-969ccecc33c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286379087-172.17.0.7-1598343315929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38235,DS-26acbf54-caec-468a-bba7-1afb8551ee11,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-a08eaf67-a096-40d7-b7a5-433e2eaa6f09,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-41a74378-95b9-46e2-bc3d-f305de346b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-cf7a3fdc-da7f-41d7-b26a-73428a98fefd,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-6e8ef1d2-cc89-4491-a474-e9e661319d80,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-83e70486-c7e8-43a4-8f87-2c08260109ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-e941e0e1-9759-418c-99d8-fb2d40ac0d52,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-5cc529f1-3878-4d32-adc1-698a60948092,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286379087-172.17.0.7-1598343315929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38235,DS-26acbf54-caec-468a-bba7-1afb8551ee11,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-a08eaf67-a096-40d7-b7a5-433e2eaa6f09,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-41a74378-95b9-46e2-bc3d-f305de346b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-cf7a3fdc-da7f-41d7-b26a-73428a98fefd,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-6e8ef1d2-cc89-4491-a474-e9e661319d80,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-83e70486-c7e8-43a4-8f87-2c08260109ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-e941e0e1-9759-418c-99d8-fb2d40ac0d52,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-5cc529f1-3878-4d32-adc1-698a60948092,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144336414-172.17.0.7-1598343573206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43510,DS-a0e0991a-c682-4815-ab0e-3183e5eab0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-8205f9be-9443-47b9-9757-940f0f3ddb15,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-bf62786f-6d3b-4ac5-b88a-d9ed280f6e73,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-26e73f1a-34a3-4470-9943-6f5a41816e60,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-99f77f9c-7a76-4b51-96fc-c595ef75679c,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-d70537be-919c-4af4-aea0-f7c0ea0ca683,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-6cd8c772-3feb-4dbf-8696-b669e0a9cbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-d179cd4c-2039-4108-8d46-8e6991a79759,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144336414-172.17.0.7-1598343573206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43510,DS-a0e0991a-c682-4815-ab0e-3183e5eab0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-8205f9be-9443-47b9-9757-940f0f3ddb15,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-bf62786f-6d3b-4ac5-b88a-d9ed280f6e73,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-26e73f1a-34a3-4470-9943-6f5a41816e60,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-99f77f9c-7a76-4b51-96fc-c595ef75679c,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-d70537be-919c-4af4-aea0-f7c0ea0ca683,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-6cd8c772-3feb-4dbf-8696-b669e0a9cbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-d179cd4c-2039-4108-8d46-8e6991a79759,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025235810-172.17.0.7-1598343617262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46701,DS-bdd9ff8a-de9b-41a6-bfb6-510f9da5ced3,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-687d8105-d22d-4e1b-972d-8661d84ebab1,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-03400b06-0c2f-4348-aaa8-9cd026d42fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-8b311530-da76-48cd-a407-53344ec7b5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-a60952ad-ec0e-45b6-a78a-8e386b5f205f,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-37771a17-e94e-45ad-a8cb-e38e4f13970c,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-3488bc2d-fda3-4c5d-8d38-0bafff11f517,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-89375eb0-dc01-4e39-a629-a276596586dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025235810-172.17.0.7-1598343617262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46701,DS-bdd9ff8a-de9b-41a6-bfb6-510f9da5ced3,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-687d8105-d22d-4e1b-972d-8661d84ebab1,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-03400b06-0c2f-4348-aaa8-9cd026d42fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-8b311530-da76-48cd-a407-53344ec7b5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-a60952ad-ec0e-45b6-a78a-8e386b5f205f,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-37771a17-e94e-45ad-a8cb-e38e4f13970c,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-3488bc2d-fda3-4c5d-8d38-0bafff11f517,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-89375eb0-dc01-4e39-a629-a276596586dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045438328-172.17.0.7-1598343874617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41694,DS-f5b7b83b-d273-4d1f-af45-575d492b3ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-8a4a9d2e-3a63-4e24-b163-2ae97b0881fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-622489d9-d684-4bef-9e12-002636f22f68,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-8febdee8-673c-4320-b722-e651ce2e34a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-6121cbc9-55df-412a-8256-386c93d404b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-396f0ee9-3ba5-4be2-9fb2-d65a757de5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-852d3692-8668-4c83-b3ee-0890a83c5d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-b3a919ba-d412-4a33-8088-2202ce1062ee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045438328-172.17.0.7-1598343874617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41694,DS-f5b7b83b-d273-4d1f-af45-575d492b3ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-8a4a9d2e-3a63-4e24-b163-2ae97b0881fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-622489d9-d684-4bef-9e12-002636f22f68,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-8febdee8-673c-4320-b722-e651ce2e34a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-6121cbc9-55df-412a-8256-386c93d404b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-396f0ee9-3ba5-4be2-9fb2-d65a757de5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-852d3692-8668-4c83-b3ee-0890a83c5d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-b3a919ba-d412-4a33-8088-2202ce1062ee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077508968-172.17.0.7-1598344110934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45049,DS-9a1ba13e-423d-46f6-92a2-ed064023a6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-b53fa776-0c84-47e1-bfc7-45946df3f581,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-e696f5af-7a73-4e3c-abfd-c048a8180c80,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-1956f415-8f41-4ca0-ae46-e8b148874762,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-59510435-6a71-4438-a476-948630bcf2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-c654d609-1144-4c36-83df-0c07a7a222a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-0fa736c8-a670-43ad-9852-df890035cbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-39750147-ceb0-47a5-b403-b8811ae26741,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077508968-172.17.0.7-1598344110934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45049,DS-9a1ba13e-423d-46f6-92a2-ed064023a6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-b53fa776-0c84-47e1-bfc7-45946df3f581,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-e696f5af-7a73-4e3c-abfd-c048a8180c80,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-1956f415-8f41-4ca0-ae46-e8b148874762,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-59510435-6a71-4438-a476-948630bcf2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-c654d609-1144-4c36-83df-0c07a7a222a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-0fa736c8-a670-43ad-9852-df890035cbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-39750147-ceb0-47a5-b403-b8811ae26741,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166348176-172.17.0.7-1598344536561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44267,DS-2a59158a-293c-4857-bd20-7537948c78a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-463cbe7d-152b-4e4a-8b8c-c82a7269205a,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-5c981bb0-675b-4d54-af54-610704e0887c,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-13aa8eed-7309-48a5-b8bc-87b54c7bd501,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-417a31fc-34dc-48f9-9c1d-1de6eadd9b91,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-5ea0db1a-644a-4a98-8b94-f1e1e7423eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-4b19b2d2-f446-4509-8fdc-24dd83f0425c,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-d64d087c-2540-4aef-b21d-0b9057102c25,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166348176-172.17.0.7-1598344536561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44267,DS-2a59158a-293c-4857-bd20-7537948c78a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-463cbe7d-152b-4e4a-8b8c-c82a7269205a,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-5c981bb0-675b-4d54-af54-610704e0887c,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-13aa8eed-7309-48a5-b8bc-87b54c7bd501,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-417a31fc-34dc-48f9-9c1d-1de6eadd9b91,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-5ea0db1a-644a-4a98-8b94-f1e1e7423eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-4b19b2d2-f446-4509-8fdc-24dd83f0425c,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-d64d087c-2540-4aef-b21d-0b9057102c25,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628397678-172.17.0.7-1598344724364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41199,DS-1a22c341-f010-4249-a06e-e7c7968a66bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-8599a48d-c5d9-46e5-9b58-f41c9a198df8,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-766cf396-d156-4f0d-9490-3524a2b90ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-7127ee7e-ad09-40b4-8f59-b8e6d6044f96,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-193dc942-e1be-4a1d-a921-a21327d9372f,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-95e93f2a-5978-43e3-a4fc-1ce96b08a4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-e9d14f60-6b24-4520-877f-07049787e6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-b0fe8b20-e9d1-4150-8e44-f6fa270bae79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628397678-172.17.0.7-1598344724364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41199,DS-1a22c341-f010-4249-a06e-e7c7968a66bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-8599a48d-c5d9-46e5-9b58-f41c9a198df8,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-766cf396-d156-4f0d-9490-3524a2b90ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-7127ee7e-ad09-40b4-8f59-b8e6d6044f96,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-193dc942-e1be-4a1d-a921-a21327d9372f,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-95e93f2a-5978-43e3-a4fc-1ce96b08a4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-e9d14f60-6b24-4520-877f-07049787e6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-b0fe8b20-e9d1-4150-8e44-f6fa270bae79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390390964-172.17.0.7-1598344896558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45323,DS-311e6d7c-d46b-47f7-809d-f80d63c0232f,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-db5a41ca-2d33-45de-bb08-a3f7fd0c46f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-7641d071-2343-41ee-b798-0051e2cea19e,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-44b3bc4d-008a-4af5-a76a-5e3c5b6a6fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-6eca3199-bc5f-43a8-9e48-432ebefad5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-cd06bc38-f5a0-45fd-b82d-50f6e447a1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-a2e1230d-013c-47ea-8c7f-dd53725819c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-09d7459e-bca5-4809-8a17-fbb02995b8cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390390964-172.17.0.7-1598344896558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45323,DS-311e6d7c-d46b-47f7-809d-f80d63c0232f,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-db5a41ca-2d33-45de-bb08-a3f7fd0c46f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-7641d071-2343-41ee-b798-0051e2cea19e,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-44b3bc4d-008a-4af5-a76a-5e3c5b6a6fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-6eca3199-bc5f-43a8-9e48-432ebefad5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-cd06bc38-f5a0-45fd-b82d-50f6e447a1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-a2e1230d-013c-47ea-8c7f-dd53725819c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-09d7459e-bca5-4809-8a17-fbb02995b8cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953844775-172.17.0.7-1598345232950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32838,DS-688277ad-2eaf-40bc-8a5c-8967b15fc10d,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-9079d8fd-093b-4c0d-8ded-272c36c7e40b,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-f9964bd7-9917-4d4b-a538-147f57a90282,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-54449e45-da59-421d-93de-a6700ba958e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-452135bf-58fd-4540-8b29-9b7f8fb20d97,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-a93e227e-baf0-458b-88eb-92025a07a53e,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-680a03d2-23ff-4136-8099-1aaedb2e770b,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-189ee576-5f1a-42c5-a700-02225d21333d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953844775-172.17.0.7-1598345232950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32838,DS-688277ad-2eaf-40bc-8a5c-8967b15fc10d,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-9079d8fd-093b-4c0d-8ded-272c36c7e40b,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-f9964bd7-9917-4d4b-a538-147f57a90282,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-54449e45-da59-421d-93de-a6700ba958e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-452135bf-58fd-4540-8b29-9b7f8fb20d97,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-a93e227e-baf0-458b-88eb-92025a07a53e,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-680a03d2-23ff-4136-8099-1aaedb2e770b,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-189ee576-5f1a-42c5-a700-02225d21333d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032976257-172.17.0.7-1598345297982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42694,DS-88c50e28-0ac3-491b-9765-7191df307da2,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-49d8a5b3-890d-442f-8149-67c954a689d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-fdd5cd04-5ab8-4223-9ff5-eadab5b3cd41,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-f02bfa94-7993-42ae-8bb4-9551bb241916,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-4863f0c8-2928-4156-90dc-4c6f31c3bdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-86eb4c9a-8a99-426e-a667-d80e1afea211,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-ce6a974e-1d7b-4cb6-ac19-1d39ba123860,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-7f306ebc-e147-45f3-b661-fec1614b9fe0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032976257-172.17.0.7-1598345297982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42694,DS-88c50e28-0ac3-491b-9765-7191df307da2,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-49d8a5b3-890d-442f-8149-67c954a689d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-fdd5cd04-5ab8-4223-9ff5-eadab5b3cd41,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-f02bfa94-7993-42ae-8bb4-9551bb241916,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-4863f0c8-2928-4156-90dc-4c6f31c3bdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-86eb4c9a-8a99-426e-a667-d80e1afea211,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-ce6a974e-1d7b-4cb6-ac19-1d39ba123860,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-7f306ebc-e147-45f3-b661-fec1614b9fe0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473166065-172.17.0.7-1598345487753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36308,DS-77fe6c7a-888a-4394-a175-877c01faaeed,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-75d15571-5db5-4a7c-be75-f9e9d19a084c,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-f34f5e0a-1ea4-4a19-b98f-7ad41d628944,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-35adfb50-5c1a-40ca-92da-2e7683f48ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-a8d5ffc6-2b23-4702-9ac3-dcc930cdb2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-4ba68b15-cafd-48bf-b24d-8f1e4779393d,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-6426fd2f-0a5a-4d8d-a4d5-a88ee2e09ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-a47feb71-06bf-453c-aa28-f99965bc65f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473166065-172.17.0.7-1598345487753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36308,DS-77fe6c7a-888a-4394-a175-877c01faaeed,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-75d15571-5db5-4a7c-be75-f9e9d19a084c,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-f34f5e0a-1ea4-4a19-b98f-7ad41d628944,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-35adfb50-5c1a-40ca-92da-2e7683f48ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-a8d5ffc6-2b23-4702-9ac3-dcc930cdb2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-4ba68b15-cafd-48bf-b24d-8f1e4779393d,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-6426fd2f-0a5a-4d8d-a4d5-a88ee2e09ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-a47feb71-06bf-453c-aa28-f99965bc65f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568261781-172.17.0.7-1598345661926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46864,DS-98d4bb61-bf6f-47cf-af94-5defb46c4ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-07980225-4171-47e9-bf0d-8d2e103e95d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-0f0fcf15-b74f-4485-8d89-1b458f76a293,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-83c36c0e-421a-4e98-b09b-6a482479574c,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-031c7181-e27e-4045-a292-790b8b92b2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-11254116-19ea-4a6c-ae23-03ece900e6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-538c8e49-9e25-4200-8e00-52e289156dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-f04e8a24-c850-4ed7-a5e7-67060d469e7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568261781-172.17.0.7-1598345661926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46864,DS-98d4bb61-bf6f-47cf-af94-5defb46c4ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-07980225-4171-47e9-bf0d-8d2e103e95d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-0f0fcf15-b74f-4485-8d89-1b458f76a293,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-83c36c0e-421a-4e98-b09b-6a482479574c,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-031c7181-e27e-4045-a292-790b8b92b2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-11254116-19ea-4a6c-ae23-03ece900e6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-538c8e49-9e25-4200-8e00-52e289156dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-f04e8a24-c850-4ed7-a5e7-67060d469e7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-588479473-172.17.0.7-1598345848433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41748,DS-6dda1f73-d0f7-499e-a68b-72c7b4295f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-b57b5950-3498-4675-bccb-7c1453d54a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-d1271ef6-41e7-41ab-a162-3e7cddcce70b,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-a92f6d3c-35b8-480b-bf9a-c79bc785e1db,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-a07a6f0e-44c6-4b17-8956-39dcbb940a82,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-4df39fa5-d586-4b4b-8302-13d56589cd05,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-aaec6ade-ae75-4951-9223-5b5c997bd43b,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-7e1e8bb1-7f45-4f0f-a4c9-8281fb9c906c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-588479473-172.17.0.7-1598345848433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41748,DS-6dda1f73-d0f7-499e-a68b-72c7b4295f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-b57b5950-3498-4675-bccb-7c1453d54a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-d1271ef6-41e7-41ab-a162-3e7cddcce70b,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-a92f6d3c-35b8-480b-bf9a-c79bc785e1db,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-a07a6f0e-44c6-4b17-8956-39dcbb940a82,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-4df39fa5-d586-4b4b-8302-13d56589cd05,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-aaec6ade-ae75-4951-9223-5b5c997bd43b,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-7e1e8bb1-7f45-4f0f-a4c9-8281fb9c906c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510125223-172.17.0.7-1598346126057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39105,DS-b18f5104-51fd-4ac7-bf8e-66aa6771013c,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-ea79c202-8f6c-40b8-8da9-81645ff6c323,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-b026c104-5c91-4474-acd0-a46a9ffe8794,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-b64e0143-db6d-4e0a-a7bd-f5e38443a45f,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-7ef26375-340b-4bb4-b8ec-987c08d5ecd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-4b3d3b07-2e98-47a0-8469-ff933aa286a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-fb696c41-0944-4d0f-95b4-1adfb3e92687,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-2aed1d13-9ddb-4f8a-a7cd-5a7ae9736a90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510125223-172.17.0.7-1598346126057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39105,DS-b18f5104-51fd-4ac7-bf8e-66aa6771013c,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-ea79c202-8f6c-40b8-8da9-81645ff6c323,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-b026c104-5c91-4474-acd0-a46a9ffe8794,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-b64e0143-db6d-4e0a-a7bd-f5e38443a45f,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-7ef26375-340b-4bb4-b8ec-987c08d5ecd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-4b3d3b07-2e98-47a0-8469-ff933aa286a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-fb696c41-0944-4d0f-95b4-1adfb3e92687,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-2aed1d13-9ddb-4f8a-a7cd-5a7ae9736a90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364044044-172.17.0.7-1598346305775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34311,DS-0f2e258f-0674-412b-ab68-e25b62cccee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-a77f3ef2-abe2-4473-99ae-a2c933f7308d,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-95031a7d-477d-4b48-bc98-8d818305fb11,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-82402f31-1ee3-410b-a08a-d909f7c0eae0,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-c5ae564a-dd9d-47b4-bd1b-be753c1dfaab,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-3b4fec25-b4b0-4b52-8c2e-14817d8db549,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-002ba02f-19fc-462b-8e56-4a31fb651571,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-89180499-0e91-48af-af9e-13c2150c2357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364044044-172.17.0.7-1598346305775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34311,DS-0f2e258f-0674-412b-ab68-e25b62cccee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-a77f3ef2-abe2-4473-99ae-a2c933f7308d,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-95031a7d-477d-4b48-bc98-8d818305fb11,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-82402f31-1ee3-410b-a08a-d909f7c0eae0,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-c5ae564a-dd9d-47b4-bd1b-be753c1dfaab,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-3b4fec25-b4b0-4b52-8c2e-14817d8db549,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-002ba02f-19fc-462b-8e56-4a31fb651571,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-89180499-0e91-48af-af9e-13c2150c2357,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388249963-172.17.0.7-1598346444877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38900,DS-db438388-cb8a-497f-8c0d-a8ce4a318520,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-62cdf516-04c3-45d1-bdfa-d5a53b08807a,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-ac6f4c4e-28b7-4000-a4cb-77f7c3e097cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-ed8a06f1-6271-4d67-a0a7-2c601f98bbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-0f99f443-f091-418a-b76c-5fa32357ece3,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-7d679aa4-28ca-45a0-8ab4-33b05fd7b920,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-0f5db12b-70f2-4d01-b5c3-372b3b0cac0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-4aeadba9-726f-4cee-9d0d-30cdae8faa98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388249963-172.17.0.7-1598346444877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38900,DS-db438388-cb8a-497f-8c0d-a8ce4a318520,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-62cdf516-04c3-45d1-bdfa-d5a53b08807a,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-ac6f4c4e-28b7-4000-a4cb-77f7c3e097cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-ed8a06f1-6271-4d67-a0a7-2c601f98bbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-0f99f443-f091-418a-b76c-5fa32357ece3,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-7d679aa4-28ca-45a0-8ab4-33b05fd7b920,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-0f5db12b-70f2-4d01-b5c3-372b3b0cac0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-4aeadba9-726f-4cee-9d0d-30cdae8faa98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792032596-172.17.0.7-1598346590832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44184,DS-0d3b2bc9-8a07-46e3-a4fe-4641f23cd31e,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-8e59bce1-2443-44fc-94f9-55a1ddb2daad,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-da50383b-9e44-4ac9-9d50-f1c2aadb1395,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-08ffcf93-6e82-4127-85cd-d6bceb2082d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-63639e03-742f-4a95-90f2-53ee0ba114bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-364d7d99-4284-43d5-b888-fabaa8fdd8be,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-d2ac2d08-9354-42fd-8f2c-16cfb42abe22,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-bcfe3a1b-3a97-4c01-a064-9a2ad95be874,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792032596-172.17.0.7-1598346590832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44184,DS-0d3b2bc9-8a07-46e3-a4fe-4641f23cd31e,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-8e59bce1-2443-44fc-94f9-55a1ddb2daad,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-da50383b-9e44-4ac9-9d50-f1c2aadb1395,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-08ffcf93-6e82-4127-85cd-d6bceb2082d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-63639e03-742f-4a95-90f2-53ee0ba114bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-364d7d99-4284-43d5-b888-fabaa8fdd8be,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-d2ac2d08-9354-42fd-8f2c-16cfb42abe22,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-bcfe3a1b-3a97-4c01-a064-9a2ad95be874,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191884816-172.17.0.7-1598346629338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34227,DS-c95c157e-953a-4dc7-a180-d8b13d801bae,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-df678bb2-ae5b-45df-b19c-6e4b60af7a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-6736446f-72c3-4357-bd7f-0658b61f9c15,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-15a08f92-3c8b-4ac1-8d11-b96bce1589ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-3043aa49-801e-46ec-84ce-ae8c7723c6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-e56c940f-c37f-49ed-8126-b65f7063df11,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-2e52ea6e-5322-4666-b07a-5a49547b6c66,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-83a8f684-5732-4502-99c5-6e3f8d7e5503,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191884816-172.17.0.7-1598346629338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34227,DS-c95c157e-953a-4dc7-a180-d8b13d801bae,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-df678bb2-ae5b-45df-b19c-6e4b60af7a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-6736446f-72c3-4357-bd7f-0658b61f9c15,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-15a08f92-3c8b-4ac1-8d11-b96bce1589ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-3043aa49-801e-46ec-84ce-ae8c7723c6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-e56c940f-c37f-49ed-8126-b65f7063df11,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-2e52ea6e-5322-4666-b07a-5a49547b6c66,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-83a8f684-5732-4502-99c5-6e3f8d7e5503,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842787276-172.17.0.7-1598346705541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35889,DS-f69fc21e-5834-4435-9a6f-a7b5e72ebd72,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-fd63e179-9d1e-44e5-904a-29f25f00d5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-f6698865-e423-4578-8452-c7d0a706eb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-dda3fef3-b52d-43aa-bbd2-2398aae8f9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-8b365a41-4eb3-40b7-8d1a-0962b4986d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-b6ed490e-cdfa-4615-bc56-840744e4442f,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-659cd0e8-809e-4f07-afe1-2c6108ac53b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-7dbe525e-8019-4690-bc78-066b54d17693,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842787276-172.17.0.7-1598346705541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35889,DS-f69fc21e-5834-4435-9a6f-a7b5e72ebd72,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-fd63e179-9d1e-44e5-904a-29f25f00d5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-f6698865-e423-4578-8452-c7d0a706eb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-dda3fef3-b52d-43aa-bbd2-2398aae8f9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-8b365a41-4eb3-40b7-8d1a-0962b4986d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-b6ed490e-cdfa-4615-bc56-840744e4442f,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-659cd0e8-809e-4f07-afe1-2c6108ac53b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-7dbe525e-8019-4690-bc78-066b54d17693,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328602077-172.17.0.7-1598346742857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43811,DS-79145897-6d0f-407c-9583-b3ef309b1a39,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-5d8775e2-5d46-4768-b0fb-cd07eb718c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-79c6345d-7e3b-42ea-947b-3af0b8bb062d,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-3c1ce7f7-9cc6-4c1c-8464-3e52dbc790ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-377c2438-9dc8-4e49-a6b3-2120f975c792,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-9b0937ab-79a9-46b9-be2e-3fa1455340bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-302e82f5-a130-493c-a79b-a99ae67329db,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-7d54c033-28c2-4821-8e67-f0ecb9123c2a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328602077-172.17.0.7-1598346742857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43811,DS-79145897-6d0f-407c-9583-b3ef309b1a39,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-5d8775e2-5d46-4768-b0fb-cd07eb718c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-79c6345d-7e3b-42ea-947b-3af0b8bb062d,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-3c1ce7f7-9cc6-4c1c-8464-3e52dbc790ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-377c2438-9dc8-4e49-a6b3-2120f975c792,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-9b0937ab-79a9-46b9-be2e-3fa1455340bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-302e82f5-a130-493c-a79b-a99ae67329db,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-7d54c033-28c2-4821-8e67-f0ecb9123c2a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718482649-172.17.0.7-1598346873619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37854,DS-0797a0f6-0728-4e6f-9cdb-4b27644d3de2,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-eb447506-31dc-47e2-bc97-5d9de407242c,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-b7b43651-cbb6-4949-b7d8-650378760b58,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-e3dc1fee-468d-4871-a1f2-d80c1477279e,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-a1103eeb-46d4-4a13-9e75-6279147797fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-e61102e9-6757-4495-8c9c-9b38e968508c,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-123b4bad-3327-40be-8390-cec6b3e4fff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-4f1f45b1-8466-4d74-a525-73d3cc966c5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718482649-172.17.0.7-1598346873619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37854,DS-0797a0f6-0728-4e6f-9cdb-4b27644d3de2,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-eb447506-31dc-47e2-bc97-5d9de407242c,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-b7b43651-cbb6-4949-b7d8-650378760b58,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-e3dc1fee-468d-4871-a1f2-d80c1477279e,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-a1103eeb-46d4-4a13-9e75-6279147797fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-e61102e9-6757-4495-8c9c-9b38e968508c,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-123b4bad-3327-40be-8390-cec6b3e4fff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-4f1f45b1-8466-4d74-a525-73d3cc966c5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344747738-172.17.0.7-1598347131331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33091,DS-15a7e964-220a-4095-9e80-5adadadaeae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-b4f8f212-1bf3-4973-9051-f8798ec3bfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-6f1a3f25-a469-4f61-9dbd-345302a01968,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-28b42e2a-cb0e-42e3-982c-665e2b584aae,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-ac676658-0d76-4de8-bf72-bf62dee651c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-f8dc4ae9-6b7b-4d14-aa9f-64b9d988b96c,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-231283a3-91f7-4197-8eea-4f4e14d79015,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-5bf321c1-e963-4f6a-8d71-5efb6f3a21a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344747738-172.17.0.7-1598347131331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33091,DS-15a7e964-220a-4095-9e80-5adadadaeae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-b4f8f212-1bf3-4973-9051-f8798ec3bfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-6f1a3f25-a469-4f61-9dbd-345302a01968,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-28b42e2a-cb0e-42e3-982c-665e2b584aae,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-ac676658-0d76-4de8-bf72-bf62dee651c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-f8dc4ae9-6b7b-4d14-aa9f-64b9d988b96c,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-231283a3-91f7-4197-8eea-4f4e14d79015,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-5bf321c1-e963-4f6a-8d71-5efb6f3a21a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106330785-172.17.0.7-1598347164187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46403,DS-2ac189d2-cccd-47fc-8320-50ac90709ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-3225b0ec-18e3-4d38-b900-ff317a389e65,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-6cd70509-a22d-4702-abae-ad583fadbc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-baae8528-2889-4d0b-917b-bb4ff4050b52,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-c4a87b1f-bba0-485e-ace5-a8524556dc69,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-a76f3637-664b-4529-a83f-f8b4fcbff677,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-6556070d-f690-410e-9fdd-96987cbf8e35,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-9328ec4c-700d-4d06-a87e-59082c2bb9a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106330785-172.17.0.7-1598347164187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46403,DS-2ac189d2-cccd-47fc-8320-50ac90709ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-3225b0ec-18e3-4d38-b900-ff317a389e65,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-6cd70509-a22d-4702-abae-ad583fadbc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-baae8528-2889-4d0b-917b-bb4ff4050b52,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-c4a87b1f-bba0-485e-ace5-a8524556dc69,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-a76f3637-664b-4529-a83f-f8b4fcbff677,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-6556070d-f690-410e-9fdd-96987cbf8e35,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-9328ec4c-700d-4d06-a87e-59082c2bb9a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630637672-172.17.0.7-1598347618697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45139,DS-c6c6ecd3-9572-4c52-b208-2e38a32f9a33,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-4f5628c8-835f-4308-9720-082dc5f50924,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-fb5fa1ca-c5ed-4bef-b3d9-cb9111d7f8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-015b130e-81ed-44aa-b698-4d67b2c47342,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-18f10666-130c-4bbc-9d46-627353d3779f,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-b874a39d-d044-42a7-979d-d3d29b514f33,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-82af55d5-1f7c-46db-a206-a9790a67bc42,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-0ec6e595-f0f9-4336-a5a1-69cb3e04d272,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630637672-172.17.0.7-1598347618697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45139,DS-c6c6ecd3-9572-4c52-b208-2e38a32f9a33,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-4f5628c8-835f-4308-9720-082dc5f50924,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-fb5fa1ca-c5ed-4bef-b3d9-cb9111d7f8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-015b130e-81ed-44aa-b698-4d67b2c47342,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-18f10666-130c-4bbc-9d46-627353d3779f,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-b874a39d-d044-42a7-979d-d3d29b514f33,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-82af55d5-1f7c-46db-a206-a9790a67bc42,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-0ec6e595-f0f9-4336-a5a1-69cb3e04d272,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773438337-172.17.0.7-1598347802378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44954,DS-6193323c-fb56-4fe3-9774-bee7c7bed294,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-6299efa1-d1be-4d40-80c7-3dc3b34321de,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-8bc5a73d-7ef7-4923-a4ff-eae583782974,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-4f5f7424-9a33-4ffd-886a-1fcc8fef7603,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-24f5f089-1c0f-473d-9995-d2b010a19010,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-b05cc0ae-baab-4557-8142-54071eb6388e,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-dce1ab63-40d9-4a79-b690-bd3f96fc7690,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-188ea791-6054-48b0-9cc5-3ae49ea8f01c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773438337-172.17.0.7-1598347802378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44954,DS-6193323c-fb56-4fe3-9774-bee7c7bed294,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-6299efa1-d1be-4d40-80c7-3dc3b34321de,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-8bc5a73d-7ef7-4923-a4ff-eae583782974,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-4f5f7424-9a33-4ffd-886a-1fcc8fef7603,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-24f5f089-1c0f-473d-9995-d2b010a19010,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-b05cc0ae-baab-4557-8142-54071eb6388e,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-dce1ab63-40d9-4a79-b690-bd3f96fc7690,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-188ea791-6054-48b0-9cc5-3ae49ea8f01c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318384980-172.17.0.7-1598347956516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45415,DS-0b0fc7b1-ec46-49ae-8286-d0522de127f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-dd499cae-f00e-4fce-82b5-3a8b492c7271,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-a7b9d950-636f-471e-8812-44cc153a2bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-cfb367e0-a5f8-4a50-b00f-3d8182d2b2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-cb96d2f9-2188-46eb-8702-d61fbe59e93c,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-e276657d-1782-4de4-8d6d-af42ebd5f2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-bdbd70c2-0c81-40af-b71e-b4f63ab7d346,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-2bb82b3f-95d8-4950-a852-5591305cae9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318384980-172.17.0.7-1598347956516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45415,DS-0b0fc7b1-ec46-49ae-8286-d0522de127f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-dd499cae-f00e-4fce-82b5-3a8b492c7271,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-a7b9d950-636f-471e-8812-44cc153a2bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-cfb367e0-a5f8-4a50-b00f-3d8182d2b2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-cb96d2f9-2188-46eb-8702-d61fbe59e93c,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-e276657d-1782-4de4-8d6d-af42ebd5f2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-bdbd70c2-0c81-40af-b71e-b4f63ab7d346,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-2bb82b3f-95d8-4950-a852-5591305cae9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1780424624-172.17.0.7-1598348140059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37495,DS-f28bf63f-23b0-4b71-91a1-7b316ec2b3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-a5fd3337-6aa0-45ec-8b25-39eba6d0b14a,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-14486379-bd6e-4b5f-911a-9fde97e7cd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-76891362-0258-4f98-a78c-9082a8573617,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-09a585f7-e94f-40a8-8104-042b388c826a,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-14d694f4-0208-4f25-bf00-0c48104891c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-d066db7e-35df-4713-b50e-e898cbf9f9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-d2ea9fb4-b402-4051-860f-b3618c714838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1780424624-172.17.0.7-1598348140059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37495,DS-f28bf63f-23b0-4b71-91a1-7b316ec2b3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-a5fd3337-6aa0-45ec-8b25-39eba6d0b14a,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-14486379-bd6e-4b5f-911a-9fde97e7cd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-76891362-0258-4f98-a78c-9082a8573617,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-09a585f7-e94f-40a8-8104-042b388c826a,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-14d694f4-0208-4f25-bf00-0c48104891c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-d066db7e-35df-4713-b50e-e898cbf9f9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-d2ea9fb4-b402-4051-860f-b3618c714838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913044552-172.17.0.7-1598348254970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45337,DS-3d0e4f81-88ba-47b0-99d5-22ba069f0e84,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-7196a8cb-c780-404d-b28a-049680e54bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-f573034a-8fea-4daa-bb87-d0769a5fc2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-03e473fe-7e98-4720-9f57-72ad5fffb459,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-3e351deb-5c56-4112-b3c7-24d3f3d39232,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-eb80aabb-ae23-4964-9d91-94263f77c5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-c7a8f68f-2f7d-45d7-b914-818ef37e3250,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-c93b2330-16d0-4626-ae92-0ab4f25d7469,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913044552-172.17.0.7-1598348254970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45337,DS-3d0e4f81-88ba-47b0-99d5-22ba069f0e84,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-7196a8cb-c780-404d-b28a-049680e54bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-f573034a-8fea-4daa-bb87-d0769a5fc2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-03e473fe-7e98-4720-9f57-72ad5fffb459,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-3e351deb-5c56-4112-b3c7-24d3f3d39232,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-eb80aabb-ae23-4964-9d91-94263f77c5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-c7a8f68f-2f7d-45d7-b914-818ef37e3250,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-c93b2330-16d0-4626-ae92-0ab4f25d7469,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5409
