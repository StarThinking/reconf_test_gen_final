reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170029265-172.17.0.18-1598151279747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39054,DS-4df09c97-0355-4a9b-8875-3275a7373f45,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-016658f1-c3ad-466b-b279-c3adc7b39c71,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-4ff6b857-72f5-496c-b1ea-592ab36a8545,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-f5e627f3-18f5-48ff-8874-1e3143e3de97,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-95bc13e8-ee12-40df-bcaa-c67660b31290,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-7a158361-f30e-4ffe-a21b-cb038e9a843b,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-4a2b1c59-ff9f-4da8-a6b0-b3ac86db9165,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-af423683-4ed2-4aa5-9d2d-65202d616d0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170029265-172.17.0.18-1598151279747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39054,DS-4df09c97-0355-4a9b-8875-3275a7373f45,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-016658f1-c3ad-466b-b279-c3adc7b39c71,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-4ff6b857-72f5-496c-b1ea-592ab36a8545,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-f5e627f3-18f5-48ff-8874-1e3143e3de97,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-95bc13e8-ee12-40df-bcaa-c67660b31290,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-7a158361-f30e-4ffe-a21b-cb038e9a843b,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-4a2b1c59-ff9f-4da8-a6b0-b3ac86db9165,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-af423683-4ed2-4aa5-9d2d-65202d616d0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907608714-172.17.0.18-1598151691133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40265,DS-519f582b-193f-41b9-9af2-32437e880dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-1f4c0898-3665-4be9-bfb6-542bbd85aa84,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-a587dae7-ffcf-4e97-9fe5-542915bc616e,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-f9fc01e4-f376-4eb5-92df-257660424b21,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-440176c0-b68b-4e37-b1b8-d6f9ac1321ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-8a00a026-acd2-4787-aa73-e54042480af8,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-fb75a538-b9c4-4268-baae-d9c2b8719b86,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-1545b8a8-4876-439b-afc3-e70d070deb18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907608714-172.17.0.18-1598151691133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40265,DS-519f582b-193f-41b9-9af2-32437e880dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-1f4c0898-3665-4be9-bfb6-542bbd85aa84,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-a587dae7-ffcf-4e97-9fe5-542915bc616e,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-f9fc01e4-f376-4eb5-92df-257660424b21,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-440176c0-b68b-4e37-b1b8-d6f9ac1321ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-8a00a026-acd2-4787-aa73-e54042480af8,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-fb75a538-b9c4-4268-baae-d9c2b8719b86,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-1545b8a8-4876-439b-afc3-e70d070deb18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2015529827-172.17.0.18-1598151798132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41227,DS-59e2f788-3c70-4fd5-8285-29c621067351,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-e8cc0e27-8001-430d-96e9-c9dbcf7991e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-8c60ff60-0389-48d5-bf09-a1eec23258d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-9aeaaaa8-05d1-4848-a24a-e68e453f8707,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-4d2856dc-ca07-4de8-b700-e904395ef2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-82d99ce0-ed03-469c-bdfc-8b0207e3e8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-48140f0c-0ad2-4f42-8290-c1b0d0ceda49,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-c5509038-af0d-4dcb-a53f-ff80bf936bc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2015529827-172.17.0.18-1598151798132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41227,DS-59e2f788-3c70-4fd5-8285-29c621067351,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-e8cc0e27-8001-430d-96e9-c9dbcf7991e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-8c60ff60-0389-48d5-bf09-a1eec23258d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-9aeaaaa8-05d1-4848-a24a-e68e453f8707,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-4d2856dc-ca07-4de8-b700-e904395ef2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-82d99ce0-ed03-469c-bdfc-8b0207e3e8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-48140f0c-0ad2-4f42-8290-c1b0d0ceda49,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-c5509038-af0d-4dcb-a53f-ff80bf936bc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-300457801-172.17.0.18-1598151949742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35363,DS-81046395-f524-491f-beaa-e4c4ade8486f,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-234532d6-15f5-4c4a-9603-19c2c738a3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-6a06aaa8-f77e-4fbc-81f0-5c11a7af3127,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-b2faf7cd-d44d-4c3e-a76b-d68f03fd1f86,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-fc6c3a38-e1dd-4f0d-b5a9-72726ca467a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-83231632-eada-4ece-91a4-dd05cc78351c,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-522e85b4-9989-45af-9dc1-6f01d39009f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-2750e65e-ae2b-437a-b9ea-1a605a257449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-300457801-172.17.0.18-1598151949742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35363,DS-81046395-f524-491f-beaa-e4c4ade8486f,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-234532d6-15f5-4c4a-9603-19c2c738a3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-6a06aaa8-f77e-4fbc-81f0-5c11a7af3127,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-b2faf7cd-d44d-4c3e-a76b-d68f03fd1f86,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-fc6c3a38-e1dd-4f0d-b5a9-72726ca467a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-83231632-eada-4ece-91a4-dd05cc78351c,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-522e85b4-9989-45af-9dc1-6f01d39009f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-2750e65e-ae2b-437a-b9ea-1a605a257449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-886971418-172.17.0.18-1598151992991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38461,DS-d950d6ef-09e7-4354-bb08-79dd889b51c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-6061f9d1-1b65-4307-97bc-0b33214984b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-c376edfa-23e4-4836-a692-82d04035d127,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-4515b3d8-5df2-4351-8648-3b30e1519b57,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-975222ef-7bc5-4738-8df7-47aa0bf0cd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-1d16d64d-649a-4212-a9d9-7fdcbab4066c,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-115c0dac-c73d-4654-af11-b69bd0fd8bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-a3dfb6eb-8b61-4f3d-938b-9f82b7d401eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-886971418-172.17.0.18-1598151992991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38461,DS-d950d6ef-09e7-4354-bb08-79dd889b51c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-6061f9d1-1b65-4307-97bc-0b33214984b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-c376edfa-23e4-4836-a692-82d04035d127,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-4515b3d8-5df2-4351-8648-3b30e1519b57,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-975222ef-7bc5-4738-8df7-47aa0bf0cd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-1d16d64d-649a-4212-a9d9-7fdcbab4066c,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-115c0dac-c73d-4654-af11-b69bd0fd8bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-a3dfb6eb-8b61-4f3d-938b-9f82b7d401eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1684015764-172.17.0.18-1598152169597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43869,DS-b135f699-f9cd-4307-9c6e-8df6bed0035b,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-1fc51012-a46d-49de-b620-8fcb7d49ebe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-cdb139a7-1535-463b-b90d-37f894947029,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-feb19427-1bea-4db8-837e-1afa940fee02,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-7a85c7d7-c154-43d0-9b98-097505ef8d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-9ee28cbd-dc71-418b-bb63-f7d2f32e8d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-a8fd3efe-81b1-4b71-8426-d4ea4e5769ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-2c723f1e-041f-4a36-9786-3e17ffea7896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1684015764-172.17.0.18-1598152169597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43869,DS-b135f699-f9cd-4307-9c6e-8df6bed0035b,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-1fc51012-a46d-49de-b620-8fcb7d49ebe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-cdb139a7-1535-463b-b90d-37f894947029,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-feb19427-1bea-4db8-837e-1afa940fee02,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-7a85c7d7-c154-43d0-9b98-097505ef8d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-9ee28cbd-dc71-418b-bb63-f7d2f32e8d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-a8fd3efe-81b1-4b71-8426-d4ea4e5769ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-2c723f1e-041f-4a36-9786-3e17ffea7896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-149400535-172.17.0.18-1598152880646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33117,DS-185e0e38-aaa8-4e07-8560-1bffdda1eca7,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-849a6cf5-4db2-473f-84b8-4ba0c9617cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-6d7a94c2-281d-4348-a492-ba98535c6dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-06acb348-88c5-411c-9e40-a59df042f439,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-e4009b05-a07c-49bc-8aae-40259c1b1c74,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-67e2dcad-607c-462f-9d0c-622248148aad,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-b1df47c8-0cbc-443e-b642-e99f2b72c07a,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-70bf0649-8f14-4f71-a8c4-004f67f4a7ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-149400535-172.17.0.18-1598152880646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33117,DS-185e0e38-aaa8-4e07-8560-1bffdda1eca7,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-849a6cf5-4db2-473f-84b8-4ba0c9617cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-6d7a94c2-281d-4348-a492-ba98535c6dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-06acb348-88c5-411c-9e40-a59df042f439,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-e4009b05-a07c-49bc-8aae-40259c1b1c74,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-67e2dcad-607c-462f-9d0c-622248148aad,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-b1df47c8-0cbc-443e-b642-e99f2b72c07a,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-70bf0649-8f14-4f71-a8c4-004f67f4a7ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690138027-172.17.0.18-1598153384817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45861,DS-ddcc5c50-c20c-45e4-95f9-f8d56278a7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-a152961f-ef55-43f5-affd-5c315453073b,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-788b4ba2-3a7f-4764-8116-69b5690ff650,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-d6d9d4c1-4e40-4035-9898-1cbf4a899257,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-a586da1d-d213-43b2-8177-6803cdbc6de5,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-c43dae7a-9ff3-4f98-aae6-500d33c0a3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-f921e832-2ed5-4642-b322-95da402bb828,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-bb72783e-bffc-45b6-a995-5ec13d698ee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690138027-172.17.0.18-1598153384817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45861,DS-ddcc5c50-c20c-45e4-95f9-f8d56278a7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-a152961f-ef55-43f5-affd-5c315453073b,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-788b4ba2-3a7f-4764-8116-69b5690ff650,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-d6d9d4c1-4e40-4035-9898-1cbf4a899257,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-a586da1d-d213-43b2-8177-6803cdbc6de5,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-c43dae7a-9ff3-4f98-aae6-500d33c0a3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-f921e832-2ed5-4642-b322-95da402bb828,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-bb72783e-bffc-45b6-a995-5ec13d698ee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698674518-172.17.0.18-1598153656501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39448,DS-fbfe5e3a-2feb-4995-b137-22215af830bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-148b40fd-62a6-4f1c-83ea-c8d069da9739,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-8fd810ca-c679-48cf-b8b7-4c1584adff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-f01d0bb0-88c7-404e-9ee7-38d3789324de,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-fa9affcf-d581-461e-b7fb-7dbd9be245a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-675e298e-af88-4f05-b45e-13d98e549c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-5661ffd2-e1f8-4ecc-b22c-e75cc33eb5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-f0a490fc-b7ee-4b76-9b35-bacd2088de42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698674518-172.17.0.18-1598153656501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39448,DS-fbfe5e3a-2feb-4995-b137-22215af830bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-148b40fd-62a6-4f1c-83ea-c8d069da9739,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-8fd810ca-c679-48cf-b8b7-4c1584adff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-f01d0bb0-88c7-404e-9ee7-38d3789324de,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-fa9affcf-d581-461e-b7fb-7dbd9be245a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-675e298e-af88-4f05-b45e-13d98e549c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-5661ffd2-e1f8-4ecc-b22c-e75cc33eb5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-f0a490fc-b7ee-4b76-9b35-bacd2088de42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1509254541-172.17.0.18-1598153829214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46262,DS-8605f660-5d07-402d-a130-3895bdbac8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-10f4f617-487c-4944-aee7-ab5a4bfb5923,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-5835934c-e74c-4207-a966-99a9c84b0931,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-939509ff-0f5a-411a-af5a-094a13bbf839,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-b3afbb46-662f-4aec-b38f-1881a5337a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-4aeb02e3-3fa2-4f00-8719-36311f4b5d13,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-e3639a18-0548-4fd5-b96c-d49ff35186b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-1da515c4-558d-4ff1-b8a6-279771bce50d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1509254541-172.17.0.18-1598153829214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46262,DS-8605f660-5d07-402d-a130-3895bdbac8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-10f4f617-487c-4944-aee7-ab5a4bfb5923,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-5835934c-e74c-4207-a966-99a9c84b0931,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-939509ff-0f5a-411a-af5a-094a13bbf839,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-b3afbb46-662f-4aec-b38f-1881a5337a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-4aeb02e3-3fa2-4f00-8719-36311f4b5d13,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-e3639a18-0548-4fd5-b96c-d49ff35186b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-1da515c4-558d-4ff1-b8a6-279771bce50d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-297316979-172.17.0.18-1598153954864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45500,DS-693ce266-1623-44a9-8283-f1d3f3af692d,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-70ca498c-d7f0-45b9-840b-7ae6d5f3734a,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-465bf8a2-8ca3-4738-b7d9-35d787268cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-fd557167-aa20-4d1b-94cd-a10b72918300,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-62df0367-e4e6-4638-a6f2-7647eab16384,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-fbbca3f4-c2de-40f7-a6d7-2333d737a6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-fcd757bf-7c93-47e5-baac-ec058ae1fee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-254d2752-9dd7-4a80-8778-23169db545ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-297316979-172.17.0.18-1598153954864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45500,DS-693ce266-1623-44a9-8283-f1d3f3af692d,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-70ca498c-d7f0-45b9-840b-7ae6d5f3734a,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-465bf8a2-8ca3-4738-b7d9-35d787268cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-fd557167-aa20-4d1b-94cd-a10b72918300,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-62df0367-e4e6-4638-a6f2-7647eab16384,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-fbbca3f4-c2de-40f7-a6d7-2333d737a6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-fcd757bf-7c93-47e5-baac-ec058ae1fee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-254d2752-9dd7-4a80-8778-23169db545ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143034048-172.17.0.18-1598153984405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-f68b824b-fb7a-417c-96a7-ab0253223c23,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-84cfb60d-a284-456b-9864-dc6503fe70ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-4411b302-c19a-4b0f-a973-9a9aa69e971d,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-33a41998-4550-423f-b110-9428c2ed677c,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-a8ed7bd1-1a3a-4220-8d7c-157ea8adf0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-af66bc83-59ab-47db-92d5-650ded273275,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-f85fd1b2-bc9d-4799-8e18-58d11cb0d396,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-2d5df8cf-7127-4506-8e82-9b84c45f5094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143034048-172.17.0.18-1598153984405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-f68b824b-fb7a-417c-96a7-ab0253223c23,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-84cfb60d-a284-456b-9864-dc6503fe70ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-4411b302-c19a-4b0f-a973-9a9aa69e971d,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-33a41998-4550-423f-b110-9428c2ed677c,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-a8ed7bd1-1a3a-4220-8d7c-157ea8adf0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-af66bc83-59ab-47db-92d5-650ded273275,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-f85fd1b2-bc9d-4799-8e18-58d11cb0d396,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-2d5df8cf-7127-4506-8e82-9b84c45f5094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639945452-172.17.0.18-1598154077771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38319,DS-dffa5916-aa9d-481c-90b6-5357d710a280,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-5263639d-6a10-4c4d-b650-74d884e78b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-93a93979-5807-45b7-b8fc-f8f5f0b6b15a,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-f55cce0e-4260-4376-890c-9ae5d9ebbe68,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-df077506-be8e-4421-8772-7cb5d0fb7ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-4e6c7689-8279-486e-953e-1a1395d3fdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-02fb5d22-2f29-48ec-b382-3426e4dc1d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-41c52c37-35cb-4f6a-b1bf-afbee4086bc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639945452-172.17.0.18-1598154077771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38319,DS-dffa5916-aa9d-481c-90b6-5357d710a280,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-5263639d-6a10-4c4d-b650-74d884e78b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-93a93979-5807-45b7-b8fc-f8f5f0b6b15a,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-f55cce0e-4260-4376-890c-9ae5d9ebbe68,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-df077506-be8e-4421-8772-7cb5d0fb7ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-4e6c7689-8279-486e-953e-1a1395d3fdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-02fb5d22-2f29-48ec-b382-3426e4dc1d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-41c52c37-35cb-4f6a-b1bf-afbee4086bc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1376363275-172.17.0.18-1598154356254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38102,DS-35bf0572-f0fb-44ec-8296-bc6449c0b54e,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-d51eaefa-97b7-41f6-a3ff-8fc1bf599483,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-9c6fb35c-bf36-4885-8385-30901b80334d,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-2965a451-684a-4852-a3d2-237f8b96168e,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-cd2b66fd-8683-4037-9842-b5579180c1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-1a162573-0f67-44ad-adf5-cee093f94171,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-40a3e806-6c8a-4512-b5a3-2ac40c363f74,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-0f475f0e-bec9-40b8-abfd-d066af2b86c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1376363275-172.17.0.18-1598154356254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38102,DS-35bf0572-f0fb-44ec-8296-bc6449c0b54e,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-d51eaefa-97b7-41f6-a3ff-8fc1bf599483,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-9c6fb35c-bf36-4885-8385-30901b80334d,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-2965a451-684a-4852-a3d2-237f8b96168e,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-cd2b66fd-8683-4037-9842-b5579180c1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-1a162573-0f67-44ad-adf5-cee093f94171,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-40a3e806-6c8a-4512-b5a3-2ac40c363f74,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-0f475f0e-bec9-40b8-abfd-d066af2b86c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167722947-172.17.0.18-1598154498107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38189,DS-78b76737-8b30-48a1-889d-56a652478036,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-e6bf305c-1ad1-4cbd-b757-40ce521c7b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-1c8be5a5-d0f8-4d03-91c5-4e3147b434cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-01f10a30-cabf-4afc-a912-c7feddd455c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-827d159d-7d65-4411-ac95-c317e1e358f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-19e713ec-54b7-4a55-b9ec-c52989099293,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-88eb1f3b-59ce-47f3-a78e-85700daaa709,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-2c97c54d-965f-4694-aca8-ef607cc6bd8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167722947-172.17.0.18-1598154498107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38189,DS-78b76737-8b30-48a1-889d-56a652478036,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-e6bf305c-1ad1-4cbd-b757-40ce521c7b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-1c8be5a5-d0f8-4d03-91c5-4e3147b434cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-01f10a30-cabf-4afc-a912-c7feddd455c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-827d159d-7d65-4411-ac95-c317e1e358f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-19e713ec-54b7-4a55-b9ec-c52989099293,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-88eb1f3b-59ce-47f3-a78e-85700daaa709,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-2c97c54d-965f-4694-aca8-ef607cc6bd8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057614077-172.17.0.18-1598154612270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43196,DS-ff77a594-1ea6-49b9-a6be-a5f5d7fdfdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-97cd58b2-608f-468a-b4ff-5df19aca9128,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-42dc6fb9-76f7-4630-9431-0ca9fcdbf647,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-5ea05fc5-6d1c-4525-a926-6efd3a1b9d92,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-3af36058-350d-42fd-8594-ecbf1b8ed3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-59ad1302-e060-46d1-8de7-33d92f20de90,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-6bc4cbda-c941-4f8b-b9d7-7d7d1413bc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-f452c180-18c9-491d-ade2-1f0b9d559c5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057614077-172.17.0.18-1598154612270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43196,DS-ff77a594-1ea6-49b9-a6be-a5f5d7fdfdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-97cd58b2-608f-468a-b4ff-5df19aca9128,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-42dc6fb9-76f7-4630-9431-0ca9fcdbf647,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-5ea05fc5-6d1c-4525-a926-6efd3a1b9d92,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-3af36058-350d-42fd-8594-ecbf1b8ed3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-59ad1302-e060-46d1-8de7-33d92f20de90,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-6bc4cbda-c941-4f8b-b9d7-7d7d1413bc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-f452c180-18c9-491d-ade2-1f0b9d559c5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853296763-172.17.0.18-1598156209993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38233,DS-1f60de59-202b-45c9-9484-2f5816374e96,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-485de5fa-5c6c-4a3b-8cc6-98afe49d02cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-fe806c56-e5ce-47e3-b24b-d065aba2da0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-5ae7d8ac-ec51-43c5-b7e1-470894013d10,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-7325b167-1310-4e77-a6b3-92d5fe8c7fec,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-3a0ac122-e62a-4c5b-9365-350b89dba2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-a9c45dd4-e6b0-40eb-8f73-1f200d4833bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-3c19530e-816f-4bcb-b978-3e4414e70456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853296763-172.17.0.18-1598156209993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38233,DS-1f60de59-202b-45c9-9484-2f5816374e96,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-485de5fa-5c6c-4a3b-8cc6-98afe49d02cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-fe806c56-e5ce-47e3-b24b-d065aba2da0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-5ae7d8ac-ec51-43c5-b7e1-470894013d10,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-7325b167-1310-4e77-a6b3-92d5fe8c7fec,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-3a0ac122-e62a-4c5b-9365-350b89dba2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-a9c45dd4-e6b0-40eb-8f73-1f200d4833bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-3c19530e-816f-4bcb-b978-3e4414e70456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5211
