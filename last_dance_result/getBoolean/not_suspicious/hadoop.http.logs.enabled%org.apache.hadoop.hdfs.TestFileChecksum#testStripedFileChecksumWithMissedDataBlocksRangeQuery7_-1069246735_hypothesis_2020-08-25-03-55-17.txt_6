reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272189424-172.17.0.20-1598327977195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37226,DS-0fcac0d4-1c96-4e2b-8159-5bf295ff1723,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-6e5fc7ab-3a5a-41a6-b6ba-1ac1c23ede05,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-224eafb6-7224-4086-8a61-9d9d645ffa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-43d5c146-bb92-4fc9-b55c-33527c88b743,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-9b58ef30-31b3-4f59-b990-64f7c7129349,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-9e57601d-a8ad-44eb-98e9-401f30a39a26,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-7000b966-7151-4d95-8f76-be732671f7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-afa50f70-5547-4f47-a15b-f60e3a9dd68d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272189424-172.17.0.20-1598327977195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37226,DS-0fcac0d4-1c96-4e2b-8159-5bf295ff1723,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-6e5fc7ab-3a5a-41a6-b6ba-1ac1c23ede05,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-224eafb6-7224-4086-8a61-9d9d645ffa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-43d5c146-bb92-4fc9-b55c-33527c88b743,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-9b58ef30-31b3-4f59-b990-64f7c7129349,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-9e57601d-a8ad-44eb-98e9-401f30a39a26,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-7000b966-7151-4d95-8f76-be732671f7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-afa50f70-5547-4f47-a15b-f60e3a9dd68d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953489426-172.17.0.20-1598328132919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34671,DS-9fe31be1-10f0-4295-a8d1-0c4ce6891b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-9549f247-fdbe-4848-859c-f9d284d5bcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-13b95c7d-e041-4048-86b9-febfad332175,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-c99dc4d9-077b-47e9-a8aa-9dd0b126d91c,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-dee265d0-8900-4184-a2f9-ad83999b66a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-4cff4973-a8e5-43f8-8482-810e8ede0ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-e55a55f9-be84-4730-9654-fb30cd077b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-364f9226-fcf8-4e14-91e7-aebd63e472d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953489426-172.17.0.20-1598328132919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34671,DS-9fe31be1-10f0-4295-a8d1-0c4ce6891b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-9549f247-fdbe-4848-859c-f9d284d5bcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-13b95c7d-e041-4048-86b9-febfad332175,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-c99dc4d9-077b-47e9-a8aa-9dd0b126d91c,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-dee265d0-8900-4184-a2f9-ad83999b66a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-4cff4973-a8e5-43f8-8482-810e8ede0ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-e55a55f9-be84-4730-9654-fb30cd077b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-364f9226-fcf8-4e14-91e7-aebd63e472d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982073789-172.17.0.20-1598328162969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40167,DS-a4a13465-bcb2-4ac2-a1cd-fb96b94c4240,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-6d94dd0a-bc93-437c-b9fc-857f70795445,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-a193ee1a-3c9d-4365-bca1-813db55aefeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-8e57d0b8-6372-4970-bf92-3c3750eddf98,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-c74f4724-a265-4c7d-a8f2-0fb765ee15be,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-e6298f30-d40d-467a-a60d-9c5e267a3775,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-0027fef3-8d9f-427e-952e-e92ba3f22e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-e6064b8e-9f26-46ed-a956-e09339d4e297,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982073789-172.17.0.20-1598328162969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40167,DS-a4a13465-bcb2-4ac2-a1cd-fb96b94c4240,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-6d94dd0a-bc93-437c-b9fc-857f70795445,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-a193ee1a-3c9d-4365-bca1-813db55aefeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-8e57d0b8-6372-4970-bf92-3c3750eddf98,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-c74f4724-a265-4c7d-a8f2-0fb765ee15be,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-e6298f30-d40d-467a-a60d-9c5e267a3775,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-0027fef3-8d9f-427e-952e-e92ba3f22e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-e6064b8e-9f26-46ed-a956-e09339d4e297,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447937060-172.17.0.20-1598328390766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38020,DS-12019ce8-bd7c-4237-b88e-8613a25ebbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-79c10875-bb8b-43db-87bb-0bbb04b55d88,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-c3b1c77a-81be-4be5-8808-93a75d144fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-093dc1fb-0be8-4e3c-b1de-df57924444e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-c480146a-69ab-4174-a74e-ab8a97c84eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-fbe71c45-4d90-4ced-8359-74cf8b92bfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-032ee237-674f-476b-b168-81bdcec078fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-63a70a81-547c-4f68-a911-4d0c134dd9d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447937060-172.17.0.20-1598328390766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38020,DS-12019ce8-bd7c-4237-b88e-8613a25ebbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-79c10875-bb8b-43db-87bb-0bbb04b55d88,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-c3b1c77a-81be-4be5-8808-93a75d144fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-093dc1fb-0be8-4e3c-b1de-df57924444e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-c480146a-69ab-4174-a74e-ab8a97c84eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-fbe71c45-4d90-4ced-8359-74cf8b92bfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-032ee237-674f-476b-b168-81bdcec078fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-63a70a81-547c-4f68-a911-4d0c134dd9d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293035711-172.17.0.20-1598328469935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40144,DS-b08a35c0-f32b-4576-9621-9b3064972b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-20319f5f-e358-4d41-bf2a-63a91b870eca,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-2955f12b-2d09-4f69-a049-1d9ae628be67,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-16a1336d-f417-4ad5-95f1-52f03a188715,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-ee04d679-2817-487e-83ea-e697e60db0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-b71e9b85-184d-45ff-9af6-13edb327d150,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-7b72bd07-ec30-47a0-8cb5-fb76e8e1e2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-3af82414-06d3-4c35-9094-0ed78b2d9a7c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293035711-172.17.0.20-1598328469935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40144,DS-b08a35c0-f32b-4576-9621-9b3064972b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-20319f5f-e358-4d41-bf2a-63a91b870eca,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-2955f12b-2d09-4f69-a049-1d9ae628be67,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-16a1336d-f417-4ad5-95f1-52f03a188715,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-ee04d679-2817-487e-83ea-e697e60db0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-b71e9b85-184d-45ff-9af6-13edb327d150,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-7b72bd07-ec30-47a0-8cb5-fb76e8e1e2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-3af82414-06d3-4c35-9094-0ed78b2d9a7c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790348359-172.17.0.20-1598328570732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41217,DS-0e0d2530-2daf-4fcb-86c1-3c90b3d01b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-99ca0504-5b1b-4067-b3cd-3ac9594d829b,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-3828ccb8-efb3-4d31-b573-5acde3f8fd76,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-ccad72fc-5f3c-401e-807d-401c14b20a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-b3009676-bf70-40da-b984-d79d0880f59b,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-63691d81-543b-40b8-880c-9f240a9949e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-5562c843-323f-44df-8e03-e350a3e05fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-37d91327-3d27-4d9e-b85c-45fdad1f3511,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790348359-172.17.0.20-1598328570732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41217,DS-0e0d2530-2daf-4fcb-86c1-3c90b3d01b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-99ca0504-5b1b-4067-b3cd-3ac9594d829b,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-3828ccb8-efb3-4d31-b573-5acde3f8fd76,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-ccad72fc-5f3c-401e-807d-401c14b20a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-b3009676-bf70-40da-b984-d79d0880f59b,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-63691d81-543b-40b8-880c-9f240a9949e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-5562c843-323f-44df-8e03-e350a3e05fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-37d91327-3d27-4d9e-b85c-45fdad1f3511,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499087220-172.17.0.20-1598328641116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44977,DS-98f1dba3-6403-49b2-a9d8-3edcc74bbec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-469f172c-8a5b-42b4-8dc9-ac5256a598b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-bb928748-ca0e-4ec9-9e90-85ed2a05d304,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-058be5f6-01f4-4564-aa97-2fb3d61caa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-19d12882-2ba9-434f-8b53-22fb4870bd50,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-67e951ee-02ce-4838-9ad3-bb7e27b12ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-e78ac16e-d472-4898-827a-b2148da07f90,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-860852b3-269f-4c94-82d8-e1a5987aed70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499087220-172.17.0.20-1598328641116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44977,DS-98f1dba3-6403-49b2-a9d8-3edcc74bbec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-469f172c-8a5b-42b4-8dc9-ac5256a598b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-bb928748-ca0e-4ec9-9e90-85ed2a05d304,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-058be5f6-01f4-4564-aa97-2fb3d61caa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-19d12882-2ba9-434f-8b53-22fb4870bd50,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-67e951ee-02ce-4838-9ad3-bb7e27b12ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-e78ac16e-d472-4898-827a-b2148da07f90,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-860852b3-269f-4c94-82d8-e1a5987aed70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1761265761-172.17.0.20-1598328680869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33042,DS-b5dc691c-c923-40df-866f-a053a59996f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-df850cca-9762-4193-a8d1-503b24b462d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-f81337c0-7d03-46b3-8622-12448ccb4813,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-f2bcf56c-4717-4691-bb14-c65a835a13c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-226c3419-2d00-421a-975e-e4664fa372c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-6ced4cde-6d43-48ad-89bc-1ba392dc8b84,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-eb909f80-66ec-43b9-9de9-5b95043c95cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-dad83696-ef15-440e-8697-9489bd0e1be2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1761265761-172.17.0.20-1598328680869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33042,DS-b5dc691c-c923-40df-866f-a053a59996f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-df850cca-9762-4193-a8d1-503b24b462d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-f81337c0-7d03-46b3-8622-12448ccb4813,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-f2bcf56c-4717-4691-bb14-c65a835a13c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-226c3419-2d00-421a-975e-e4664fa372c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-6ced4cde-6d43-48ad-89bc-1ba392dc8b84,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-eb909f80-66ec-43b9-9de9-5b95043c95cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-dad83696-ef15-440e-8697-9489bd0e1be2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235567043-172.17.0.20-1598328713534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40046,DS-4af4c032-e586-4acc-b78f-6730bb870812,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-73632777-b8ed-45a2-942d-ea91f0d32dba,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-8cc1c174-9431-4216-930e-cfa5eeae2738,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-eb002715-1d10-404a-86f0-921de13f6501,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-dbbcf124-5cd7-4df7-98a4-d32127cfddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-bb7eef32-0b9d-4404-954d-da6e45ddd82c,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-1870e80a-eb4d-454f-b2ba-b5378db898a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-cd3c60c3-d9bb-4d1d-8056-5e9e7c0b9d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235567043-172.17.0.20-1598328713534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40046,DS-4af4c032-e586-4acc-b78f-6730bb870812,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-73632777-b8ed-45a2-942d-ea91f0d32dba,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-8cc1c174-9431-4216-930e-cfa5eeae2738,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-eb002715-1d10-404a-86f0-921de13f6501,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-dbbcf124-5cd7-4df7-98a4-d32127cfddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-bb7eef32-0b9d-4404-954d-da6e45ddd82c,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-1870e80a-eb4d-454f-b2ba-b5378db898a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-cd3c60c3-d9bb-4d1d-8056-5e9e7c0b9d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136605534-172.17.0.20-1598328823833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35021,DS-a37b0071-a690-4c66-8db4-abfcd3d8da44,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-960a9834-4a15-46a2-8407-c6e01390d796,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-bb0013cd-4681-4a5f-a6fe-d259766fb0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-d37ed429-71d0-49fd-86ab-9afe5eb02a80,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-cf225a1d-97de-459c-9a87-f309f24800d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-a9e18d5d-b9bb-4afa-9adc-8e64c0eb94d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-d9febec0-8398-4840-8c9a-8d3c8dac3873,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-637394b3-b4f1-40c8-90c2-9d13edc8b2c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136605534-172.17.0.20-1598328823833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35021,DS-a37b0071-a690-4c66-8db4-abfcd3d8da44,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-960a9834-4a15-46a2-8407-c6e01390d796,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-bb0013cd-4681-4a5f-a6fe-d259766fb0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-d37ed429-71d0-49fd-86ab-9afe5eb02a80,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-cf225a1d-97de-459c-9a87-f309f24800d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-a9e18d5d-b9bb-4afa-9adc-8e64c0eb94d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-d9febec0-8398-4840-8c9a-8d3c8dac3873,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-637394b3-b4f1-40c8-90c2-9d13edc8b2c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-453932476-172.17.0.20-1598328860784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46041,DS-f05b34c4-e5a3-4d6e-8766-113ebfc2e81a,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-5d2da39d-5114-4966-bc61-94b49f391c56,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-054f18f7-aa11-4c9e-b1c6-f117c09918e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-7b2efe25-d828-45dc-a48d-d6692b922814,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-c6bc5292-caa5-445b-b3c5-cd5bf774bd93,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-046ff417-ea06-4a38-9731-803a75678c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-cca87e18-8b2f-4d51-b9f6-d5777f7ab577,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-570c6c87-d1c1-4d9f-838a-3613d2b83010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-453932476-172.17.0.20-1598328860784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46041,DS-f05b34c4-e5a3-4d6e-8766-113ebfc2e81a,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-5d2da39d-5114-4966-bc61-94b49f391c56,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-054f18f7-aa11-4c9e-b1c6-f117c09918e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-7b2efe25-d828-45dc-a48d-d6692b922814,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-c6bc5292-caa5-445b-b3c5-cd5bf774bd93,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-046ff417-ea06-4a38-9731-803a75678c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-cca87e18-8b2f-4d51-b9f6-d5777f7ab577,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-570c6c87-d1c1-4d9f-838a-3613d2b83010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797793380-172.17.0.20-1598328975681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41598,DS-f5c749f3-cf18-4ec5-98bd-57e866dcfbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-3f27e71d-b123-4b8d-85da-39006076e5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-a01164c6-eb95-4ef6-a0a1-e75bace5f70e,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-18a43ab3-4240-4f9e-bc6f-afcc8a60b244,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-dacbccc1-0edf-4542-ba8b-231235843fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-d58ad996-05ae-44e5-a285-e661a1a42832,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-8b11ffd6-ea46-4cdc-9ea2-a076fe590f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-61471457-729c-46cc-81c7-2712e17ad3c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797793380-172.17.0.20-1598328975681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41598,DS-f5c749f3-cf18-4ec5-98bd-57e866dcfbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-3f27e71d-b123-4b8d-85da-39006076e5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-a01164c6-eb95-4ef6-a0a1-e75bace5f70e,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-18a43ab3-4240-4f9e-bc6f-afcc8a60b244,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-dacbccc1-0edf-4542-ba8b-231235843fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-d58ad996-05ae-44e5-a285-e661a1a42832,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-8b11ffd6-ea46-4cdc-9ea2-a076fe590f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-61471457-729c-46cc-81c7-2712e17ad3c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229859262-172.17.0.20-1598329305508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40433,DS-4a75de09-7bc3-4b90-a0c1-4d98ff183495,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-14a5e0d9-8326-4b99-8a10-ba548d7d77aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-7c820f5f-7dc0-4721-a377-269b5d5de48f,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-2fe62fc6-4ff5-4628-beba-d47c82aceb57,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-3c5f375c-caff-4860-aa58-3fadfd00899d,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-179ff0e8-7428-4665-9975-a954ca33d154,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-a2680f5f-e373-4421-9f63-4b9a1790c528,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-1955583a-7537-46fa-a92a-7980559bc95e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229859262-172.17.0.20-1598329305508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40433,DS-4a75de09-7bc3-4b90-a0c1-4d98ff183495,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-14a5e0d9-8326-4b99-8a10-ba548d7d77aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-7c820f5f-7dc0-4721-a377-269b5d5de48f,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-2fe62fc6-4ff5-4628-beba-d47c82aceb57,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-3c5f375c-caff-4860-aa58-3fadfd00899d,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-179ff0e8-7428-4665-9975-a954ca33d154,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-a2680f5f-e373-4421-9f63-4b9a1790c528,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-1955583a-7537-46fa-a92a-7980559bc95e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427530956-172.17.0.20-1598329371113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36955,DS-abb691f2-ea98-4c77-bd10-b1964c4302c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-76cab7d0-47c3-4bd0-81be-12308b92b2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-49c9b54e-8e33-475b-a477-aa4e62361d97,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-8c9eecc5-9381-4aab-a043-c15afe427a48,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-ef732b3f-5457-42be-b233-199155fb0b25,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-cdecc1b5-55ac-4bbe-859a-50964524a6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-6d1aad87-a502-4293-bc3c-87d583ad8f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-1558e397-dd46-42c5-ba9a-e970dad742e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427530956-172.17.0.20-1598329371113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36955,DS-abb691f2-ea98-4c77-bd10-b1964c4302c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-76cab7d0-47c3-4bd0-81be-12308b92b2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-49c9b54e-8e33-475b-a477-aa4e62361d97,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-8c9eecc5-9381-4aab-a043-c15afe427a48,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-ef732b3f-5457-42be-b233-199155fb0b25,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-cdecc1b5-55ac-4bbe-859a-50964524a6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-6d1aad87-a502-4293-bc3c-87d583ad8f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-1558e397-dd46-42c5-ba9a-e970dad742e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896956728-172.17.0.20-1598329888567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40430,DS-6cf945e1-484f-4322-9471-dd400c875e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-7e7a9c1f-3e2f-42f4-919d-a801e29e6e02,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-08606d58-21fd-49d9-a697-9312871a5e19,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-15951dcd-70d7-4175-8f7a-142e78c8a4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-e22a4727-c9b6-4550-87ed-1baafaf1e992,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-29192de0-b13e-4b0f-9f82-ab6de828c795,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-ed78bf18-4043-4f11-a436-ad2081a71806,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-82225432-ba21-4cfb-905f-081f5c7084e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896956728-172.17.0.20-1598329888567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40430,DS-6cf945e1-484f-4322-9471-dd400c875e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-7e7a9c1f-3e2f-42f4-919d-a801e29e6e02,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-08606d58-21fd-49d9-a697-9312871a5e19,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-15951dcd-70d7-4175-8f7a-142e78c8a4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-e22a4727-c9b6-4550-87ed-1baafaf1e992,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-29192de0-b13e-4b0f-9f82-ab6de828c795,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-ed78bf18-4043-4f11-a436-ad2081a71806,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-82225432-ba21-4cfb-905f-081f5c7084e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726161079-172.17.0.20-1598329920914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46198,DS-5be43265-45db-4d0a-a6c9-089e9ea9bffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-7f3e8b50-9437-4c81-b5d8-ac0836a8155a,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-81829c66-ddcd-4d0f-b0a3-8579e4a4430a,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-861bb4e3-29f5-47da-ac08-1896b1edc51e,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-3ead6354-6a4e-458b-aea4-9569cefabd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-37734905-3c72-4f05-b72c-29bbc6bbb41e,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-39d697ae-03eb-437a-a58c-fe733eceeff6,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-d24cda71-0f36-4c46-9df3-aa44c7e8dd69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726161079-172.17.0.20-1598329920914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46198,DS-5be43265-45db-4d0a-a6c9-089e9ea9bffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-7f3e8b50-9437-4c81-b5d8-ac0836a8155a,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-81829c66-ddcd-4d0f-b0a3-8579e4a4430a,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-861bb4e3-29f5-47da-ac08-1896b1edc51e,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-3ead6354-6a4e-458b-aea4-9569cefabd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-37734905-3c72-4f05-b72c-29bbc6bbb41e,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-39d697ae-03eb-437a-a58c-fe733eceeff6,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-d24cda71-0f36-4c46-9df3-aa44c7e8dd69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1233308903-172.17.0.20-1598330024640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34268,DS-035289af-b371-4ee2-b3c8-9be1b926b9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-b461d782-f96c-4334-b17f-1241b0ab25e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-64bfba08-dd97-4eb7-834d-f459ce38f960,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-c2bf756a-6e67-4e70-a8fc-0348b6c81584,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-8e6caa77-1f15-4f42-801b-b296cbff3fab,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-6d26116b-f1c4-4b7e-a9a0-bc4cae358592,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-458da574-ffb4-4751-81ea-cd6c09bbdb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-f66c8140-9f31-4698-b561-44880abcdb52,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1233308903-172.17.0.20-1598330024640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34268,DS-035289af-b371-4ee2-b3c8-9be1b926b9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-b461d782-f96c-4334-b17f-1241b0ab25e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-64bfba08-dd97-4eb7-834d-f459ce38f960,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-c2bf756a-6e67-4e70-a8fc-0348b6c81584,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-8e6caa77-1f15-4f42-801b-b296cbff3fab,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-6d26116b-f1c4-4b7e-a9a0-bc4cae358592,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-458da574-ffb4-4751-81ea-cd6c09bbdb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-f66c8140-9f31-4698-b561-44880abcdb52,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432269260-172.17.0.20-1598330227741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38352,DS-f79114b8-eb1d-41cb-8acc-82b7f6c6df18,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-1d416171-cafb-45f2-8e0a-bd82cf00851d,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-0bb8094c-bb22-481a-aa16-695bc46106b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-63c258e4-91c3-4149-a042-7fc568ee0423,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-803239d9-73cd-495f-8f35-1b2501f99c75,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-c29d5f0e-f422-446c-b945-93a49a9beff2,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-2a9c731f-b7b3-43e3-9c9c-51e5fe5d6c68,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-e7f29e7f-e354-46cc-9c51-ced38d8180ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432269260-172.17.0.20-1598330227741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38352,DS-f79114b8-eb1d-41cb-8acc-82b7f6c6df18,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-1d416171-cafb-45f2-8e0a-bd82cf00851d,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-0bb8094c-bb22-481a-aa16-695bc46106b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-63c258e4-91c3-4149-a042-7fc568ee0423,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-803239d9-73cd-495f-8f35-1b2501f99c75,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-c29d5f0e-f422-446c-b945-93a49a9beff2,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-2a9c731f-b7b3-43e3-9c9c-51e5fe5d6c68,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-e7f29e7f-e354-46cc-9c51-ced38d8180ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108230144-172.17.0.20-1598330291719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39204,DS-dffcb989-c883-4f64-a7fa-d5dded49fdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-8e7733bb-1485-431b-a493-20f1421ff23f,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-c25c2f86-11e9-405a-b682-c12a54b3dec5,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-5ab3ffb3-9762-4da9-9132-cae1439aabcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-2f65cc0c-e2cd-42a9-85da-9e0c872930d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-bd37cb60-8cfd-4829-bcc8-e43cbe2674d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-7c6fba75-b67d-4003-84e0-3ad1f606e65f,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-bdd1f1ed-90cc-4f83-8af6-878f86d57ebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108230144-172.17.0.20-1598330291719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39204,DS-dffcb989-c883-4f64-a7fa-d5dded49fdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-8e7733bb-1485-431b-a493-20f1421ff23f,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-c25c2f86-11e9-405a-b682-c12a54b3dec5,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-5ab3ffb3-9762-4da9-9132-cae1439aabcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-2f65cc0c-e2cd-42a9-85da-9e0c872930d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-bd37cb60-8cfd-4829-bcc8-e43cbe2674d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-7c6fba75-b67d-4003-84e0-3ad1f606e65f,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-bdd1f1ed-90cc-4f83-8af6-878f86d57ebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075482787-172.17.0.20-1598330328178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45551,DS-63840acb-e09a-4d8a-8f88-e1056d6b3e17,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-c535c7d5-c1c2-45a8-aa70-3b6eb6340526,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-a8cbb55c-0532-4eb6-9ea4-86b0ffe48952,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-da3a846f-bfef-4a6a-bdfa-82506d726675,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-7c4e055c-1d56-4ca4-a0ea-e1f02a161703,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-4924a3fd-8086-4c7d-bc5e-6d44015a6afd,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-2671c065-091a-480f-a82c-da0482a3697f,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-ea0112d6-3d99-4717-891f-66b7b478e6e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075482787-172.17.0.20-1598330328178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45551,DS-63840acb-e09a-4d8a-8f88-e1056d6b3e17,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-c535c7d5-c1c2-45a8-aa70-3b6eb6340526,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-a8cbb55c-0532-4eb6-9ea4-86b0ffe48952,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-da3a846f-bfef-4a6a-bdfa-82506d726675,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-7c4e055c-1d56-4ca4-a0ea-e1f02a161703,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-4924a3fd-8086-4c7d-bc5e-6d44015a6afd,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-2671c065-091a-480f-a82c-da0482a3697f,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-ea0112d6-3d99-4717-891f-66b7b478e6e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292799669-172.17.0.20-1598331199467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39891,DS-eae3b7ea-d67a-4c87-9cca-8136c78ff100,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-9f184603-2d0f-4d9a-a4d8-0e2ba8e795aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-0a0293ec-bc8e-4f89-b84b-a382f2403cca,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-c30cc9b8-b523-4df7-8c7b-cf370d668fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-a55ee228-2693-4344-bcda-2526977e5eff,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-3d87740b-1181-4ab2-a138-b4c6a6efa5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-2e597b4b-ab4a-413c-924e-1d5b2268f355,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-9375f394-3220-442f-a099-775a2607157e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292799669-172.17.0.20-1598331199467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39891,DS-eae3b7ea-d67a-4c87-9cca-8136c78ff100,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-9f184603-2d0f-4d9a-a4d8-0e2ba8e795aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-0a0293ec-bc8e-4f89-b84b-a382f2403cca,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-c30cc9b8-b523-4df7-8c7b-cf370d668fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-a55ee228-2693-4344-bcda-2526977e5eff,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-3d87740b-1181-4ab2-a138-b4c6a6efa5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-2e597b4b-ab4a-413c-924e-1d5b2268f355,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-9375f394-3220-442f-a099-775a2607157e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618122425-172.17.0.20-1598331340599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40920,DS-2fbe604d-38bc-4b37-b575-7291e6564f09,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-d30bfb4c-52ec-4454-ae0d-5afbdb79fde4,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-68d9f6a9-552e-4037-bc42-08875948fb27,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-40ea2629-1839-4fd0-81d6-654d9bf4864a,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-fd6566e7-36e8-4bcc-a0fc-00376c446441,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-351eb857-0ca9-447b-95b0-e4b7a1222749,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-3dc089f6-e67d-497f-a8a4-af398926cc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-bd99e724-76b4-4c78-88ce-1e60430e21e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618122425-172.17.0.20-1598331340599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40920,DS-2fbe604d-38bc-4b37-b575-7291e6564f09,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-d30bfb4c-52ec-4454-ae0d-5afbdb79fde4,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-68d9f6a9-552e-4037-bc42-08875948fb27,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-40ea2629-1839-4fd0-81d6-654d9bf4864a,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-fd6566e7-36e8-4bcc-a0fc-00376c446441,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-351eb857-0ca9-447b-95b0-e4b7a1222749,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-3dc089f6-e67d-497f-a8a4-af398926cc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-bd99e724-76b4-4c78-88ce-1e60430e21e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406239975-172.17.0.20-1598331380630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33789,DS-2ba8bc18-4155-4f60-b789-3a7a1333ec5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-8afe3e64-da8d-4c8a-9641-7ec3963c0d31,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-43ce10e8-ea17-4c7d-af38-f4d0d5c9c7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-be65ceec-5895-439f-91ad-e5f5fb8745d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-2008f1ec-fd30-4de8-849d-18d9851fd602,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-5fde45b9-85f5-4018-b5e3-adcfcb29f10c,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-d3eb7ee4-2f7a-4077-86eb-c9c590f19ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-2c5db1d5-149e-48e9-8f05-339653a24c0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406239975-172.17.0.20-1598331380630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33789,DS-2ba8bc18-4155-4f60-b789-3a7a1333ec5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-8afe3e64-da8d-4c8a-9641-7ec3963c0d31,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-43ce10e8-ea17-4c7d-af38-f4d0d5c9c7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-be65ceec-5895-439f-91ad-e5f5fb8745d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-2008f1ec-fd30-4de8-849d-18d9851fd602,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-5fde45b9-85f5-4018-b5e3-adcfcb29f10c,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-d3eb7ee4-2f7a-4077-86eb-c9c590f19ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-2c5db1d5-149e-48e9-8f05-339653a24c0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218291956-172.17.0.20-1598331847883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37152,DS-33f0be50-d915-433e-a4b5-6702ee0445aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-cbe18da4-b296-4db3-a4e6-231a38851bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-8435fc1b-5569-4b84-9293-cadff2cde51d,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-9729e1a0-e9df-443d-a2e8-97805d4ee1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-df0accb3-1182-4be3-bd59-d7a25cca1643,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-82d8b403-639b-45d6-9dd9-a539442df59c,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-6ff30ca0-dbe7-4c89-94ee-6ec0e99abc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-15fedddc-4fad-4d13-b8e1-9226b2f6d5c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218291956-172.17.0.20-1598331847883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37152,DS-33f0be50-d915-433e-a4b5-6702ee0445aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-cbe18da4-b296-4db3-a4e6-231a38851bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-8435fc1b-5569-4b84-9293-cadff2cde51d,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-9729e1a0-e9df-443d-a2e8-97805d4ee1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-df0accb3-1182-4be3-bd59-d7a25cca1643,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-82d8b403-639b-45d6-9dd9-a539442df59c,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-6ff30ca0-dbe7-4c89-94ee-6ec0e99abc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-15fedddc-4fad-4d13-b8e1-9226b2f6d5c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605919541-172.17.0.20-1598332048209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36958,DS-0410ddef-371b-4283-aa7b-241e130d2cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-0f4e94d0-6cce-41b9-9aad-3a716b0d9d19,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-aa35f155-8c0f-43c4-aa42-1d280db02623,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-92154cf5-fd34-4096-954a-5fc5037c0a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-4e6ab99b-1f2f-4644-a566-5ba90a0634a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-d8bcecfe-9bdf-480d-85a4-a8eb4fa839b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-b63d4f45-3486-4fc8-9891-f9d9dc440b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-56a5ce9f-e0ca-40c0-b6f2-37cf840a506c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605919541-172.17.0.20-1598332048209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36958,DS-0410ddef-371b-4283-aa7b-241e130d2cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-0f4e94d0-6cce-41b9-9aad-3a716b0d9d19,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-aa35f155-8c0f-43c4-aa42-1d280db02623,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-92154cf5-fd34-4096-954a-5fc5037c0a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-4e6ab99b-1f2f-4644-a566-5ba90a0634a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-d8bcecfe-9bdf-480d-85a4-a8eb4fa839b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-b63d4f45-3486-4fc8-9891-f9d9dc440b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-56a5ce9f-e0ca-40c0-b6f2-37cf840a506c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148140933-172.17.0.20-1598332285525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44266,DS-c7557545-fa63-43b1-962f-a151dccfcb57,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-4778b759-a474-4aeb-8404-788ef37df6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-6b35688b-7887-40e8-a951-ddc7155abc09,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-342c002f-f47d-476a-a9f3-2dd3001003ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-d7f81827-4d90-489f-a4a1-7263b1137b95,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-04775111-03cf-4388-b9e0-511ea2b32d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-eead933e-2b5a-44b0-ac7a-2c0ff0da6753,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-f3bf0df4-f180-42bb-96cd-35b77dbb1de1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148140933-172.17.0.20-1598332285525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44266,DS-c7557545-fa63-43b1-962f-a151dccfcb57,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-4778b759-a474-4aeb-8404-788ef37df6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-6b35688b-7887-40e8-a951-ddc7155abc09,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-342c002f-f47d-476a-a9f3-2dd3001003ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-d7f81827-4d90-489f-a4a1-7263b1137b95,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-04775111-03cf-4388-b9e0-511ea2b32d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-eead933e-2b5a-44b0-ac7a-2c0ff0da6753,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-f3bf0df4-f180-42bb-96cd-35b77dbb1de1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323053090-172.17.0.20-1598332393082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36894,DS-d45ecacd-269f-4f4e-bb65-97d350a4a035,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-81b2a646-4a60-43fe-8879-dab81396e75f,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-59170940-d951-47d7-8cab-639ce8e82c17,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-dd233846-aace-4fd6-bff8-a8571a3b78e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-7228c154-d3ee-4fcf-90ca-ad31441ea7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-2c0f35f1-165e-4672-84d2-4b6efa494276,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-c980951e-0ae5-4cd8-a78c-5112e0773bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-1eb6f980-17a3-4e95-9609-9582e160b23f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323053090-172.17.0.20-1598332393082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36894,DS-d45ecacd-269f-4f4e-bb65-97d350a4a035,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-81b2a646-4a60-43fe-8879-dab81396e75f,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-59170940-d951-47d7-8cab-639ce8e82c17,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-dd233846-aace-4fd6-bff8-a8571a3b78e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-7228c154-d3ee-4fcf-90ca-ad31441ea7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-2c0f35f1-165e-4672-84d2-4b6efa494276,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-c980951e-0ae5-4cd8-a78c-5112e0773bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-1eb6f980-17a3-4e95-9609-9582e160b23f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074149009-172.17.0.20-1598332429506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39426,DS-741fd754-16d0-414c-a648-48155bd9676c,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-880c2549-1606-491d-aa96-ec1824981b93,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-8e3ca619-937b-42da-9d6d-3c98c68e59fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-7a261583-057d-45ec-803c-08cc3b747f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-f974cc48-e158-41b9-953e-c08748b83ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-de0968e3-7081-4ad5-9f23-eef6b3297a21,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-b954ce8a-74e6-489c-8754-86cb0c82859c,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-87fe877a-0e1a-4082-9a00-45aa11896d1e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074149009-172.17.0.20-1598332429506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39426,DS-741fd754-16d0-414c-a648-48155bd9676c,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-880c2549-1606-491d-aa96-ec1824981b93,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-8e3ca619-937b-42da-9d6d-3c98c68e59fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-7a261583-057d-45ec-803c-08cc3b747f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-f974cc48-e158-41b9-953e-c08748b83ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-de0968e3-7081-4ad5-9f23-eef6b3297a21,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-b954ce8a-74e6-489c-8754-86cb0c82859c,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-87fe877a-0e1a-4082-9a00-45aa11896d1e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844402687-172.17.0.20-1598332500285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45225,DS-ea660bd0-da3b-44f0-b144-67eb9082ddb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-38775a39-96e2-4c51-b892-7c938f3b6b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-87bf7e28-e09a-4693-81c2-33ed1ff7d858,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-e8157cb7-8aa8-4197-8ee9-c07138a52cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-4fb6b95d-a21b-46d0-b832-c3020c9be850,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-311c864e-7c72-4821-b03b-7ad963a6ddb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-03707856-120e-4e2e-afa5-4f5b91348916,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-429069eb-e668-47c2-81ce-4805a9f614e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844402687-172.17.0.20-1598332500285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45225,DS-ea660bd0-da3b-44f0-b144-67eb9082ddb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-38775a39-96e2-4c51-b892-7c938f3b6b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-87bf7e28-e09a-4693-81c2-33ed1ff7d858,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-e8157cb7-8aa8-4197-8ee9-c07138a52cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-4fb6b95d-a21b-46d0-b832-c3020c9be850,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-311c864e-7c72-4821-b03b-7ad963a6ddb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-03707856-120e-4e2e-afa5-4f5b91348916,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-429069eb-e668-47c2-81ce-4805a9f614e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078727815-172.17.0.20-1598332537594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45919,DS-5597d7f4-2c62-463b-af9e-5aaf50e58da7,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-a35f7c53-225c-4d40-b207-36dac594a73c,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-8f0df791-e08e-4947-a4ae-0b5c13eeb731,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-978365ff-6a0f-433d-8806-cedb7396f682,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-7d6bf0d7-a703-4f89-a8d5-ecd7bd4f4f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-62c5fa86-482c-4c13-b9ee-3213825876c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-309a2881-9f3c-4203-87ae-b4fa98bc2fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-eade6783-8471-4416-86df-0ca975da199c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078727815-172.17.0.20-1598332537594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45919,DS-5597d7f4-2c62-463b-af9e-5aaf50e58da7,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-a35f7c53-225c-4d40-b207-36dac594a73c,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-8f0df791-e08e-4947-a4ae-0b5c13eeb731,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-978365ff-6a0f-433d-8806-cedb7396f682,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-7d6bf0d7-a703-4f89-a8d5-ecd7bd4f4f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-62c5fa86-482c-4c13-b9ee-3213825876c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-309a2881-9f3c-4203-87ae-b4fa98bc2fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-eade6783-8471-4416-86df-0ca975da199c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66762577-172.17.0.20-1598332569055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42748,DS-4e2928cb-cf7a-4790-a0ba-7238d45d0a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-06e86916-2663-4b1e-9d2b-76596de869e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-10e39ce4-c82e-40e3-bca2-06e5660a9898,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-a78fe4fd-0387-44fe-a139-3946ff2717c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-733bdf61-0040-4be2-a961-5b4509a9e386,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-8a613e3c-6fa8-4526-b764-3b8e9a4e0328,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-3c91a269-b2c3-4381-83b4-0b6999a80d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-d580e1bf-4c14-42f5-8092-f57959da4430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66762577-172.17.0.20-1598332569055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42748,DS-4e2928cb-cf7a-4790-a0ba-7238d45d0a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-06e86916-2663-4b1e-9d2b-76596de869e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-10e39ce4-c82e-40e3-bca2-06e5660a9898,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-a78fe4fd-0387-44fe-a139-3946ff2717c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-733bdf61-0040-4be2-a961-5b4509a9e386,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-8a613e3c-6fa8-4526-b764-3b8e9a4e0328,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-3c91a269-b2c3-4381-83b4-0b6999a80d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-d580e1bf-4c14-42f5-8092-f57959da4430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5308
