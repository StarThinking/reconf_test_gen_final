reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166259880-172.17.0.21-1598122407843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35853,DS-7a3a28bb-83e7-4476-acfb-cc611c487084,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-0a0b92e3-74c0-4ecd-b716-86973bd6ffef,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-3ff0d4ec-ef5f-4193-b86a-a034839b5bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-602f4106-2fd4-4bf2-aa71-6ab4b11564b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-032eb319-cee6-48ab-91f5-b1e3726a9b20,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-8905f072-5b4a-4797-bcd6-15d4a98d1383,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-435090a8-8ae2-4e2c-b4cc-dbde39a74cec,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-dd50ce84-dcfc-4f0d-9662-ee3268dae20e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166259880-172.17.0.21-1598122407843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35853,DS-7a3a28bb-83e7-4476-acfb-cc611c487084,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-0a0b92e3-74c0-4ecd-b716-86973bd6ffef,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-3ff0d4ec-ef5f-4193-b86a-a034839b5bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-602f4106-2fd4-4bf2-aa71-6ab4b11564b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-032eb319-cee6-48ab-91f5-b1e3726a9b20,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-8905f072-5b4a-4797-bcd6-15d4a98d1383,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-435090a8-8ae2-4e2c-b4cc-dbde39a74cec,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-dd50ce84-dcfc-4f0d-9662-ee3268dae20e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57247669-172.17.0.21-1598123315289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33865,DS-70e45820-e572-40d7-818e-f25decdbb811,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-bc949078-42eb-4a08-8a22-c325dc1f5e66,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-cd60d6d9-8d61-491a-b7f7-801968e89a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-42b135e5-bac9-4d88-af81-27a9aa4800ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-3543ac67-8699-4ac1-a909-29faea6b234a,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-1bc7f8b1-3ff3-47a7-a68a-53fa6de4b5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-c927ba04-b162-4956-9644-9c7b64be77d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-68c18934-fd56-432d-b6a8-af39ec2e4305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57247669-172.17.0.21-1598123315289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33865,DS-70e45820-e572-40d7-818e-f25decdbb811,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-bc949078-42eb-4a08-8a22-c325dc1f5e66,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-cd60d6d9-8d61-491a-b7f7-801968e89a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-42b135e5-bac9-4d88-af81-27a9aa4800ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-3543ac67-8699-4ac1-a909-29faea6b234a,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-1bc7f8b1-3ff3-47a7-a68a-53fa6de4b5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-c927ba04-b162-4956-9644-9c7b64be77d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-68c18934-fd56-432d-b6a8-af39ec2e4305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967754149-172.17.0.21-1598123432189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39700,DS-ff2b59f1-2237-4bfd-ae94-ca5e02c8391d,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-a6f38494-3f92-4689-8133-d66a29f3d766,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-6e8f15c6-ead2-48c3-a831-aad2fdde7800,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-164fcaa3-c3cb-417c-99c6-576cb9c7a855,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-d5f8a61c-150d-4111-9e28-a74479a6e2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-42d1735f-cbe8-4ddf-836f-b49445000e52,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-d6e6cac7-d217-4189-b29d-ee43e7f30b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-ba4ef412-e53a-48d0-bd26-2367d4e5e42c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967754149-172.17.0.21-1598123432189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39700,DS-ff2b59f1-2237-4bfd-ae94-ca5e02c8391d,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-a6f38494-3f92-4689-8133-d66a29f3d766,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-6e8f15c6-ead2-48c3-a831-aad2fdde7800,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-164fcaa3-c3cb-417c-99c6-576cb9c7a855,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-d5f8a61c-150d-4111-9e28-a74479a6e2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-42d1735f-cbe8-4ddf-836f-b49445000e52,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-d6e6cac7-d217-4189-b29d-ee43e7f30b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-ba4ef412-e53a-48d0-bd26-2367d4e5e42c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105919737-172.17.0.21-1598123709101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41399,DS-d9a85117-838c-4d0b-872f-65d613bf2510,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-68a64a06-b660-4de2-b60a-7c5a81831835,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-3285f03d-53b8-4b83-a22e-8979cf5e966d,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-915ab402-9fdf-405a-aeec-7416d8960169,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-e217658e-fa66-43fe-999d-ae442aaf8d60,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-f45d9892-be57-40f5-9489-1bc7ffb6eae5,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-0f33c17b-c5ab-4343-9619-7c1950c7e1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-24001207-826c-4dc2-8c95-a23197a45988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105919737-172.17.0.21-1598123709101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41399,DS-d9a85117-838c-4d0b-872f-65d613bf2510,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-68a64a06-b660-4de2-b60a-7c5a81831835,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-3285f03d-53b8-4b83-a22e-8979cf5e966d,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-915ab402-9fdf-405a-aeec-7416d8960169,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-e217658e-fa66-43fe-999d-ae442aaf8d60,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-f45d9892-be57-40f5-9489-1bc7ffb6eae5,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-0f33c17b-c5ab-4343-9619-7c1950c7e1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-24001207-826c-4dc2-8c95-a23197a45988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145198585-172.17.0.21-1598124001237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44405,DS-13a317e9-d939-465f-bd22-424d42c5da54,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-447c01b1-698d-482a-8e6d-cd75dfcd7c07,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-f8bd911e-0262-4b25-9f60-a4e8c6d8e679,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-8a2e05b2-f618-4094-b1d0-59cc4eb0fc01,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-48f3c24a-3f8a-4cc4-a9fd-6fd07ddd9021,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-187d60e3-6284-4567-9429-7c21548fe87c,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-01a669de-95a6-4885-8511-8897e043ee59,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-46c9d88d-4480-4cfe-af50-7c6027f76618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145198585-172.17.0.21-1598124001237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44405,DS-13a317e9-d939-465f-bd22-424d42c5da54,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-447c01b1-698d-482a-8e6d-cd75dfcd7c07,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-f8bd911e-0262-4b25-9f60-a4e8c6d8e679,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-8a2e05b2-f618-4094-b1d0-59cc4eb0fc01,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-48f3c24a-3f8a-4cc4-a9fd-6fd07ddd9021,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-187d60e3-6284-4567-9429-7c21548fe87c,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-01a669de-95a6-4885-8511-8897e043ee59,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-46c9d88d-4480-4cfe-af50-7c6027f76618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68165664-172.17.0.21-1598124530309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35575,DS-e3e31971-0313-4385-a7a3-a9ea97c84c99,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-beee839b-8293-4953-94a7-a9957c01d044,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-dce8cc35-9bfa-4850-b0d1-4653d7413462,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-712756e6-d802-46cc-a19c-ddf049181faf,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-46afdd9f-7655-4d6a-820b-88fb13842d64,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-89b09875-7100-49ef-84a0-482ea926184f,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-7f77e204-afb3-4cd8-84fa-ec9c42ade593,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-c4634588-f377-4736-83f9-ef07b639faf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68165664-172.17.0.21-1598124530309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35575,DS-e3e31971-0313-4385-a7a3-a9ea97c84c99,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-beee839b-8293-4953-94a7-a9957c01d044,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-dce8cc35-9bfa-4850-b0d1-4653d7413462,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-712756e6-d802-46cc-a19c-ddf049181faf,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-46afdd9f-7655-4d6a-820b-88fb13842d64,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-89b09875-7100-49ef-84a0-482ea926184f,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-7f77e204-afb3-4cd8-84fa-ec9c42ade593,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-c4634588-f377-4736-83f9-ef07b639faf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-103201947-172.17.0.21-1598125705240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39872,DS-d4179b67-0d19-45a1-a70a-bf95047c1f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-7971df92-195d-4b18-892c-03827e43f0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-c417269e-1012-4617-bdb6-c55d84c866a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-f22a5eb7-ccc9-4127-a2f1-85462ade8198,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-5657473c-6784-4be5-8070-578d43c120b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-7bff069c-a40a-4cb1-a8e9-832976d070be,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-712e7672-2381-464b-a287-d8b5dce39ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-175f9029-166d-4616-abfe-2dcd986b7d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-103201947-172.17.0.21-1598125705240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39872,DS-d4179b67-0d19-45a1-a70a-bf95047c1f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-7971df92-195d-4b18-892c-03827e43f0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-c417269e-1012-4617-bdb6-c55d84c866a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-f22a5eb7-ccc9-4127-a2f1-85462ade8198,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-5657473c-6784-4be5-8070-578d43c120b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-7bff069c-a40a-4cb1-a8e9-832976d070be,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-712e7672-2381-464b-a287-d8b5dce39ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-175f9029-166d-4616-abfe-2dcd986b7d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271843598-172.17.0.21-1598125751119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39282,DS-0df52e4c-05ee-4b33-93b8-a0e5097a6529,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-9011ac2f-28b8-4831-aae0-c42334d7a9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-fbb1c2ac-97e4-48be-aee7-0eed969621cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-fc4887ec-75e2-4066-bf2d-83d9b983cd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-a653b708-3b51-4da0-8637-617d03ac0c78,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-6029e7cb-b8c6-468b-a8c6-3c1e02e0cf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-057cd8cf-383c-4423-bbe2-42bcf7da4441,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-2670964d-77ce-4fc9-ba87-75efbe9ef3bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271843598-172.17.0.21-1598125751119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39282,DS-0df52e4c-05ee-4b33-93b8-a0e5097a6529,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-9011ac2f-28b8-4831-aae0-c42334d7a9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-fbb1c2ac-97e4-48be-aee7-0eed969621cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-fc4887ec-75e2-4066-bf2d-83d9b983cd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-a653b708-3b51-4da0-8637-617d03ac0c78,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-6029e7cb-b8c6-468b-a8c6-3c1e02e0cf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-057cd8cf-383c-4423-bbe2-42bcf7da4441,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-2670964d-77ce-4fc9-ba87-75efbe9ef3bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661365557-172.17.0.21-1598125835299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45151,DS-544eccb4-48c7-4a83-a882-cdf907e712c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-557505f3-7d01-4a9f-95e3-f8a3363ec571,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-1ac5d208-1051-4d9b-b39b-c7544fa4f2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-b8b04267-4eaa-406a-9456-34a9989d5115,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-ccca6f22-97f2-4da2-8307-dc1b8b539531,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-df0b865e-dc38-4f1e-aeb7-f42594e770ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-67e2661d-3869-4858-91fa-31449fc69371,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-1fca63d0-6118-44da-9b89-acba49092324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661365557-172.17.0.21-1598125835299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45151,DS-544eccb4-48c7-4a83-a882-cdf907e712c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-557505f3-7d01-4a9f-95e3-f8a3363ec571,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-1ac5d208-1051-4d9b-b39b-c7544fa4f2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-b8b04267-4eaa-406a-9456-34a9989d5115,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-ccca6f22-97f2-4da2-8307-dc1b8b539531,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-df0b865e-dc38-4f1e-aeb7-f42594e770ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-67e2661d-3869-4858-91fa-31449fc69371,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-1fca63d0-6118-44da-9b89-acba49092324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996556887-172.17.0.21-1598126205526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39883,DS-209c8a64-7c97-4d70-b03f-36381815704b,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-ac3a071c-ac3b-4408-80e5-554855eb9a69,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-6f713091-e345-439f-8a80-eca5515e09d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-c9763c0c-d57b-4c59-b4f0-f13b703a2af1,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-e481f3ba-761f-4ebb-967f-ad30815228f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-6cedf361-128e-4ef2-be25-2db1a0a665b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-f45a00ef-82d8-452e-ab84-77bf508beb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-62550e7c-a114-4f02-9f39-c689aaaed7ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996556887-172.17.0.21-1598126205526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39883,DS-209c8a64-7c97-4d70-b03f-36381815704b,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-ac3a071c-ac3b-4408-80e5-554855eb9a69,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-6f713091-e345-439f-8a80-eca5515e09d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-c9763c0c-d57b-4c59-b4f0-f13b703a2af1,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-e481f3ba-761f-4ebb-967f-ad30815228f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-6cedf361-128e-4ef2-be25-2db1a0a665b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-f45a00ef-82d8-452e-ab84-77bf508beb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-62550e7c-a114-4f02-9f39-c689aaaed7ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104508258-172.17.0.21-1598126338951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37779,DS-e23a23f9-b99e-4ee6-a6e2-455fb966a75d,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-c6839dce-5e80-4240-8088-010b5706e53b,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-1a169bc4-44b3-4036-964f-2fb8a546b58f,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-b4da3e24-0585-49fe-af5a-df8356d6126e,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-e9f30872-e4ff-4055-a23d-01662503d588,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-34dba79d-7122-4261-a262-5c1d37b90538,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-5f6848fd-b963-4b4c-a479-7cd11409b6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-30c4e4b5-a39b-4a7a-b92f-380210340e7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104508258-172.17.0.21-1598126338951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37779,DS-e23a23f9-b99e-4ee6-a6e2-455fb966a75d,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-c6839dce-5e80-4240-8088-010b5706e53b,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-1a169bc4-44b3-4036-964f-2fb8a546b58f,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-b4da3e24-0585-49fe-af5a-df8356d6126e,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-e9f30872-e4ff-4055-a23d-01662503d588,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-34dba79d-7122-4261-a262-5c1d37b90538,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-5f6848fd-b963-4b4c-a479-7cd11409b6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-30c4e4b5-a39b-4a7a-b92f-380210340e7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695735984-172.17.0.21-1598126773543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42525,DS-0646e5bf-8102-42da-aa9f-1ff1864f86ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-b3dd64b7-1041-409f-bfb0-13e0521eb130,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-a18b9537-227c-4c6e-a261-6ab6723e5590,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-a27991d3-140d-403d-afb5-97bafc463e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-46e8e55a-48f9-4443-a46d-543f49013e52,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-6f78daa0-efa1-40d3-b5d8-32a3d2be6baf,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-401ebbd8-7ae7-4200-8a3b-82657bd513fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-24ea807d-eff2-4d87-a6ac-726792543e4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695735984-172.17.0.21-1598126773543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42525,DS-0646e5bf-8102-42da-aa9f-1ff1864f86ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-b3dd64b7-1041-409f-bfb0-13e0521eb130,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-a18b9537-227c-4c6e-a261-6ab6723e5590,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-a27991d3-140d-403d-afb5-97bafc463e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-46e8e55a-48f9-4443-a46d-543f49013e52,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-6f78daa0-efa1-40d3-b5d8-32a3d2be6baf,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-401ebbd8-7ae7-4200-8a3b-82657bd513fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-24ea807d-eff2-4d87-a6ac-726792543e4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058852211-172.17.0.21-1598126842253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-7c64c926-76bf-44f4-9f94-c38f02c650bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-e17a0a8d-6139-468f-9386-5d4752d8408a,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-dfdfd749-f743-4612-9c94-a1ba754a1778,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-7b446e0b-666a-4f08-b029-d8d3d3bb261a,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-85259764-eff7-4dd9-a0e2-dd5d92b4001a,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-e8406a89-0647-4640-9320-f0524c7eed33,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-227841b4-6d4c-48db-92fd-944d015c877e,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-9ee850da-4cda-4468-9178-5e0c58adafba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058852211-172.17.0.21-1598126842253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-7c64c926-76bf-44f4-9f94-c38f02c650bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-e17a0a8d-6139-468f-9386-5d4752d8408a,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-dfdfd749-f743-4612-9c94-a1ba754a1778,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-7b446e0b-666a-4f08-b029-d8d3d3bb261a,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-85259764-eff7-4dd9-a0e2-dd5d92b4001a,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-e8406a89-0647-4640-9320-f0524c7eed33,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-227841b4-6d4c-48db-92fd-944d015c877e,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-9ee850da-4cda-4468-9178-5e0c58adafba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928860186-172.17.0.21-1598126896611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44272,DS-23c27ff4-5561-4a78-a393-ca33a6a7319a,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-e3e9f5cc-a121-4777-8790-a816c5ea72b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-30b2859a-abd2-40a3-8b54-1370b3542867,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-4b6da22c-ae4a-4699-8a10-e408edbbe521,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-ef60393a-e353-429f-8a83-f82794550f92,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-28f57b19-6ab4-4e64-95bf-e84d21a998c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-ba2b6cb3-0130-42bc-878c-329e7c9d24c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-0c25a233-d578-4be4-800a-b295df2a4829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-928860186-172.17.0.21-1598126896611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44272,DS-23c27ff4-5561-4a78-a393-ca33a6a7319a,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-e3e9f5cc-a121-4777-8790-a816c5ea72b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-30b2859a-abd2-40a3-8b54-1370b3542867,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-4b6da22c-ae4a-4699-8a10-e408edbbe521,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-ef60393a-e353-429f-8a83-f82794550f92,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-28f57b19-6ab4-4e64-95bf-e84d21a998c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-ba2b6cb3-0130-42bc-878c-329e7c9d24c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-0c25a233-d578-4be4-800a-b295df2a4829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123352386-172.17.0.21-1598127100754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46760,DS-4b54dd48-cbb8-4084-bba6-fe8c54d372e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-df74cb96-7a84-4c1e-86d5-6c81f2efc676,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-7e99a378-df22-4f31-aff7-66487566463f,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-0c396e1a-1bdb-4846-8bb2-a4166cc32195,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-35736ac3-b260-42ab-a149-d974c9d6754a,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-35a7a713-7e3c-4c0a-a7f8-e5265b491380,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-b19ac88d-1ddc-405d-aa5c-3db325379e71,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-ce9490b0-078d-42aa-a235-e741d510848c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123352386-172.17.0.21-1598127100754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46760,DS-4b54dd48-cbb8-4084-bba6-fe8c54d372e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-df74cb96-7a84-4c1e-86d5-6c81f2efc676,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-7e99a378-df22-4f31-aff7-66487566463f,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-0c396e1a-1bdb-4846-8bb2-a4166cc32195,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-35736ac3-b260-42ab-a149-d974c9d6754a,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-35a7a713-7e3c-4c0a-a7f8-e5265b491380,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-b19ac88d-1ddc-405d-aa5c-3db325379e71,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-ce9490b0-078d-42aa-a235-e741d510848c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543580902-172.17.0.21-1598127191584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32862,DS-522ebca7-3ff6-44bf-9530-f8756dc460ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-284b24f9-19b9-405a-8f06-5c3148a210a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-b34dbe74-23a4-4794-bc38-fbf74367a6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-3795f860-dff0-4d0d-bcaf-9b3e1eafe6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-e4b356aa-20bb-4c81-aa9c-e3709ae37524,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-f3bff860-049a-4a55-8ab1-97901c024a84,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-1d5726a4-12ad-4a70-a982-03a7a5e2264a,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-8a2c40a8-fe4d-4955-a10c-dd239cd2203a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543580902-172.17.0.21-1598127191584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32862,DS-522ebca7-3ff6-44bf-9530-f8756dc460ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-284b24f9-19b9-405a-8f06-5c3148a210a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-b34dbe74-23a4-4794-bc38-fbf74367a6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-3795f860-dff0-4d0d-bcaf-9b3e1eafe6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-e4b356aa-20bb-4c81-aa9c-e3709ae37524,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-f3bff860-049a-4a55-8ab1-97901c024a84,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-1d5726a4-12ad-4a70-a982-03a7a5e2264a,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-8a2c40a8-fe4d-4955-a10c-dd239cd2203a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722458164-172.17.0.21-1598127511429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44316,DS-3965a761-2ada-4dfc-8403-6d1843398ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-3b53424a-df93-4ed7-b942-d4ee8c982358,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-73e5ed52-9da4-4f16-9edd-cd289c20ef31,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-59f43582-646d-4efc-ac97-839d856cbfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-4e704507-a0d8-4496-9866-706e1d410188,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-8e61c22f-c0eb-43ab-9ec1-186ac95a2883,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-be3e5a76-5214-4b28-b00f-359fc5f77313,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-04e9f5a0-3c37-4adb-acb3-1259a9bcc802,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722458164-172.17.0.21-1598127511429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44316,DS-3965a761-2ada-4dfc-8403-6d1843398ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-3b53424a-df93-4ed7-b942-d4ee8c982358,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-73e5ed52-9da4-4f16-9edd-cd289c20ef31,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-59f43582-646d-4efc-ac97-839d856cbfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-4e704507-a0d8-4496-9866-706e1d410188,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-8e61c22f-c0eb-43ab-9ec1-186ac95a2883,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-be3e5a76-5214-4b28-b00f-359fc5f77313,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-04e9f5a0-3c37-4adb-acb3-1259a9bcc802,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146918832-172.17.0.21-1598127722605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42250,DS-1f1fde1d-8a41-42ab-8c93-e74a23a311ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-fca3dab0-c9f1-4773-a7c5-e888c4ecb354,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-a44ff755-5879-4fb8-bc24-4b6a942d5ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-528452de-c39b-4187-bb84-2a8073cf284f,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-4bd9e338-fbc1-4300-826a-6b6355654237,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-90f12641-195a-42f7-ba29-e156f467b36a,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-a809d6ef-2302-4b0a-babb-36d8577888ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-15bc8e76-1e85-46bc-ade8-3b003346e655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146918832-172.17.0.21-1598127722605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42250,DS-1f1fde1d-8a41-42ab-8c93-e74a23a311ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-fca3dab0-c9f1-4773-a7c5-e888c4ecb354,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-a44ff755-5879-4fb8-bc24-4b6a942d5ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-528452de-c39b-4187-bb84-2a8073cf284f,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-4bd9e338-fbc1-4300-826a-6b6355654237,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-90f12641-195a-42f7-ba29-e156f467b36a,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-a809d6ef-2302-4b0a-babb-36d8577888ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-15bc8e76-1e85-46bc-ade8-3b003346e655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6101
