reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361456318-172.17.0.2-1598135721213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36406,DS-601c46e0-96e7-4f9b-989a-2688696b0dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-fcd87078-f285-47ed-a313-1c36d47b3186,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-077cad51-34a2-4119-84a3-461628766b97,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-379eab72-31ba-45be-8d66-4b3fb76dbe11,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-78faed65-857c-4ee4-972c-816030734050,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-938f66a9-9c0e-4f08-b449-a2cd395af93b,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-cf233581-1922-4cdc-96e4-f42615f6819e,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-1014bdff-18af-49c5-bdd5-5e0663fe32b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361456318-172.17.0.2-1598135721213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36406,DS-601c46e0-96e7-4f9b-989a-2688696b0dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-fcd87078-f285-47ed-a313-1c36d47b3186,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-077cad51-34a2-4119-84a3-461628766b97,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-379eab72-31ba-45be-8d66-4b3fb76dbe11,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-78faed65-857c-4ee4-972c-816030734050,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-938f66a9-9c0e-4f08-b449-a2cd395af93b,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-cf233581-1922-4cdc-96e4-f42615f6819e,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-1014bdff-18af-49c5-bdd5-5e0663fe32b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796160593-172.17.0.2-1598135795289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33799,DS-06b20b29-c8eb-4e62-9986-d36ac7c71ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-1ec15ca5-142a-463d-8cd1-244a4ad3e926,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-18da4f9f-1f1f-4cdc-aaab-7ccbc88c70e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-3043bb4b-0f2c-497d-8737-7335b6941d76,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-1cc07003-7854-4d5f-83a5-38f5a95e8337,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-afedcf88-105c-47ce-a0ed-4768d3757b56,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-39031d2d-5182-4e13-9bc6-e1e1bee596bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-9c5192ca-eee1-41a7-910b-b022fafe41a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796160593-172.17.0.2-1598135795289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33799,DS-06b20b29-c8eb-4e62-9986-d36ac7c71ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-1ec15ca5-142a-463d-8cd1-244a4ad3e926,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-18da4f9f-1f1f-4cdc-aaab-7ccbc88c70e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-3043bb4b-0f2c-497d-8737-7335b6941d76,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-1cc07003-7854-4d5f-83a5-38f5a95e8337,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-afedcf88-105c-47ce-a0ed-4768d3757b56,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-39031d2d-5182-4e13-9bc6-e1e1bee596bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-9c5192ca-eee1-41a7-910b-b022fafe41a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314057098-172.17.0.2-1598135929170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40222,DS-958a3b6a-69f2-476b-8882-125807471a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-d56495e3-f707-4f13-880e-08c5e58cb80f,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-92ce5b9a-0996-48ce-a0ec-321748251710,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-bcea9277-bf87-45ec-b98e-c89278baaea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-d5cd117c-cc94-4b07-b1cc-7ba11781beb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-56543073-ca9f-4e97-91d8-8119352b51d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-c2c7a272-dea7-46a9-b7b6-4977d1f7dd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-a04dbacf-4a54-440e-bde3-3c6fa7cbe789,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314057098-172.17.0.2-1598135929170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40222,DS-958a3b6a-69f2-476b-8882-125807471a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-d56495e3-f707-4f13-880e-08c5e58cb80f,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-92ce5b9a-0996-48ce-a0ec-321748251710,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-bcea9277-bf87-45ec-b98e-c89278baaea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-d5cd117c-cc94-4b07-b1cc-7ba11781beb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-56543073-ca9f-4e97-91d8-8119352b51d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-c2c7a272-dea7-46a9-b7b6-4977d1f7dd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-a04dbacf-4a54-440e-bde3-3c6fa7cbe789,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532007726-172.17.0.2-1598136047003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35645,DS-ea7207fd-6a18-4458-b4ea-7199bd1cbda5,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-cc3187bc-3e00-4b24-a18c-31d3f1bd3b12,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-de8140fe-e989-4e30-95f0-6f48ee8fec73,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-9c6652ad-4fe2-4348-96a4-d2fce7eff96e,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-d6b28fee-a9cc-4b20-be76-abc1e7b1b847,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-a4864beb-64ff-4059-91c8-76c5b28fea38,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-7ffe4bd5-c716-4b4a-b5f4-6ad195a460a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-7709bd35-e3b6-4095-b8ce-c0b978ab97b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532007726-172.17.0.2-1598136047003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35645,DS-ea7207fd-6a18-4458-b4ea-7199bd1cbda5,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-cc3187bc-3e00-4b24-a18c-31d3f1bd3b12,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-de8140fe-e989-4e30-95f0-6f48ee8fec73,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-9c6652ad-4fe2-4348-96a4-d2fce7eff96e,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-d6b28fee-a9cc-4b20-be76-abc1e7b1b847,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-a4864beb-64ff-4059-91c8-76c5b28fea38,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-7ffe4bd5-c716-4b4a-b5f4-6ad195a460a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-7709bd35-e3b6-4095-b8ce-c0b978ab97b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345016567-172.17.0.2-1598136386662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40920,DS-087fcaa4-0614-4501-829c-6d96602c894c,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-c68c8063-9462-4e02-ae64-642c71711e54,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-5ec47555-ac0c-4fe3-b5a0-47796244fe50,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-0aac25e2-052f-4653-913f-be5b2484496f,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-7677be3f-84f0-46e6-bb83-ade6217eeaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-2b0e8d73-0534-4bd2-8886-5e0388b5fb17,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-917a2427-4278-4c82-87b5-16c7874b127c,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-88153802-dbb8-4d5e-b163-d3f3e0944913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345016567-172.17.0.2-1598136386662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40920,DS-087fcaa4-0614-4501-829c-6d96602c894c,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-c68c8063-9462-4e02-ae64-642c71711e54,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-5ec47555-ac0c-4fe3-b5a0-47796244fe50,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-0aac25e2-052f-4653-913f-be5b2484496f,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-7677be3f-84f0-46e6-bb83-ade6217eeaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-2b0e8d73-0534-4bd2-8886-5e0388b5fb17,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-917a2427-4278-4c82-87b5-16c7874b127c,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-88153802-dbb8-4d5e-b163-d3f3e0944913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514743046-172.17.0.2-1598136518309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37549,DS-0a9814fb-3f66-46c2-a2a7-3513d7d7fe03,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-acf0afb3-117e-4375-9b76-3fdd2c09beba,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-3cb8d57c-54eb-4729-b8fc-41badc2e1c21,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-e28e682c-1f84-4118-a8fb-27c8a641b573,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-466e9499-d1cc-48bc-ac8e-557563e362de,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-9dd041ad-e11e-4823-aebc-5cfb4d72a757,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-793a1373-e2bb-4269-af94-26527cf7e2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-1df94193-5862-4226-b8a8-a32068955383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514743046-172.17.0.2-1598136518309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37549,DS-0a9814fb-3f66-46c2-a2a7-3513d7d7fe03,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-acf0afb3-117e-4375-9b76-3fdd2c09beba,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-3cb8d57c-54eb-4729-b8fc-41badc2e1c21,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-e28e682c-1f84-4118-a8fb-27c8a641b573,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-466e9499-d1cc-48bc-ac8e-557563e362de,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-9dd041ad-e11e-4823-aebc-5cfb4d72a757,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-793a1373-e2bb-4269-af94-26527cf7e2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-1df94193-5862-4226-b8a8-a32068955383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730476780-172.17.0.2-1598137171870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36228,DS-102ebb69-9da2-49f4-a3b3-a70eda2e8f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-a4146608-f844-4a8f-9deb-b4742e8aa406,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-d71316da-47f1-4086-a141-492db4e339fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-8b1cf0af-a859-4a42-b9bb-94737418eebf,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-a00ae74d-a3f6-4cc1-99e3-43986bd87cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-bea6a7a3-c9fd-40cc-a38c-34c5be3b6234,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-6726737f-36c3-43b3-87e4-f6c6eeab2922,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-3e88a9c3-990d-4b35-816c-fdcaeb858d8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730476780-172.17.0.2-1598137171870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36228,DS-102ebb69-9da2-49f4-a3b3-a70eda2e8f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-a4146608-f844-4a8f-9deb-b4742e8aa406,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-d71316da-47f1-4086-a141-492db4e339fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-8b1cf0af-a859-4a42-b9bb-94737418eebf,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-a00ae74d-a3f6-4cc1-99e3-43986bd87cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-bea6a7a3-c9fd-40cc-a38c-34c5be3b6234,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-6726737f-36c3-43b3-87e4-f6c6eeab2922,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-3e88a9c3-990d-4b35-816c-fdcaeb858d8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316121845-172.17.0.2-1598137209168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46598,DS-d44f177f-4f75-4b7a-8514-0f43fb51fd25,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-fdea3865-9564-4dd8-b1b3-29d3f706f8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-79f6c33c-efef-4190-bae7-65716f056411,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-6f9e875b-4a08-404d-a1bd-70a1a4aff9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-b67e17a6-c10f-43e2-9a9b-3220a7f1add7,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-5fe20611-bcea-4e30-a41c-1b9f5d4a8ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-7edf6990-f7f2-4ad1-affc-5702a4520e66,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-588574c5-db83-4cd5-a7f8-229589842b18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316121845-172.17.0.2-1598137209168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46598,DS-d44f177f-4f75-4b7a-8514-0f43fb51fd25,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-fdea3865-9564-4dd8-b1b3-29d3f706f8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-79f6c33c-efef-4190-bae7-65716f056411,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-6f9e875b-4a08-404d-a1bd-70a1a4aff9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-b67e17a6-c10f-43e2-9a9b-3220a7f1add7,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-5fe20611-bcea-4e30-a41c-1b9f5d4a8ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-7edf6990-f7f2-4ad1-affc-5702a4520e66,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-588574c5-db83-4cd5-a7f8-229589842b18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537736164-172.17.0.2-1598137554796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37219,DS-5c1fbda4-f6c9-4719-b791-730301d47c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-22b4c180-028d-43c6-b0fa-0d55606e393e,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-d696d5da-aa6a-44c9-a1a9-12d8bfa42e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-6606eb1a-ea6e-4087-8022-da2084796767,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-e777af11-4229-4495-b4d7-2f58d3eca20c,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-86e30e9a-d19c-4891-b912-0a5f40fe9d28,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-05b593c8-84db-4dcd-8e5f-c51c1b5f326b,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-bbf4b884-45a5-48c3-a62b-34bb68aa5565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537736164-172.17.0.2-1598137554796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37219,DS-5c1fbda4-f6c9-4719-b791-730301d47c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-22b4c180-028d-43c6-b0fa-0d55606e393e,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-d696d5da-aa6a-44c9-a1a9-12d8bfa42e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-6606eb1a-ea6e-4087-8022-da2084796767,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-e777af11-4229-4495-b4d7-2f58d3eca20c,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-86e30e9a-d19c-4891-b912-0a5f40fe9d28,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-05b593c8-84db-4dcd-8e5f-c51c1b5f326b,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-bbf4b884-45a5-48c3-a62b-34bb68aa5565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918284470-172.17.0.2-1598137587949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36826,DS-26f665cd-c57a-4968-bd6b-2512c31b470a,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-606e305d-6532-4cd1-8cb7-4411ffd84c53,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-239a77f0-1a3c-4672-a092-ad86cdeaa363,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-99e92e0b-9013-47a9-99de-ce1b34998655,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-36541e6d-7f50-4af1-90b4-3bc731b78812,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-6c0cfba4-38d0-4280-8262-95ce09af2262,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-65fb10ea-a336-4608-b878-ce4c8a9b4ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-ed548e9c-0692-4dad-8bcb-0a8b0dcae84b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918284470-172.17.0.2-1598137587949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36826,DS-26f665cd-c57a-4968-bd6b-2512c31b470a,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-606e305d-6532-4cd1-8cb7-4411ffd84c53,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-239a77f0-1a3c-4672-a092-ad86cdeaa363,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-99e92e0b-9013-47a9-99de-ce1b34998655,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-36541e6d-7f50-4af1-90b4-3bc731b78812,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-6c0cfba4-38d0-4280-8262-95ce09af2262,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-65fb10ea-a336-4608-b878-ce4c8a9b4ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-ed548e9c-0692-4dad-8bcb-0a8b0dcae84b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564167412-172.17.0.2-1598137805379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43755,DS-fb144ba7-78f7-4ac4-9e85-3dc34d1d2dec,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-8c5f39e0-0f54-479f-8d84-544a4bdd1f29,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-7af27133-382a-432f-aa7d-4f51276bb771,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-16d76a4b-bf52-40bd-ac96-a98185b43e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-f99e31b8-03d9-46ea-9178-7596f8ad0052,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-314b41ef-07d3-4b5e-a5a5-b81e5f39e4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-3f2cc5f7-5ba7-4150-8bb4-54dc98b94aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-6befbd21-d956-4918-9023-c9f147dd7ba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564167412-172.17.0.2-1598137805379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43755,DS-fb144ba7-78f7-4ac4-9e85-3dc34d1d2dec,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-8c5f39e0-0f54-479f-8d84-544a4bdd1f29,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-7af27133-382a-432f-aa7d-4f51276bb771,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-16d76a4b-bf52-40bd-ac96-a98185b43e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-f99e31b8-03d9-46ea-9178-7596f8ad0052,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-314b41ef-07d3-4b5e-a5a5-b81e5f39e4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-3f2cc5f7-5ba7-4150-8bb4-54dc98b94aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-6befbd21-d956-4918-9023-c9f147dd7ba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698354217-172.17.0.2-1598137969972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41180,DS-ca849c33-c2a1-4ffd-844d-6329ad0f8303,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-b6ccf22f-bfa2-4cae-a478-02e96046725c,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-56b731b9-2cc2-479e-9325-43c6ee1ea5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-daa8e006-5176-4335-ae33-900f6ba91f17,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-583402d4-4c38-4aae-9c86-3336d592419a,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-d26b40f1-8005-43d2-b512-29b3effebefe,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-1ee5c926-5163-4a3e-9190-d56afb783ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-f656d80b-2a38-44cd-a3ef-43593469fcfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698354217-172.17.0.2-1598137969972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41180,DS-ca849c33-c2a1-4ffd-844d-6329ad0f8303,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-b6ccf22f-bfa2-4cae-a478-02e96046725c,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-56b731b9-2cc2-479e-9325-43c6ee1ea5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-daa8e006-5176-4335-ae33-900f6ba91f17,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-583402d4-4c38-4aae-9c86-3336d592419a,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-d26b40f1-8005-43d2-b512-29b3effebefe,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-1ee5c926-5163-4a3e-9190-d56afb783ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-f656d80b-2a38-44cd-a3ef-43593469fcfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083661905-172.17.0.2-1598138056623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41891,DS-41c6f4bf-fc29-4137-8498-439f7d5925a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-5934420b-8f5d-4f37-b9ff-c5dda0c979a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-4d31a673-9356-4a0e-9e9b-3a2208098cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-f5251758-dab7-4321-b119-22037be63cba,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-fb46bb6a-7a9f-4584-8508-72cf536403b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-a6f4b9db-fcf2-45f4-8349-4c79a04db02b,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-f8fc35d5-ea83-4234-9226-0da847020430,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-d4a27c9f-11de-4a6a-93be-6877efc72b91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083661905-172.17.0.2-1598138056623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41891,DS-41c6f4bf-fc29-4137-8498-439f7d5925a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-5934420b-8f5d-4f37-b9ff-c5dda0c979a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-4d31a673-9356-4a0e-9e9b-3a2208098cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-f5251758-dab7-4321-b119-22037be63cba,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-fb46bb6a-7a9f-4584-8508-72cf536403b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-a6f4b9db-fcf2-45f4-8349-4c79a04db02b,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-f8fc35d5-ea83-4234-9226-0da847020430,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-d4a27c9f-11de-4a6a-93be-6877efc72b91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019743962-172.17.0.2-1598138117354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32824,DS-36d3ac56-eaec-496e-817e-5c45c808bcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-fab3d0d5-e092-4eb3-9ba3-8052ab2e26b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-5ce9852f-5b30-4233-b067-1bd60f4d378e,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-1e499dc3-af67-4cab-979a-9431c5790afc,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-ee07616b-6066-49dd-82b4-11e710a93bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-c8ccaae4-8e90-438d-b463-c5cce9e338ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-3d0fbae5-7335-43d5-8fca-393eea2bbc68,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-1cf4fe2f-c97a-4933-8004-ce1445afde59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019743962-172.17.0.2-1598138117354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32824,DS-36d3ac56-eaec-496e-817e-5c45c808bcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-fab3d0d5-e092-4eb3-9ba3-8052ab2e26b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-5ce9852f-5b30-4233-b067-1bd60f4d378e,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-1e499dc3-af67-4cab-979a-9431c5790afc,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-ee07616b-6066-49dd-82b4-11e710a93bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-c8ccaae4-8e90-438d-b463-c5cce9e338ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-3d0fbae5-7335-43d5-8fca-393eea2bbc68,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-1cf4fe2f-c97a-4933-8004-ce1445afde59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777011815-172.17.0.2-1598138715480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37879,DS-c9bb8762-11ca-4fd3-bb2c-e73074cacb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-7ffdd5ef-c183-44e2-9221-994740c2714f,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-164170db-8c5f-481e-996a-2f2c7729abe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-81fe2bab-c6c3-4188-9afa-bd6b28907530,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-eb5253c0-4841-4327-bcaa-4c6731703b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-05219fa7-93fb-4c4f-8981-aade463b762e,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-29e22277-1336-46ea-b34f-2a17caf10090,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-22e4c391-0058-490b-855f-32f8a891d279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777011815-172.17.0.2-1598138715480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37879,DS-c9bb8762-11ca-4fd3-bb2c-e73074cacb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-7ffdd5ef-c183-44e2-9221-994740c2714f,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-164170db-8c5f-481e-996a-2f2c7729abe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-81fe2bab-c6c3-4188-9afa-bd6b28907530,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-eb5253c0-4841-4327-bcaa-4c6731703b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-05219fa7-93fb-4c4f-8981-aade463b762e,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-29e22277-1336-46ea-b34f-2a17caf10090,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-22e4c391-0058-490b-855f-32f8a891d279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949513548-172.17.0.2-1598138773906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42017,DS-18891c1d-c6b1-4d48-b5cc-27e3396e031d,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-724d4108-2f89-40f5-83bc-552e5a2ef9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-7a992206-8c0d-42f1-b956-52ff1095abf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-caf78d04-96d8-45bb-9b5c-87964862f9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-40089596-b2c0-45a6-8c00-cd5201700c09,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-274186cb-10f0-4f52-bc97-4ce189a3d691,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-4d135bf5-7675-4b72-a66c-2e7a7bd901d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-5b085c18-f011-4ac1-810a-e30b7514177d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949513548-172.17.0.2-1598138773906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42017,DS-18891c1d-c6b1-4d48-b5cc-27e3396e031d,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-724d4108-2f89-40f5-83bc-552e5a2ef9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-7a992206-8c0d-42f1-b956-52ff1095abf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-caf78d04-96d8-45bb-9b5c-87964862f9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-40089596-b2c0-45a6-8c00-cd5201700c09,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-274186cb-10f0-4f52-bc97-4ce189a3d691,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-4d135bf5-7675-4b72-a66c-2e7a7bd901d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-5b085c18-f011-4ac1-810a-e30b7514177d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349494340-172.17.0.2-1598139698767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44848,DS-8c046176-87c8-45f3-9cbe-4528c5100f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-d154c936-70b4-4a02-8f2c-b78d2dec014c,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-e7a6b0e3-9aee-4fb2-ae9a-94c334c7d927,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-1df69d77-2f61-476c-97ff-72d0631686ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-d6ab6c3a-d597-465d-a93c-0ce99dff5c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-2c16912f-4207-4959-b358-33f8651f4699,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-c9c00ecc-c6dc-4ee7-a253-32f3dc2c48c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-4cc1dc71-9f4b-48c0-9543-e59e73e980cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349494340-172.17.0.2-1598139698767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44848,DS-8c046176-87c8-45f3-9cbe-4528c5100f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-d154c936-70b4-4a02-8f2c-b78d2dec014c,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-e7a6b0e3-9aee-4fb2-ae9a-94c334c7d927,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-1df69d77-2f61-476c-97ff-72d0631686ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-d6ab6c3a-d597-465d-a93c-0ce99dff5c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-2c16912f-4207-4959-b358-33f8651f4699,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-c9c00ecc-c6dc-4ee7-a253-32f3dc2c48c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-4cc1dc71-9f4b-48c0-9543-e59e73e980cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785613761-172.17.0.2-1598140209052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41826,DS-f733f630-f701-445e-8b80-c74e9c2319ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-8bc78a4d-e8a7-41d6-b9e2-05c0cdf1740d,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-304e6892-b544-4926-9e3a-7e8b91a19179,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-02d85128-323f-48c2-a7ff-ae8ddca3febe,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-3129c84f-ebc1-48db-b377-f7526fafa541,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-bc4d8b3d-4d69-4fe3-8f0f-cfab6ce3ae38,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-f854b007-a604-4ad7-9d10-8502c32189c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-edf61ab6-6d34-4083-9bfc-2ad165bac620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785613761-172.17.0.2-1598140209052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41826,DS-f733f630-f701-445e-8b80-c74e9c2319ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-8bc78a4d-e8a7-41d6-b9e2-05c0cdf1740d,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-304e6892-b544-4926-9e3a-7e8b91a19179,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-02d85128-323f-48c2-a7ff-ae8ddca3febe,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-3129c84f-ebc1-48db-b377-f7526fafa541,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-bc4d8b3d-4d69-4fe3-8f0f-cfab6ce3ae38,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-f854b007-a604-4ad7-9d10-8502c32189c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-edf61ab6-6d34-4083-9bfc-2ad165bac620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749602882-172.17.0.2-1598140348583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35884,DS-6edbfcb1-161e-4fd9-873b-99d9364a0333,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-93430fe8-9029-40eb-9841-b4da3c0d3357,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-8e9791be-c4c5-49b8-815a-35956184a8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-67c5e440-6f34-4f62-9f27-1301209e4f19,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-39c7c301-1498-4abe-9a8a-c6f064ff1f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-faadbd3c-40fd-46c0-8d00-2364619c60cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-33be62d0-d40e-4c5d-8513-375bdd2ccf20,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-3b63dc88-4b7c-4aeb-81a2-df8422f0bc7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749602882-172.17.0.2-1598140348583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35884,DS-6edbfcb1-161e-4fd9-873b-99d9364a0333,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-93430fe8-9029-40eb-9841-b4da3c0d3357,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-8e9791be-c4c5-49b8-815a-35956184a8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-67c5e440-6f34-4f62-9f27-1301209e4f19,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-39c7c301-1498-4abe-9a8a-c6f064ff1f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-faadbd3c-40fd-46c0-8d00-2364619c60cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-33be62d0-d40e-4c5d-8513-375bdd2ccf20,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-3b63dc88-4b7c-4aeb-81a2-df8422f0bc7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5048
