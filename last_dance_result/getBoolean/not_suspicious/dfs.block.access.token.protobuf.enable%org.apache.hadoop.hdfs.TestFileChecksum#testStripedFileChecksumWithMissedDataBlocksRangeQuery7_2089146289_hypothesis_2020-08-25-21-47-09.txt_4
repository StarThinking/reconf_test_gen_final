reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410017147-172.17.0.11-1598392045067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37529,DS-70ceb53b-b441-42fa-a1ab-bda88e65978f,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-faf2461a-2e6a-48b7-b400-a9a9eaf01471,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-f0abf651-d149-4705-a71b-a70ed1b681db,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-ffefd534-bdd1-4695-9990-592590284ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-ce24e3f0-e697-4589-95d0-a6a377f2fddd,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-f011dea9-5c78-45b1-9804-1d29e0be602e,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-a47995f3-fe9d-48bc-b980-7b81e2527d06,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-4b1bc804-fe9c-45b5-b445-a79147d82ff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410017147-172.17.0.11-1598392045067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37529,DS-70ceb53b-b441-42fa-a1ab-bda88e65978f,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-faf2461a-2e6a-48b7-b400-a9a9eaf01471,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-f0abf651-d149-4705-a71b-a70ed1b681db,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-ffefd534-bdd1-4695-9990-592590284ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-ce24e3f0-e697-4589-95d0-a6a377f2fddd,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-f011dea9-5c78-45b1-9804-1d29e0be602e,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-a47995f3-fe9d-48bc-b980-7b81e2527d06,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-4b1bc804-fe9c-45b5-b445-a79147d82ff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755991755-172.17.0.11-1598392320404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40131,DS-48135688-e02f-431b-92be-ab882b07f78f,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-10679200-bbe5-414e-bbf1-3b9738171192,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-0b7b783c-d434-4115-b3bd-18cc029d5e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-82301750-eb90-4060-a180-2863611ca14d,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-fc1ed830-3507-44fa-a547-0217539edbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-b5d954c7-2b09-4ac3-b5fb-60bc1930f249,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-98fad348-97a5-4f51-8cdb-f1e1569aff76,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-164734e2-6c10-408a-a87e-d55c13b6d912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755991755-172.17.0.11-1598392320404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40131,DS-48135688-e02f-431b-92be-ab882b07f78f,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-10679200-bbe5-414e-bbf1-3b9738171192,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-0b7b783c-d434-4115-b3bd-18cc029d5e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-82301750-eb90-4060-a180-2863611ca14d,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-fc1ed830-3507-44fa-a547-0217539edbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-b5d954c7-2b09-4ac3-b5fb-60bc1930f249,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-98fad348-97a5-4f51-8cdb-f1e1569aff76,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-164734e2-6c10-408a-a87e-d55c13b6d912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896709234-172.17.0.11-1598392446386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39575,DS-3a6f7bf7-428b-4c63-b952-8bcb125d7d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-8e694642-d759-49b0-bdb4-f589c722d3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-4904dddc-ea88-40c4-b4fc-93e769d087ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-ddc9318d-8663-4a35-8ccc-3775518dc10a,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-15f56ded-9dd9-4eff-9c90-dde186ddbee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-c6234b65-472a-41ec-8c8c-05763ad2badb,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-2ebac373-9806-4f28-9521-ba9a98f35c31,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-16439390-f595-4c4a-885e-e9a48041a0f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896709234-172.17.0.11-1598392446386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39575,DS-3a6f7bf7-428b-4c63-b952-8bcb125d7d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-8e694642-d759-49b0-bdb4-f589c722d3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-4904dddc-ea88-40c4-b4fc-93e769d087ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-ddc9318d-8663-4a35-8ccc-3775518dc10a,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-15f56ded-9dd9-4eff-9c90-dde186ddbee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-c6234b65-472a-41ec-8c8c-05763ad2badb,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-2ebac373-9806-4f28-9521-ba9a98f35c31,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-16439390-f595-4c4a-885e-e9a48041a0f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629098763-172.17.0.11-1598392520083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42051,DS-2d028085-c7f9-4c95-9ac3-07b161a7bc69,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-a65e0669-ef1d-4998-8fd1-e285c575ee3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-88594e16-ef42-4463-97c5-48cdb3ccf295,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-f4ff1162-a0e7-4413-ae36-ef373ccce277,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-fbbb2fb6-d7af-4e72-9ad3-ac081f83a521,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-b0c89967-732f-4ce7-9d86-3d942f984f38,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-46d6d30b-f4e7-4f76-ac74-46378d11f8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-2c5c52e7-ba77-42ed-b921-c76b10ce861a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629098763-172.17.0.11-1598392520083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42051,DS-2d028085-c7f9-4c95-9ac3-07b161a7bc69,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-a65e0669-ef1d-4998-8fd1-e285c575ee3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-88594e16-ef42-4463-97c5-48cdb3ccf295,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-f4ff1162-a0e7-4413-ae36-ef373ccce277,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-fbbb2fb6-d7af-4e72-9ad3-ac081f83a521,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-b0c89967-732f-4ce7-9d86-3d942f984f38,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-46d6d30b-f4e7-4f76-ac74-46378d11f8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-2c5c52e7-ba77-42ed-b921-c76b10ce861a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914685289-172.17.0.11-1598392632817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44863,DS-f9ea9db6-71e3-4f65-9aae-00d854d6aad1,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-f0bc8f5e-3e9a-478c-bb6a-d06f743773fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-302aa94a-a1bd-4927-b62b-454a729dbbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-c2f1c271-b717-4b06-8fc7-ca6f1a3211c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-e3c0fe28-3dfe-41da-a6ac-4cd2330520cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-3653239a-4772-4d90-bd02-42da2789fd74,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-0ebe5800-c603-4666-bb97-277a56b55318,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-bdf9d73c-4bcd-4edb-a7c9-a4f84f7c6f07,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914685289-172.17.0.11-1598392632817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44863,DS-f9ea9db6-71e3-4f65-9aae-00d854d6aad1,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-f0bc8f5e-3e9a-478c-bb6a-d06f743773fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-302aa94a-a1bd-4927-b62b-454a729dbbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-c2f1c271-b717-4b06-8fc7-ca6f1a3211c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-e3c0fe28-3dfe-41da-a6ac-4cd2330520cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-3653239a-4772-4d90-bd02-42da2789fd74,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-0ebe5800-c603-4666-bb97-277a56b55318,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-bdf9d73c-4bcd-4edb-a7c9-a4f84f7c6f07,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786091220-172.17.0.11-1598392699465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35349,DS-423c708e-e523-4a2b-9733-70d1eafaac5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-eda45905-be6b-467a-9044-e71c0f1090b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-72cb4357-0dd3-4e21-97b3-c193ce144713,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-be01edcc-e962-4488-b151-225e3a5a339c,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-507340b7-8733-433f-8bc7-57fdcb4d7fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-a32177da-1c86-4bd7-934e-852544bcfb07,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-5fd86d9b-dfd9-4feb-adb9-d4602936e1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-fb194b38-b75d-4a5c-9154-e60481fa27e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786091220-172.17.0.11-1598392699465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35349,DS-423c708e-e523-4a2b-9733-70d1eafaac5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-eda45905-be6b-467a-9044-e71c0f1090b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-72cb4357-0dd3-4e21-97b3-c193ce144713,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-be01edcc-e962-4488-b151-225e3a5a339c,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-507340b7-8733-433f-8bc7-57fdcb4d7fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-a32177da-1c86-4bd7-934e-852544bcfb07,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-5fd86d9b-dfd9-4feb-adb9-d4602936e1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-fb194b38-b75d-4a5c-9154-e60481fa27e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541106882-172.17.0.11-1598392729048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37012,DS-afececa8-ae38-4ae3-9051-e34df280c216,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-d245a541-5b19-4f8d-8487-434efb079157,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-8d28d199-5a73-419e-ac6b-551a945d36d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-57fe2637-cace-469d-b36c-5d3d6ffe33b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-e0b0854c-162b-4676-981f-82f05bdfbce4,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-7a9b0a60-c1ae-4465-8b4b-fca7c6664c01,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-165a4aa7-5f20-45c7-8fa5-58102bd7be6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-5dbf441f-957d-401a-8a0b-a9c8425fc2f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541106882-172.17.0.11-1598392729048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37012,DS-afececa8-ae38-4ae3-9051-e34df280c216,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-d245a541-5b19-4f8d-8487-434efb079157,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-8d28d199-5a73-419e-ac6b-551a945d36d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-57fe2637-cace-469d-b36c-5d3d6ffe33b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-e0b0854c-162b-4676-981f-82f05bdfbce4,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-7a9b0a60-c1ae-4465-8b4b-fca7c6664c01,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-165a4aa7-5f20-45c7-8fa5-58102bd7be6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-5dbf441f-957d-401a-8a0b-a9c8425fc2f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667764996-172.17.0.11-1598392968554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45003,DS-bbbc8992-52fb-4589-9963-67be477327d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-cb5eb35b-bdd1-4e5e-a5be-356a989ecc89,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-aa2a3705-5ffd-46d9-a54e-d5133c2fa613,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-8ed1cb11-7256-4b4f-b570-1355932cbf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-c81f1c51-bfcb-4dbe-bd8b-c9b1d8cb32ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-86a0d34b-fb08-4038-8b1f-8a07a05a553b,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-55e1248b-5747-4ed9-9b2e-a9aa253ad884,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-539686f4-99e5-4ffb-87d3-446b8e85dd2e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667764996-172.17.0.11-1598392968554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45003,DS-bbbc8992-52fb-4589-9963-67be477327d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-cb5eb35b-bdd1-4e5e-a5be-356a989ecc89,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-aa2a3705-5ffd-46d9-a54e-d5133c2fa613,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-8ed1cb11-7256-4b4f-b570-1355932cbf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-c81f1c51-bfcb-4dbe-bd8b-c9b1d8cb32ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-86a0d34b-fb08-4038-8b1f-8a07a05a553b,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-55e1248b-5747-4ed9-9b2e-a9aa253ad884,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-539686f4-99e5-4ffb-87d3-446b8e85dd2e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255877706-172.17.0.11-1598393095724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33569,DS-5d32f693-988c-4dc1-bb8a-cff531e477f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-7d87783c-ddb4-49c1-b8d5-db573f5f6f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-e74e346d-3750-4128-a236-37370d7c40eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-5432efb2-f14a-4192-a031-a8657302c9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-b0ae0653-5889-4f47-8d51-6fe253bc9267,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-62460ce2-ea04-4e53-92b4-0d8e95a733bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-a92fbac5-9b3b-4019-9edf-36bc9677ca7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-76fab4da-2800-4e60-8681-1b9637f7b5da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255877706-172.17.0.11-1598393095724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33569,DS-5d32f693-988c-4dc1-bb8a-cff531e477f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-7d87783c-ddb4-49c1-b8d5-db573f5f6f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-e74e346d-3750-4128-a236-37370d7c40eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-5432efb2-f14a-4192-a031-a8657302c9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-b0ae0653-5889-4f47-8d51-6fe253bc9267,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-62460ce2-ea04-4e53-92b4-0d8e95a733bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-a92fbac5-9b3b-4019-9edf-36bc9677ca7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-76fab4da-2800-4e60-8681-1b9637f7b5da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143152351-172.17.0.11-1598393129911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34933,DS-e80bd5f7-5108-48ac-8ffa-d2024783eb84,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-878cc440-4573-4e6f-9b75-8e2f574132b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-39e780f6-5fa7-4ff5-8e3a-6a4bcab82e17,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-2533df96-6e90-43b6-8481-2db576b98d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-1f5cac21-4611-40d4-82cc-0e4d5bfd134f,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-d7d33214-8cdf-4fd3-8f07-e35cb4f18d21,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-65dc295a-023b-47c7-ae80-d59579a2b38d,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-061c5251-19b8-4a8a-8578-4ef2613c6c74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143152351-172.17.0.11-1598393129911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34933,DS-e80bd5f7-5108-48ac-8ffa-d2024783eb84,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-878cc440-4573-4e6f-9b75-8e2f574132b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-39e780f6-5fa7-4ff5-8e3a-6a4bcab82e17,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-2533df96-6e90-43b6-8481-2db576b98d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-1f5cac21-4611-40d4-82cc-0e4d5bfd134f,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-d7d33214-8cdf-4fd3-8f07-e35cb4f18d21,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-65dc295a-023b-47c7-ae80-d59579a2b38d,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-061c5251-19b8-4a8a-8578-4ef2613c6c74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485453934-172.17.0.11-1598393511192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34601,DS-0cdc8404-234b-49fe-889b-214806b1671d,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-1288474c-b331-442a-ae75-0da0080504e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-b41f33aa-de70-49da-a904-3a180f30468f,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-8c1bcabe-8767-486b-99ce-04f81bd29862,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-f3dd4219-edf0-4e86-be8f-99d6553df38b,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-86a74a8a-0ca4-44bb-8661-7e0c055e0092,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-547fe34e-1f3e-4d3a-87a8-a321e4bc8001,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-78979d0a-23ce-43a3-bcde-df02f71774f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485453934-172.17.0.11-1598393511192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34601,DS-0cdc8404-234b-49fe-889b-214806b1671d,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-1288474c-b331-442a-ae75-0da0080504e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-b41f33aa-de70-49da-a904-3a180f30468f,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-8c1bcabe-8767-486b-99ce-04f81bd29862,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-f3dd4219-edf0-4e86-be8f-99d6553df38b,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-86a74a8a-0ca4-44bb-8661-7e0c055e0092,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-547fe34e-1f3e-4d3a-87a8-a321e4bc8001,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-78979d0a-23ce-43a3-bcde-df02f71774f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101712247-172.17.0.11-1598393598376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35443,DS-11d8a4c7-2b36-41d8-acba-02299bbd1dba,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-819870cb-f0a2-4907-9e72-a7aa34797eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-aae56c62-28df-4160-b291-3bffb04a1826,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-f718f4d9-f94c-4f53-ba38-d5df8a7e7518,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-e7ae3777-2221-49e8-a095-18967285c08d,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-f3787484-b43f-48ea-bdfa-aa1888530ede,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-d38172a3-7034-4d2d-a551-3949782acfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-dc7e6a89-a829-4bb2-a645-705e82219555,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101712247-172.17.0.11-1598393598376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35443,DS-11d8a4c7-2b36-41d8-acba-02299bbd1dba,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-819870cb-f0a2-4907-9e72-a7aa34797eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-aae56c62-28df-4160-b291-3bffb04a1826,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-f718f4d9-f94c-4f53-ba38-d5df8a7e7518,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-e7ae3777-2221-49e8-a095-18967285c08d,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-f3787484-b43f-48ea-bdfa-aa1888530ede,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-d38172a3-7034-4d2d-a551-3949782acfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-dc7e6a89-a829-4bb2-a645-705e82219555,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094544740-172.17.0.11-1598393692191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37885,DS-fa4bcd46-fb06-414e-a75c-cc0def5f6ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-ed7a4f8a-5e5f-4b21-a819-a48bda40859e,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-e8e04683-93dc-40f0-9468-b08bab896980,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-77b5ba99-e54e-435c-8d68-ab4a74450351,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-0937cb4c-86c6-4185-8525-b191907cc049,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-782575b8-1bb4-4fe0-8c14-d8d4ce505f27,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-377361da-160f-413f-8c8d-27d4614ff7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-d1635888-fd1a-40bf-a5ab-6e72002dc66d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094544740-172.17.0.11-1598393692191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37885,DS-fa4bcd46-fb06-414e-a75c-cc0def5f6ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-ed7a4f8a-5e5f-4b21-a819-a48bda40859e,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-e8e04683-93dc-40f0-9468-b08bab896980,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-77b5ba99-e54e-435c-8d68-ab4a74450351,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-0937cb4c-86c6-4185-8525-b191907cc049,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-782575b8-1bb4-4fe0-8c14-d8d4ce505f27,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-377361da-160f-413f-8c8d-27d4614ff7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-d1635888-fd1a-40bf-a5ab-6e72002dc66d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926077599-172.17.0.11-1598393827000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41072,DS-8874d6b8-69a4-4419-8613-2b64d814a802,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-e2a920b5-4a42-447c-9696-0f49d651af12,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-7e11a0f6-536c-46ba-9a24-7eef30757542,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-7f375e76-1d0c-44ac-a2bb-1e615c026a63,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-ae292ee5-02ed-49ee-a474-68a36a166a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-acf812b4-90e2-45ba-9369-d7a413bbf5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-f5d86d05-bf86-49d8-97c4-ce334f8d21af,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-a0dd08e3-e7a5-4fb9-93fb-955e1847ca6a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926077599-172.17.0.11-1598393827000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41072,DS-8874d6b8-69a4-4419-8613-2b64d814a802,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-e2a920b5-4a42-447c-9696-0f49d651af12,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-7e11a0f6-536c-46ba-9a24-7eef30757542,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-7f375e76-1d0c-44ac-a2bb-1e615c026a63,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-ae292ee5-02ed-49ee-a474-68a36a166a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-acf812b4-90e2-45ba-9369-d7a413bbf5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-f5d86d05-bf86-49d8-97c4-ce334f8d21af,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-a0dd08e3-e7a5-4fb9-93fb-955e1847ca6a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121670223-172.17.0.11-1598394073635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42181,DS-71d140e3-a5d4-4379-9e57-1c68ad33b534,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-392dc34b-c12d-429c-8d68-da1bd1807982,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-89afe037-9e19-4e56-ac30-06c97a9d63c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-9480a5aa-5c27-4a90-a92d-16930872cb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-f2d6004d-2d97-4588-a393-1e4de5f3e58f,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-91189e28-854e-412d-9816-b9e882cca546,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-c023fff1-7930-4aed-b498-cc24f147cd11,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-894188a5-0666-448e-8aed-c44eb71fb254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121670223-172.17.0.11-1598394073635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42181,DS-71d140e3-a5d4-4379-9e57-1c68ad33b534,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-392dc34b-c12d-429c-8d68-da1bd1807982,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-89afe037-9e19-4e56-ac30-06c97a9d63c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-9480a5aa-5c27-4a90-a92d-16930872cb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-f2d6004d-2d97-4588-a393-1e4de5f3e58f,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-91189e28-854e-412d-9816-b9e882cca546,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-c023fff1-7930-4aed-b498-cc24f147cd11,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-894188a5-0666-448e-8aed-c44eb71fb254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817402310-172.17.0.11-1598394139946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43337,DS-4f61b3e0-a96a-40d9-8a54-48990da0afc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-fefbc242-e1e1-46c1-bf11-ae1688dbb7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-6947b0f8-a17a-4883-b23d-f6fcd9bffacb,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-e0b945af-56f7-4654-b2d1-02a4d7014788,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-18f3b9a7-59a7-49ca-a12a-45d0bd321963,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-cb56c2e8-ade4-45c4-b0da-51fa0bab1d89,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-51392229-8973-405d-a9fd-f4e935daf64a,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-6d2d4453-2688-4338-96c1-c42b3bd72d43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817402310-172.17.0.11-1598394139946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43337,DS-4f61b3e0-a96a-40d9-8a54-48990da0afc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-fefbc242-e1e1-46c1-bf11-ae1688dbb7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-6947b0f8-a17a-4883-b23d-f6fcd9bffacb,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-e0b945af-56f7-4654-b2d1-02a4d7014788,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-18f3b9a7-59a7-49ca-a12a-45d0bd321963,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-cb56c2e8-ade4-45c4-b0da-51fa0bab1d89,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-51392229-8973-405d-a9fd-f4e935daf64a,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-6d2d4453-2688-4338-96c1-c42b3bd72d43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334250035-172.17.0.11-1598394277734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43029,DS-a807a8fe-2895-409b-9ed4-07b36267dc15,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-3914df34-9835-42c0-92be-7784e4e808d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-ffdfaa0a-b091-4e61-b093-1f403a85518e,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-37c713ff-6eb0-4ec0-aa6f-ff0b71300926,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-9f37d5f7-a54a-4057-83d1-c6202a550535,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-d6163624-fe59-466e-9a33-e388b84e7ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-754ef876-e71c-431d-a244-f33659ca86b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-d9352936-8378-410b-b55c-875ebfff3c5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334250035-172.17.0.11-1598394277734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43029,DS-a807a8fe-2895-409b-9ed4-07b36267dc15,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-3914df34-9835-42c0-92be-7784e4e808d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-ffdfaa0a-b091-4e61-b093-1f403a85518e,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-37c713ff-6eb0-4ec0-aa6f-ff0b71300926,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-9f37d5f7-a54a-4057-83d1-c6202a550535,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-d6163624-fe59-466e-9a33-e388b84e7ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-754ef876-e71c-431d-a244-f33659ca86b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-d9352936-8378-410b-b55c-875ebfff3c5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799652289-172.17.0.11-1598394453434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39210,DS-84ab82b9-7b4f-4390-8edd-1d1f1ec2e0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-a6ede717-f3f9-4836-b792-b801905481db,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-35f05c30-af5f-47ed-83d2-a687e6d92f64,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-168bb06a-aa47-4ebd-83d4-446cda18d7db,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-29367b34-6ff6-4f6d-967c-36ccc70d1896,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-869fd09e-8778-4e1d-917a-6b39d179092a,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-7dd87197-9ca2-4a53-ac78-8b031f4a3fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-7ccc05f6-cd15-4a24-a762-6f1df06e1a43,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799652289-172.17.0.11-1598394453434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39210,DS-84ab82b9-7b4f-4390-8edd-1d1f1ec2e0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-a6ede717-f3f9-4836-b792-b801905481db,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-35f05c30-af5f-47ed-83d2-a687e6d92f64,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-168bb06a-aa47-4ebd-83d4-446cda18d7db,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-29367b34-6ff6-4f6d-967c-36ccc70d1896,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-869fd09e-8778-4e1d-917a-6b39d179092a,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-7dd87197-9ca2-4a53-ac78-8b031f4a3fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-7ccc05f6-cd15-4a24-a762-6f1df06e1a43,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213891137-172.17.0.11-1598394483985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39162,DS-813f1ccc-3780-4bbc-af81-efc500246e28,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-27b3c0a5-1931-4017-8f0c-b07f6abc87a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-15140d9e-fde5-4b0e-afa0-3c687313b23e,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-cbe99601-d8dd-4812-a9c8-bf58a9291945,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-03f34c2f-30d5-4481-928a-053d7c24f6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-a42e3ade-f783-45c1-b9e8-939c66688786,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-dd3c7f0c-bc9f-44e5-a0ff-2a0abf35aa8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-4ea6387e-53bf-4631-8382-88de4604d990,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213891137-172.17.0.11-1598394483985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39162,DS-813f1ccc-3780-4bbc-af81-efc500246e28,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-27b3c0a5-1931-4017-8f0c-b07f6abc87a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-15140d9e-fde5-4b0e-afa0-3c687313b23e,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-cbe99601-d8dd-4812-a9c8-bf58a9291945,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-03f34c2f-30d5-4481-928a-053d7c24f6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-a42e3ade-f783-45c1-b9e8-939c66688786,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-dd3c7f0c-bc9f-44e5-a0ff-2a0abf35aa8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-4ea6387e-53bf-4631-8382-88de4604d990,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148072991-172.17.0.11-1598394575115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38648,DS-80da2af9-2928-426f-bf77-a427b48060d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-f0dd9862-519d-4c9e-a696-7c82fa0de2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-4cff8fc4-8464-427f-bfc9-015d25f75976,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-ba6137df-45b1-4e1a-8daf-b53dfe6a4947,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-d039cb62-4c98-4031-9b50-a806fa672554,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-5b5165d7-0194-49a2-a9be-0c99b3083cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-9b0d3814-0b03-4c50-83e3-55b4d3263bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-f3f586c8-cd87-4cec-8a25-7beca27d1df4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148072991-172.17.0.11-1598394575115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38648,DS-80da2af9-2928-426f-bf77-a427b48060d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-f0dd9862-519d-4c9e-a696-7c82fa0de2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-4cff8fc4-8464-427f-bfc9-015d25f75976,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-ba6137df-45b1-4e1a-8daf-b53dfe6a4947,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-d039cb62-4c98-4031-9b50-a806fa672554,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-5b5165d7-0194-49a2-a9be-0c99b3083cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-9b0d3814-0b03-4c50-83e3-55b4d3263bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-f3f586c8-cd87-4cec-8a25-7beca27d1df4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56083101-172.17.0.11-1598394974816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33061,DS-8a447c46-dc9b-4078-9a68-fbb597fc628c,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-555430f7-7f1d-4e4c-a197-6df664da788c,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-85f98c18-f06b-4e52-ab9c-af48c1e3a042,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-87e73f16-4d8d-4ea6-a3e0-a076e89d59f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-f85851e4-6681-41f9-9271-a80c86dfd6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-3827dcbf-ad32-42f1-a209-e93fa76227d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-067d6155-d3ea-4fef-9839-011bef0c6f62,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-f5eef337-1755-475f-abe8-5e3f1dbf8cdb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56083101-172.17.0.11-1598394974816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33061,DS-8a447c46-dc9b-4078-9a68-fbb597fc628c,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-555430f7-7f1d-4e4c-a197-6df664da788c,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-85f98c18-f06b-4e52-ab9c-af48c1e3a042,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-87e73f16-4d8d-4ea6-a3e0-a076e89d59f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-f85851e4-6681-41f9-9271-a80c86dfd6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-3827dcbf-ad32-42f1-a209-e93fa76227d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-067d6155-d3ea-4fef-9839-011bef0c6f62,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-f5eef337-1755-475f-abe8-5e3f1dbf8cdb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892634417-172.17.0.11-1598395007154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45927,DS-14004c64-9e66-4df6-beb0-be0eec6c8119,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-b86341d7-b6d0-4e3f-881d-91e4d864c0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-a216fcaa-ef9b-4a84-b5d3-6996a526c1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-ac0feb55-f3e8-4bda-b19b-3efab4d6df11,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-bcbbd71d-bc30-47f1-998f-9fe3f1704443,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-57987974-84be-4e9f-9606-eaae696241b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-3c9be626-0d4e-4897-aa2d-f281a6f7b832,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-34632ca4-1910-44e1-896f-6eac8455f33f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892634417-172.17.0.11-1598395007154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45927,DS-14004c64-9e66-4df6-beb0-be0eec6c8119,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-b86341d7-b6d0-4e3f-881d-91e4d864c0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-a216fcaa-ef9b-4a84-b5d3-6996a526c1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-ac0feb55-f3e8-4bda-b19b-3efab4d6df11,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-bcbbd71d-bc30-47f1-998f-9fe3f1704443,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-57987974-84be-4e9f-9606-eaae696241b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-3c9be626-0d4e-4897-aa2d-f281a6f7b832,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-34632ca4-1910-44e1-896f-6eac8455f33f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913460043-172.17.0.11-1598395040478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44783,DS-ea96838e-5ab0-4415-93d5-fb1e4c0ae838,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-b77ab66b-7edb-41cb-9f5b-e37181853634,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-e7034186-8df1-4f01-9074-b48d1b8b7735,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-48f16721-775d-4fcc-af32-4bb679414a12,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-ed121e9c-4d2b-4b34-8971-09a22d4c7447,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-554b726b-d0e2-47ff-b05b-25adc221a735,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-b7ce7e20-3fd1-417c-9d6d-034029efeb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-7b9ec008-beaf-4891-9344-fc2b9ab9b275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913460043-172.17.0.11-1598395040478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44783,DS-ea96838e-5ab0-4415-93d5-fb1e4c0ae838,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-b77ab66b-7edb-41cb-9f5b-e37181853634,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-e7034186-8df1-4f01-9074-b48d1b8b7735,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-48f16721-775d-4fcc-af32-4bb679414a12,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-ed121e9c-4d2b-4b34-8971-09a22d4c7447,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-554b726b-d0e2-47ff-b05b-25adc221a735,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-b7ce7e20-3fd1-417c-9d6d-034029efeb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-7b9ec008-beaf-4891-9344-fc2b9ab9b275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214216443-172.17.0.11-1598395080808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34002,DS-ee6dafa7-1267-425b-be19-06a11338d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-7be524a5-f5ea-47f4-9cce-5798aca95928,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-c13e1489-b525-4210-8bd7-d88ee6f238fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-d2bf93af-5c10-475f-a5d5-589dd45b044e,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-104f77e5-4b2c-4e57-8567-f6ec616de32b,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-0f4e917f-24e8-4036-9c6f-fb50774cdffe,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-1a607016-8259-4739-993f-6c4ddd16abb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-c3b27932-1bc6-4e09-87e8-311ee2fbc9f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214216443-172.17.0.11-1598395080808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34002,DS-ee6dafa7-1267-425b-be19-06a11338d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-7be524a5-f5ea-47f4-9cce-5798aca95928,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-c13e1489-b525-4210-8bd7-d88ee6f238fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-d2bf93af-5c10-475f-a5d5-589dd45b044e,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-104f77e5-4b2c-4e57-8567-f6ec616de32b,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-0f4e917f-24e8-4036-9c6f-fb50774cdffe,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-1a607016-8259-4739-993f-6c4ddd16abb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-c3b27932-1bc6-4e09-87e8-311ee2fbc9f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667730368-172.17.0.11-1598395113455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45193,DS-0bfa8e93-f2b9-40e8-ba71-078cae76fe76,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-48bc5ce2-9f97-4162-b5dd-c566eed2479d,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-2f8d4d4e-4f75-44c4-b7f3-edc42482ca01,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-6f0575f6-4728-4aca-8f2f-7c019d8304a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-b62aff02-2215-4626-9d57-f8ba1e3666e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-466ca815-60aa-424f-89bc-84d2cae09874,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-30d23d97-9f89-49f3-9ba3-db3c9c5f7864,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-41aea253-ba48-4e7b-9bfe-03a766351404,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667730368-172.17.0.11-1598395113455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45193,DS-0bfa8e93-f2b9-40e8-ba71-078cae76fe76,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-48bc5ce2-9f97-4162-b5dd-c566eed2479d,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-2f8d4d4e-4f75-44c4-b7f3-edc42482ca01,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-6f0575f6-4728-4aca-8f2f-7c019d8304a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-b62aff02-2215-4626-9d57-f8ba1e3666e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-466ca815-60aa-424f-89bc-84d2cae09874,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-30d23d97-9f89-49f3-9ba3-db3c9c5f7864,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-41aea253-ba48-4e7b-9bfe-03a766351404,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872880196-172.17.0.11-1598395288512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38627,DS-80ad8929-bc09-4db2-bdc6-6433da9e2919,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-ea4a318b-cc56-43bb-83e0-797aad0cd131,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-af63d895-9527-4ef8-8091-83e1a5552711,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-14e642d3-cf24-48fd-b265-a63f0d1d1e12,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-490b72c6-d0cb-4138-b9de-836036bb81eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-c64e5c46-b30c-451d-8d82-4fb7e442a7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-35219565-bb43-4bc5-8667-103841db028c,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-76a6e219-5df0-4ea0-86d1-3199586bf238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872880196-172.17.0.11-1598395288512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38627,DS-80ad8929-bc09-4db2-bdc6-6433da9e2919,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-ea4a318b-cc56-43bb-83e0-797aad0cd131,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-af63d895-9527-4ef8-8091-83e1a5552711,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-14e642d3-cf24-48fd-b265-a63f0d1d1e12,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-490b72c6-d0cb-4138-b9de-836036bb81eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-c64e5c46-b30c-451d-8d82-4fb7e442a7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-35219565-bb43-4bc5-8667-103841db028c,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-76a6e219-5df0-4ea0-86d1-3199586bf238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715769931-172.17.0.11-1598395420785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44856,DS-0c4b451d-effe-4033-903a-0f79b4e2a1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-1e530386-bd16-469b-a6d8-471a00cdcab8,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-1545f226-6cff-44d6-8046-18bcbd13634d,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-64920c9c-4bb7-4984-a399-145e59c603d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-ae8a6833-d039-4489-a5d0-cf96399ec763,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-1b4660ff-1c21-4f9a-af85-980b921fe841,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-5b921445-ff01-4ebf-8216-b522fcda6ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-4480e764-b869-4739-a9c5-f91b5832fe86,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715769931-172.17.0.11-1598395420785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44856,DS-0c4b451d-effe-4033-903a-0f79b4e2a1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-1e530386-bd16-469b-a6d8-471a00cdcab8,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-1545f226-6cff-44d6-8046-18bcbd13634d,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-64920c9c-4bb7-4984-a399-145e59c603d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-ae8a6833-d039-4489-a5d0-cf96399ec763,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-1b4660ff-1c21-4f9a-af85-980b921fe841,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-5b921445-ff01-4ebf-8216-b522fcda6ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-4480e764-b869-4739-a9c5-f91b5832fe86,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154844263-172.17.0.11-1598395458358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36147,DS-2150effc-6939-4a53-8a85-b8654c001551,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-cda370f0-6ebe-4add-81fc-d35c7a05c37b,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-e2fdbdda-5e46-4f06-9f3d-18667bc65daf,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-23d27b51-1064-461b-ac46-7d2b9581987c,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-386bc1a4-9617-478f-8de6-9fec12811d95,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-b839cb15-3316-4821-8eca-804d497d98e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-bcbfb6d2-a999-4dd8-add6-45af1952059f,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-2adb2652-7a8a-496f-8082-1615c15909b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154844263-172.17.0.11-1598395458358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36147,DS-2150effc-6939-4a53-8a85-b8654c001551,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-cda370f0-6ebe-4add-81fc-d35c7a05c37b,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-e2fdbdda-5e46-4f06-9f3d-18667bc65daf,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-23d27b51-1064-461b-ac46-7d2b9581987c,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-386bc1a4-9617-478f-8de6-9fec12811d95,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-b839cb15-3316-4821-8eca-804d497d98e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-bcbfb6d2-a999-4dd8-add6-45af1952059f,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-2adb2652-7a8a-496f-8082-1615c15909b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912288274-172.17.0.11-1598395518981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37707,DS-c0a889f2-0fcf-4a9c-b37f-56b22143fc52,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-49bcc128-256d-463f-a73e-f5155b466744,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-96450344-f933-4d01-a4a2-190d84dbe362,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-3c02dbf7-9f9c-4538-8326-8fcd60777215,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-8acf9dfa-3216-4f92-b6e4-bf526bede581,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-d576c2d7-0332-47f2-97e7-733576922887,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-ffe84ad2-faf5-44c5-bb6b-9e16218776be,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-3e542260-1b14-475f-a4b3-8f50f25b7fb1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912288274-172.17.0.11-1598395518981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37707,DS-c0a889f2-0fcf-4a9c-b37f-56b22143fc52,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-49bcc128-256d-463f-a73e-f5155b466744,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-96450344-f933-4d01-a4a2-190d84dbe362,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-3c02dbf7-9f9c-4538-8326-8fcd60777215,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-8acf9dfa-3216-4f92-b6e4-bf526bede581,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-d576c2d7-0332-47f2-97e7-733576922887,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-ffe84ad2-faf5-44c5-bb6b-9e16218776be,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-3e542260-1b14-475f-a4b3-8f50f25b7fb1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315770651-172.17.0.11-1598395641871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39771,DS-1ed6a6b2-8fd4-448b-8fa9-70d10f5b2541,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-802e94b7-4f83-4583-82ea-f6b2a89900a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-fb7e595c-a65e-4231-8d09-8a59f03de672,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-c5efd9f1-5880-43d6-9c76-9723d2cb1c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-769c8695-4dc0-48b6-8976-147ba4aac420,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-802f4480-6433-4c91-a32c-cf61e0afc64b,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-4b4ad874-da0f-4558-8e11-f6e60857ec41,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-59115429-d235-40b4-a47b-ac6a2864b368,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315770651-172.17.0.11-1598395641871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39771,DS-1ed6a6b2-8fd4-448b-8fa9-70d10f5b2541,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-802e94b7-4f83-4583-82ea-f6b2a89900a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-fb7e595c-a65e-4231-8d09-8a59f03de672,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-c5efd9f1-5880-43d6-9c76-9723d2cb1c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-769c8695-4dc0-48b6-8976-147ba4aac420,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-802f4480-6433-4c91-a32c-cf61e0afc64b,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-4b4ad874-da0f-4558-8e11-f6e60857ec41,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-59115429-d235-40b4-a47b-ac6a2864b368,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745654207-172.17.0.11-1598395794228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39376,DS-47cc65d3-0e84-49b2-9ec6-d923c7677178,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-63718d93-c5da-4c3b-8554-ba7b40297326,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-ecd1dc65-53ce-421a-bb24-1b79dbee8906,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-f4a93cb0-7d7a-471b-a295-516654903ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-fd5ef1d8-ffc1-4dea-a489-849868ae1554,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-7c379b50-1a7c-4cfa-932c-f36192db0cce,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-1417a83e-5731-489c-9145-24fdc146d1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-c0723e90-4d72-45d0-9aa0-3ec15ddbbd73,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745654207-172.17.0.11-1598395794228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39376,DS-47cc65d3-0e84-49b2-9ec6-d923c7677178,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-63718d93-c5da-4c3b-8554-ba7b40297326,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-ecd1dc65-53ce-421a-bb24-1b79dbee8906,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-f4a93cb0-7d7a-471b-a295-516654903ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-fd5ef1d8-ffc1-4dea-a489-849868ae1554,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-7c379b50-1a7c-4cfa-932c-f36192db0cce,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-1417a83e-5731-489c-9145-24fdc146d1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-c0723e90-4d72-45d0-9aa0-3ec15ddbbd73,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1646458930-172.17.0.11-1598395831680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44683,DS-6070dcc0-2900-460a-87eb-2a00fdc61727,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-e86cd144-c086-4157-ad12-06e792abf1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-a3c5c582-71c0-4cfb-9c1b-12117c2e5ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-4d0219b9-b8ca-4edf-a9f1-92e98aa0605a,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-9f58154a-cd97-44d2-875b-a682a8368003,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-2ab0a4c8-52ae-4797-8f80-2b3900a11001,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-f23198e0-dc31-40d3-8ed1-7b3210ddd27d,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-85033ab3-2258-4946-927d-3e052f8acfd3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1646458930-172.17.0.11-1598395831680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44683,DS-6070dcc0-2900-460a-87eb-2a00fdc61727,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-e86cd144-c086-4157-ad12-06e792abf1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-a3c5c582-71c0-4cfb-9c1b-12117c2e5ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-4d0219b9-b8ca-4edf-a9f1-92e98aa0605a,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-9f58154a-cd97-44d2-875b-a682a8368003,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-2ab0a4c8-52ae-4797-8f80-2b3900a11001,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-f23198e0-dc31-40d3-8ed1-7b3210ddd27d,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-85033ab3-2258-4946-927d-3e052f8acfd3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226867689-172.17.0.11-1598395856001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42611,DS-c7410acd-df1a-4d27-bf47-98f66aa56c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-3747edf9-eb0b-4196-988c-5cc39c020450,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-bf34a5ad-0bd2-4d58-ab75-061880b6eb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-5e825bc4-2113-4e4d-8343-861c1ae71574,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-7c3ad020-6b48-4057-b1f7-2a0c5670224d,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-09ca706e-2b99-4864-b642-b5306062ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-71012c97-1b07-4f64-9a81-ad957026ad9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-162b2259-f49c-47d6-8679-f7994fc6aee0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226867689-172.17.0.11-1598395856001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42611,DS-c7410acd-df1a-4d27-bf47-98f66aa56c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-3747edf9-eb0b-4196-988c-5cc39c020450,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-bf34a5ad-0bd2-4d58-ab75-061880b6eb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-5e825bc4-2113-4e4d-8343-861c1ae71574,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-7c3ad020-6b48-4057-b1f7-2a0c5670224d,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-09ca706e-2b99-4864-b642-b5306062ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-71012c97-1b07-4f64-9a81-ad957026ad9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-162b2259-f49c-47d6-8679-f7994fc6aee0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417970667-172.17.0.11-1598396218269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38391,DS-445246de-7ad2-495d-b95b-b696520d4817,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-f3f0d920-6dcf-4bae-80f5-0096601a3655,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-7ee40646-0ebf-4aaf-a42b-7e6498275d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-232eb7fb-24c1-47b3-be56-941f8b5ec7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-49ec15be-d4b6-482d-97e9-a99cc6ed9bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-082a5b29-7df6-4bd5-8c8c-dbc7253ec02c,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-7b1ec6e4-0678-4aae-9c92-146161b38501,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-4424e0df-6ac7-4e86-9428-8d2321a5f5d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417970667-172.17.0.11-1598396218269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38391,DS-445246de-7ad2-495d-b95b-b696520d4817,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-f3f0d920-6dcf-4bae-80f5-0096601a3655,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-7ee40646-0ebf-4aaf-a42b-7e6498275d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-232eb7fb-24c1-47b3-be56-941f8b5ec7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-49ec15be-d4b6-482d-97e9-a99cc6ed9bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-082a5b29-7df6-4bd5-8c8c-dbc7253ec02c,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-7b1ec6e4-0678-4aae-9c92-146161b38501,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-4424e0df-6ac7-4e86-9428-8d2321a5f5d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786951032-172.17.0.11-1598396464494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38348,DS-1e0474bb-0ad3-46a0-bc9f-38292b21ddb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-d5f687f3-a224-4ad5-8282-440a00431be9,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-50c4eedb-f3da-4ecb-a4b2-2e38c33fa7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-8dff780b-6486-4ddb-86a4-978e10e44cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-d028d04c-03f5-464a-80e8-fd5bfa4cace8,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-52b1e95b-d257-42c6-acaf-38a697127636,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-f97e25be-179e-4d49-ae99-f2def9218308,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-7be1a522-fd6e-4b94-becc-1aa203a8e84d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786951032-172.17.0.11-1598396464494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38348,DS-1e0474bb-0ad3-46a0-bc9f-38292b21ddb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-d5f687f3-a224-4ad5-8282-440a00431be9,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-50c4eedb-f3da-4ecb-a4b2-2e38c33fa7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-8dff780b-6486-4ddb-86a4-978e10e44cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-d028d04c-03f5-464a-80e8-fd5bfa4cace8,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-52b1e95b-d257-42c6-acaf-38a697127636,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-f97e25be-179e-4d49-ae99-f2def9218308,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-7be1a522-fd6e-4b94-becc-1aa203a8e84d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036135005-172.17.0.11-1598396643283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40046,DS-12d9fcdc-ab5a-4532-bfba-0b18c24aba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-7856d807-020d-4e59-ad48-e30170b6bd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-51a61769-fdc4-4c63-aa47-0e89b7b853df,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-f2b4c39f-eba5-4ba6-acca-3ae484172ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-19f05a9d-dd3f-48f7-b419-8f52570ba396,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-3bbe056f-9767-49f0-89b8-8e234bf4aed4,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-e7cc07cd-ab76-4a94-a59a-1a95f0cbc087,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-8d9d29bd-3df6-4139-803e-c774990f37c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036135005-172.17.0.11-1598396643283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40046,DS-12d9fcdc-ab5a-4532-bfba-0b18c24aba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-7856d807-020d-4e59-ad48-e30170b6bd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-51a61769-fdc4-4c63-aa47-0e89b7b853df,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-f2b4c39f-eba5-4ba6-acca-3ae484172ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-19f05a9d-dd3f-48f7-b419-8f52570ba396,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-3bbe056f-9767-49f0-89b8-8e234bf4aed4,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-e7cc07cd-ab76-4a94-a59a-1a95f0cbc087,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-8d9d29bd-3df6-4139-803e-c774990f37c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484554751-172.17.0.11-1598396940690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42731,DS-489011e6-83c3-4aad-9495-09c3f8d95142,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-01caef21-76b9-4456-87c2-db03f749f85c,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-272f3f72-2f61-4b2f-bd8f-c114051eca28,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-2e341e04-e2fa-49b9-aa45-5e112cf1336c,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-ba878ff6-d409-4380-a7ef-339bea87cdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-10436235-5687-471a-991d-ad15952ba99c,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-952bf4ee-0de3-4d5d-b32b-6ce400e8523a,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-82b1f49f-7668-4f35-a919-4b95086f336a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484554751-172.17.0.11-1598396940690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42731,DS-489011e6-83c3-4aad-9495-09c3f8d95142,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-01caef21-76b9-4456-87c2-db03f749f85c,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-272f3f72-2f61-4b2f-bd8f-c114051eca28,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-2e341e04-e2fa-49b9-aa45-5e112cf1336c,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-ba878ff6-d409-4380-a7ef-339bea87cdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-10436235-5687-471a-991d-ad15952ba99c,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-952bf4ee-0de3-4d5d-b32b-6ce400e8523a,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-82b1f49f-7668-4f35-a919-4b95086f336a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 4932
